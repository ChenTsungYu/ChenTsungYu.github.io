# AWS Certified SysOps Administrator – Associate
###### tags: `AWS` `exam`
# Resource
A Cloud Guru
# Monitoring & Reporting
## Cloudwatch
![](https://i.imgur.com/cHicVsN.png)
用於監控其他 AWS 服務情況，如: 
- Compute:
    - Autoscalling group
    - ELB
    - Route53 Healthy Check
- Storage & Content Devivery:
    - EBS
    - Storage Gateway
    - Cloudfront
- Others:
    - Cloudwatch log
    - SQS
    - SNS
    - **Estimated Charges on AWS Bill**

### Cloudwatch 應用場域
不只限於 AWS Service，也**可用於地端 (On-premise)**![](https://i.imgur.com/4F4FWpI.jpg)
可透過安裝 SSM Agent or  Cloudwatch Agent 於目標機器中，蒐集相關得 metrics 後回傳至 Cloudwatch Dashboard
### Cloudwatch 儲存 Log 的時間多長？
![](https://i.imgur.com/5Ne2ncS.jpg)
Cloudwatch 預設會**無限制存放** log 資料，甚至仍**可提取被 Terminated 的 EC2 or ELB 的資料**

## EC2
監控 EC2 (Host Level) 的指標標含：
- **Default metrics:**
    - CPU: cpu utilization + credit usage
    - Network: network in + out
    - Disk: read/write for Ops/Bytes
    - Status Check:
        - instance status = check the ec2
        - system status = check the underlying hardware

**Default Time interval: 5 min**
**Ram** is not included in the aws ec2 metrics
- **Custom metrics:**
ec2 的 Metrics 相關範例:
    - ram usage
    - swap usage

### Metrics granularity (粒度) -> for ec2
- basic(normal) monitoring(default):
  metrics are collected at a **5 min** interval 
- detailed monitor(paid): 
  metrics are collectd at a **1 min** interval includes CPU, Network, Disk and Status Check Metrics; or your can set 3 mins or any amount less than 5 mins
- custom metric
basic resolution: minimum granularity is **1 min** 
high resolution: all the way to 1 second resolution
![](https://i.imgur.com/QWG1e7m.png)

### Cloudwatch Alarm
設置門檻值，可用於整合 EC2 CPU Utilizaion, ELB or Charges on AWS Billing 發布警報

## EBS
- an ebs volume is a network drive you can attach to your instances while the run 
- it allows your instances to **persist data**
- it's a **network drive** (not a physical drive)

#### EBS Type 
![](https://i.imgur.com/uBpbbeW.jpg)
![](https://i.imgur.com/IQdWp3L.jpg)
- General Purpose (SSD) - gp2: 
    - 低延遲
    - system boot volumes
    - 適合**開發、測試環境**
    - 最高上限為 **10,000 IOPS; 16GB**
- Provision IOPS (SSD) - io1
    - for critical business app
    - 可容許**大於 10,000 IOPS** or 160 MB/s of hhroughput of per volumn
    - 適用於 IOPS 較高的情況: 單位時間內系統能處理的I/O請求數量
    - 亦適用於高吞吐量(Throughput)的需求: 單位時間內傳輸的資料量
    - 適合**大規模工作量的資料庫(DB)**
    - 延伸閱讀：[儲存設計-IOPS](https://blog.xuite.net/attlee.ken/twblog/240772147-%E5%84%B2%E5%AD%98%E8%A8%AD%E8%A8%88-IOPS)
- Throughput Optimized (HDD) - st1
    - 適用於資料串流(straming)的場景: 資料是持續的
    - 適合**Big Data, Data warehouse, Log processing**
    - **Cannt be a boot volume**
    - 延伸閱讀： [Big Data Battle : Batch Processing vs Stream Processing](https://gowthamy.medium.com/big-data-battle-batch-processing-vs-stream-processing-5d94600d8103)
- Cold (HDD) -sc1
    - 以高吞吐量為主的儲存方案
    - **lowest storage cost**
    - **infrequently accessed**
    - **Cannt be a boot volume**

補充：
- HDD 類型的 EBS 無法提供皆 boot volume(You cannt boot OS from them)
- EBS is **no pre-warming (no require initializaion) needed**; [reference](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html)
- **storage blocks on volumes restored from snapshot (e.g. pull from S3 and written to volumns) must be initialize**

#### EBS Volumn Status check
- ok: normal
- **warning**: degrade, severely degrade
- **impaired**: stalled, Not available
- insufficient data: insufficient data

**Exam Tip:**

Know that Degraded or Severely Degraded = Warning
Stalled or Not Available = Impaired

#### Modified EBS Volumn
![](https://i.imgur.com/vRgHsBA.png)
![](https://i.imgur.com/XlUE6qP.png)

## ELB: Elastic Load Balancer 
Elastic Load Balancer Type
- Application
    - layer7
    - multiple http application across machines 
    - multiple applications on the same machine 
    - base on route in url
    - base on hostname in url
    - awesome for micro service and container-base application 
    - has port mapping feature to redirect to a dynamic port 
    - stickiness can be enabled at the target group level
        - same request goes to the same instance
        - stickiness is directly generated by the alb(not the applicaion)
- Network 
    - for ultra-high performace scenario
    - static ip address
    - be capable of handling millions of requests/sec
    - 
- Classic

### Monitoring type
- Cloudwatch metrics
     - data points to Amazon CloudWatch for load balancers
- Access log: 
    - capture detailed information about requests sent to your load balancer. You can use these access logs to analyze traffic patterns and troubleshoot issues
    - **disabled by default**
    - time interval: 5 mins, 60mins
    - Could be stored in S3
    - only pay for s3 storage
    - ogs are already encrypted
    - information include:
        - time
        - Client ip
        - latencies
        - request paths
        - server response
        - trace id
    - Important:
      ![](https://i.imgur.com/sDDroZ5.png)
- Request tracing:
  - To track HTTP requests from clients to target services
  - **only available for ALB**
  - add or update the X-Amzn-Trace-Id header
![](https://i.imgur.com/I9N4yBh.png)
- CloudTrail log:
  - capture the detail information about ELB API Call 
  - log file cloud be stored in S3
## Cloudwatch v.s. Cloudtrail
- Cloudwatch monitoring performance
    - number of request
    - CPU Utilization
    - Memory Utilization
- Cloudtrail monitoring API Call in AWS platform
    - Auditing things
    - Monitoring activities of users
## Elasticcache
### Consist of two engines
- Memcached
    - an in-memory **object store**
    - cache doesn't survive reboots
    - Can handle the loads up to 90% 
- Redis
    - in-memory **key-value store**
    - super low latency
    - **four core**: e.g. 90% CPU Utilization，the threshold for CPU Utilization would be 22.5
### Monitoring CPU Utilization type
- CPU Utilization
- Swap Usage
- Evictions
- Concurrent Connections 

### SwapUsage
![](https://i.imgur.com/3eJBqeH.png)
The Swap File (or Paging File) is **the amount of disk storage space reserved on disk** if your computer runs out of ram.
- (Typically) the size of swap file = the size of RAM
#### Memcached
- shloud be about 0 and not exceed 50Mb
- if Memcached exceed 50Mb, U should increase memcached_connections_overhead parameter
#### Redis
- **use reserved-memory, not SwapUsage**
### Evictions
![](https://i.imgur.com/SCoLS5c.png)![](https://i.imgur.com/HCtX0Sb.png)
#### Memcached
- There is **no recommended setting** ; Choose a threshold based off your application
- **Scale Up** (ie increase the memory of existing nodes) OR **Scale Out** (add more nodes)，兩者任一
#### Redis
- There is **no recommended setting** ; Choose a threshold based off your application
- only increase the memory of existing nodes) OR **Scale Out** (add more nodes)
### Concurrent Connections
- There is **no recommended setting**. Choose a threshold based off your application
- **Remember to set an alarm on the number of concurrent connections for elasticache**

## Organizations
- global service
- allows to centrally manage policies across multiple aws accounts
- the main account is the master account -- you can't change it other accounts are member accounts
- Control Access To AWS Services
- member accounts can **only be part of one organization**
- **consolidated billing across all accounts -- single payment method**
- pricing benefits from **aggregated usage**(volume discount for ec2, s3...)
- api is available to automate aws account creation and management

### Control Access To AWS Services
- could create Service Control Policies (SCPs) centrally control AWS service use across multiple AWS accounts
- could specifically **Allow or Deny individual AWS Services**
### OU & service control policies(SCPs)
![](https://i.imgur.com/LAXh8mk.png)
- organize accounts in organizational unit(OU)
    - can be anything: dev/test/prod or finance/hr/it 
    - can nest OU within OU
    - helpful to separate dev and pro resources 
    - helpful to only allow approved services
    - apply service control policies(scps)to ou
        - permit/deny access to aws services
        - scp has a similar syntax to iam
        - it's a filter to iam

## Resource Group
make it easy to group your resources using the tags that are assigned to them. You can group resources that share one or more
tags. -> 藉由標籤 (Tag) 替 Resource 做分組歸類，便於進行管理。標籤可以對共享一個或多個資源進行分組
![](https://i.imgur.com/a9u80cb.jpg)

### Resource groups 包含
1. Region
2. Name
3. Health Checks
#### Specific information
- For EC2 - Public & Private IP Addresses
- For ELB - Port Configurations
- For RDS - Database Engine etc

### Note
- Case Sensitive
- 可搭配 System Management 做自動化

## Cost Explore
A tool is enable to view and analyze the cost
- can view data for up to the **last 13 months**
- forecast how much will likely spent for the next three months
- get recommendations for what Reserved Instances (RI) to purchase
- Use tags to tag your resources.
- Configure tags for cost centres (such as by department, employee id etc).
- Activate cost allocation tags to track your costs by tags.

## EC2 Pricing Modal
### Reserved
- Applications with steady state or predictable usage (穩定且可預測的使用量) 
- Users able to make upfront payments to reduce their total computing costs even further (預先進行付款可享有更優惠的價格)
    - Standard RI’s： Up to **75% off** on demand
        - reservation period can 1 ~ 3 years
        - reserve a specific isntance type
        - pay upfront for waht you use with long-term ( > 1 year) commitment
    - Convertible RI’s： Up to **54% off** on demand) capability to change the attributes of the RI as long as the exchange results in the creation of Reserved Instances of equal or greater value
    - Scheduled RI’s： available to launch within the time windows you reserve. This option allows you to match your capacity reservation to a predictable recurring schedule that only requires a fraction of a day, a week, or a month(可在預定的時間範圍內啟動。可將容量保留與可預測的定期計劃，如該計劃僅需要一天，一周或一個月的一小部分)

### Spot
short workloads, for cheap, can lose instances. 
- Apps have flexible start&end times
- Apps are only feasible at very low compute prices (僅在非常低的計算價格下可行)
- Users with urgent computing needs for large amounts of additional capacity (需要大量的額外容量應付緊急需求的用戶)
- can get discount of up to **90%** compare to on demand
- **used for batch jobs, big data analysis, or workloads that are resilient to failures**
- not suitable for critical jobs or databases

### Dedicated Hosts (專用主機)
no other customers will share you hardware
- Useful for regulatory requirements that may not support multitenant virtualization.
- Great for licensing which does not support multi-tenancy or cloud deployments.
- Can be purchased On-Demand (hourly.)
- Can be purchased as a Reservation for up to 70% off the OnDemand price.

### 小結
- On Demand - allow you to **pay a fixed rate by the hour** (or by the second) with no commitment.
- Reserved - provide you with a capacity reservation, and offer a significant discount on the hourly charge for an instance.1 Year or 3 Year Terms
- Spot - enable you to bid whatever price you want for instance capacity, providing for even greater savings if your applications have flexible start and end times. (It might be shut down suddently)
- Dedicated Hosts - Physical EC2 server dedicated for your use. Dedicated Hosts can help you reduce costs by allowing you to use your existing server-bound software licenses

## AWS Config
[FAQs](https://aws.amazon.com/config/faq/?nc1=h_ls)
- enable **compliance auditing**, **security analysis**, **resource change tracking**
- discover existing AWS resources
- export a complete inventory of your AWS resources with all configuration details
- determine how a resource was configured at any point in time
- Configuration snapshots and logs config changes of AWS resources
- Automated compliance checking
- 可以透過 Amazon Simple Notification Service (SNS) 取得每個組態變更的通知
- can be aggregated across regions and accounts

### 相關術語
- Configuration History
Collection of config items for a resource
over time.
- Configuration Recorder
The configuration of Config that records
and stores config items.

### Recorder setup
- Logs config for account in region
- **Stores in S3**
- Notifies with SNS

### What can be seen in AWS Config:
- Resource Type
- Resource ID
- Compliance
- Timeline
- Configuration Details
- Relationships
- Changes
- CloudTrail Events

### Config Rules
1. Compliance Check：Periodic, Configuraion Snapshot Delivery
2. Managed Rule
3. Permissions needed for Config
![](https://i.imgur.com/IUHwx0L.jpg)
4. Restrict Access:
![](https://i.imgur.com/9YrLxIg.jpg)
5. Monitoring Config:
![](https://i.imgur.com/eAmNK4J.jpg)

## cloudtaych vs cloudtrail vs config
### cloudwatch
performance monitoring(metrics, cpu, network, etc...) & dashboards events & alerting
log aggregation & analysis
### cloudtrail
- record api calls made within your account by everyone 
- can define trails for specific resources
- global service
### config
- record configuration changes
- evaluate resources against compliance rules 
- get timeline of changes and compliance

## AWS Service Health Dashboard vs Personal Health Dashboard
### Service Health Dashboard
it basically shows the health of each AWS Service
![](https://i.imgur.com/cOixaR9.png)

### Personal Health Dashboard
it provides alerts and remediation guidance when AWS is experiencing events that may impact you.
![](https://i.imgur.com/I8mTrA3.png)

# Deployment & Provisioning
## Common reasons why EC2 instances may fail to launch
- **InstanceLimitExceeded error:**
reach the number of intstance u can launch in a region (default limit of the number of instance in a region is **20**)
- **InsufficientInstanceCapacity error:**
AWS does not currently have enough available On-Demand capacity to service your request
**sol:**
    - Wait a few minutes and try again
	- Request fewer instances
	- Select a different instance type
	- Try purchasing Reserved Instances instead
	- Submit a new request without specifying the Availability Zone
    
## EBS Volumes
- allows you to create storage volumes and attach them to your EC2 instances

### 2 different variants of SSD:
- gp2 - General Purpose - boot volumes
- io1- Provisioned IOPS - I/O intensive, NoSQL / relational databases, latency sensitive workloads

**IOPS (Input/Output Operations per second):** 
used to benchmark performance for SSD volumes

### Scenario: Hitting the IOPS Limit of your Volume
**Q:** 
What happens if your are using gp2 and your workload exceeds the IOPS limit of the gp2 volume you have provisioned?
**A:**
- You will start to get your I/O requests queuing
- Depending on your application’s sensitivity to IOPS and latency, you may see your application becoming slow

**Sol:**
two approaches to address hitting the IOPS limit:
1. For gp2, you can increase the size of your volume — but if your volume is already **5.2TB** or more, you will have already reached the **16,000 IOPS limit for gp2 volumes**
2. If you need more than 16,000 IOPS, you will need to **change your storage class to Provisioned IOPS**

## Bastion Hosts
def: a host located in your **Public subnet.**

- Allows you to connect to your EC2 instances using **SSH or RDP only**.
- You can log-in to the Bastion host over the internet, from your desktop.
- You then use the Bastion host to initiate an SSH / RDP session over the Private subnet to your EC2 instances in the Private subnet.
- This allows you to **safely administer your EC2 instances without exposing them to the internet** (Used to **securely connect to instances in a Private subnet**)

### Architecture
![](https://i.imgur.com/otzzvOX.png)
- Sys Admin team connect to the Bastion over the internet.
- The Bastion connects to your instances over the Private subnet.

## AWS Load Balancer
There are three type of Load Balancer
### Application Load Balancer
- Operating at OSI layer 7 (on Application layer) -> HTTP(s) 協定
- url based routing
- **does not support static ip**, but **has a fixed dns**
- ![](https://i.imgur.com/JtfhPJS.png)

### Network Load Balancer
- Operating at OSI layer 4 (on Transport layer) -> TCP/IP; UDP
- **super fast performance** (Use for extreme performance!)
- **most expensive**
- provide **static(or elastic) ip address**
- suitable for the application where latency is really important
- ![](https://i.imgur.com/6k3Rxft.png)

### Classic Load Balancer
legacy option (not recommend option)
### pre-warming
- elb scale gradually to traffic
- elb may fail in case of sudden(突然), spike(穿刺) of traffic (a sudden increase of traffic of this scale)
- ![](https://i.imgur.com/K3b6xxk.png)
- if you expect high traffic, open a support ticket with aws to pre-warm your elb:
    - duration (start and end dates) of traffic 
    - expected requests per second (expected requests rate)
    - Total size of request

### extra information
You don’t have to choose one or the other, you can get the benefit of both, by putting an ALB behind a NLB.
![](https://i.imgur.com/vHvNJUn.jpg)

### Load Balancer Error Messages
**Code:**
- **200**: success
- **4xx**: error from client side
    - **400**: Bad request e.g. header is malformed
    - **401**: Unauthorized -> user access denied
    - **403**: Forbidden -> request is blocked by WAF access control list
    - **460**: client closed connection -> client timeout period may be too short
    - **463**: x-forwarded-for header > **30 ip**
- **5xx**: error from server side 
    - **500**: internal server error -> e.g. error on the load balancer
    - **502**: Bad gateway -> e.g. application server closed the connection or sent back a malformed response
    - **503**: Service Unavailable -> no registered targets
    - **504**: Gateway timeout -> e.g. application is not responding - problem with your web server, application server or database.
    - **561**: Unauthorized -> received an error code from the ID provider when trying to authenticate a user

### common troubleshooting
- check security group
- check health checks
- sticky sessions may bring imbalance on the LB side
- for multi az, make sure cross zone balancer is enabled
- user internal lb for private applications that don't need a public access 
- enable deletion protection to prevent against accidental deletes

### Monitoring
all lb metrics are directly pushed to **cloudwatch metrics**
metrics are gather at **60 seconds intervals (default)**
#### General health
- **Backend Connection Error:** number of unsuccessful connections to backend instances
- **health host count / unhealthy host count:** number of healthy / unhealthy instances registered
- **HTTPCode_Backend_2XX,3XX,4XX,5XX**: number of HTTP response codes generated by the registered instances.

#### Performance Metric
- **Latency**: number of seconds taken for registered instance to **respond / connect**
- **RequestCount**: number of requests completed / connections made during the specified interval (1 or 5 mins)
- SurgeQueueLength - number of pending requests, max queue size is 1024, additional requests will be rejected **(Classic only)**
- SpilloverCount - number of requests rejected because the surge queue is full **(Classic only)**

### Summary
![](https://i.imgur.com/XF8mZPu.jpg)

## System Management 
a management tool which gives you **visibility and control over AWS infrastructure**
- Integrates with CloudWatch: provide dashboards to view e.g. operational data & detect problems
- Organize your inventory, grouping resources (resource groups) together by application or environment including **on-premises systems**
- Includes **Run Command** which **automates operational tasks across resources** — e.g. security patching, package installs.

### Run Command
- Allow to run **pre-defined commands** on one or more EC2 instances
- Stop, restart, terminate, re-size instance
- Attach / detach EBS volumes
- Create snapshots, backup DynamoDB tables
- Apply patches and updates
- Run an Ansible playbook
- Run a shell script
- integrated with aws config
- state manager: define and maintaining configuration of os and applications

### how ssm works
- install the ssm agent onto the system we control
- installed by default on amazon linux ami and some ubuntu
- if an isntance can't be controlled with ssm it's probably an issue with the ssm agent 
- make sure the ec2 isntance have a proper iam role to allow ssm actions

### ssm resource groups
- create, view or manage logical group of resources thanks to tags
- allows creation of logical groups of resources such as:
    - applications
    - different layers of an application stack 
    - production versus development stack
- regional service
- works with ec2, s3, synamoDB, lambda, etc...

### SSM Documents
- documents can be in **json or yaml**
- user define parameters
- user define actions
- main documents already exist in aws

## Placement Group
![](https://i.imgur.com/kwyPRi7.png)
**Advantage:**
Allow users to control how thier EC2 instances are deployed 
**scenario:**
sometimes you want control over the ec2 instance placement strategy
### Three types of Placement Group
![](https://i.imgur.com/V6RAhcm.png)
- Cluster: instances are all created in a single AZ -> **Low latency, high network throughput** ![](https://i.imgur.com/36gLmN5.png)
- Partition: instances are created **in a logical segment** call partition (can be **Multi-AZ**)
![](https://i.imgur.com/FK2Tx2B.png)
- Spread: spreads instances across underlying hardware(**max 7 instances per group per AZ**) -> **Max availability in order to minimize the impact**
![](https://i.imgur.com/hTzmgna.png)

# High Availability
## Elasticity v.s. Scalability
### Elasticity (horizontal)
Elasticity allows you to stretch out and retract back your infrastructure
- **based on your demand**
- **only pay for what you need**
- is used during a **short time period**. e.g. hours or days
### Scalability (vertical)
building out the infrastructure to **meet your demands long term** (e.g. weeks, days, months and years)
### Sample
![](https://i.imgur.com/IBKBFUk.png)
![](https://i.imgur.com/qYssZ3D.png)
### Tips
![](https://i.imgur.com/z62Kt5t.png)

# RDS
- A relation database service
- it's a managed db service for db use sql as a query language allow you create db in the cloud that are managed by aws e.g. postgresql, oracle mysql, mariadb, mssql, aurora

## RDS Multi-AZ Failover
**Multi-AZ:**
keeps a copy of your production database in a separate Availability Zone -> can recover from failure or disaster.
- sync replication (synchronous physical / logical replication to **keep data on the standby up-to-date with the primary**)
- one DNS name - automatic app failover to stanby
- increase availability
- failover in case of loss of az, loss of network, instance or storage failure
- database operations can resume quickly without administrative intervention (automatically)

![](https://i.imgur.com/Q4mIiuJ.jpg)

> Multi-AZ is **for Disaster Recovery only**
> Multi-AZ is **not a scalling solution**

### synchronous logical replication v.s. synchronous physical replication 
- synchronous logical replication -> **MS SQL Server**
- synchronous physical replication -> **MySQL, Oracle, and PostgreSQL**

### Multi-AZ Failover Advantages
- High availability
- Backups Restore’s are taken from secondary which avoids I/O suspension to the primary

![](https://i.imgur.com/AYNagA1.png)

### Tips
> **Read Replica’s are used to scale**
> 
> Amazon handles the failover for you. Done by
updating the **private DNS** for the database
endpoint. => Don't worry about change ip address

## RDS read replicas
Once the Read Replica is created, **database updates on the source DB Instance** will be
replicated using a supported engine's native, asynchronous replication. You can create multiple Read Replicas for a given source DB Instance and distribute your application’s read traffic amongst them

- allowed to **elastically scale out** beyond the capacity constraints of a single DB Instance for **read-heavy database workloads**.
- **Read only copies** of your database
- For **performance improvement**, you need **Read Replicas**
- up to **5 read replicas**
- **within az, cross az or cross region**
- replication is async, so read are eventually consistent

### When to use Read Replica's?
- Scaling beyond the compute or I/O capacity of a single DB Instance for read-heavy database workloads => I/O 讀寫的 loading 過大，需做 Scaling
- excess read traffic can be directed to one or more Read Replicas
- Serving read traffic while the source DB Instance is unavailable. If your source DB Instance cannot take I/O requests (e.g. due to I/O suspension for backups or scheduled maintenance) => direct read traffic to your Read Replica(s)
- **Business reporting or data warehousing** scenarios: business reporting queries to run against a Read Replica, rather than your primary, production DB Instance

### Supported Versions
- **MySQL, PostgreSQL, MariaDB:**
    - uses engines **native asynchronous replication** to update the read replica
- **Aurora:**
    - employes an **SSD-backed virtualized storage layer** purpose-built for database workloads
    - replicas share the same underlying storage as the source instance, lowering costs and avoiding the need to copy data to the replica nodes

### Creating Read Replicas
When creating a new Read Replica, AWS will **take a snapshot** of your database

- if Multi-AZ is **not enabled**:
This snapshot will be of your **primary database** and can **cause brief I/O suspension** (around 1 minute).
- If Multi-AZ is **enabled**:
The snapshot will be of your **secondary database** and you will **not experience any performance hits** on your primary database.

### Connecting to Read Replica
When a new read replica is created you will be able to **connect to it using a new end point** DNS address.

### Tips:
- **read replicas can be promoted** to its own db => this will break the replication link between the primary and the secondary
- **up to 5 read replicas** for MySQL, PostgreSQL & MariaDB
- read replicas can be in different regions for all engines
- Replication is **Asynchronous only**, not synchronous
- Read Replica’s **can be built off Multi-AZ’s databases**
- **Read Replica’s themselves can now be Multi-AZ**
- you can have **read replicas of read replicas** -> beware of latency
- read replicas can be used to run BI/analytics reports for exmaple
- each read replica **has its own dns endpoint**
- read replicas help scaling read traffic
- read replicas help with disaster recovery by using a cross region
- **DB Snapshots and Automated backups cannot be taken of read replicas**
- Key Metric to look for is **REPLICA LAG**
- Read Relica v.s. Multi-AZ

### Extra
- [Synchronous vs. Asynchronous Replication Strategies](https://www.nakivo.com/blog/synchronous-vs-asynchronous-replication-strategy/)

### Lab
須先對RDS 啟用 Automate Backup 才允許 Create read replica

## Encrypting RDS Instances
### Steps To Encrypt RDS Snaps
- Take a Snap of existing RDS instance
![](https://i.imgur.com/Kp2lIl9.png)
- Copy the snap to the same/different region
![](https://i.imgur.com/zGzlBAj.png)
- Encrypt the copy during the copy process.
![](https://i.imgur.com/MNlGcAf.png)
- Restore the snap
![](https://i.imgur.com/wPhbr1I.png)
- encryption at rest capability with **aws kms --aes 256**
![](https://i.imgur.com/ru3turd.png)
Encrypted by default and not allowed to be disble
![](https://i.imgur.com/olBpICl.png)

### How To Share Encrypted Snaps Between Accounts?
share DB snapshots that have been encrypted "at rest" using the AES-256 encryption algorithm.

**Step:**
- Create a **CUSTOM KMS Encryption key**.
- Create an RDS snapshot using the **custom key**.
- Share the CUSTOM AWS KMS encryption key that was used to encrypt the snapshot.
- Use the AWS Management Console, AWS CLI, or Amazon RDS API to share the encrypted snapshot with the other accounts.

**Restrictions:**
- can't share encrypted snapshots **as public**.
- can't share Oracle or Microsoft SQL Server snapshots that are encrypted using Transparent Data Encryption (TDE).
- can't share a snapshot that has been encrypted using the **default** AWS KMS encryption key of the AWS account that shared the snapshot

## DB parameter group
- you can configure the db engine using parameter groups 
- synamic parameters are apllied immediately
- static parameters are applied after instance reboot
- you can modify parameter group associated with a db 
- see doc for list of parameters for a db technology

## RDS backups vs snapshots
### backups
- backups are continuous and allow point in time recovery
- backups happen during maintenance widows
- when you delete a db instance, you can retain automated backups 
- backups have a retention period of you set between 0 and 35 dys
### snapshots
- snapshots takes **I/O operatoins** and can stop the dtabase from seconds to minutes 
- snapshots taken on multi-az db **don't impact the master** - just the standby 
- snapshots are incremental after the first snapshots
- you can copy & share db snapshots
- **manual snapshots don't expire**
- you can **take a final snapshot** when you delete your db

## Aurora
- Aurora is a proproetary tech from aws
- Aurora storage automatically grows in increment of 10GB, up to 64TB
- Aurora can have **15 read replicas** (storage autoscaling)
- **2 copies** of your data is contained **in each AZ**, with **minimum of 3 AZ**. **6 copies of your data** => **Redundancy**
- **Storage is self-healing**: Data blocks and disks are continuously scanned for errors and repaired automatically

### Aurora Cluster
![](https://i.imgur.com/eLlybZH.png)
### Type of Aurora Replica
- Aurora Read Replicas
- MySQL Read Replicas

### Issue: Aurora 100% CPU Utilization?
- Is it **Writes** causing the issue?    
A: Scale Up (increase **instance size**)
- Q: Is it **Reads** causing the issue?   
A: Scale Out (increase the **number of read replicas**).

### Aurora Serverless
- an on-demand, auto-scaling configuration for Aurora (MySQL-compatible edition) => automatically start-up, shut down, and scale up or down capacity based on your application's needs
- pay on a per-second basis for the database capacity you use
- Encryption at rest is **turned on by default**
- Once Encryption is turned on, **all read replicas will be encrypted**
- Choice of Migration (just a few clicks in the Amazon RDS Management Console): 
    - standard 
    - serverless configurations

### Aurora Lab
- **Multi-AZ** Deployment
![](https://i.imgur.com/Sq3zol0.png)
- **Role of writing and reading are in different zone**
![](https://i.imgur.com/qWMBneC.png)
- Create a reader -> Scenario: CPU achive 100%
![](https://i.imgur.com/sZp6bLK.png)

## Failover Control
AWS RDS Failover is defined by Tiers. The lower the tier **the higher the priority with Tier 0** being the highest priority available
![](https://i.imgur.com/iWnI4T7.png)
Tiers 0 > Tiers 1 > Tiers 2 > .... > Tiers 15

![](https://i.imgur.com/16yPW6J.png)

## Cross Region Replicas - Creating a new
cross region replica will also **create a new
Aurora cluster** in the target region. If the
replication is disrupted, you will have to set
up again. It is recommended that you
select **"Multi-AZ Deployment"** to ensure
high availability for the target cluster

## Extra
- DB **Cluster level** can't be deleted before  the node level of instances are deleted

## RDS vs Aurora
- **postgresql** and **mysql** are both supported as aurora db
- Aurora is AWS cloud optimized and claims 5x performance improvement over mysql over 3x of poestgresql
- **Aurora** can have **15 replicas** while **mysql has 5**
- Encryption of Aurora at rest is turned on by **default**; RDS for Mysql & PostgreSQL isn't

# Elasticache
- web service that makes it easy to deploy, operate, and scale an **in-memory cache** in the cloud
- significantly improve **latency and throughput** for many **read-heavy application** workloads (such as social networking, gaming, media sharing and Q&A portals)
- Caching improves application performance by **storing critical pieces of data in memory** for low-latency access. 
- Cached information may include the results of I/O-intensive database queries or the results of computationally-intensive calculations

## Type of Elasticache

### Memcached
- adopted memory object caching system
- ElastiCache is **protocol compliant** with Memcached

### Redis
- an open-source in-memory key-value store
- supports **Master / Slave replication** and **Multi-AZ** which can be used to achieve cross AZ redundancy.

## Tips
- Elasticache is a good choice if your database is particularly **read-heavy** and **not prone to frequent changing**.
- The important things for monitoring:
    - CPU Utilization
	- Swap Usage
	- Evictions
	- Concurrent Connections

> **Redshift** is a good answer if the reason your database is feeling stress is
because management keep running **OLAP transactions** on it etc.

# Cloudfront
- CDN Service
- system of distributed servers
## Key Terminolog
- Edge Location - This is the **location where content will be cached**. This is separate to an AWS Region/AZ.
- Origin - This is the origin of all the files that the CDN will distribute. This can be an S3 Bucket, an EC2 Instance, an Elastic Load Balancer, or Route53.
- Distribution - This is the name given the CDN which consists of a collection of Edge Locations.

## How Cloudfront work?
![](https://i.imgur.com/NrKgjgL.png)
Amazon CloudFront can be used to deliver your entire website, including dynamic, static, streaming, and interactive content using a
global network of edge locations. Requests for your content are automatically routed to the nearest edge location, so content is delivered with the best possible performance.

## Purpose of Cloudfront
- reduce the number of requests that the origin server must respond to directly.
- reduce the load of origin server
- reduce the latency (more object are server from Cloudfront edge loactions which are closer to users) 
![](https://i.imgur.com/5oTTnJ9.png)

## Cache Hit Ratios
The more requests that CloudFront is able to serve from edge locations, the better it works.

**The ratio of requests served from edge locations** (rather than the origin) is known as the cache hit ratio. 

> The more requests from edge locations, the **better the performance**

### How to maximise Cache Hit Ratios
#### Specifying How Long CloudFront Caches Your Objects: 
configure your origin to **add a Cache-Control max-age** directive to your objects, and **specify the longest practical value for max-age**

The **shorter the cache duration**, the more frequently CloudFront forwards another request to your origin to determine whether the object has changed and, if so, to get the latest version.
#### Caching Based on Query String Parameters
Query String Parameters examples:
- http://www.example.com?**id=a1**
- http://www.example.com?**id=A1**
- http://www.example.com?**Id=a1**
- http://www.example.com?**ID=a1**

the examples above would be calling to origin server **four difference times** -> The cases are different

Query String Parameter is **CASE SENSITIVE**. Ensure your application uses consistent variables.
#### Caching Based on Cookie Values
Create **separate cache behaviors for static and dynamic content**, and configure CloudFront to **forward cookies to origin** only for **dynamic content**.

**Example**

If you create a cache behavior for which the path pattern is `*.css` and for which CloudFront doesn't cache based on cookie values, then CloudFront forwards requests for `.css` files to your origin **only for the first request** that an edge location receives for a given `.css` file and for the first request after a `.css` file expires
#### Caching Based on Request Headers
If you configure CloudFront to cache based on request headers, you can improve caching if you Configure CloudFront to **forward and cache based on only specified headers** instead of forwarding and caching based on all headers.

Also try to **avoid caching based on request headers** that have **large numbers of unique values**.
![](https://i.imgur.com/6sBd5d9.png)
#### Remove Accept-Encoding Header When Compression is Not Needed
By default, when CloudFront receives a request, it checks the value of the Accept-Encoding header. If the value of the header contains gzip, then CloudFront adds the header and value **gzip— Accept-Encoding: gzip—to the cache key**, and then forwards it to the origin. 

This behaviour ensures that CloudFront serves either an object or a compressed version of the object, based on the value of the Accept-Encoding header. 

If compression is not enabled—because the origin doesn't support it, CloudFront doesn't support it, or the content is not compressible—you can increase the cache hit ratio by specifying different behaviour
#### Serving Media Content by Using HTTP
You can use CloudFront to deliver on-demand video or live streaming video using any HTTP origin. One way you can set up video workflows in the cloud is by using CloudFront together with AWS Media Services.

# Troubleshooting Autoscaling
## Instances not launching in to Autoscaling Groups
Below is a list of things to look for if your instances are not launching in to an autoscaling group:
- Associated Key Pair does not exist
- Security group does not exist
- Autoscaling config is not working correctly
- Autoscaling group not found
- Instance type specified is not supported in the AZ
- AZ is no longer supported
- Invalid EBS device mapping
- Autoscaling service is not enabled on your account
- Attempting to attach and EBS block device to an instance-store AMI

# Storage & Data management
## [S3](https://aws.amazon.com/s3/faqs/)
- an object (key-value) storage (for files, images, web pages)
- an unlimited storage
- Files are stored in Buckets (similar to a folder)
- Names must be unique globally -> S3 is a universal namespace
- **region leve**
- Amazon guarantee and built for **99.99%** availability for the S3 platform
- Tiered Storage Available
- Lifecycle Management
- Versioning
- Encryption
- Secure your data - Access Control Lists and Bucket Policies => 限制特定條件才能夠對 S3 存取

### [Storage Tiers/Classes](https://aws.amazon.com/s3/storage-classes/?nc1=h_ls)
![](https://i.imgur.com/kYAmxEh.png)
#### Standard: 
99.99% availability, 99.999999999% durability, stored redundantly **across multiple
devices in multiple facilities**, and is designed to sustain the loss of 2 facilities concurrently.
#### IA (Infrequently Accessed): 
For data that is **accessed less frequently**, but requires rapid access when needed. Lower fee than S3, but you are **charged a retrieval fee**.
#### One Zone IA: 
Same as IA however data is stored **in a single A-Ze only**, still 99.999999999% durability, but only 99.5% availability. Cost is **20% less than regular S3 - IA**.
#### Reduced Redundancy Storage: 
Designed to provide **99.99% durability** and **99.99% availability** of objects **over a given year**. Used for data that can be recreated if lost, e.g. thumbnails. (Starting to disappear from AWS documentation but may still feature in exam)
#### Glacier:
Very cheap, but used for archival only. Optimised for data that is **infrequently accessed** and it **takes 3 - 5 hours** to restore from Glacier

#### Intelligent Tiering
- the only cloud storage class
- be suitable for data Unknown (e.g. new applications) or unpredictable (e.g. data lakes) access patterns
- 2 tiers: frequent and infrequent access
- Automatically moves your data to most cost-effective tier based on how frequently you access each object
- 99.999999999% durability, 99.9 availability over a given year
- Optimizes cost
- **No fees for accessing data** but a small monthly **fee for monitoring / automation** $0.0025 per 1,000 objects

### Charge
- Storage **per GB**
- **Requests** (Get, Put, Copy, etc.)
- Storage Management Pricing
    - Inventory, Analytics, and Object Tags
- Data Management Pricing
    - Data transferred out of S3
- **Transfer Acceleration**
    - Use of CloudFront to optimize transfers

### S3 Lifecycle Policies
- used to ensure users are using the most cost effective option to store objects in S3
- based on **object creation date**
- S3 can transition your objects to Infrequently Accessed Storage or to Glacier based on the rules you configure
- can also set an expiry date for object you want S3 to delete after a certain time period has elapsed

### MFA Delete & S3 Versioning
#### S3 Versioning
- S3 Versioning enables users to revert to older versions of S3 objects.
- Multiple versions of an object are **stored in the same bucket**.
- Versioning also protects users from accidental / malicious deletes.
- With **versioning enabled**, a DELETE action doesn’t delete the object version, but **applies a delete marker** instead.
- To **permanently delete**, provide the **object Version ID** in the delete request

#### MFA Delete
- You will need a valid code from your MFA device in order to permanently delete an object version.
- MFA also needed to **suspend / reactivate versioning** on an S3 bucket

### S3 Encryption
- Encryption In-Transit
    - SSL/TLS (HTTPS)
- Encryption At Rest
    - Server Side Encryption
        - SSE-S3
        - SSE-KMS
        - SSE-C
    - Client Side Encryption

#### Enforcing Encryption on S3 Buckets

Every time a file is uploaded to S3, a **PUT request is initiated**

If the file is to be encrypted at upload time, the **x-amz-server-side-encryption**
parameter will be included in the request header.
![](https://i.imgur.com/AzNjQn0.png)

> If you want to enforce the use of encryption for your files stored in S3, use an **S3 Bucket Policy to deny all PUT requests** that **don’t include** the **x-amz-server-side encryption** parameter in the request header.

### Lab
![](https://i.imgur.com/hsGCsqZ.png)
- Eidt policy
![](https://i.imgur.com/0oUYNBQ.png)
- Conditional
![](https://i.imgur.com/A9xba0P.png)
- policy JSON
![](https://i.imgur.com/bxjWDgc.png)
- Fixed policy JSON with adding `/*` after Resource
![](https://i.imgur.com/f9Lk3pk.png)
- Server-side Encryption Settings
![](https://i.imgur.com/wWrzUiE.png)

## EBS Volumes v.s. Instance Store Volumes
### two types of volumes
#### Root Volume 
where your operating system is installed
- Root device volumes can either be **EBS volumes** or **Instance Store volumes**.
- An **Instance store** root device volume’s maximum size is **10Gb**.
- An **EBS** root device volume can be **up to 1 or 2Tb** (depending on the OS)
#### Additional Volumes
e.g. D:\ E:\ F:\ or /dev/sdb, /dev/
sdc, /dev/sdd

### Terminating an Instance - EBS
- EBS root device volumes are **terminated by DEFAULT** when the EC2 instance is terminated. You can stop this by **unselecting the "Delete on Termination"** option
![](https://i.imgur.com/04FwIGl.png)
- Other EBS volumes attached to the instance are preserved, however, if you delete the instance
### Terminating an Instance - Instance Store
- Instance store device root volumes are terminated by DEFAULT when the EC2 instance is terminated. **You cannot stop this**
![](https://i.imgur.com/cj1vsjz.png)
- Other **instance store** volumes will **be deleted on termination automatically**
- Other **EBS** volumes attached to the EC2 instance will **persist automatically**

### Stopping an Instance
- EBS-backed instances: **can be stopped**.
- Instance Store-backed instances: **CANNOT be stopped** (only rebooted or terminated)

### Instance Store Data
The data in an instance store **persists only during the lifetime** of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data on instance store volumes is **lost** under the following circumstances:
- Failure of an underlying drive
- Stopping an Amazon EBS-backed instance
- Terminating an instance

#### Note
Don't rely on instance store volumes for valuable, longterm data. Instead, **keep your data safe** by using a replication strategy across multiple instances, storing data in **S3**, or using **EBS volumes**

**Comparison**
![](https://i.imgur.com/eO5DCzi.png)

### Tips
![](https://i.imgur.com/wdG5pXF.jpg)

### Upgrading EC2 Volume Types
- EBS volumes can be changed on the fly(except for magnetic standard)
- Best practice to **stop the EC2 Instance** and then change the volume
- Users can change volume by **taking snapshot** and then **use snapshot to create a new volume**
- If a volume changes on the fly, users must wait for 6hr making another change
- Users can scale EBS volume up only
- Volumes must be in the same AZ as the EC2 Instance

## Encyption & Downtime
most AWS resources, encryption can only be enabled **at creation**
- **EFS (Elastic File System)**: If you want to encrypt an EFS filesystem already exists, you will need to create a new encrypted EFS and migrate your data.
- **RDS (Relational Database)**: If you want to encrypt an existing RDS, you will need to create a new encrypted database and migrate your data

### EBS Volumes
- **cannot encrypt an unencrypted volume** or **unencrypt an encrypted volume**
- can **migrate data** between **encrypted and unencrypted** volumes (e.g. use rsync or Robocopy)
#### How to encrypt an existing volume? (important)
create snapshot -> **copy the snapshot** and **apply encryption** at the same time to give you an encrypted snapshot -> restore the encrypted snapshot to new encrypted volume

### S3
- **S3 Buckets and Objects**: enable encryption on your S3 Buckets and Objects **at any time**.

### Tips
Remember that for the majority of services, you will need to enable encryption at creation time:
- EFS
- RDS
- EBS Volumes
- To add encryption later will involve migrating your data in some way: you may wish to stop your applications at this time.
- **S3 Buckets and Objects**: enable encryption on your S3 Buckets and Objects **at any time**.

## KMS & CloudHSM?
- Both allow users to **generate, store and manage cryptographic keys** used to protect data in AWS
- HSMs (Hardware Security Modules) are used to protect the confidentiality of your keys
- Both offer a high level of security

### KMS
- **Shared hardware**, multi-tenant managed service
- Suitable for applications for which multi-tenancy is not an issue
- **Free-tier eligible**
- **Encrypt data stored in AWS**, including EBS Volumes, S3, RDS, DynamoDB etc.

### Cloud HSM 
- physical device, user for e.g. financial payment systems
- Dedicated HSM (Hardware Security Module) instance, hardware is **not shared with other tenants no Free-Tier**
- HSM is under your **exclusive control within your own VPC**

### Tips
- Both KMS and CloudHSM enable you to generate, store and manage your own encryption keys to encrypt data stored in AWS
- KMS is **multi-tenancy** and good for use cases which **do not require dedicated hardware**
- If your application has a **requirement for dedicated hardware** for managing keys, **use CloudHSM**

## AMIs
- Template for the root volume: e.g. Operating System, Applications
- Launch permissions: defining which AWS accounts can use the AMI to launch instances
- **Block device mapping to specify EBS volumes** to attach to the instance at launch time

### AMIs Are `Regional`
- AMI are registered on a `per-region basis`

### Sharing AWS AMIs
- can keep it private
- share itwith a specified list of AWS accounts
- make it publicly available or even sell your AMI to other AWS users
- sharing account still has control and ownership of the AMI and **is still charged for storage of the AMI** within their AWS account

### Copying AMIs
- The owner of the source AMI must **grant read permissions** for the storage that backs the AMI (**EBS snapshot or S3**)
- If you copy an AMI that was shared with you, you are then the owner of the copy and will **be charged for storage of the target AMI** in the destination region

#### Limitations
- cannot directly copy an **encrypted AMI** shared by another account
    - **Copy the snapshot** & **re-encrypt using your own key**
    - The sharing account must also share with you the **underlying snapshot and encryption key** used to create the AMI
    - You’ ll own the copied snapshot and can register it as a new AMI
- **cannot directly copy** an AMI with an **associated billingProducts** code (applies to Windows, RedHat and AMIs from AWS Marketplace.)
    - billingProducts code is used to **bill for the use of an AMI** e.g. where a small fee is included to cover the Windows Server or SQL Server licence
- Launch an EC2 instance using the shared AMI and create an AMI from the instance

## Snowball
- a **physical device** used for transporting many **terabytes or petabytes** of data
- Tamper-resistant enclosure
- 256-bit encryption
- Region specific, not for transporting data from one region to another
- Connect the device to your **local network**.
- Snowball client **automatically encrypts and copies** the data

### When to Use ?
- have many TB or PB of data to upload
- don’t want to make expensive upgrades to your network for a one-off data transfer
- frequently experience backlogs of data
- in a **physically isolated environment**, **high-bandwidth internet isn't available** or is **cost-prohibitive**
- it **takes more than a week** to upload your data
## Snowball Edge
- **100TB** device, which also features onboard compute power which can be clustered to act as a **single storage and compute pool**
- undertake **local processing / edge computing**, as well as data transfer
- **S3-compatible endpoint**, supports **NFS**, and can also **run Lambda functions** as data is copied to the device.(**S3 buckets and Lambda functions** come pre-configured on the device)

## Snowball Vs Sowball Edge
- Snowball: **Data transfer only**.
- Snowball Edge: provides **Edge Computing** in addition **to data transfer**.
- Snowball: 
    - have 100s of TB to upload
    - data is taking a few days to upload
- Snowball Edge: 
    - **process the data locally** before returning the device to AWS.

## Storage Gateway
consists of an **on-premises software appliance** which connects with AWS cloud-based storage to give you a **seamless and secure integration** between **on-premises IT environment and AWS**.
![](https://i.imgur.com/zThGXXw.png)
- Storage Gateway Virtual Appliance is **installed in data center**
- Supports **VMware ESXi or Microsoft Hyper-V**
- On-premises systems seamlessly **integrate with AWS storage e.g. S3**

### Types of Storage Gateway
#### File Gateway - NFS / SMB
- Files stored **as objects** in S3 buckets
- Accessed using **NFS or SMB** mount point
- To your on-premises systems this appears like a file system mount backed by S3: **All the benefits of S3**: bucket policies, S3 versioning, lifecycle management, replication etc
- **Low-cost alternative** to **on-premises storage**
- ![](https://i.imgur.com/DMcmClX.png)

#### Volume Gateway (iSCSI)
- Stored Volumes
    - The gateway **stores all data locally**, so your applications **get low latency access** to the entire dataset
	- You need **your own storage infrastructure** as all data is **stored locally in your data center**
	- Volume Gateway provides **durable off-site async backups** in the form of **EBS snapshots** which are **stored in S3**
	- ![](https://i.imgur.com/PDnS6do.png)
- Cached Volumes
    - **stores all data in S3** and **caches only frequently accessed** data locally
	- You need **only enough local storage capacity to store** the frequently accessed data
	- Applications still **get low-latency** access to frequently used data **without a large investment in on-premises storage**
	- ![](https://i.imgur.com/1Kg9CY8.png)
#### Virtual Tape Gateway (VTL)
- provides cost effective data archiving in the cloud using **Glacier**
- **don’t need to invest** in your own tape backup infrastructure
- **can integrate with existing tape backup infrastructure**: e.g NetBackup, Backup Exec, Veeam etc. which connect to the VTL using iSCSI
- Data is **stored on virtual tapes** which are stored in Glacier and accessed using the VTL
- ![](https://i.imgur.com/YIHW3Vt.png)

### Tips
- File Gateway: 
    - Flat files（**as objects**） stored on S3, accessed using NFS or SMB
- Volume Gateway: 2 types
    - **Stored Volumes** - **Entire dataset stored on-site**, backed-up to S3 as **EBS Snapshots**
    - **Cached Volumes** - Entire dataset stored in S3, **only frequently accessed data cached on-site**
- Tape Gateway - VTL
    - Used for archiving your backups to **Glacier**
    - Can be used **with or without** your own backup application

## Athena
- an interactive query service: **analyse and query data** located in S3 using **standard SQL**
- **Serverless**: nothing to provision, **pay per query / per TB scanned**
- Works directly with **data stored S3**.

### Use Cases
- Can be used to **query log files stored in S3**, e.g. ELB logs, S3 access logs, etc.
- **Generate business reports** on data stored in S3
- Analyse AWS cost and Usage reports
- Run queries on click-stream data

## EFS
![](https://i.imgur.com/1ftAJCX.png)
- Managed NFS Filesystem (**Linux** systems Only; **FSx -> Windows**): Highly available, scalable shared filesystem
- Multiple EC2 Instances: Great for applications which need to access shared files. e.g. a shared configuration file or state information. You cannot do this with **EBS**. 
- Lifecycle Management: Files which have not been accessed recently get moved to EFS Infrequent Access
- Encryption: In transit and at rest. You must **enable it at creation**, you **cannot enable it later**.
    - Can **ONLY be enabled** at file system **creation**! If you decide to encrypt an EFS filesystem later on, you must **create a new, encrypted EFS filesystem and migrate your files**.

### Lab
- Create EFS
![](https://i.imgur.com/RINTBU5.png)
- Enable Lifecycle
![](https://i.imgur.com/g5SJRjy.png)
- Enable Encryption
![](https://i.imgur.com/5iHlDBU.png)

- Create
![](https://i.imgur.com/ULDYRPG.png)
- comfirm
![](https://i.imgur.com/bfv27Te.png)
![](https://i.imgur.com/KLTKOhu.png)
![](https://i.imgur.com/MwpPeSm.png)
- Click
![](https://i.imgur.com/6FkiRaU.png)
- Lanch the EC2 in the same VPC with EFS
![](https://i.imgur.com/xvIBnaf.png)
- Past the security group ID in inbound rule for target VPC
![](https://i.imgur.com/LXE1W1V.png)

# Security
## Compliance
### PCI DSS
The Payment Card Industry Data Security Standard **(PCI DSS)**
> a widely accepted set of policies and procedures intended to **optimize the security of credit, debit and cash card transactions** and protect cardholders against misuse of their personal information
#### Build and Maintain a Secure Network and Systems
- Requirement 1: Install and maintain a **firewall** configuration to protect cardholder data
- Requirement 2: **Don't use vendor-supplied defaults** for system passwords and other security parameters
#### Protect Cardholder Data
- Requirement 3: Protect stored cardholder data
- Requirement 4: Encrypt transmission of cardholder data across open, public networks

#### Maintain a Vulnerability Management Program
- Requirement 5: Protect all systems against malware and regularly update anti-virus software or programs
- Requirement 6: Develop and maintain secure systems and applications

#### Implement Strong Access Control Measures
- Requirement 7: Restrict access to cardholder data by business need to know
- Requirement 8: Identify and authenticate access to system components
- Requirement 9: Restrict physical access to cardholder data
#### Regularly Monitor and Test Networks
- Requirement 10: Track and monitor all access to network resources and cardholder data
- Requirement 11: Regularly test security systems and processes.
#### Maintain an Information Security Policy
- Requirement 12: Maintain a policy that addresses information security for all personnel.
### Other frameworks
- FIPS 140-2: a U.S. government computer security standard used to approve cryptographic modules. Rated from Level 1 to Level 4, with 4 being the highest security. **Cloud HSM** meets the **level 3 standard**
## DDoS
**def:**
an attack that attempts to **make your website or application unavailable to your end users**.

This can be achieved by:
- multiple mechanisms, such as large packet floods
- using a combination of reflection and amplification techniques
- using large botnets.

[whitepapers](https://d1.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf)
![](https://i.imgur.com/ZQic6wO.png)

- DDoS attacks are most common at **layers 3, 4, 6, and 7** of the Open Systems
![](https://i.imgur.com/nWlOBMp.png)
![](https://i.imgur.com/akpBWAS.png)

### How To Mitigate DDoS?
- Minimize the Attack Surface Area
- Be Ready to Scale to Absorb the Attack
- Safeguard Exposed Resources
- Learn Normal Behavior
- Create a Plan for Attacks

### AWS Shield
- **Free service** that protects all AWS customers on ELB, CloudFront and Route 53
- Protects against **SYN/UDP Floods**, Reflection attacks, and other **layer 3 / layer 4 attacks.**
- **Turned on by default**
### the technologies you can use to mitigate a DDoS attack:
- CloudFront
- Route53
- ELB’s
- WAFs
- Autoscaling (Use for both WAFs and Web Servers)
- CloudWatch
## Security Token Service(STS)
**Grants users limited and temporary access to AWS resources**. 

Users can come from three sources:
- Federation (typically Active Directory)
	- **Uses** Security Assertion Markup Language (**SAML**)
	- Grants temporary access based off the **users Active Directory credentials**. Doesn't need to be a user in IAM
- **Single sign on(SSO)** allows users to log in to AWS console without assigning IAM credentials
- Federation with Mobile Apps
    - Use Facebook/Amazon/Google or other OpenID providers to log in.
- **Cross Account** Access
    - Let’s users from one AWS account access resources in another

### Key term
- **Federation**: combining or joining a list of users in one domain (such as IAM) with a list of users in another domain (such as Active Directory, Facebook etc)
- **Identity Broker**: a service that allows you to take an identity from point A and join it (federate it) to point B
- **Identity Store**: Services like Active Directory, Facebook, Google etc
- **Identities**: a user of a service like Facebook etc.
### Scenario
![](https://i.imgur.com/MxomaZy.png)

![](https://i.imgur.com/phYnM64.png)
#### Steps
1. Employee enters their username and password
2. The application calls an Identity Broker. The broker captures the username and password
3. The Identity Broker uses the organization’s LDAP directory to validate the employee’s identity
4. The Identity Broker calls the new GetFederationToken function using IAM credentials. The call must include an IAM policy and a duration (1 to 36 hours), along with a policy that specifies the permissions to be granted to the temporary security credentials
5. The Security Token Service confirms that the policy of the IAM user making the call to GetFederationToken gives permission to create new tokens and then returns four values to the application: An access key, a secret access key, a token, and a duration (the token’s lifetime)
6. The Identity Broker returns the temporary security credentials to the reporting application.
7. The data storage application uses the temporary security credentials (including the token) to make requests to Amazon S3.
8. Amazon S3 uses IAM to verify that the credentials allow the requested operation on the given S3 bucket and key
9. IAM provides S3 with the go-ahead to perform the requested operation.
## Logging
Services:
- AWS CloudTrail
- AWS Config
- AWS CloudWatch Logs
- VPC Flow Logs

Resource: [Security at Scale: Logging in AWS](https://d0.awsstatic.com/whitepapers/compliance/AWS_Security_at_Scale_Logging_in_AWS_Whitepaper.pdf)
### Control Access to Log Files
#### Prevent unauthorized access:
- IAM users, groups, roles and polices
- Amazon S3 bucket policies
- Multi Factor Authentication 
#### Ensure role-based access:
- IAM users, groups, roles and polices
- Amazon S3 bucket policies
### Obtain Alerts on Log File Creation and Misconfiguration 
#### Alerts when logs are created or fail:
- CloudTrail notifications
- AWS Config Rules
#### Alerts are specific, but don't divulge detail
- CloudTrail SNS notifications only point to log file location.
### Manage Changes to AWS Resources and Log Files
#### Log changes to system components:
- AWS Config Rules
- CloudTrail
#### Controls exist to prevent modifications to logs:
- IAM and S3 controls and policies
- CloudTrail log file validation
- CloudTrail log file encryption

### CloudWatch vs CloudTrail vs Config?
- CloudWatch monitors performance.
- CloudTrail monitors API calls in the AWS platform.
- AWS Config records the state of your AWS environment and can notify you of changes.

## WAF
- a web application **firewall**
- **monitor** the **HTTP/HTTPS requests** that are forwarded to 
    - **CloudFront**
    - **ALB**
    - **API Gateway**
- control access to your content
    - can configure conditions:
        - what **IP addresses** are allowed to make this request
        - what **query string** parameters need to be passed for the request to be allowed
        - ALB or CloudFront will either allow this content to be received or to give A HTTP **403** Status Code
        - Country that requests originate from
        - Values in request headers.
		- Strings that appear in requests, either specific strings or string that match regular expression (regex) patterns.
		- Length of requests.
		- Presence of SQL code that is likely to be malicious (or SQL injection).
		- Presence of a script that is likely to be malicious (cross-site scripting).

### (Basic level) allows 3 different behaviours
- **Allow** all requests except the ones that you specify
- **Block** all requests except the ones that you specify
- **Count** the requests that match the properties that you specify


### Which Services Does It integrate with?
- Application Load Balancers
- CloudFront
- API Gateway
#### It DOES NOT integrate with:
- Classic Load Balancers
- Network Load Balancers

## Hypervisors, Isolation of AWS Resources and AWS Firewalls
computer software, firmware or hardware that creates and runs virtual machines
### Tips
- Choose **HVM** over PV where possible
- PV is isolated by **layers**, Guest OS sits on Layer 1, Applications Layer 3
- Only AWS Adminstrators have access to hypervisors
- AWS staff don't have access to EC2, that is your responsibility as a customer.
- All storage memory and RAM memory is **scrubbed** before it’s delivered to you

## EC2 Dedicated Instances vs Dedicated Hosts
### Dedicated Instances
- EC2 instances that run in a **VPC on hardware**
- **physically isolated** at the **host hardware level** from instances that belong to other AWS accounts
- **share hardware with** other instances from the **same AWS account** that are **not Dedicated instances**.
- Pay for **On-Demand**
- save up to **70%** by purchasing **Reserved Instances(RI)**
- save up to **90%** by purchasing Spot Instances
- In EC2 console
![](https://i.imgur.com/WeQ4B1R.png)
### Dedicated Hosts

### Dedicated Instances vs Dedicated Hosts
![](https://i.imgur.com/m8wKgWz.png)
- **Both** dedicated instances and dedicated hosts **have dedicated hardware**
- Dedicated instances are charged by the instance, dedicated hosts are charged by the host.
- If you have **specific regulatory requirements or licensing conditions**, choose **dedicated hosts**.
- Dedicated instances may share the same hardware with other AWS instances from the same account that are not dedicated.
- Dedicated hosts give you much better visibility into things like sockets, cores and host id.

### Systems Manager
#### Run Command
- Commands can be applied to a group of systems based on AWS instance tags or by selecting manually
- SSM agent needs to be installed on all your managed instances
- The commands and parameters are defined in a Systems Manager Document
- Commands can be issued using AWS Console, AWS CLI, AWS Tools for Windows PowerShell, Systems Manager API or Amazon SDKs
- You can use this service with your on-premise systems as well as EC2 instances

#### Parameter Store
- can store values as plain text or you can encrypt the data
- can store sensitive data(e.g. key, password)![](https://i.imgur.com/iBzhSwN.png)![](https://i.imgur.com/PIa54iq.png)
- Confidential information such as passwords, database connection strings, and license codes can be stored in SSM Parameter Store
- access parameters accross services(e.g. EC2, CloudFormation, Lambda, EC2 Run Command )