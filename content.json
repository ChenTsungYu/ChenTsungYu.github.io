{"pages":[{"title":"標籤","text":"","link":"tags/index.html"},{"title":"所有文章","text":"","link":"all-archives/index.html"},{"title":"分類","text":"","link":"categories/index.html"},{"title":"","text":"Hi there 👋 You are now reaching Tom’s profile. 🤓🚀 A Software Engineer.🌱 Python 🐍 , JavaScript, AWS, K8s🔭 Backend, DevOps Connect with me 📬","link":"about/index.html"}],"posts":[{"title":"[Postgres] 資料庫的索引(Index)","text":"前言上一篇記錄了資料庫儲存資料的概念與其儲存結構，本文將初步探討資料庫裡的索引(Index)，了解 Index 的作用、行為以及實際操作方式。 本篇主要筆記 Udemy - SQL and PostgreSQL: The Complete Developer’s Guide 及 Udemy - Fundamentals of Database Engineering 的課程內容，但以自己較易理解的方式加以整理，可能和原課程內容有些出入。 資料庫未使用 Index 的情況下，會採讀取整張表的方式來找出目標資料，這種搜尋方式作 Full Table Scan。 Full Table ScanFull Table Scan 中文翻作全表掃描，又作 Sequential Scan，按順序讀取整張資料表，搜尋效率最差，過程中涉及多次 I/O 讀取 Heap Table File 裡的 page。 試想一下，若要在厚厚的一本書(資料表)裡找出某個文字段落(某筆資料)，在沒有目錄的幫助下，肯定是一頁一頁找，得花上不少時間，資料庫也是同等道理。 因此我們需要找方法來提升查詢效率，其中一個方式就是 Index。 什麼是 Index? Index 就類似於一本書(資料表)的目錄，我們能根據目錄快速地找到想要的內容所在位置。 Index 一般來說都採用 B-Tree 的資料結構，也是最常見的 Index 類型，除了 B-Tree 外還有其他類型，本篇主要聚焦在 B-Tree，index 裡除了被設置為 index 欄位的值外，會有個 row pointer (指針) 指向該 row 位於 Heap Table File 的位置，讓資料庫能有效地根據 pointer 參照的位置取得資料，藉此改善查詢效率。 透過 Index 查詢的流程如下圖所示： 執行 SQL SELECT 時查找使用者名為 Tom 的資訊，若 Index 裡找出 Tom 這個人，取得 Tom 在 Heap Table File 的位置為 Block 1，資料庫會直接到 Heap File 的 Block 1 裡取出 Tom 的資料，而非從第一個 block 開始搜尋，過程中會經歷兩次 I/O (兩次 I/O 的過程可以參考前一篇討論)。 什麼是 B-Tree?B-Tree 是一種常用於外部存儲的資料結構，適用於讀&amp;寫資料區塊相對大的儲存系統，結構為 m-way 的自平衡搜尋樹，B 即 Balance 的意思，存放 有序 的資料，樹的節點 (node) 裡有儲存鍵值對(key-value pair)的元素(element)，分別存 index 的位置與該筆資料於 Heap File 的位置，父層節點會透過 pointer 指向子節點 。 常見應用：資料庫、文件系統 幾個重要名詞:Degree: 分支度，一個 node 擁有子樹的個數Root Node: 樹的最上層Internal Node: 至少有一個子節點Leaf Node: 沒有子樹 B-Tree 幾項重要特性 根節點 (Root Node) 至少有兩個子節點(Child Node) 可以為空 所有的 Leaf Node 都在同一階層 除了 Root Node、Leaf Node 外，其他節點至少會有個子節點，最多有 m 個 同個節點裡的 key 是升冪排列 B-Tree的高度: 不包含 Leaf Node 的階層數 B-Tree的高度和磁碟存取時的 I/O 次數有正相關，影響走訪(traversal)整棵樹的時間複雜度 B-tree 是如何幫助資料庫搜尋?設置 index 時，會指定哪個欄位作為 index 的資料，資料庫會將 Heap Table File 裡該欄位的值及對應的位置。 下圖以 user name 作為 index 的範例： index 的內容包含了 user name (e.g. Alf)、該筆資料於 heap file 的位置(e.g. block 0)，並以字母為依據進行排序，排序好 index 值後會被放入樹狀的資料結構裡，樹的葉節點存放一個個鍵值(key-value)的元素，而 root node 會定義好一些規則判別要到哪個葉節點取資料。 上圖範例是找出 Riann 這個 user name，資料庫進行 index 搜尋時找出右方葉節點裡的 Riann，並藉由 pointer 得知 Riann 位於 Heap File 的 block 1，就直接從 block 1 裡找資料，而不會從 block 0 開始找，加快搜尋的時間。 Index 存放於 Disk &amp; Memory 的示意圖Disk 裡 Index 會包含 Heap File 的 meta data、根節點、葉節點的資料等 Clustered Index v.s. Non-clustered IndexClustered Index 是根據資料在儲存空間上的排序而建立，而 Non-clustered Index 不一定要按照實體資料的排序而建立。 Clustered Index中文作 叢集索引 ，概念類似書(比喻作資料表)的目錄，用於快速查找書的內容，而每本書會有一個目錄，所以每張資料表只會有一個 Clustered index。 事實上，Clustered Index 的機制在不同的關連式資料庫有不同的實作方式，如: SQL Server裡預設會將 Primary Key (主鍵) 作為 Clustered Index。 以下引用自 MS SQL server 文件： CLUSTERED | NONCLUSTEREDIndicate that a clustered or a nonclustered index is created for the PRIMARY KEY or UNIQUE constraint. PRIMARY KEY constraints default to CLUSTERED, and UNIQUE constraints default to NONCLUSTERED. 而 Clustered Index 在 PostgreSQL 裡有別於 SQL server，需透過 CLUSTER 的指令來完成 Clustered Index。 具體實現機制參考 Stack Overflow - About clustered index in postgres相關討論。 Non-clustered Index中文作 非叢集索引，概念類似書(比喻作資料表)的附錄，每本書可以有多個附錄，每張資料表能有多個 Non-clustered Index。 比較有無 index 差異先建立 1 百萬筆測試資料 123456789101112131415161718192021create table employees( id serial primary key, name text); create or replace function random_string(length integer) returns text as $$ declare chars text[] := '{0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z}'; result text := ''; i integer := 0; length2 integer := (select trunc(random() * length + 1)); begin if length2 &lt; 0 then raise exception 'Given length cannot be less than 0'; end if; for i in 1..length2 loop result := result || chars[1+random()*(array_length(chars, 1)-1)]; end loop; return result; end; $$ language plpgsql; insert into employees(name)(select random_string(10) from generate_series(0, 1000000)); 查看資料表 12345678postgres-# \\d employees; Table &quot;public.employees&quot;Column | Type | Collation | Nullable | Default--------+---------+-----------+----------+---------------------------------------id | integer | | not null | nextval('employees_id_seq'::regclass)name | text | | |Indexes: &quot;employees_pkey&quot; PRIMARY KEY, btree (id) 注意:PostgreSQL 裡，每個 primary key 預設都會另外建一個 btree 類型的 index 查詢 employees 表裡的 id = 2000 的 id 值， 並透過查詢計劃 explain analyze 語句來分析查詢效能 1explain analyze SELECT id FROM employees WHERE id = 2000; 查詢結果 12345678QUERY PLAN------------------------------------------------------------------------------------------------------------------------------- Index Only Scan using employees_pkey on employees (cost=0.42..4.44 rows=1 width=4) (actual time=0.058..0.062 rows=1 loops=1) Index Cond: (id = 2000) Heap Fetches: 0 Planning Time: 0.201 ms Execution Time: 0.113 ms(5 rows) 結果裡可以看到有命中預設的 index，查詢速度變非常快。 Heap Fetches: 0 ：不需要存取 Heap Table File 的資料，直接存取 index 就可以拿到資料，因為查詢語句指定的欄位只有 id 而已，而 id 在 Postgres 裡有預設建立好的 index，故不需從 Heap Table File 找對應的值。 Postgres 預設會在每張表的主鍵(Primary Key)或被設唯一限制(UNIQUE Constraint)的欄位自動建立 index 。 Source: PostgreSQL Docs PostgreSQL automatically creates a unique index when a unique constraint or primary key is defined for a table. The index covers the columns that make up the primary key or unique constraint (a multicolumn index, if appropriate), and is the mechanism that enforces the constraint. 把 select 出來的欄位改成非預設建立 index 欄位 - name ： 12345678postgres=# explain analyze SELECT name FROM employees WHERE id = 937481; QUERY PLAN-------------------------------------------------------------------------------------------------------------------------- Index Scan using employees_pkey on employees (cost=0.42..8.44 rows=1 width=6) (actual time=0.219..0.225 rows=1 loops=1) Index Cond: (id = 937481) Planning Time: 0.323 ms Execution Time: 0.306 ms(4 rows) name 欄位未被設為 index，會存放於 disk 裡的 heap table，故資料庫要先去 heap table 拿對應的資料，所以多一段花費時間。 Tips:執行重複的查詢會發現花費時間會縮短，原因是資料庫本身的快取(Cache) 機制 若把 WHERE 條件改成 name： 123456789101112postgres=# explain analyze SELECT id FROM employees WHERE name = 'Zs'; QUERY PLAN------------------------------------------------------------------------------------------------------------------------- Gather (cost=1000.00..11310.94 rows=6 width=6) (actual time=179.857..333.772 rows=21 loops=1) Workers Planned: 2 Workers Launched: 2 -&gt; Parallel Seq Scan on employees (cost=0.00..10310.34 rows=2 width=6) (actual time=14.909..147.673 rows=7 loops=3) Filter: (name = 'Zs'::text) Rows Removed by Filter: 333327 Planning Time: 0.944 ms Execution Time: 334.032 ms(8 rows) 在沒有命中 index 的查詢下，Postgres Planner 會採 Seq Scan (Sequential Scan) 的方式搜尋整張資料表(full table scan)，花費時間為 334.032 ms ，較先前查詢費時許多，從結果可觀察到有沒有命中 index 在資料量大的狀況下會顯著地影響查詢效能。 建立 Index 的缺點雖然 index 有助於提升搜尋效能，但也有其缺點，如：Index 會佔用資料庫的空間，是以空間來換取時間，且每次在表中新增、修改或刪除時，都必須更動該表上的所有 Index，Index 建越多，資料庫需要執行的工作就越多，花額外成本來維護 Index，最終導致效能降低，應謹慎評估使用 Index。 Index 雖有助於提高 查詢(SELECT) 速度，但會降低 寫入(INSERT) 以及 更新(UPDATE) 資料的速度 → 因為同時要更動 Index 思考是否真的需要建 Index 的情況 資料量較小的表 該欄位頻繁且大量被更新或新增 避免使用包含太多 NULL 值的欄位 評估 Index Hit Rate執行下方的 SQL 語句可以查看 Index 命中的比率，藉此評估建好的 Index 是不是在查詢時被有效命中 1234567891011select t.schemaname, t.relname as &quot;Table Name&quot;, io_i.indexrelname as &quot;Index Name&quot;, case when (io_i.idx_blks_hit &lt;&gt; 0 or io_i.idx_blks_read &lt;&gt; 0) then round(io_i.idx_blks_hit/(io_i.idx_blks_hit::numeric + io_i.idx_blks_read::numeric), 4) else null end as &quot;Index Hit Ratio&quot;from pg_stat_user_tables t join pg_statio_user_indexes io_i on io_i.relid = t.relidorder by &quot;Index Hit Ratio&quot; desc; 建立 index語法: 1create index &lt;index_name&gt; on &lt;table&gt;(&lt;column&gt;); 範例：替 employees 表裡的 name 欄位建 index 1create index employees_name on employees(name); 再執行一次 name 的查詢 1234567891011postgres=# explain analyze SELECT id,name FROM employees WHERE name = 'Zs'; QUERY PLAN------------------------------------------------------------------------------------------------------------------------ Bitmap Heap Scan on employees (cost=4.47..27.93 rows=6 width=10) (actual time=0.930..1.211 rows=21 loops=1) Recheck Cond: (name = 'Zs'::text) Heap Blocks: exact=21 -&gt; Bitmap Index Scan on employees_name (cost=0.00..4.47 rows=6 width=0) (actual time=0.859..0.861 rows=21 loops=1) Index Cond: (name = 'Zs'::text) Planning Time: 3.024 ms Execution Time: 1.299 ms(7 rows) 命中 index 的情況下，執行時間下修到只剩 1.299 ms。 雖說有對 name 欄位下了 index，但特定情況下仍可能無法發揮作用。例如： 將剛剛 WHERE = 的條件改為 LIKE 123456789101112postgres=# explain analyze SELECT id,name FROM employees WHERE name LIKE '%ZA%'; QUERY PLAN---------------------------------------------------------------------------------------------------------------------------- Gather (cost=1000.00..11319.34 rows=90 width=10) (actual time=1.113..132.030 rows=1215 loops=1) Workers Planned: 2 Workers Launched: 2 -&gt; Parallel Seq Scan on employees (cost=0.00..10310.34 rows=38 width=10) (actual time=0.340..114.713 rows=405 loops=3) Filter: (name ~~ '%ZA%'::text) Rows Removed by Filter: 332929 Planning Time: 2.710 ms Execution Time: 132.185 ms(8 rows) 從結果觀察到同樣以 name 作為搜尋條件，卻出現沒有命中 index 的情形，選擇用 Seq Scan (Sequential Scan)的方式掃描整張表，由此可知並非只要加上 index，資料庫的 Planner 就會在每次搜尋時選擇 index。 Index Scan v.s. Index Only ScanIndex Only Scan 與 Index Scan 兩者主要差異在於: Index Only Scan 的資料是直接來自於 index，不需要再到 Heap File 取得資料，一般來說讀取的速度較 Index Scan 更快。 1234567891011121314151617-- 建表create table grades (id serial primary key, g int, name text ); -- 寫入測試資料insert into grades (g,name ) select random()*100,substring(md5(random()::text ),0,floor(random()*31)::int) from generate_series(0, 500);-- 建 indexCREATE INDEX id_idx ON grades(id); 分別測試 SELECT 不同欄位的結果： 查詢 id 123456789postgres=# explain analyze select id from grades where id = 7; QUERY PLAN-------------------------------------------------------------------------------------------------------------------- Index Only Scan using id_idx on grades (cost=0.27..8.29 rows=1 width=4) (actual time=0.073..0.078 rows=1 loops=1) Index Cond: (id = 7) Heap Fetches: 1 Planning Time: 0.249 ms Execution Time: 0.130 ms(5 rows) 查詢 name 12345678postgres=# explain analyze select name from grades where id = 7; QUERY PLAN---------------------------------------------------------------------------------------------------------------- Index Scan using id_idx on grades (cost=0.27..8.29 rows=1 width=15) (actual time=0.060..0.064 rows=1 loops=1) Index Cond: (id = 7) Planning Time: 0.360 ms Execution Time: 0.219 ms(4 rows) 比較上方兩條 query，經由 explain 分析的結果，下方的 query 查詢的 name 欄位需到 Heap Table File 裡讀取 name 對應的資料。 相較之下查詢 id 的 query 因為 id 本身已被設定為 index，故資料庫在讀取 index 時，會一起將命中的 index 值一並取出並回傳。 Includes Index如果希望把其他欄位的值也存在 index 上，可以採用 include 的 SQL 語句結合 index 將其他欄位納入 index。 範例:先移除原先建立好的 index 1DROP index id_idx; 將 name 欄位納入 index 1create index id_idx on grades(id) include (name) 查看建好 index 後的結果 12345678910postgres=# \\d grades; Table &quot;public.grades&quot; Column | Type | Collation | Nullable | Default--------+---------+-----------+----------+------------------------------------ id | integer | | not null | nextval('grades_id_seq'::regclass) g | integer | | | name | text | | |Indexes: &quot;grades_pkey&quot; PRIMARY KEY, btree (id) &quot;id_idx&quot; btree (id) INCLUDE (name) 接著對 SELECT 語句進行分析 123456789postgres=# explain analyze select name from grades where id = 7; QUERY PLAN--------------------------------------------------------------------------------------------------------------------- Index Only Scan using id_idx on grades (cost=0.27..8.29 rows=1 width=15) (actual time=0.097..0.103 rows=1 loops=1) Index Cond: (id = 7) Heap Fetches: 1 Planning Time: 1.745 ms Execution Time: 0.182 ms(5 rows) 加了 include 之後，explain 分析的結果從 Index Scan → Index Only Scan，代表查詢連同後來納入的 name 值直接從 Index 裡面取出，沒有額外到 Heap Table File 裡取值。 NOTE： include 會把其他指定的欄位納入 Index，適合把 include 指定的欄位用在 Index Only Scan 的策略上。 重要：include 的欄位並 不作為 Index 的 search key！故把上面的查詢條件 where 改為 name 時，資料庫就不會在 Index 裡搜尋到 name 值。 會增加 Index 的大小，隨著 Index 的增長，查詢 index 的速度會變慢，故在使用上要評估實際使用的場景以及取捨，再決定是否要採用。 將剛剛 include 的 name 欄位作為 where 條件： 123456789postgres=# explain analyze select name from grades where name = 'Zs'; QUERY PLAN-------------------------------------------------------------------------------------------------- Seq Scan on grades (cost=0.00..10.26 rows=1 width=15) (actual time=0.661..0.663 rows=0 loops=1) Filter: (name = 'Zs'::text) Rows Removed by Filter: 501 Planning Time: 0.365 ms Execution Time: 0.733 ms(5 rows) 從上述分析結果得知，雖然 name 透過 include 被納入 id_idx，但 id_idx 的 search key 是 id 欄位非 name，資料庫採用 Seq Scan 的方式。 分析 index 使用的情況透過以下的 SQL query 可以查詢到 index 的使用情形 1SELECT * FROM pg_stat_user_indexes; 查詢結果 123456relid | indexrelid | schemaname | relname | indexrelname | idx_scan | idx_tup_read | idx_tup_fetch-------+------------+------------+------------+-------------------------+----------+--------------+---------------39249 | 39256 | public | employees | employees_pkey | 36 | 2000035 | 2000032 39249 | 39259 | public | employees | employees_name | 2 | 21 | 0 39262 | 39269 | public | grades | grades_pkey | 0 | 0 | 0 39262 | 39272 | public | grades | id_idx | 17 | 17 | 17 查看指定的 index 大小語法：&lt;index_name&gt; 替換成指定的 index 名稱 1SELECT pg_size_pretty(pg_relation_size('&lt;index_name&gt;')); 範例： 查看 grades 這張表的 index: id_idx 12345postgres=# SELECT pg_size_pretty(pg_relation_size('id_idx')); pg_size_pretty---------------- 40 kB(1 row) 延伸探討 為什麼 Postgres 有時不選擇 Index Scan 卻選擇 Sequential Scan？ 有時候 PostgreSQL 在查詢時會選擇用 Sequential Scan 的方式，不採用下好的 Index 做 Index Scan，主要有幾個原因: 資料類型不匹配有些強制型別轉換會導致 Index 未被使用的情形，我們拿前面的 SQL 範例做調整，把搜尋條件 id 加上型別轉換(cast) ::numeric 的語句，改成下方的樣子: 1explain analyze select id from grades where id = 7::numeric; 型別轉換阻止 Postgres 使用建立好的 Index，藉由 explain analyze 分析產生以下結果： 123456789postgres=# explain analyze select id from grades where id = 7::numeric; QUERY PLAN------------------------------------------------------------------------------------------------- Seq Scan on grades (cost=0.00..11.52 rows=3 width=4) (actual time=0.086..0.840 rows=1 loops=1) Filter: ((id)::numeric = '7'::numeric) Rows Removed by Filter: 500 Planning Time: 0.372 ms Execution Time: 0.899 ms(5 rows) 從結果可看出 Postgres Planner 選擇 Seq Scan 而非前面的 Index Only Scan using id_idx on grades 評估結果是Sequential Scan 更快在資料量很小時，Sequential Scan 會比 Index Scan 更加有效，原因是 Index Scan 至少要發生兩次 I/O，一次是讀取 Index 的資料，一次是讀取 Heap File 裡的資料，搜尋代價遠高於 Index Scan。 總結前面談到有設置且命中 Index 在資料量大的情況下，對查詢效率會有顯著的差異。 使用 Index 前也須考量使用情境與其缺點，而且並非只要建立好 Index，SQL 查詢就一定會命中 Index，這些都是使用上要注意的地方。 善用 PostgresSQL Planner 的提示有助於評估當前 SQL 運行的狀況，衡量如何使用 Index。 參考 Difference between Clustered and Non-clustered index Index-Only Scans and Covering Indexes Indexes in PostgreSQL — 1 CLUSTER - PostgreSQL Docs","link":"2022/06/29/Database/Index/"},{"title":"[JSDC 2020] 參與心得","text":"前言上週參加今年JavaScript 開發者年會(JavaScript Developer Conference; 簡稱JSDC)，其實這是第一次參加，去年原本有想報，結果錯過報名時間……. 回歸正題，本次 JSDC 的所有議程中主要想聽是關於:遠端工作以及導入 TypeScript 相關議題 以下列舉參加其中幾場的分享及心得 Topic: Remote TeamSpeaker: TonyQ (王景弘) 這場的講者是大名鼎鼎的 TonyQ ! TonyQ 在本次議程中，以假設在被迫遠端(或面試需要遠端)的情況下，從三個面向來討論遠端工作 原因 為何要Remote? TonyQ 以自身及所聞周遭的遠端工作者經驗來討論會 Remote 的理由： 工作型態：本身可能是SOHO族，以接案的形式工作，客戶本身並不關心自己在哪裡工作，對方提出需求，你提供產出，只需要定期開會(or 碰面)確認進度，確保能夠有產出。 交通因素: 通勤時間過長，乾脆在家工作，遠比通勤所花的時間來的有效益 時間因素: 自身工作內容比較特殊，如:管伺服器 or 系統的人，因為系統可能在離峰時間、非正常上班時間出事，需要On-call 遠端維護主機 空間因素: 團隊分散在各地，辦公室有多個點，大家不在同一個空間，若要實體討論，花費的時間、金錢的成本過高，若透過數位工具，可以幫助團隊省下這部分的成本 家庭/健康因素： 家裡臨時需要協助，e.g. 家人有突發狀況、COVID-19 講者表示能夠面對面溝通很好，也喜歡隨時進入工作狀態，不用費盡心思出門到辦公室工作，隨時與團隊夥伴保持聯繫。 而遠端工作對於 TonyQ 來說，是一種工作方法，不同的工作方法，要用不同的態度來處理，想要上手遠端工作，需具備幾項條件: 自我管理 團隊整體對目標有一定的共識(避免大家看起來做同一件事情，卻分道揚鑣的窘境) 接著以管理者的身份來分享自己在管理 Remote Team 的經驗 個人先找總機有一個統一的管道可以讓團隊成員去問問題，作為主要的溝通窗口 Line Slack Teams 建環境由於遠距工作倚賴數位溝通，會需要一些其他工具 VPN: 連進公司內網 Git Repo Security Guide 確認必須的行政邏輯 工時 請假 afk (away from keyboard) 團隊工作時間確認必須的行政邏輯 確認任務分配模式 issue tracking Redmine Trello Teams PM / 主管 同事 溝通討論公私分明，討論完後再把結論填回 issue treacking PR &amp; Code Review 使用 Azure DevOps 先 push 到其他 branch 發 PR，code review 後再 merge concall/電話 Teams 可以在 pure web 完成分享螢幕、通訊 在家工作建議準備可工作的書房或空間 管理者情感遠端還是要做 Team Building 避免部屬與上司相互猜測彼此工作狀況 有沒有人最近少講話或情緒不太穩定 關照情緒需要電話或者見面了解 規劃盡量用文字而少用電話，安排要減少情緒。 進度問題 傳統叫下屬交工作報告 用 Readmine 查看活躍度，查看 commit 花費時間和紀錄 新人文件一定要寫 幫助新人融入團隊最快的方法 不用太精緻，txt 也行 同仁已讀不回怎麼辦 把工作交付他人（對同仁的處罰） SOS 怎麼處理 有排人值班 oncall，用電話溝通 如何避免重工 避免里長伯類型的同仁 明確指派任務 SOS人員無法解決時應向上呈報 技能落差 要死線前才發現無法完成 要派有技術的人 watch，定時 commit 記錄落後派人去盯 不用全部都盯，盯重要 issue 就好 開會模式 不開大會，開小組會 同仁不適應怎辦 用主管權利引導他，定期 tag 同仁回復討論，通常要嘛他適應，要嘛他走 建議原則： 高響應 定期 keep alive 對於新人，可以要求指定時間回報狀況 高容錯 對於文字多思考可能的意思 溝通需要更多的容錯 盡可能有第三個人在場 (避免 1v1 單人聊天)-讓其他人也知道狀態，避免雙方認知有落差，此時有第三方可以幫忙作證 高產出 工作不要排滿，七八分就好，排滿很危險 禁忌： 忌消失 忌不懂裝懂 忌缺確認 忌追殺 (除非 SOS) 總結團隊需要定期更新目標，落實目標管理，走在正確的方向 Topic: 本科 / 遠端 / 新創 經驗分享Speaker: 邱弘毅 (沒一村)講者有在經營粉專 - 沒一村隨便說，接著回答幾個大家都會問的問題 本科 vs 研究所很多人必須面對的課題: 考研？ or 工作？講者提到可以先想理想工作是什麼 理想工作 IC 半導體 vs 軟體工程師 台灣 IC 半導體一定要唸碩士(門檻) Data Engineer vs software engineer 研究 vs 開發以Software Engineer 來說，因為本身都是做開發，不ㄧ定要唸研究所 國內 vs 國外研究所 國內: 研究、修課 國外: 修課 如果有想要國外工作，可以念國外研究所 機會成本對講者來說，機會成本是非常重要的，比較下面兩個 本科直接工作：累積兩年工作經驗 + 薪水 研究所： 得到更多 domain specific 研究經驗 兩者要做取捨，這就回到自己本身的理想工作是什麼？ 遠端工作講者目前的公司位於美國，團隊的開發者也都是四散在各地，簡單跟大家分享近一年的遠端工作心得 遠端工作疑問如何找到工作？ AngelList：大多數為國外新創 Upworks (接案發包) Linkedin 臉書遠端社團 https://www.facebook.com/groups/1190343134374259/ https://www.facebook.com/groups/remotetaiwan/ 能力需求？ 英文 or 外文：能夠溝通，聽說讀寫據基本能力。 自制力：對遠端工作者是必須具備的能力 自學能力 溝通能力 優缺點? 優點:時間彈性、減少通勤時間、效率高 缺點: 容易超時工作、缺少和同事交流 Topic: 用不用 TypeScript 隨便你，反正我是用了Speaker: Will 保哥保哥本次想討論的主題是為何要使用TypeScript，用了有什麼好處？ 什麼是 TypeScript？TypeScript 由微軟開發，主要提供 JavaScript 型別系統和對 ES6 的支援，屬於強型別。 因為 TypeScript 誕生得主因是 JavaScript 本身是弱型別語言，在撰寫上非常自由，不需事先定義好資料型別。不過也因為風格自由，可能倒置程式執行時，發生不可預期之錯誤。舉例來說： 以下圖片取自保哥的簡報 上述範例可以看出，因為未事先宣告資料型別，所以在執行 processData 這個函式時，無法得知街道的物件data會是什麼，接著執行函式內邏輯時，出現TypeError這項型別錯誤的提示訊息，只要打錯字，這支程式基本上就掛了。 若轉成 TypeScript 上述保哥所舉得範例，左邊預先定義一個Interface，宣告Data這個物件的屬性包含三種型別。 而下方的錯誤訊息來自IDE的提示，很貼心的提示你可能發生的問題。 講者觀點:弱型別並非沒有，還是有些大神可以把他玩到極致，產出如同藝術家般的作品，但是對一般人來說是很難做到;而強型別玩到極致，如同蓋大樓，藉由大量型別的定義，幫助開發者建構中大型的專案，在實際案例中，不可能所有開發者都是藝術家級別。 透過規範來幫助開發者建構出易維護、擴充的程式碼，減少錯誤。 TypeScript 是透過型別來擴充 JavaScript，透過編譯的方式來產生 JavaScript，而 TypeScript 的型別檢查是發生在程式編譯的階段 好處: 讓開發工具看懂原始碼 後續保哥分享了他在公司將一個兩萬行JS Code 的專案升級成 TypeScript，過程中發現型別的問題非常大，花費不少時間做Complie Error，陸續將可被規範的物件，定義出該有的樣子，同時也提到導入 TypeScript 的確會增加開發時間，畢竟要先定義好型別，不過放長遠來想，或許是個值得投資的項目。 後記感謝 ALPHA Camp 活動贊助，以優惠價取得門票，有幸參與今年JSDC研討會，實屬難得的機會。","link":"2020/10/24/Conference/%5BJSDC%202020%5D%20%E5%8F%83%E8%88%87%E5%BF%83%E5%BE%97/"},{"title":"[Canvas] 座標系操作","text":"坐標系轉移繪製同樣的圖形有相同的座標，我們可以透過座標系轉換，繪製在不同的位置/角度。 轉移方法 Translate(x,y): 相對當下位置偏移(x,y) Rotate(deg): 以當下位置為中心(相對於原點)旋轉的角度(deg) Scale(x,y): 以當下位置為中心(相對於原點)作縮放(x,y) 狀態保存&amp;還原 save(): 保存當下狀態 restore(): 還原上一個儲存狀態 原則: 採資料結構的先進後出(stack)，即最先儲存的狀態，還原順序是排最後。 座標轉換在繪製物件的應用 因座標重置，較容易指定 用相對位置去思考會比較直覺 可在當前座標做額外繪製 setTransform (直接設定矩陣) A X縮放 C Y傾斜 E X偏移 B X傾斜 D Y縮放 D Y偏移 若要進行重設，設定(1,0,0,1,0,0)，將x,y的縮放設為1倍，其餘設為0。 相對關係的繪製假設今天要繪製一連串的矩形，可採以下方式: 123456789ctx.save(); // 儲存初始狀態for(let i=0; i&lt;7; i++){ ctx.fillRect(0,0,50,50); ctx.translate(50,0);}ctx.restore(); // 還原成初始狀態 相對角度的繪製每隔45度，繪製多個圓形環繞圓心。 123456789101112ctx.save(); // 儲存初始狀態for(let i=0; i&lt;8; i++){ ctx.beginPath(); // 繪製圓形 ctx.arc(50, 0, 10 ,0 ,Math.PI*2);} ctx.fill(); ctx.rotate(Math.PI / 4);ctx.restore(); // 還原成初始狀態","link":"2019/07/14/Canvas/Canvas(coordinate)/"},{"title":"[CSS] Flexbox 排版","text":"前言這篇要討論的是比較新式的排版-FlexBoxFlexBox為了適應不同螢幕尺寸和顯示設備而生的布局模式。現在因為手機普及，使用者大多用手機上網，為了改善使用者體驗，寫網頁需要考量到網頁呈現在手機上的排版方式。 Go! FlexBox的特徵: 首先，要先將FlexBox做分類， 分為外容器屬性(Container)與內元件屬性(Items)。 外容器(Container):若想切換FlexBox的排版模式，要在CSS樣式宣告display，display分為兩種： 1.display:** flex** 為塊級元素，似block ２.display: inline-flex 為行內塊元素，似inline-block 以下提供範例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;style&gt; * { margin: 0; padding: 0; } .box { max-width: 100%; border: 3px black solid; display:flex; } .item { width: 150px; text-align: center; padding: 1rem; font-size: 2rem; } .item:nth-of-type(1) { background: red; padding-bottom: 1rem; font-size: 2rem; } .item:nth-of-type(2) { background: yellow; padding-bottom: 5rem; font-size: 2rem; } .item:nth-of-type(3) { background: green; font-size: 2rem; } .item:nth-of-type(4) { background: blue; font-size: 2rem; } .item:nth-of-type(5) { background: pink; font-size: 2rem; } &lt;/style&gt; &lt;div class=&quot;box&quot;&gt; &lt;div class=&quot;item1 item&quot;&gt;item1&lt;/div&gt; &lt;div class=&quot;item2 item&quot;&gt;item2&lt;/div&gt; &lt;div class=&quot;item3 item&quot;&gt;item3&lt;/div&gt; &lt;div class=&quot;item4 item&quot;&gt;item4&lt;/div&gt; &lt;div class=&quot;item5 item&quot;&gt;item5&lt;/div&gt; &lt;/div&gt; 當外層盒子宣告display時，裡面的盒子會變成水平排列。 好，到這邊我們需要先瞭解幾件事情： .box 已經變成了 Flexbox Model 排版模式，會直接影響到其第一層子元素( item)的排版行為。 .box 是 Flexbox Model 中的 Flex container。 item 是 Flexbox Model 中的 Flex item(s)，因為是 .box的第一層子元素。 此範例適用於任何父子元素，不僅限於 ul、li，也可以用在任何 div 或其它元素。 Flex Container 相關屬性，此上圖程式碼為例共有六種屬性可以設定，在記屬性前必須需先了解FlexBox的兩個軸線。 當 .box 設定為 display:flex **時，就代表會有這兩個隱形的軸，Main Axis** 表示從左至右；Cross Axis **表示從上至下**。 當** flex-direction** 設定為以下的值時，就會影響到第一層子元素(Flex Items)的排列方向： row：為預設值，代表 Flex Items 會從左至右依序排列。 column：代表 Flex Items 會從上至下依序排列。 row-reverse：代表 Flex Items 會從右至左依序排列。 column-reverse：代表 Flex Items 會從下至上依序排列。 程式碼(前四個): 1234.box{ // 第一種 flex-direction: row || column || row-reverse || column-reverse;} flex-direction: row-reverse; flex-direction: column flex-direction: column-reverse 1234.box{ /* 第2種*/ flex-wrap: wrap || no-wrap || wrap-reverse;} 說明： wrap：代表當 Flex Items 數量過多，多到 Flex Container 裝不下的時候，會斷行，會斷行的方向會是往下斷行。 flex-wrap: wrap no-wrap：此為預設值，代表即使 Flex Items 數量過多，依然不會斷行，Flex Container 都會試圖去包含這些 Flex Items 在同一列。 flex-wrap: nowrap wrap-reverse：代表當 Flex Items 數量過多，多到 Flex Container 裝不下的時候，會斷行，會斷行的方向會是往上斷行。 flex-wrap: wrap-reverse flex-flow 單純只是個 flex-direction 和 flex-wrap 同時用的縮寫 1234.box{/* 第三種*/ flex-flow: &lt;flex-direction&gt; &lt;flex-wrap&gt;;} justify-content 是用來定義 Flex Items 該如何在 Main Axis 排列。 1234.box{/* 第四種 */ justify-content: flex-start || flex-end || center || space-between || space-around || space-evenly ;} flex-start：是預設值。代表 Flex Items 從 Main Axis 的起點開始排列。 flex-end：代表 Flex Items 整個的結尾要往 Main Axis 的尾端貼齊。 center：item針對 Main Axis 來置中。 space-between： 各個 Flex Item 延著 Main Axis 平均分散，但 Flex Item 之間會保留相同大小的空間，首、尾都要貼緊邊界。 space-around：各個 Flex Item 延著 Main Axis 平均分散，但每一個 Flex Item 周圍都要保持相同的距離，在不設margin下，首、尾不貼邊界，且距離邊界保留的空間大小相等。 space-evenly：每個小方塊之間和與父容器之間擁有相同的間隔。 space-between &amp; space-around &amp; space-evenly區別 space-between：每個小方塊擁有相同的間隔，但與父容器之間沒有間隔。 space-around：每個小方塊之間與父容器有間隔，但小方塊與父容器之間的間隔是小方塊彼此間隔的一半。 假設今天與父容器的間隔為X，那小方格之間的間隔就是2X。 space-evenly：每個小方塊之間和與父容器之間擁有相同的間隔。假設今天與父容器的間隔為X，那小方格之間的間隔仍為X。 來看看實作: justify-content: flex-start justify-content: flex-end justify-content: center justify-content: space-between justify-content: space-around align-items :與 justify-content 非常相似，但定義 Flex Items 該如何在 Cross Axis 排列 flex-start： 表Flex Items 高度並不會增加至 Flex Container 的高度，各 Flex Items 會直接對齊 Cross Axis 的起點。 flex-end： 表Flex Items 高度並不會增加至 Flex Container 的高度，各 Flex Items 會直接對齊 Cross Axis 的最終點。 center：每個 Flex Items 會直接對齊** Cross Axis 高度的中間**。 stretch：預設值，表 Flex Items 的高度，沿著 Cross Axis，都會自動增加高度至 Flex Container 的高度。按照字面就是延伸，將Item的高度延伸至Container的高度。 baseline：會依據 Flex Items 的基準線來對齊。下圖範例可知雖然各個item高度不同，但對齊的基準是文字內容。 align-content:主要是用在 Flex Container 中的 Flex Items 產生多行時，這些 Flex Item 該如何針對 Cross Axis 來排列。 1234.box{ /* 第六種 */ align-content: flex-start || flex-end || center || stretch;} flex-start：遇到 Flex Items 斷行，會沿著 Cross Axis 排列，似置頂的方式： flex-end：遇到 Flex Items 斷行，會沿著 Cross Axis 會如下排列(置底)： center: 遇到 Flex Items 斷行，會沿著 Cross Axis 會如下排列(置中)： stretch：預設值，遇到 Flex Items 斷行，各 items 的高度會沿著 Cross Axis 自動增減。 Main Axis和Across Axis 會因為flex-direction的設置而有所不同，當flex-direction設置為column時，Main Axis和Across Axis要和flex-direction: row時相反。 即row的Main Axis = column的Across Axis，反之亦然。Flex Item :上面實作完Container相關的屬性後，往下實作Flex Item 相關屬性。 Flex Item共有六種屬性可以設定:1234.item{ /* 第一種 *\\ order: &lt;number&gt;; // 預設值 0} order :可以是任何的整數，所有的 Flex Items 預設值都是0。所有的 Flex Items 排列順序都會按照 order 值的大小，從最小開始排，依序排到最大值。 1234.item:nth-of-type(1) { background: red; order: 1;} 因為item的order被設為1，比其他item的order值(預設為0)還要大，故排至最後。 flex-grow:設定該 Flex Item 自行延伸，將多餘空間填滿。 flex-grow 預設值是 0，其表不延展填滿。 *若同時有多個元素都設有數值時,是相對倍數做放大。** * **不可為負值，但可為小數點。 1234.item{ // 第二種 flex-grow: 0 ; // 預設值是 0} 若將item1的flex-grow值設為1，可以得下面結果: 剩餘的空間被 item1 所填滿 flex-shrink:元件的縮減，是一個數值，空間分配不足時會改變當前元件的收縮程度，預設值為 1，如果設置為 0 則不會縮放。收縮的程度也是相對於其他元素的。數值不可為負數。 ***可用於在改變螢幕大小時，將不重要的資訊做縮小。 1234.item{ /* 第三種 */ flex-shrink:1 // 預設值是 1} 以下範例實作，將item1的flex-shrink設為4，會得到以下結果: item1 所小的幅度大於其他 item flex-basis:元件的基準值， 用來設定 Flex Item 的寬度，單位可以是任何百分比、不同的單位值(e.g. px ,rem)， 預設值為auto。 預設情況下，Flex Item 的寬度是會依據內容來自動變寬。 123.item:nth-of-type(1) { flex-basis: 50px;} item1被限制在50px的寬度 flex:flex 是縮寫，分別代表 flex-grow、flex-shrink、flex-basis。 *flex: default *是 flex: 0 1 auto; 的縮寫。 1234.item{ /* 第五種 */ flex: &lt;flex-grow&gt; &lt;flex-shrink&gt; &lt;flex-basis&gt;; // 預設值依序為 0 1 auto;} 如果要設其中1個或2個單位的話,會有不同結果: 1個值: flex:2; /* **flex-grow /* flex: 30px ; /* **flex-basis /* 2個值: flex: 1 30px; /* **flex-grow | flex-basis */** flex: 2 2 ; /* **flex-grow | flex-shrink /* align-self:只會影響特定 Flex Item ，針對該Flex Item的Cross Axis 排列方式調整，不會影響到其它的 Flex Items。下面範例以item3為調整對象。 12345.item{ /* 第六種 */ align-self: auto || flex-start || flex-end || center || baseline || stretch; // 預設值是 stretch;} auto：該 Flex Item 的值，會直接參考 Flex Container 的 align-items 值，兩者相同。 flex-start：該 Flex Item 會對齊 Cross Axis 的起點，高度不會自動擴展。 flex-end：該 Flex Item 會對齊 Cross Axis 的底部，高度不會自動擴展。 center：該 Flex Item 會對齊 Cross Axis 的中間，高度不會自動擴展。 baseline： 有設定成 baseline 的這些 Flex Items ，會彼此對齊 baseline。 將 item1~3 都設 baseline stretch(預設)：該 Flex Item 會自動擴展，佔滿整個 Flex Container。 以上為這次的筆記整理，相較以往的排版，這樣的排版的確彈性許多。","link":"2019/07/14/CSS/CSS%20Layout%20_FlexBox/"},{"title":"[Canvas] 入門","text":"Go!特性 可自由繪製元件區域 可控制每像素的顏色與繪製 有較高的操控度 可動態改寫圖片 掌握要點 繪製圖形 向量概念 三角函數 物件導向開發 像素在一個固定寬度和高度的圖片內，切割成一個個的小格子，canvas可分別指定每個格子的顏色 如何知道在那些像素做改變？透過點座標的方式定位，根據原點指定垂直（Y軸）及橫向（X軸）偏移，確認位置 Canvas的坐標系方向 原點設置在左上角 角度為逆時鐘 原點往下延伸為＂Y軸＂ 0度表X軸方向 90度表Y軸方向 如何使用Canvas以繪出一個填滿黑色的三角形為例： 在HTML加上canvas#mycanvas，加上Canvas標籤後設置id，方便抓取。 在JS中: 1234567891011121314151617const canvas = document.getElementById('mycanvas');const ctx = canvas.getContext(&quot;2d&quot;); // 指定繪圖介面，在2D上繪圖 // 設定畫布尺寸，將畫布尺寸設為等同視窗尺寸大小，撐滿整個視窗canvas.width = window.innerWidth;canvas.height = window.innerHeight; // 起始點座標(50,50)，繪製直線連到 ctx.beginPath(); // 開始進行繪圖 ctx.moveTo(50,50); ctx.lineTo(100,100); ctx.lineTo(250,20); ctx.closePath();// 關閉繪製 ctx.fillStyle = &quot;black&quot;; // 繪製顏色 ctx.fill(); // 進行填滿繪製 基礎圖形 填滿矩形：fillRect(x,y,w,h) 繪製框線矩形strokeRect(x,y,w,h) 清除矩形範圍clearRect(x,y,w,h) 設置框線的寬度 lineWidth 設置圖形透明度 globalAlpha x,y表座標位置，w,h表寬和高路徑繪圖上述的基礎圖形只能繪出矩形，若要畫出其他圖形，可採用路徑繪圖的方式完成。 開始一個新的路徑，給予點座標，做連線操作，再指定填色或線條顏色，最後將路徑填色描繪出來。 路徑的開始＆關閉：beginPath＆closePath 移動＆畫線: moveTo、lineTo、arc(弧形)… 指定填色或線條顏色:fillStyle、lineStyle 將路徑填色&amp;描繪出來: stroke(描繪路徑線條)、fill(將圖案填滿) 圓形的路徑 arc(x,y,r,start Angle,end Angle,state)x,y 為圓心座標，r為半徑，state為畫弧方向: true表逆時針； false表順時針(預設) 計算弧度：0-360必須寫 0～2*Math.PI 角度是 ＂逆順時針選由下方開始旋轉＂ 色彩系統 rgb rgba hsl(彩度,飽和度,亮度)，正常值:(50%,50%) hsla(彩度,飽和度,亮度,透明度) 時間函數＆動畫 setInterval(updateFn,time) requestAnimationFrame(update):給定一個函數後，自動判斷何時該更新畫面，提升動畫效能。 更新影格:使用clearRect或fillRect覆蓋上次繪圖的圖形","link":"2019/07/14/Canvas/Canvas/"},{"title":"[Postgres] 資料庫裡的儲存概念","text":"前言本文主要探討資料庫裡的儲存概念，了解資料庫是如何將資料存在硬碟(Disk)裡，儲存原理在各家主流資料庫會有差異，但大方向是相同的，內容會以 Postgres 為主，少部分提及其他資料庫的做法。 本篇主要筆記 Udemy - SQL and PostgreSQL: The Complete Developer’s Guide 及 Udemy - Fundamentals of Database Engineering 的課程內容，但以自己較易理解的方式加以整理，可能和原課程內容有些出入。 資料庫儲存結構的相關名詞了解主流的關聯式資料庫如何儲存資料前，須先對下面幾項名詞有所理解: Table Row_ID Tuple Page I/O Heap Index Table資料表由行(Column)、列(Row) 組成 Row_ID 資料庫內部會對每筆資料自己額外建一個 row_id，由系統維護 這部分因各家資料庫有所差異: MySQL (innoDB) 的主鍵和 row_id 是同一個。 Postgres 則是有個系統生成的欄位 row_id Tuple (or Item)指的是資料表裡的一筆資料(即一個 row)，這些 tuple 會被存放到 Page 上，後續有圖片說明他們之間的關係。 每個 Tuple 都有個別的 ID，簡稱 TID，在 Postgres 裡面等同 row id，其內容包含： block number: Block 的位置編號 tuple index within block(Offset): tuple 位於該 block 的位置 關於 Tuple 相關說明，摘錄自 PG 官方文件內容：Object Identifier TypesA final identifier type used by the system is tid, or tuple identifier (row identifier). This is the data type of the system column ctid. A tuple ID is a pair (block number, tuple index within block) that identifies the physical location of the row within its table. 範例： TID = (3,10)表示該 tuple 資料位於第 11 個(編號從 0 開始) block 內的第 3 個 element。 TID 會和後續 Index 存放的內容息息相關，後面會提到。 Page(or Block) Page 用於存放資料表的所有資料，故每張 Page 裡會有多個 Tuple 根據不同的儲存模型，資料存在 Page 的方式不同 資料庫讀取資料的方式：單次 I/O 讀取一張 or 多張表的資料 每張表都有固定的大小 (e.g. 8KB in postgres and sql server, 16KB in MySQL) 範例: 一張 Page 可放 3 個 Row，若有 1001 筆，則會有 334 個 Page (1001/3 = 333 ~, 多的兩筆需加一個 Page 存放) 影響 query 效能好壞的關鍵:單個 query 讀取多少的 Page、產生了幾次 I/O I/Oinput/output 又作 I/O 用於表示向 Disk 發出讀取的請求 盡可能減少 I/O 次數 → 單個查詢的 I/O 次數越少，查詢的回應速度越快 單次 I/O 可以取得 1 or 多個 Page 的資料，會因不同因素(e.g. Disk partition)有所不同 單次 I/O 無法只讀取單一筆 (Row) 的資料，而是讀取 Page 裡多筆資料，資料庫再把其他不需要的資料給過濾掉 → 故每次 query 有不小的成本 Heap是一種資料結構，用於存放一個個的 Page 資料，多個 Page 組成一個 Heap File 要迭代 Heap 找到我們想要的資料是昂貴的開銷 建立索引(Index) 可以準確地告訴資料庫要讀取 Heap 裡的哪個部分，也就是只讀取哪些 Page 的資料 → 即 index 可以加速查詢效率的原因 Heap, Page, Tuple 之間的關係圖PostgreSQL 將 table 資料都存成一個一個的檔案，我們稱為 Heap 或 Heap files，Heap file 由多個 Block 組成，每個 Block 為 8KB，Block(Page) 裡面的 Item (Tuple)，就是存放的資料。 資料庫讀取資料的過程：資料庫會從電腦磁碟(Disk)讀取資料表，將資料表裡的資料載入記憶體(Memory)，最後移動至 CPU 進行處理。 來看個實際例子：資料庫會先到 Disk 的 Heap File 裡讀取 user 表，載入至記憶體，接著逐筆進行搜尋。 IndexIndex (中文作”索引”)是 B+ tree 的資料結構，以犧牲儲存空間、減慢寫入 &amp; 更新資料的速度為代價，換取更好的查詢效率，具有 pointer(指針) 指向 Heap 裡的資料，這些 pointer 在意義上是個數值，指向資料庫的 TID(row id)，TID(row id) 會包含許多有關於 Heap 裡 Page 的 meta data。 關於 Index 的幾個重點： 可以對 1 or 多個欄位下 Index Index 會準確地告訴資料庫在 Heap 中取的哪個 Page，而不是把 Heap 裡的每個 Page 都掃過一遍 Index 會被存在獨立 Heap File 的 Page 裡，一樣透過 I/O 從 Disk 裡讀取 Index 資料 從 Disk 取出的 Index 資料，會放入 Memory，如果 Index 過大的話，可能遇到非所有 Index 都能放進 Memory 搜尋 → 故單個 Index 的大小盡可能縮小，才能夠放入 Memory 快速地搜尋 Index 是如何存放在 Disk? (簡化的版本)Index 表裡面存放了被設置為 Index 的欄位內容作為 key 值，以及該 key 對應 Page(Block), Row(Tuple) 的位置，也就是「儲存的 key 值與 TID 的配對關係」。 以上圖表為例，EMP_ID 欄位被設置為 Index，Key 為 EMP_ID 的值，其中 10 (1,0) 可以解讀為：Key = 10, TID = (offset = 1, block = 0)。這組數字表示 EMP_ID 為 10 的值位在第 0 個 Page(Block) 裡的第 1 個 Tuple。注：offset 表偏移量 直接從 index 裡取得 TID，藉由取得的 TID 值，快速定位該值是位在哪個 Page(Block) 內的第幾個 Row(Tuple) 另外，在使用 Index 的過程中，資料庫會經歷兩次 I/O， 第一次 I/O (IO1)去專門存放 Index 的目標資料的 Heap File，從 Index 裡面取出目標 Page 和 Row 所在位置後，以此為依據進行第二次 I/O (IO2)，到存放原始資料的 Heap File 裡找出目標資料。 小結前面內容討論資料庫儲存資料的幾個重要結構: Heap, Page, Tuple, Index，以及他們之間的關系，最後討論 SQL 執行查詢語句時，是如何跟 Disk 要資料載入記憶體，另外，知道結構之間的關係將有助於未來優化 SQL 語句。 參考 The Internals of PostgreSQL - Database Cluster, Databases, and Tables","link":"2022/06/20/Database/%E8%B3%87%E6%96%99%E5%BA%AB%E5%A6%82%E4%BD%95%E5%AD%98%E6%94%BE%E8%B3%87%E6%96%99/"},{"title":"[JavaScript] Array","text":"前言JavaScript 的陣列可以看作是一種特別的「物件」，透過 typeof會返回陣列的類型是object。陣列是一組按次序排列的值， 放在裡面的東西稱為元素，每個元素都有其位置，稱為索引，找到索引值，就可以得知該位置元素的值。 陣列只能透過 [] 來存取 索引值從0開始排序，最後一個索引值為 array.length-1 陣列內可以是原始的資料類型、其他陣列、函式等等。 建立陣列的方式:使用中括號[]12345678910var ary1 = []; //建立一個空陣列var ary2 = [1,2,3]; //有3個元素的陣列，元素型別為numbervar ary3 = [1,'a',true]; //陣列可放入不同型別的元素var arr =[ //陣列中也可以包含陣列，稱作多維陣列 [&quot;湯母&quot;,&quot;170cm&quot;,&quot;60kg&quot;,123456], [&quot;湯尼&quot;,&quot;180cm&quot;,&quot;80kg&quot;,1235456], [&quot;傑尼&quot;,&quot;175cm&quot;,&quot;70kg&quot;,456], [&quot;捷克&quot;,&quot;176cm&quot;,&quot;75kg&quot;,1256], ]var ary5 = [ {x:1,y:2},{x:3,y:4} ]; //陣列中也可以包含物件 透過 new 關鍵字來建立12345var a = new Array();a[0] = &quot;apple&quot;;a[1] = &quot;boy&quot;;a[2] = &quot;cat&quot;; 判斷陣列 使用Array.isArray( )函式，依回傳true或false來判斷該物件是否為陣列 1234567var arr = [1, 2, 3, 4, 5, 6];var obj = { x: 1, y: 2};console.log(Array.isArray(arr)); //trueconsole.log(Array.isArray(obj)); //false 陣列的存取稱作陣列實字(Array literal) 123456var a = [];a[0] = &quot;apple&quot;;a[1] = &quot;boy&quot;;a[2] = &quot;cat&quot;;a.length; // 3 陣列與字串的比較: 1234var str = 'Javascript';console.log(str[1]); //aconsole.log(typeof str); //stringconsole.log(Array.isArray(str)); //false 字串在JavaScript中似陣列，每個元素都可視為字元，所以能用中括號[ ]，透過索引值來讀取字串，但實際類型依舊是string，而不是陣列。 陣列方法(method)排序sort( )陣列中sort( )方法，會先將元素轉字串，再依據字串的Unicode編碼進行排序，會改變原陣列。預設以字串形式去比較(首字比較)， 大寫排在前面 ，如果想不區分大小寫排序，可使用toLowerCase( )方法。 1234// 比較字符串大小var str1 = 'abcdefd'var str2 = 'abbffda'alert(str1 &gt; str2) // true // 第3個字符 c&gt;b 所以 str1比較大 若以數字方式去做sort( )排序，會得出非預期的結果 1234arr = [2, 3, 17, 12, 32, 45, 13]var temp = arr.sort()console.log(temp); // 12,13,17,2,3,32,45 解決方式: 使用一個比較的函式做為引數，來判斷元素的大小與排列順序 1234567arr = [2, 3, 17, 12, 32, 45, 13]// 排序處理(將str 轉為 int) -&gt; function處理arr.sort(function(a,b) { return a - b // 回傳值由小到大 // [2, 3, 12, 13, 17, 32, 45] return b - a // 回傳值由大到小 // [45, 32, 17, 13, 12, 3, 2]})console.log(arr); 特殊排序處理採parseInt() 123456arr1 = ['235px', '123px', '64px', '654px']arr1.sort(function (a, b) { return parseInt(a) - parseInt(b) // 64px,123px,235px,654px return parseInt(b) - parseInt(a) // 654px,235px,123px,64px}) document.write(arr1) 亂數排序的陣列採Math.random() 123456var arr2 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]arr2.sort(function () { // 返回 true 或 false (交換或不交換) return Math.random() - 0.5; Math.random()為0-1的數 返回true 或 false})document.write(arr2) // 9,8,3,2,10,1,5,7,6,4 將陣列中元素的排列順序倒轉過來採reverse() 123var ary = ['A', 'B', 'C', 'D'];console.log(ary.reverse()); //[&quot;D&quot;, &quot;C&quot;, &quot;B&quot;, &quot;A&quot;]console.log(ary); //[&quot;D&quot;, &quot;C&quot;, &quot;B&quot;, &quot;A&quot;] indexOf() indexOf(searchValue,fromIndex) searchValue: 檢索字串值(必填) fromIndex: 起始位置(選填) 默認值為: 0 搜尋陣列中是否有符合給定值的元素，若有，就回傳第一個符合元素的索引值；若無，回傳-1。 1234var str4 = 'hello world!!!' // 空格也須算入console.log(str4.indexOf('o')); // 查找 'o' 首次出現的位置 // 4console.log(str4.indexOf('o',5)); // 從第&quot;5&quot;個元素開始查找 'o' 首次出現的位置 // 7 console.log(str4.indexOf('!!')); // 檢索多個字串 // 11 陣列的尾端添加一個或多個元素，並返回添加新元素後的陣列長度 push()方法，push()會改變原陣列 1234567var arr1 = [];arr1.push(1); arr1.push(&quot;a&quot;); arr1.push(true, {});console.log(arr1.push()); // 4 (陣列長度)console.log(arr1); // [1, 'a', true, {}] 刪除陣列的最後一個元素，並返回該元素。pop()方法 1234var arr = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;];console.log(arr.pop()); // cconsole.log(arr); // [&quot;a&quot;, &quot;b&quot;] 對空陣列使用pop()方法，不會報錯，而是返回undefined。 1[].pop() // undefined 刪除陣列的第一個元素，並返回該元素。shift()方法 1234var a = ['a', 'b', 'c'];console.log(a.shift()); // 'a'console.log(a); // ['b', 'c'] 用於在陣列的第一個位置添加元素，並回傳添加新元素後的陣列長度， 可以接受多個參數。unshift()方法 12345var arr2 = [ 'c', 'd' ];arr2.unshift('a', 'b') console.log(arr2.unshift()); // 4console.log(arr2); // ['a', 'b', 'c','d'] 分割join()‘方法，( )內的參數表分割符號。若無參數，則以 , 做分割符號,並且轉為string 12345var a = [1, 2, 3, 4];a.join(' ') // '1 2 3 4'a.join(' | ') // &quot;1 | 2 | 3 | 4&quot;a.join() // &quot;1,2,3,4&quot; 如果陣列元素是undefined或null或空值，會被轉成空字串。 123456789101112131415161718192021222324[undefined, null].join('#') // '#'['a',, 'b'].join('-') // 'a--b'``` ### 合併`concat( )` 方法，將2個以上的陣列與字串合併成新的陣列， 將新陣列元素，添加到原陣列的尾端， 回傳一個新陣列，原陣列不變。```javascript// 合併2個var arr1 = ['a', 'b', 'c'];var arr2 = ['d', 'e', 'f'];console.log(arr1.concat(arr2)); //[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;]// 合併3個var arr1 = ['a', 'b', 'c'];var arr2 = ['d', 'e', 'f'];var arr3 = ['g', 'h', 'i'];console.log(arr1.concat(arr2, arr3)); //[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;, &quot;i&quot;]// 合併字串、數字與陣列var arr1 = ['a', 'b', 'c'];var arr2 = ['d', 'e', 'f'];var arr3 = ['g', 'h', 'i'];console.log(arr1.concat(arr2, arr3, 'j', 'k', 1, 2)); //[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;, &quot;i&quot;, &quot;j&quot;, &quot;k&quot;, 1, 2] 提取目標陣列的一部分， 回傳一個新陣列，原陣列不變slice() arr.slice(start, end);1234567var a = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;];console.log( a.slice(0)); // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]console.log( a.slice(1)); // [&quot;b&quot;, &quot;c&quot;]console.log(a.slice(1, 2)); // [&quot;b&quot;]console.log(a.slice(2, 6)); // [&quot;c&quot;]console.log(a.slice());// [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;] // 返回原陣列 上面例子，slice()第一個參數為起始位置（從0開始），第二個參數為終止位置（但該位置的元素本身不包括在內）。如果省略第二個參數，則回傳到原陣列的最後一個元素。 如果slice()的參數是負數，則表示倒數的位置，例: -1表示從倒數第一個元素開始 123var a = ['a', 'b', 'c'];a.slice(-2) // [&quot;b&quot;, &quot;c&quot;]a.slice(-2, -1) // [&quot;b&quot;] 如果第一個參數大於等於陣列長度，或者第二個參數小於第一個參數，則回傳空陣列。 123var a = ['a', 'b', 'c'];a.slice(4) // []a.slice(2, 1) // [] 字串的分割，並回傳陣列。split()方法 split(sep,lenght) sep做分割符; length: 指定回傳陣列最大長度 123456789101112131415161718192021'a|b|c'.split('|', 0) // []'a|b|c'.split('|', 1) // [&quot;a&quot;]'a|b|c'.split('|', 2) // [&quot;a&quot;, &quot;b&quot;]'a|b|c'.split('|', 3) // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]'a|b|c'.split('|', 4) // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]// split方法按照給定規則分割字串，返回一個由分割出來的子字串組成的陣列。'a|b|c'.split('|') // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]// 如果分割規則為空字串，則返回陣列的元素是原字串的每一個字元。'a|b|c'.split('') // [&quot;a&quot;, &quot;|&quot;, &quot;b&quot;, &quot;|&quot;, &quot;c&quot;]// 如果省略參數，則返回陣列的唯一元素就是原字串。'a|b|c'.split() // [&quot;a|b|c&quot;]//如果滿足分割規則的兩個部分緊鄰著（即兩個分割符中間沒有其他字串），則返回陣列之中會有一個空字串。'a||c'.split('|') // ['a', '', 'c']// 如果滿足分割規則的部分處於字串的開頭或結尾（即它的前面或後面沒有其他字串），則返回陣列的第一個或最後一個成員是一個空字串。'|b|c'.split('|') // [&quot;&quot;, &quot;b&quot;, &quot;c&quot;]'a|b|'.split('|') // [&quot;a&quot;, &quot;b&quot;, &quot;&quot;] 顛倒字串方法 轉為陣列 : 用 split(‘’) 陣列反轉 拼接成字符串 : 可用join(‘’)12var str1 = '123456'alert(str1.split('').reverse().join('')) 刪除原陣列的一部分元素splice()方法，並可以在刪除的位置添加新的陣列元素， 回傳值是被刪除的元素，splice()會改變原陣列。 arr.splice(start, count, addElement1, addElement2, ...); 第一個參數是刪除的起始位置（從0開始），第二個參數是被刪除的元素個數。如果後面還有更多的參數，則表示這些就是要被插入陣列的新元素。 從原陣列4號位置開始，刪除了兩個陣列元素。1234var a = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;];console.log(a.splice(4, 2)); // [&quot;e&quot;, &quot;f&quot;]console.log(a); // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;] 除了刪除元素，還插入了兩個新元素。1234var a = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;];console.log(a.splice(4, 2, 1, 2)); // [&quot;e&quot;, &quot;f&quot;] // 回傳被刪除的元素console.log(a); // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, 1, 2] 起始位置如果是負數，就表示從倒數位置開始刪除。 123var a = ['a', 'b', 'c', 'd', 'e', 'f'];console.log(a.splice(-4, 2)) // [&quot;c&quot;, &quot;d&quot;]// 從倒數第四個位置c開始刪除兩個元素。 如果只是單純地插入元素，splice()的第二個參數可以設為0。 123456789 var a = [1, 1, 1]; console.log(a.splice(1, 0, 2)) // [] console.log(a) // [1, 2, 1, 1]``` &gt; 如果只提供第一個參數，等同於將原陣列在指定位置拆分成兩個陣列。```javascript var a = [1, 2, 3, 4]; console.log(a.splice(2)) // [3, 4] console.log(a) // [1, 2] 陣列的所有元素依次傳入參數函數map()方法，回傳每一次的執行結果組成一個新陣列。 123456789var arr = [1, 2, 3, 4, 5, 6];console.log( arr.map(function(x) { return x * x; })); // [1, 4, 9, 16, 25, 36] console.log(arr); // [1, 2, 3, 4, 5, 6] // 不改變原先陣列 forEach()forEach()與map()很相似，也是對陣列的所有元素依次執行參數函數。但是，forEach方法不回傳值，只用來操作元素。 forEach的用法與map方法一致，參數是一個函數，該函數同樣接受三個參數：當前值(Value)、當前位置(Index)、整個陣列(Array)。 123456789101112var ary = [1, 2, 3, 4, 5, 6];var sum = 0;ary.forEach(function(v) { sum += v; });console.log(sum); //21 // a: 當前值 i: 當前位置(索引值) a: 整個陣列ary.forEach(function(v, i, a) { a[i] = v + 1;});console.log(ary); //[2, 3, 4, 5, 6, 7] // 改變原始陣列 forEach()無法中斷執行，會將所有元素都跑完。如果希望符合某種條件時就中斷遍歷，要使用for循環。 123456var arr = [1, 2, 3];for (var i = 0; i &lt; arr.length; i++) { if (arr[i] === 2) break; console.log(arr[i]);} forEach()不會跳過undefined和null，但會跳過空位。 1234567891011121314151617ar log = function (n) { console.log(n + 1);};[1, undefined, 2].forEach(log)// 2// NaN// 3[1, null, 2].forEach(log)// 2// 1// 3[1, , 2].forEach(log)// 2// 3 map( )和forEach()差異: map( )對執行參數函數方式跟forEach()一樣，差別在於map( )會回傳新陣列，不會修改原陣列。如果陣列遍歷的目的是為了得到回傳值，那麼使用map()，否則使用forEach()。 filter()filter()用於過濾陣列元素， 將元素依序傳入回傳的函數中， 回傳滿足條件(運算結果為true)的元素所組成的一個陣列， 該不會改變原陣列。 1234var test = [1, 2, 3, 4, 5];test.filter(function(elem) { return elem &gt; 3;}); // [4, 5] // 返回大於3的元素所組成的新陣列 filter()的參數函數可以接受三個參數：當前元素，當前位置和整個陣列 1234[1, 2, 3, 4, 5].filter(function (elem, index, arr) { return index % 2 === 0;});// [1, 3, 5] // 返回偶數位置的元素組成的新陣列。 some()，every()回傳一個 boolean值，表示判斷陣列中的元素是否符合某種條件。 兩者都接受三個參數：當前元素、當前位置和整個陣列，然後回傳一個boolean值。 some()方法只要一個(以上)元素的回傳值是true，則整個some()的回傳值就是true，否則回傳false。另外，some( )會在第一次遇到運算結果為true時，就停止繼續對元素運算 12345var arr = [1, 2, 3, 4, 5];arr.some(function (elem, index, arr) { return elem &gt;= 3;}); // true// 如果陣列arr有一個元素 &gt;= 3，some()就回傳`true`。 every方法所有元素的回傳值都是true，整個ever()才回傳true，否則回傳false 12345var arr = [1, 2, 3, 4, 5];arr.every(function (elem, index, arr) { return elem &gt;= 3;}); // false// 陣列arr並非所有元素 &gt;=3， every() 回傳 false。 範例來源 範例來源","link":"2019/07/18/Javascript/JavaScript_Array/"},{"title":"Git&#x2F;Github操作","text":"前言本篇筆記如何用Git上傳自己的專案到github上面。 下載首先，先在搜尋引擎輸入Git找到官網，進入官網後滾輪往下滑動會看到電腦可安裝版本。 Win10為例 點選下載安裝後就可以到”開始”內找尋有無git的檔案，接著打開命令提示字元(或作終端機)，在”開始”的地方搜尋 cmd ，打開介面後輸入: git –version 可以看到目前下載的版本。 接下來進行Git本機端基本操作:先到自己的專案建立資料夾，例如我在D槽建立資料夾名為: project1，回到命令提示字元設定檔案路徑，今天我將專案資料夾放D槽，那我的路徑就是 d:表示路徑切換至D槽， cd 後接資料夾路徑名稱。 基本指令如下:git init: 初始化 Git Repositorygit status: 觀察Repository檔案追蹤狀況git add 檔名 : 將檔案加入追蹤清單，如: git add .git commit -m “此處填版本訊息”: 建一組版本更新訊息git branch: 查看分支(branch) : 預設為 mastergit remote -v: 查詢遠端的repositorygit log: 查詢更改紀錄git remote add 雲端名稱(自己取) 網址 :將本機端和Github雲端上的專案相連git push 遠端空間名稱 遠端空間的分支(名稱): 將本機端的資料上傳(push) 到雲端git clone 遠端空間網址(clone那邊) 本機資料夾名稱: 下載/複製(clone)Github雲端專案到本機端開始進行實作:輸入指令: git init 進行初始化，可以看到以下畫面，要注意的點在windows下系統預設會隱藏資料夾檔案。 透過資料夾上方工具列的部分可以找到”檢視”，點擊後找到隱藏項目進行勾選，就可以看到我們隱藏的git資料夾。 隱藏的資料夾浮現了! 輸入: git status 觀察Repository檔案追蹤狀況。 可以看見預設的分支(branch)是master。 將我的專案放入該資料夾內 我們在命令提示字元輸入 git status 來看發生什麼事 跳出我們剛剛新增檔案的相關訊息 另外只要修改過專案的程式碼也會被記錄。 輸入 git add . 將檔案加入追蹤清單，並輸入git status 查看狀態。 顯示更新訊息 輸入 git commit -m “此處填版本訊息” 再輸入一次 git status，可以發現訊息已經被清空，之前的更改紀錄已經被保留，後續可以在github上看到。 git branch指令可以看到分支名稱 註冊一個github帳號，登入後看到畫面右上角 點選”Your repositories” 點入之後看到畫面中間有個綠色的”New”按鈕，取你要的repository名稱再點選creat repository。 創建完成會在畫面看到自己建立的repository名稱，點選後進入畫面。 看到自己的網址複製起來 接下來要進行遠端操作輸入 git remote -v 進行遠端查詢，因為還沒連接到遠端，所以是空的， 再來輸入 git remote add name url (name建立自己的遠端空間名稱;url為遠端地址，把剛剛複製的網址貼上即可) 輸入git remote -v 進行查詢。 輸入 git push name branchName(name 遠端空間名稱; branchName 遠端空間的分支名稱) 遠端傳輸成功! 養成確認的好習慣: git status 回到github上剛剛新增repository的地方進行頁面重整，另外在畫面可以看到我們初次新增的commit 名為 “first version”。 刷新後成功載入! 最後是實作複製的部分，把別的專案複製(clone)下來。 輸入 git clone 遠端空間網址(clone那邊) 本機資料夾名稱 以我下載demo這個repository為例 複製你要的遠端空間網址 接下來要將demo整個clone到我本機端，命名為project1的資料夾。 clone成功! 查看我的project1資料夾是不是有另一個叫project1的資料夾。 結束! 以上為今日筆記。","link":"2019/07/14/Git/git_github/"},{"title":"[JavaScript] Function","text":"前言函數是重複呼叫的程式區塊，還能接受輸入的參數，不同的參數會返回不同的值，如果運用的當，可以讓程式變得簡潔且彈性。 函數定義(Function Definition)JavaScript 有三種定義函數的方式 1.函數宣告 2.函數表達式 3.用 new 建構函式 函數宣告( Function Declaration)function宣告的區塊就是一個函數。function後面是函數名，函數名後面是()，裡面是傳入函數的參數。函數體放在{}裡面。並透過函數名()進行呼叫。 12345function hello() { console.log('Hi')}//函數呼叫hello() // Hi 函數表達式( Function Expression)採用賦值給變數的方式，又稱作匿名函數。 12345var hi = function hello() { console.log('Hi')}//匿名函數的呼叫hi() // Hi 採用函數表達式聲明函數時，function後面不帶有函數名。但加上函數名，該函數名只在函數體內部有效，在函數體外部無效。 12345var print = function x(){ console.log(typeof x);};x // ReferenceError: x is not definedprint() // function 用 new 建構函式透過new的語法建立一個函數，不過這個較少人使用。 12345678var pluse = new Function( 'x','y', 'return x + y');// 等同于function pluse(x, y) { return x + y;} 如果同一個函數被多次聲明，後面的聲明就會覆蓋前面的聲明。 12345var print = function x(){ console.log(typeof x);};x // ReferenceError: x is not definedprint() // function arguments剛才上述的例子可以發現，呼叫函數內放的參數(10,20)稱作實際參數(簡稱實參)，而function區塊內的參數(a,b)稱作形式參數(簡稱形參)。實參會被放入一個叫arguments的object裡面。 來看範例: 1234567891011function sum(a, b) { console.log(arguments); // 儲存實參[10,20] console.log(a,b); // 10 20 console.log(arguments[0],arguments[1]); // 10 20 arguments[0] = 100; // 100 將100賦值給arguments[0]，取代10 console.log(a,b); // 100 20 console.log(arguments[0],arguments[1]); // 100 20 console.log(arguments.length);// 2 獲得arguments的長度}sum(10,20); 上面例子可知sum()函數被呼叫後傳入10,20兩個實參，並存在arguments內，可以透過arguments[index]來獲得裡面的參數(index表索引值)。另外也知道可以透過=的方式進行賦值，且透過length獲得長度。 假設今天實參個數&gt;形參個數，多餘的實參會仍然被放入arguments的裡面。 1234567 // 實參 &gt; 形參個數時，多的會存在argumentsfunction sum(a, b) { console.log(arguments); // 儲存實參[10,20,30,40,50] console.log(a, b); // 10 20 console.log(arguments.length); // 5 arguments的長度}sum(10, 20,30,40,50); 上面例子可知當實參個數&gt;形參個數，多餘的還是會被存放，arguments總長度為5 arguments雖然看起來像array，但他還是一個object， array專有的方法， 不能在arguments上直接使用。 如果要讓arguments使用array方法，真正的解決方法是將arguments轉為真正的array。下面是兩種常用的轉換方法：slice方法和逐一填入新array。參考來源 1234567var args = Array.prototype.slice.call(arguments);// 或者var args = [];for (var i = 0; i &lt; arguments.length; i++) { args.push(arguments[i]);} return將返回結果回傳到函數呼叫的地方，下面做個範例: 123456function sum(a, b) { return a + b;}var h = sum(10, 20); // 回傳 a + b到此處，並賦值給 hconsole.log(h); // 30 上面範例所得回傳結果賦值給h，h=30。 另外，要注意的地方是: return 之後的程式不會執行 123456789 // return 之後的code不會執行function sum(a, b) { console.log(&quot;return之前&quot;); return a + b; console.log(&quot;如果看到我代表有執行return之後的code&quot;); // 無顯示}var h = sum(10, 20); console.log(h); // 30 提升（Hoisting）在執行任何程式碼前， JavaScript將定義的變數(variables)和函數(function)存放在記憶體內， 看起來是單純地將變數和函式宣告，移動到程式的區塊頂端，但實際位置和程式碼中完全一樣，這樣的動作只有先儲存宣告，尚未賦值。 先比較兩個例子: 1234function catName(name) { console.log(&quot;My cat's name is &quot; + name);}catName(&quot;Tigger&quot;); // 輸出結果: &quot;My cat's name is Tigger&quot; 12345catName(&quot;Chloe&quot;); // &quot;My cat's name is Chloe&quot;function catName(name) { console.log(&quot;My cat's name is &quot; + name); } 即使我們函式的程式碼之前就先呼叫它，程式碼仍然可以運作， 但是，如果採用賦值定義函數，JavaScript就會報錯。 12f(); // TypeError: undefined is not a functionvar f = function (){}; 上面的程式等同於下面的形式: 123var f;f();f = function () {}; 上面程式第二行，呼叫f的時候，f只是被宣告了，但還沒有被賦值，等於undefined，所以會報錯。 如果同時採用function命令和賦值語句聲明同一個函數，最後總是採用賦值語句的定義。 只有宣告會提升,賦值不會(變數預設值被設為undefined )所有JS的變數, 預設值為undefinedundefined 為一個JS內建的特殊值,並非字串,表示該變數尚未被設定(賦值) 如果同時採用function宣告和賦值同一個函數，一律採用賦值定義的function。 123456789var f = function () { console.log('1');}function f() { console.log('2');}f() // 1 例子主要參考MDN 函數內部的變數提升與全局作用域一樣，函數作用域內部也會產生“Hoisting”現象。var宣告的變數，不管在什麼位置，變數宣告都會被提升到函數作用域的頂部，看個例子: 12345678910111213function foo(x) { if (x = 100) { var tmp = x * 2; }}// 等同下方function foo(x) { var tmp; if (x = 100) { tmp = x * 2; };} scope(函數作用域)為變數存在的範圍， 在ES5 規範裡面，JavaScript 只有兩種作用域：一種是全局(global)作用域(簡稱全域)，所有地方都可以讀取；另一種是函數作用域，變數只在函數內部存在。ES6 又新增了塊級作用域，之後另外記錄成一篇。 簡單來說: 不在function內就稱為全域! 另外，變數在函數外所宣告稱作全域變數，在函數內稱作區域變數，不過先決條件是要在宣告var的情況下。紀錄一下區域變數和變數會遇到的情況。 全域變數可在函數內讀取 123456var v = 1;function f() { console.log(v);}f() // 1 函數內的區域變數無法從函數外部讀取 1234function f(){ var v = 1;}v // ReferenceError: v is not defined 函數內部定義的變數，會在該作用域內覆蓋同名的全域變數。 1234567var v = 1;function f() { var v = 2; console.log(v);}f(); // 2console.log(v); // 1 對於var來說，區域變數只能在函數內部宣告，在其他區塊中宣告一律都是全域變數。 1234if (true) { var x = 5;}console.log(x); // 5 函數本身也是一個值，有自己的作用域。它的作用域與變數一樣，就是其宣告時所在的作用域，與其運行時所在的作用域無關。換句話說: 函數執行時所在的作用域，是定義時的作用域，而不是呼叫時所在的作用域 1234567891011var a = 1;var b = function () { console.log(a);};function f() { var a = 2; b();}f() // 1 // 非 2上面的例子，函數b是在函數f的外部聲明的，所以它的作用域綁定在函數外層，區域變數a不會到函數f內取值，所以輸出1，而不是2。若將var a = 1刪除，就會得到Uncaught ReferenceError: a is not defined的錯誤回報。 再一個例子: 12345678910var x = function () { console.log(a);};function y(f) { var a = 2; f();}y(x) // ReferenceError: a is not defined 上面例子將函數x作為參數，傳入函數y。但函數x是在函數y外宣告，作用域綁定於函數外層，因此找不到函數y的內部變數a，導致報錯。 函數內宣告的函數，作用域綁定函數內部 1234567891011function foo() { var x = 1; function bar() { console.log(x); } return bar;}var x = 2;var f = foo();f() // 1 上面例子，函數foo內部宣告一個函數bar，bar的作用域綁定foo。當我們在foo外部取出bar執行時，變數x指向的是foo內部的x，而不是foo外部的x。 兩個以上 function 都有作用域，但不同區域的同命變數實際上是不同的。即使同名變數被宣告多次，但彼此之間沒有關係，都是獨立的變數。 123456789101112var scope = &quot;全域&quot;;function value1() { var scope = &quot;區域1&quot;; return scope;}function value2() { var scope = &quot;區域2&quot;; return scope;}console.log(value1()); //區域1console.log(value2()); //區域2console.log(scope); //全域 若無var宣告 1234567scope = '全域';function getValue() { scope = '區域'; return scope;}console.log(getValue()); //區域console.log(scope); //區域 作用域還牽涉閉包(Closure)的問題，之後找時間研究做成一篇筆記。","link":"2019/07/22/Javascript/JavaScript_Function/"},{"title":"[JavaScript] Ajax","text":"筆記Ajax前，要先理解網站的主從架構：客戶端和服務器端 客戶端(Client-side)： 指訪客的電腦和瀏覽器 伺服器端(Server-side): 回應客戶端請求為伺服器端 舉個例子，今天當使用者用瀏覽器連線上你的 ISP (網路供應商 e.g. 中華電信)造訪網站(對網站提出請求)，將網站伺服器上的資料及程式碼下載到本地端(使用者電腦)，並在瀏覽器上做呈現。 下面畫張圖表做說明: 好，現在知道造訪網頁的過程中會發生什麼事情之後，要了解要如何跟Server拿資料，發送Request。 用Javascript寫網頁的時候，可以發現Javascript是一行一行執行，這樣的特性稱作”同步”。 同步的意思是Javascript執行到某一行的時候，會等這行執行完畢，才執行到下一行，確保執行順序。 換句話說，當今天Javascript發出一個Request時，會等待Response回來，在回來之前，Javascript引擎是不會做任何動作的！ 問題來了，牽涉到網路操作時，當網路上有多個請求，如果還是維持同步的方式執行程式碼，要接收到上一個Response才能送出下一個Request 可以預期到變得非常耗時間，不穩定的操作就需要用到”非同步”的方式。 非同步是什麼意思呢？就是執行完之後就不管它了，不等結果回來就繼續執行下一行。 舉個例子： 今天要去一間小吃店吃飯，點完餐後在菜單上寫下自己所在的桌號，將菜單交給櫃台(發送請求)讓老闆知道你坐哪一桌，點餐完畢不需要站在店門口等餐點做好(不用等Response)，可以回到自己位置做自己的事(發出其他Request)，老闆自動把做好的餐點送過來(Response回來)。 最後我們就需要透過ajax操作來達到非同步的目的！ 什麼是 Ajax？全名是「Asynchronous JavaScript and XML」, 翻譯：Javascript對XML(註)的異步請求操作。 重點在於＂Asynchronous＂這個字，實現＂非同步＂的操作獲取數據內容。 另外，server端傳輸90%會是JSON格式的檔案，下面程式碼會用JSON檔做例子（點此連結參考解釋JSON） 我們可以透過 透過XMLHttpRequest遠端撈別人的資料。 過程: 打開瀏覽器 -&gt; 創建對象: XMLHttpRequest() 輸入網址 -&gt; open()方法 open()需帶入3個參數: a. 方法(method): get/post b. url c. async(異步) 3.enter(發送request) -&gt; send() 4.接收數據 request.onreadystatechange = function（） 參數：是傳遞給服務器的具體數據，例如登入的帳號密碼； 常用請求方式: get/post get請求：在請求URL(網址)後面以＂?＂的形式跟上發給服務器的參數，多個參數之間用&amp;隔開 ? 後面跟的是要傳給server的參數 &amp; 參數之間的間隔 post 請求：發給服務器的參數全部放在請求體中（URL 中看不到） 【注：post 傳遞的數據量沒有顯示，具體得看服務器的處理能力】 Http請求報文分3部分1.請求行 2.請求頭 3.請求體 *readystate屬性: Ajax請求返回的數據即存放在該屬性之下(返回字串) 0: 初始化,還沒調用open()方法 1: 載入,已調用send()方法,正在發送request 2: 載入完成,send()方法完成,已收到全部response(響應內容) 解析,正在解析response(從server端返回的數據) 4.完成,response響應內容解析完成,可在client端調用 status: server狀態(http的狀態碼):可從開發者工具觀看 1開頭: 消息類 2開頭: 成功類 3開頭: 重定向類 4開頭: (client端)請求錯誤類 ex: 404 5開頭: 伺服器(server)錯誤類 以下程式碼進行操作說明： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;script&gt; document.onclick = function () { // 點擊網頁發起ajax請求 // 創建請求對象 向XMLHttpRequest 撈資料 var request = new XMLHttpRequest() // 設置請求 request.open('GET', 'JSON1.json', true) // True表異步操作 request.send() // 發送請求 // onreadystatechange (當readystate改變時觸發) request.onreadystatechange = function () { // response解析完成 if (request.readyState == 4) { // 請求到數據 if (request.status == 200) { // 200 -&gt; success document.write(request.response) // 數據轉為json對象(object) -&gt; json數據解析 var jsonData = JSON.parse(request.response) // 獲取key(people) 內的陣列 var people = jsonData.people // 渲染 var oUl = document.createElement('ul') for (var i = 0; i &lt; people.length; i++) { var oLi = document.createElement('li') // 對每個people下的object找對應的key(firstName)進行渲染 oLi.innerHTML = people[i].firstName; oUl.appendChild(oLi) } document.body.appendChild(oUl) } } } } &lt;/script&gt; 資料格式為:12345678910111213141516171819{ &quot;people&quot; : [ { &quot;email&quot; : &quot;aaaa&quot;, &quot;firstName&quot; : &quot;Brett&quot;, &quot;lastName&quot; : &quot;McLaughlin&quot; }, { &quot;email&quot; : &quot;bbbb&quot;, &quot;firstName&quot; : &quot;Jason&quot;, &quot;lastName&quot; : &quot;Hunter&quot; }, { &quot;email&quot; : &quot;cccc&quot;, &quot;firstName&quot; : &quot;Elliotte&quot;, &quot;lastName&quot; : &quot;Harold&quot; } ]} 輸出結果如下圖： Same Origin Policy但是如果將原本的JSON1的檔案改成串接到別人網站的連結時： wtf…. 瀏覽器立馬報錯。 為什麼會有這個錯誤呢？ 瀏覽器因為安全性的考量，有一個東西叫做同源政策，Same-origin policy。 現在這個網站的網站「不同源」的時候，瀏覽器一樣會發 Request，但是會把 Response 給擋下來，JavaScript 拿到並且傳回錯誤。 不同源是什麼意思？？？簡言之，只要是網域（ Domain） 不一樣就是不同源，網址開頭http和https也不同源，端口號(port)不一樣也不同源。相關的解決方案 ＊註：XML為儲存網頁數據的結構 參考資料： http://www.cnblogs.com/SanMaoSpace/archive/2013/06/15/3137180.html http://huli.logdown.com/posts/2223581-ajax-and-cors","link":"2019/07/14/Javascript/ajax(basic)/"},{"title":"[JavaScript] DOM 操作","text":"前言這篇筆記先做一部分的 DOM 基礎操作，後續再慢慢補。 BOM (Browser Object Model；瀏覽器物件模型)是瀏覽器所有功能的核心，與網頁的內容無關。 早期各家瀏覽器廠商幾乎各自在自家瀏覽器上實作功能，沒有同一規範，非常混亂。後來 W3C 把各家瀏覽器都有實作的部分，進行整合納入 HTML5 的標準中，也就是 BOM 。 來源 BOM 的核心是 window 物件。 在瀏覽器裡的 window 物件提供兩個功能: ECMAScript 標準裡的「全域物件」 (Global Object)JavaScript 用來與瀏覽器溝通的窗口 更詳細的解釋保留在這篇好文。 DOM(文件物件模型；Document Object Model）是 HTML、XML 和 SVG 文件的程式介面(API)。它提供了一個文件（樹）的結構化表示法，並定義讓程式可以存取並改變文件架構、風格和內容的方法。DOM 提供了文件以擁有屬性與函式的節點與物件組成的結構化表示—MDN解釋。 另外，DOM 樹是由一個一個節點所構成，最上層的節點做 document， HTML 裡面每個元素、屬性都代表著其中一個節點。 DOM 的 document 其實也是 window 物件的子物件之一，window 是 BOM 物件，而非 js 物件 DOM 標準被分成 3 個不同的部分組成： 核心 DOM — 對所有文檔類型標準模型 XML DOM — 為 XML 文檔標準模型 HTML DOM — 為 HTML 文檔的標準模式 除了根節點，其他節點都有三種層級關係: 父節點關係（parentNode): 該節點的上層節點子節點關係(childNode): 該節點的下層節點同級節點關係（sibling）: 與該節點同層的節點 節點通常分成以下幾種:Document: 這份文件，也就是這份 HTML 檔的開頭，所有的一切都會從 Document 開始往下執行。 DocumentType：doctype標籤（如&lt;!DOCTYPE html&gt;） Element: 指文件內的各個標籤，因此像是 &lt;div&gt;、&lt;p&gt; 等等各種 HTML Tag 都是被歸類在 Element 裡面。 Text: 標籤包起來的文字，例: &lt;h1&gt;Hello World&lt;/h1&gt; 中， Hello World 被 &lt;h1&gt; 標籤包起來，因此 Hello World 就是此標籤的 Text Attribute Attribute 就是指各個標籤內的相關屬性，如&lt;a&gt;標籤的href。 Comment：註釋 DocumentFragment：文檔片段節點屬性有 3 種:1.nodeType 2.nodeName( 屬性含有某個節點的名稱) 3.nodeValue nodeTypenodeType 屬性返回一個整數值，表示節點的類型。 不同節點有不同的 nodeType 屬性值: 元素節點（element）：1 屬性節點（attr）：2 文本節點（text）：3 文檔節點（document）：9 註釋節點（Comment）：8nodeNamenodeName 屬性返回節點的名稱。 不同節點的 nodeName 返回的屬性值如下 元素節點(element)：大寫標籤名 屬性節點(attr): 屬性名稱(非大寫) 文本節點(text)：#text 文檔節點(document)：#document 註釋節點（Comment）：#commentnodeValuenodeValue 屬性返回一個字串，表當前節點本身文本值。 只有文本節點（text）、註釋節點（comment）和屬性節點（attr）有文本值， 其他類型的節點一律返回 null 元素節點(element)：null 屬性節點(attr): 屬性值 文本節點(text)：文本內容 文檔節點(document)：null 註釋節點(Comment)：#comment範例: 12345678910111213141516171819// 元素節點var oBox = $('box');alert(oBox.nodeName); // DIV // 注意大寫alert(oBox.nodeType); // 1alert(oBox.nodeValue); // null// 屬性節點var att = oBox.attributes[0]; // 獲取節點屬性alert(att.nodeName); // id // 注意小寫alert(att.nodeType); // 2alert(att.nodeValue); // box})&lt;body&gt; &lt;div id=&quot;box&quot;&gt; hello &lt;/div&gt;&lt;/body&gt; textContent textContent 屬性返回當前節點和它的所有子節點的文本內容。textContent 屬性自動忽略當前節點內部的 HTML 標籤，返回所有文本內容。在插入文本時，會將標籤解釋為文本，而不會當作標籤處理。 12345// HTML // &lt;div id=&quot;divA&quot;&gt;This is &lt;span&gt;some&lt;/span&gt; text&lt;/div&gt;document.getElementById('divA').textContent// This is some text firstChildfirstChild 屬性返回當前節點的第一個子節點，如果當前節點沒有子節點，則返回 null。 12345// HTML&lt;p id=&quot;p1&quot;&gt;&lt;span&gt;First span&lt;/span&gt;&lt;/p&gt;var p1 = document.getElementById('p1');p1.firstChild.nodeName // &quot;SPAN&quot; firstChild 返回的除了元素節點，還可能是文本節點或註釋節點。 1234567// HTML&lt;p id=&quot;p1&quot;&gt; &lt;span&gt;First span&lt;/span&gt;&lt;/p&gt;var p1 = document.getElementById('p1');p1.firstChild.nodeName // &quot;#text&quot; lastChildlastChild 屬性返回當前節點的最後一個子節點，如果當前節點沒有子節點，則返回 null。用法與 firstChild 屬性相同。 DOM 基本操作 document.getElementById(‘idName’) 找尋 DOM 中符合此 id 名稱的元素，並回傳對應的元素， 這個方法只能在 document上使用，不能在其他元素節點上使用。。 document.getElementsBytagName(‘tag’) 找尋 DOM 中符合此 tag 名稱的所有元素，並回傳對應的元素集合(HTMLCollection )，為 HTMLCollection 。 document.getElementsByClassName(‘className’) 找尋 DOM 中符合此 class 名稱的所有元素，並回傳相對應的 element 集合，為 HTMLCollection 。 document.querySelector(‘selector’) document.querySelector 方法接受一個 CSS 選擇器作為參數，返回匹配該選擇器的元素節點。如果有多個節點滿足匹配條件，則返回第一個匹配的節點。如果沒有發現匹配的節點，則返回 null。 另外， querySelector 也可以用來選擇下一層的元素 12345// HTML&lt;h1 id=&quot;titleId&quot; class=&quot;titleClass&quot;&gt;&lt;b&gt;123&lt;/b&gt;&lt;/h1&gt;// querySelectordocument.querySelector('.titleClass b'); // 123 document.querySelectorAll(‘selector’) document.querySelectorAll 方法與 querySelector 用法類似，區別是返回一個 NodeList 集合，包含所有匹配給定選擇器的節點。 這兩個方法都支持複雜的 CSS 選擇器。 12345// 選擇 data-foo-bar 屬性為 someval 的元素document.querySelectorAll('[data-foo-bar=&quot;someval&quot;]');// 同時選擇 div，a，script 三個元素document.querySelectorAll('DIV, A, SCRIPT'); querySelector和getElementsByClassName 的比較123456789101112131415// HTML&lt;ul class=&quot;view&quot;&gt; &lt;li&gt;第一&lt;/li&gt; &lt;li&gt;第二&lt;/li&gt; &lt;li&gt;第三&lt;/li&gt;&lt;/ul&gt;// JSvar text = document.querySelector(&quot;.view&quot;);var text1 = document.getElementsByClassName('view');var text2 = document.getElementsByTagName('h1');console.log(text1);console.log(text2); console.log(text); 上圖可知 getElementByTagName 和 getElementsByClassName 都是返回一個類似陣列的元素集合。 querySelector 系列的是 Static(靜態)的 node list，而 getElementsBy*系列的返回的是一個 Live(動態) Node List。 12345678910111213// Demo 1var ul = document.querySelectorAll('ul')[0], lis = ul.querySelectorAll(&quot;li&quot;);for(var i = 0; i &lt; lis.length ; i++){ ul.appendChild(document.createElement(&quot;li&quot;));}// Demo 2var ul = document.getElementsByTagName('ul')[0], lis = ul.getElementsByTagName(&quot;li&quot;); for(var i = 0; i &lt; lis.length ; i++){ ul.appendChild(document.createElement(&quot;li&quot;)); } Demo 2 中的 lis 是一個動態的 Node List，每一次調用 list 都會重新對 document 進行查詢，導致無限循環的問題。Demo 1 中的 lis 是一個靜態的 Node List，是一個 li 集合，對 document 的任何操作都不會對其產生影響。 createElement()創建元素節點如果需要修改內容或是設定屬性還需要用其他 DOM 操作，如:textContent、setAttribute。 123456// 創建元素節點var oTitle = document.createElement('h1')oTitle.textContent = '你好' // 你好// 添加元素到介面中: appendChild()document.body.appendChild(oTitle); 用createElement 與 innerHTML 寫入文檔的比較:`createElement`: 1.不會把原本的em所取代。 2.方法：組完字串後,將語法傳入html進行渲染 3.優點：效能較好 4.缺點：資安風險，易引起腳本注入攻擊。 `innerHTML`: 1.會先將原有的內容全部刪除後再做新增 2.方法：以DOM節點來處理 3.優點：安全性較高 4.缺點：效能較差getAttribute() 獲取節點屬性值getAttribute()只返回字符串， 不會返回其他類型的值。 1234567891011121314151617// HTML&lt;div id=&quot;box&quot; class=&quot;section&quot; data-index=&quot;0&quot; data-isShow=&quot;true&quot;&gt; Test Statement&lt;/div&gt;// 自定義屬性oBox.tab = 10// 獲取節點屬性alert(oBox.tab) // 10// 獲取節點屬性的值var att = oBox.attributes; // 獲取到: id=&quot;box&quot; class=&quot;section&quot; data-index=&quot;0&quot; data-isShow=&quot;true&quot;alert(att['class'].nodeValue) // sectionalert(att['id'].nodeValue) // box// 獲取節點屬性: getAttribute()alert(oBox.getAttribute('data-index')) // 0 setAttribute() 創建屬性.setAttribute()用於為當前元素節點新增屬性。如果同名屬性已存在，則相當於編輯已存在的屬性。 setAttribute(“屬性名稱”, “屬性內容”) 12var b = document.querySelector('button');b.setAttribute('name', 'myButton'); removeAttribute() 刪除屬性.removeAttribute()移除指定屬性。 123456// old HTML // &lt;div id=&quot;div1&quot; align=&quot;left&quot; width=&quot;200px&quot;&gt; document.getElementById('div1').removeAttribute('align');// now HTML// &lt;div id=&quot;div1&quot; width=&quot;200px&quot;&gt; 來源1 來源2 W3C","link":"2019/07/21/Javascript/JavaScript_DOM/"},{"title":"[JavaScript] Date&amp; Timer","text":"前言定時器和倒數計時器所用到: Date()、 setTimeout()和setInterval()這幾個方法來完成，算是蠻常用到的。 Date()Date()是JavaScript 原生的時間方法，它以國際標準時間(UTC)1970年1月1日00:00:00作為時間起點，單位為毫秒。 取得當前時間的方法:可以作為一般函數直接呼叫，回傳當前時間 1console.log(Date()); // Mon May 13 2019 09:32:21 GMT+0800 (台北標準時間) 即使帶有參數，Date作為普通函數使用時，返回的還是當前時間 1console.log(Date(2019,5,13)); // Mon May 13 2019 09:32:21 GMT+0800 (台北標準時間 new 方法透過new 方法賦值給一變數，透過變數取得當前時間， 返回的是字串。 123var nowTime = new Date();console.log(nowTime); // Mon May 13 2019 09:32:21 GMT+0800 (台北標準時間) Date()方法可接受多種格式參數，回傳一個該參數對應的時間 123456789101112131415// 参数為時間零點開始計算的毫秒数var nowTime = new Date(1378218728000)console.log(nowTime); // Tue Sep 03 2013 22:32:08 GMT+0800 (CST)// 参数為日期字串var nowTime = new Date('January 6, 2013');console.log(nowTime); // Sun Jan 06 2013 00:00:00 GMT+0800 (台北標準時間)// 参数為多個整数值，// 代表年、月、日、小時、分鐘、秒、毫秒var nowTime = new Date(2013, 0, 1, 0, 0, 0, 0)console.log(nowTime); // Tue Jan 01 2013 00:00:00 GMT+0800 (CST) Date方法使用函數的參數，有幾點要注意: 只要是能被Date.parse()解析的字串，都可以當作參數 以下返回的都是同一個時間。 1234567891011new Date('2019-5-13')new Date('2019/5/13')new Date('05/13/2019')new Date('2019-May-13')new Date('May, 15, 2019')new Date('May 15, 2019')new Date('May, 15, 2019')new Date('May 15, 2019')new Date('15 May 2019')new Date('15, May, 2019')// Mon May15 2019 09:32:21 GMT+0800 參數為年、月、日等多個整數時，年和月是不能省略的，其他參數都可以省略的。也就是說，至少需要兩個參數，因為如果只使用“年”這一個參數，Date會將誤為毫秒數。 下面程式碼中，2013被解釋為毫秒數，而不是年份 12new Date(2013)// Thu Jan 01 1970 08:00:02 GMT+0800 下面範例返回的都是2013年1月1日零點 12345678new Date(2013, 0)// Tue Jan 01 2013 00:00:00 GMT+0800 (CST)new Date(2013, 0, 1)// Tue Jan 01 2013 00:00:00 GMT+0800 (CST)new Date(2013, 0, 1, 0)// Tue Jan 01 2013 00:00:00 GMT+0800 (CST)new Date(2013, 0, 1, 0, 0, 0, 0)// Tue Jan 01 2013 00:00:00 GMT+0800 (CST) 重要的參數取值範圍，需特別注意月份計算的起始點是0 年：使用四位數年份，比如2000。如果寫成兩位數或個位數，則加上1900，即10代表1910年。如果是負數，表示公元前。月：0表示一月，依次類推，11表示12月。日：1到31。小時：0到23。分鐘：0到59。秒：0到59毫秒：0到999 參數如果超出了正常範圍，會被自動換算12345678910111213new Date(2013, 15)// Tue Apr 01 2014 00:00:00 GMT+0800 new Date(2013, 0, 0)// Mon Dec 31 2012 00:00:00 GMT+0800// 日期設為0，表上個月的最後一天參數還可以使用負數，表示扣去的時間new Date(2013, -1)// Sat Dec 01 2012 00:00:00 GMT+0800 new Date(2013, 0, -1)// Sun Dec 30 2012 00:00:00 GMT+0800 get()除上述方法，還可以透過一系列get方法，獲取特定時間， 且返回的都是*整數**: getTime()：返回當前時間距離1970年1月1日00:00:00的毫秒數getDate()：返回當前時間對應每個月的幾號（從1開始）。getDay()：返回星期幾，星期日為0，星期一為1，以此類推。getFullYear()：返回四位的年份。getMonth()：返回月份（0表示1月，11表示12月）。getHours()：返回小時（0-23）。getMilliseconds()：返回毫秒（0-999）。getMinutes()：返回分鐘（0-59）。getSeconds()：返回秒（0-59）。 範例: 1&lt;iframe src=&quot;https://medium.com/media/b98d1fb2ab2415601ae8fd733e890dde&quot; frameborder=0&gt;&lt;/iframe&gt; 時間設置的方法set()一系列set*方法，用來設置當前時間。 setDate(date)：設置當前時間對應的每個月的幾號（1-31），返回改變後時間(毫秒)。setFullYear(year)：設置四位年份。setHours(hour)：設置小時（0-23）。setMilliseconds()：設置毫秒（0-999）。setMinutes(min)：設置分鐘（0-59）。setMonth(month)：設置月份（0-11）。setSeconds(sec)：設置秒（0-59）。setTime(milliseconds)：設置毫秒時間。 TimerJavaScript提供定時的方法，可以設置定時器。 setTimeout()setTimeout()用來指定某個函數或某段code在多少毫秒之後執行。var timer = setTimeout(function|code, delay); setTimeout()函數接受兩個參數，第一個參數function|code是將要延遲執行的函數名稱或一段code，第二個參數delay是延遲執行的毫秒數。 第二個參數如果省略，則默認為0。 12345function test() { console.log(2);}setTimeout(test, 3000); // 3秒後執行，輸出2 clearTimeout()取消setTimeout()設的定時器。 setInterval()setInterval()函數的用法與setTimeout()完全一致，差別在於setInterval()可以無限次的設置定時器執行。 1var timer = setInterval(function|code, delay) clearInterval()取消setInterval()設的定時器。 setInterval()可以無限次的設置定時器，所以setInterval()有重複設置的問題。 1&lt;iframe src=&quot;https://medium.com/media/d515060fcf7a2e27e7d7b4c74e49227c&quot; frameborder=0&gt;&lt;/iframe&gt; 上述的code會遇到點擊兩次start鈕時，index+1的時間會加快，點stop鈕無法停止的狀況。 解決辦法是設置if條件判斷: 1&lt;iframe src=&quot;https://medium.com/media/b04f24f869d003a1dd15a0dcc7acfa1d&quot; frameborder=0&gt;&lt;/iframe&gt; 將停止時鐘的函數在後面添加timer=null，表時鐘狀態為關閉，並且在點擊事件函數內的時鐘設置，多添加if條件判斷，確定時鐘狀態為null才能開啟時鐘，解決重複設置的問題。 實作一個倒數計時器1&lt;iframe src=&quot;https://medium.com/media/c8c8068fc7c9b32c16d657964c6133a8&quot; frameborder=0&gt;&lt;/iframe&gt; 透過取得當前時間，以及設置結束時間兩者之間的差距，配合setInterval()來完成。參考來源1 參考來源2","link":"2019/07/13/Javascript/datatime/"},{"title":"[JavaScript] ES6 Syntax","text":"前言筆記一下這陣子學的一些 ES6 語法 template literal（模版字串）模板字符串使用反引號(``)來代替普通字符串中的用雙引號和單引號。模板字符串可以包含特定語法（${expression}）的佔位符。–MDN 使用模版字串可以讓 code 用更優雅的方式來表示，以下做比較。 傳統字串拼接 1234567const name = &quot;Bob&quot;;const lastName = &quot;sanders&quot;;const age = 25;const arr = document.querySelector(&quot;#test&quot;);const dialog = &quot;My name is &quot; + name + &quot;&quot; + lastName + &quot;. And I'm &quot; + age + &quot; years old&quot;; 模版字串寫法，省略許多 “ + “ 號，${}內可放入變數 1const dialog = My name is ${name} ${lastName}.And I'm ${age} years old; 除此之外，還可以套用標籤，可以 1arr.innerHTML = `&lt;h1&gt; My name is ${name} &lt;/h1&gt;`; // 輸出 具&lt;h1&gt;標籤特性的文字 Destructure(解構)ES6 允許按照一定規則，從陣列和物件(object)中提取值，對變數進行賦值，這被稱作解構。範例參考來源: MDN 陣列的解構賦值 可以從陣列中提取值，按照對應位置，對變數賦值。 12345678910111213ES5 let a = 1; let b = 2; let c = 3;** ES6 let [a, b, c] = [1, 2, 3]; // 變數聲明並賦值時的解構 var foo = [&quot;one&quot;, &quot;two&quot;, &quot;three&quot;]; var [one, two, three] = foo; console.log(one, two, three); // &quot;one&quot; 對陣列使用嵌套的方式進行解構12let [foo, [[bar], baz]] = [1, [[2], 3]];console.log(foo, bar, baz); // 1 2 3 忽略某些返回值12345let [, , third] = [&quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;];console.log(third); // &quot;baz&quot;let [x, , y] = [1, 2, 3];console.log(x, y); // 1 3 解析一個從函數返回的陣列1234567function f() { return [1, 2];}var a, b;[a, b] = f();console.log(a, b); // 1 2 交換變數12345var a = 1;var b = 3;[a, b] = [b, a];console.log(a, b); // 3 1 當解構一個陣列時，可以使用剩餘模式，將陣列剩餘部分賦值給一個變數 123let [head, …tail] = [1, 2, 3, 4];console.log(head) // 1console.log(tail) // [2, 3, 4] 如果解構不成功，變數的值就等於 undefined 12let { foo } = { bar: &quot;baz&quot; };console.log(foo); // undefined 物件的解構賦值除了上述的陣列，還可以解構物件起手式 123let { foo, bar } = { foo: &quot;aaa&quot;, bar: &quot;bbb&quot; };console.log(foo); // &quot;aaa&quot;console.log(bar); // &quot;bbb&quot; 通過解構，無需聲明即可賦值一個變數 12345({ a, b } = { a: 1, b: 2 });console.log(a, b); // 1 2// 如同var { a, b } = { a: 1, b: 2 }; 從一個對像中提取變數並賦值給和物件屬性名不同的新的變數名 1234let o = { p: 42, q: true };let { p, q } = o;console.log(p, q); // 42 true 物件可賦值給另一物件相同的屬性名 123456789101112131415const person = { name: &quot;Tom&quot;, lastName: &quot;Chen&quot;, age: 25};// ES5const name = person.name;const lastName = person.lastName;// ES6const { name: firstName, age: old } = person;console.log(firstName, old); // Tom 25 默認值: 物件的變數可以先賦予默認值。當要提取的物件沒有對應的屬性，變數就被賦予默認值。 123456789var { a = 10, b = 5 } = { a: 3 };console.log(a); // 3console.log(b); // 5// 也可以給新的變量命名並提供默認值var { a: aa = 10, b: bb = 5 } = { a: 3 };console.log(aaㄝ, bb); // 3 5 物件的解構與陣列有一個重要的不同: 陣列的元素是按次序排列的，變數的取值由它的位置決定；而物件的屬性沒有次序，變數必須與屬性同名，才能取到正確的值。 物件可作為函數參數傳入同個屬性名的值1234567891011const person = { name: &quot;Tom&quot;, lastName:&quot;Chen&quot;, age:25}function sayName({*name*, *lastName*}) { console.log(name, lastName); // Tom Chen}sayName(person); 以函數回傳一個物件，將屬性名賦值給另一個物件相同的屬性名 12345678910function getPerson() { return { name1: &quot;Bob&quot;, lastName: &quot;Chen&quot;, age: 21 };}const { name1, age1 } = getPerson();console.log(name1, age1); // Bob 21 Arrow function(箭頭函式)ES6 允許使用箭頭(=&gt;)定義函數，箭頭函數省略了 ES5 的 function 這個關鍵字，讓 code 更簡潔。 參數如果只有一個可以省略小括號。函數執行的 code 執行只有一行可省略 return 123456var f = v =&gt; v;// 等同var f = function(v) { return v;}; 如果箭頭函數不需要參數或需要多個參數，就使用一個圓括號代表參數部分。 1234567891011var f = () =&gt; 5;// 等同var f = function() { return 5;};var sum = (num1, num2) =&gt; num1 + num2;// 等同var sum = function(num1, num2) { return num1 + num2;}; 如果箭頭函數直接返回一個object(物件)，必須在對像外面加上{}大括號 參數為一物件時 const obj = () =&gt; ({ name: &quot;bob&quot;, age: 25 }); const person = obj(); console.log(person); {name: &quot;bob&quot;, age: 25} [Top](#6bb4) [template literal](#b48d) [Destructure](#14e7) [Arrow function](#ade1) [rest&amp;spread operator](#c6e9) [bottom](#1fdc)rest operator(其餘運算子)&amp;spread operator(展開運算子)在 ES6 中，新增了一個 “…” 的關鍵字， “…” 的關鍵字依據使用時機點的不同而功能有所不同，主要分為: rest operator(其餘運算子)&amp;spread operator(展開運算子) 摘要 兩個運算子符號都是三個點(…) 都是在陣列值運算 一個是展開陣列中的值，一個是集合其餘的值成為陣列 spread operator(展開運算子)把一個陣列展開成個別的值，就是把原先陣列內的值一個一個拆解。展開運算子有幾個特性: 淺層複製: 陣列與物件相同都有著傳參考的特性。若把陣列賦予到另一個值上，修改其中一個另一個也會跟著變動(連帶責任 XD)。 傳統方法123456const random = [&quot;txt1&quot;, &quot;text2&quot;];const more = random;more[0] = &quot;new&quot;;console.log(random); [&quot;new&quot;, &quot;text2&quot;] // 改變原始陣列console.log(more); [&quot;new&quot;, &quot;text2&quot;] ###展開運算子寫法: 1234567891011const numbers = [1, 2, 3, 4];const value = [...numbers];console.log(value); [1, 2, 3, 4]value.push(5);console.log(numbers); [1, 2, 3, 4] // 不改變原始陣列console.log(value); [1, 2, 3, 4, 5] 類陣列轉成純陣列JavaScript 中有許多披著陣列的外皮，但卻不能使用陣列方法處理的類陣列。 12345const list = document.querySelectorAll(&quot;.list-item&quot;);console.log(list); // NodeList(3) [li.list-item, li.list-item.special, li.list-item]const special = list.filter(item =&gt; item.classList.contains(&quot;special&quot;)); // NodeList(3) 無法用陣列處理console.log(special); // list.filter is not a function 使用展開運算子將類陣列轉成純陣列1234567const list = [...document.querySelectorAll(&quot;.list-item&quot;)];console.log(list); // [li.list-item, li.list-item.special, li.list-item]// 過濾出有special這個 class名稱的元素const special = list.filter(item =&gt; item.classList.contains(&quot;special&quot;));console.log(special); // [li.list-item.special] 合併陣列傳統兩個陣列合併用 concat() 1234567// 合併陣列 傳統寫法const names = [&quot;John&quot;, &quot;Peter&quot;, &quot;Bob&quot;];const moreName = [&quot;Susy&quot;, ...names];const namesAll = names.concat(moreName);console.log(even); // [&quot;John&quot;, &quot;Peter&quot;, &quot;Bob&quot;, &quot;Ken&quot;, &quot;Susy&quot;, &quot;John&quot;, &quot;Peter&quot;, &quot;Bob&quot;] 展開運算子可以有一樣的效果，code 的可讀性更高12345const names = [&quot;John&quot;, &quot;Peter&quot;, &quot;Bob&quot;];const moreName = [&quot;Susy&quot;, ...names];const namesAll1 = [...names, ...moreName];console.log(namesAll1); // [&quot;John&quot;, &quot;Peter&quot;, &quot;Bob&quot;, Susy&quot;,&quot;John&quot;, &quot;Peter&quot;, &quot;Bob&quot;] 轉變字串為單字串的陣列123const letters = &quot;hello there&quot;;const arr = […letters];console.log(arr); ['h', 'e', 'l', 'l', 'o', ' ', 't', 'h', 'e', 'r', 'e'] 可以用來把某個陣列展開，然後傳入函式作為傳入參數值123456789function add(num1, num2, num3, num4) { let result = num1 + num2 + num3 + num4; return result; }// const result = add(numbers); // 1,2,3,4 undefined undefined undefined// 把陣列中的元素取出並相加const result = add(...numbers); // 10console.log(result); 其餘運算子（rest operator）其餘運算字會把輸入函式中的參數值變成陣列的形式，Function 接受的參數數量不固定，可在參數前面加上” … ”，並使用陣列的方法(forEach、map、reduce) 。 123456789101112function sum(...args) { console.log(args); // (5) [1, 2, 3, 4, 5] let result = args .filter(item =&gt; item &gt; 3) .reduce((acc, curr) =&gt; { acc += curr; return acc; }, 0); console.log(result); }sum(1, 2, 3, 4, 5); // 9 如果 function 有先定義別的參數，就會將傳入的參數值先給定義好的參數，剩下的就全部填入其餘參數。 1234567function restArr(x, y, ...others) { console.log(&quot;x&quot;,x); // x： 1 console.log(&quot;y&quot;,y); // y： 2 console.log(&quot;others&quot;,others); // others： [3, 4, 5]}restArr(1, 2, 3, 4, 5); 其餘參數必須是函式內參數的「最後一個」。如果放在其餘的參數前，就會產生錯誤。參考來源: ECMAScript 6 入門 、 MDN","link":"2019/07/29/Javascript/javascript_ES6/"},{"title":"[JavaScript] Event","text":"前言這篇筆記關於Javascript事件操作的觀念。JavaScript 是一個事件驅動 (Event-driven) 的程式語言。 什麼是事件驅動?就是當瀏覽器載入網頁，開始讀取文檔(document)後，雖然馬上會讀取 JS事件相關的程式碼，但需等到「事件」被觸發(滑鼠點擊、按下鍵盤)後，才會再執行相應程式。 Event Flow(事件流程)一個事件發生後，會在子元素和父元素之間傳遞。傳遞分成三階段。我們可以觀察一下網頁元素接收事件的順序。 第一階段：從根結點window傳導到目標節點（上層傳到底層），稱為”捕獲階段”（capture phase）。第二階段：在目標節點上觸發，稱為”目標階段”（target phase）。第三階段：從目標節點傳導回window節點(從底層傳回上層），稱為”冒泡階段”（bubbling phase）。 addEventListener() 事件監聽用於綁定事件的監聽函數，可以利用addEventListener()來進行DOM的事件操作， 用於在當前節點或對象上面。 .addEventListener(type, listener[, useCapture]); 這個方法中可傳入3個參數: type：事件名稱，有區分大小寫。 listener：監聽函數。事件發生時，會呼叫該監聽函數。 useCapture：Boolean值，true: 事件捕獲 ; false: 事件冒泡。 Event Propagation(事件冒泡)當一個元素接收到事件後,會將接收到的事件往上傳給父元素,一直傳到頂端的根節點(document)。 來看個例子: 今天有3個不同顏色及大小的方格分別為紅(view1)、藍(view2)、紫(view3)，點擊view3(被包在最裡面)時，view2和view1和document也會同時被觸發。 示意圖: 觀察觸發的順序，可以發現由觸發事件節點由內而外，來比較一下相對於它的「事件捕獲」。 Event Capturing(事件捕獲)相對於「事件冒泡」，「事件捕獲」是從最外層，一層一層內方向傳遞事件，和「事件冒泡」相反。再使用一次剛剛的圖作範例XD 實作的話可以用下方的程式碼: 12345678910111213141516171819202122232425262728// HTML&lt;div id=&quot;view1&quot;&gt; &lt;div id=&quot;view2&quot;&gt; &lt;div id=&quot;view3&quot;&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;// JSoView1.addEventListener('click', function () { console.log('view1 --- 事件捕獲') }, true)oView2.addEventListener('click', function () { console.log('view2 --- 事件捕獲')}, true)oView3.addEventListener('click', function () { console.log('view3 --- 事件捕獲')}, true) // ---------------oView1.addEventListener('click', function () { console.log('view1 --- 事件冒泡')}, false)oView2.addEventListener('click', function () { console.log('view2 --- 事件冒泡')}, false)oView3.addEventListener('click', function () { console.log('view3 --- 事件冒泡')}, false) 點擊view3獲得的結果會是 事件傳遞流程事件一開始從文檔的根節點流向目標對象(捕獲階段)，然後在目標對向上被觸發(目標階段)，之後再回到文檔的根節點。 如果今天不想要將事件傳遞到所有的父元素節點，那要如何阻止事件冒泡呢? 程式碼如下: 非IE: stopPropagation() ; IE: ev.cancelBubble = true;兼容寫法: ev.stopPropagation ? ev.stopPropagation() : ev.cancelBubble = true; 我們可以在監聽事件的函數傳入一個ev做參數，作為事件來源。回到剛才例子，假設只想要讓事件從頂層傳遞到view2的話，可以在view2的事件監聽處打上上面那段程式碼。範例如下: 123456789101112131415161718192021222324252627282930// HTML&lt;div id=&quot;view1&quot;&gt; &lt;div id=&quot;view2&quot;&gt; &lt;div id=&quot;view3&quot;&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;// JSoView1.addEventListener('click', function () {console.log('view1 --- 事件捕獲')}, true)oView2.addEventListener('click', function (ev) { // 阻止事件冒泡 ev.stopPropagation ? ev.stopPropagation() : ev.cancelBubble = true; console.log('view2 --- 事件捕獲')}, true)oView3.addEventListener('click', function () { console.log('view3 --- 事件捕獲')}, true) //------------------------------oView1.addEventListener('click', function () { console.log('view1 --- 事件冒泡')}, false)oView2.addEventListener('click', function () { console.log('view2 --- 事件冒泡')}, false)oView3.addEventListener('click', function () { console.log('view3 --- 事件冒泡')}, false) 所得結果 事件捕獲與冒泡都同樣適用。 preventDefault 取消預設行為可以取消HTML元素的預設行為 ，如 &lt;a&gt; 連結，或表單submit 等等， 如果我們需要在這些元素上綁定事件，但又不想要觸發它的預設行為，那取消它們的預設行為就是很重要的一件事。範例:有一個通往 yahoo連結 &lt;a&gt;: 12345678 &lt;a id=&quot;link&quot; href=&quot;https://tw.yahoo.com/&quot;&gt;Google&lt;/a&gt;````假設點擊這個 `&lt;a&gt;`時，我希望瀏覽器執行 `console.log('yahoo!')`; 那可以先註冊 click 事件```javascript var link = document.querySelector('#link'); link.addEventListener('click', function (e) { console.log('yahoo!'); }, false); 結果會發現，即便我們為了&lt;a&gt; 去註冊了 click 事件，但是當我點擊這個 link 的時候，瀏覽器依然會把我帶去 yahoo的網頁。 如果這時候，我希望執行的是console.log('yahoo!'); 而不是直接把我帶去 yahoo的網站，那麼可以怎麼做？ 這時候可以利用 event 物件提供的 event.preventDefault() ： 12345var link = document.querySelector('#link'); // 在 evend function 加上 e.preventDefault(); link.addEventListener('click', function (e) { e.preventDefault(); console.log('yahoo!'); }, false); 再點擊 link 一次，你會發現瀏覽器預設的跳轉頁面的行為不見了，console.log('yahoo!'); 也可順利執行。 JavaScript 的 addEventListener() 裡，最後面加上 return false 也會有同樣的效果。在 jQuery 的addEventListener() 裡最後加上 return false 來得到preventDefault() 與 stopPropagation() 的效果是沒問題的。 事件(event)對象:當一個事件發生時,和當前對象發生的相關信息,都會臨時保存在這個對象中 事件源:觸發該事件的來源節點，以下為兼容不同瀏覽器的寫法: IE: srcElement屬性firefox target屬性google/safari: srcElement、target都有 例子: 123456789101112// HTML&lt;input type=&quot;text&quot; placeholder=&quot;帳號&quot; id=&quot;user&quot;&gt;&lt;br /&gt; // JSvar oUser = $('user')oUser.onkeydown = function (ev) {// 按下哪個鍵? // 事件來源ev = event || ev // 查找按下的鍵對應的codeconsole.log(ev.keyCode); // Enter對應的code是13 ; tab是9} 使用keydown事件來觸發，我們可以傳入ev這個參數做事件源，根據使用者在鍵盤上輸入的鍵所輸出的數值，來確定使用者按下哪個鍵，例如輸入enter，輸出的數值就是13，tab鍵則是9。 舉個應用: 123456789101112131415161718// HTML&lt;div id=&quot;test&quot;&gt;&lt;/div&gt; // JSvar oTest = $('test')oTest.onclick = function (ev) {// 事件對象ev = window.event || ev // 事件源(滑鼠點擊位置)// 滑鼠相對於'瀏覽器' 頁面的位置 -&gt; clientalert(ev.clientX); // 水平方向(X軸)alert(ev.clientY); // 垂直方向// 滑鼠相對於'事件源'的位置 -&gt; offsetalert(ev.offsetX); // 水平方向(X軸)alert(ev.offsetY); // 垂直方向} 點擊上面的紫色方形可以取得滑鼠相對於瀏覽器、事件源的位置。 元素節點的事件屬性除addEventListener()方法外，元素節點的事件屬性，同樣可以指定監聽函數。 123div.onclick = function (event) { console.log('觸發事件');} “元素節點的事件屬性”的缺點:同一個事件只能定義一個監聽函數。如果定義兩次onclick屬性，後一次定義會覆蓋前一次。使用這個方法指定的監聽函數，也是只會在冒泡階段觸發EventTarget.addEventListener是比較推薦的指定監聽函數的方法，優點：同一個事件可以添加多個監聽函數。能夠指定在哪個階段（捕獲階段還是冒泡階段）觸發監聽函數。 this 的指向若是想要對「觸發事件的元素」做某些事時，可以使用this方法來達成。 12345678910111213// HTML// &lt;button id=&quot;btn&quot;&gt;點擊&lt;/button&gt; // JSvar btn = document.getElementById('btn');btn.addEventListener( 'click', function (e) { console.log(this.id); // 點擊按鈕以後輸出btn }, false);","link":"2019/07/23/Javascript/js_event/"},{"title":"Webhook VS. WebSocket","text":"前言本文紀錄常見的兩種API形式：Webhook、WebSocket 比較Webhook、WebSocket兩者最大的差別在於一個是主動型，另一個為被動型，來近一步討論兩者的差別。 Webhook屬於被動型的API，藉由事件去觸發API。舉下圖範例來說假設開發一個Linebot，使用者對機器人輸入文字，這些文字資料透過Line平台到Bot Application，這過程中產生一個事件(Event)，Bot Application會處理這段資料，再回應給Line 平台，最後送回給使用者，透過事件去trigger。 WebSocket屬於主動型的API，最具代表性的生活案例就是聊天室，有朋友主動發訊息給自己時，會自動把新訊息在自己的頁面做更新，而不是等自己主動去刷新網站頁面才能收到對方的訊息。以常見的 Client-Server 架構來說，會長的像下方圖示 圖片源WebSocket其實是網路協定的一種，有別於一般常見的http或 https採用 輪詢(Polling) 的方式。 輪詢: 讓 Client 端每隔一段時間就自動送出一個 HTTP Request 給 Server，獲取最新的資料 WebSocket 協定只需透過一次連結便能保持連線，不必再透過一直發送 Request 來與 Server 互動！ HTTP 回傳資訊後就會關閉 TCP 的API，而 WebSocket 會一直開著，只需透過一次連結便能保持連線，如同一個通道一般，只要通道保持開啟且暢通的狀態，就可以允許 Server 和 Client 端進行雙向溝通，不必再透過一直發送 Request 與Server 進行互動，直到通道關閉為止(例如：關閉網頁)，而這樣的特性有利於實作具即時的功能(e.g. 聊天室)。 參閱 differences between webhook and websocket HTTP and Websockets: Understanding the capabilities of today’s web communication technologies WebSocket 通訊協定簡介：比較 Polling、Long-Polling 與 Streaming 的運作原理","link":"2020/05/18/Network/Webhook%20VS.%20WebSocket/"},{"title":"網路概論入門","text":"前言這學期修了外系的一堂網路概論，利用這個機會做個複習用的筆記。 課堂主要在討論現今網路的標準，採用的是TCP/IP及OSI的混合架構 以下做個簡單的整理: 由最下層開始排序: 第一層: 實體層(Physical layer)採用實體設備，並用2進制做數據傳輸，實體層需規範設備或傳輸線的規格，確保訊號傳輸穩定。 常見設備: 網路線、集線器(Hub) 第二層: 數據鏈接層(Data link layer)在網路(Network)之間建立邏輯連結，並在傳輸過程做流量控制、錯誤偵測，將實體層的訊號封裝，稱作Data Frame。常見例子: 網路卡地址(MAC Address)、Switch 第三層: 網絡層(Internet layer)將IP、資料組成封包，並決定數據封包要經過哪些router或switch。例子: Router、switch、ADSL 第四層: 傳輸層(Transport layer)進行點對點的處理，進行傳輸時會先將較大的資料切割成多個適合傳輸的封包(packet)，除了偵測錯誤之外，更重要的是，他會進行錯誤更正 這是傳輸層才會有的，只要錯一個bit，資料就會整個砍掉，重新傳輸。 主要協定: TCP、UTP 第五層: 應用層(Application layer)處理應用程式，提供users網路服務。 常見協定有: http、smtp、ftp 例子: e-mail、文件傳輸、數據加密 TCP/IP 的遞送原理:1.將來源IP和目的IP分別與子網路遮罩(Subnet Mask)進行AND運算 2.比較AND運算結果: a. 相同: 透過LAN的方式傳送 原因: 來源和目的IP在同一子網路 b. 不相同: 透過WAN傳送 原因：目的IP不在本地網段 一些名詞解釋： 路由器router(又做gateway):將多個區域網路做串聯的裝置 廣域網路(Wide Area Network, WAN)跨區域型的計算機網路的集合，連接多個網路節點，大部分都是跨越一個省、市，或是國家。 其中WAN包含大小不同的子網，這些子網可以是LAN或小型WAN 區域網路(Local Area Network, LAN)某區域內的多台計算機網路的集合，單一個網路節點，是封閉型的，例如公司內部的區域網路、學校網路 生活實例：一家大型公司的總公司在美國，分公司分佈各地，若將所有分公司網路連接一起，一個分公司表一個區域網路，整個公司網路表一個廣域網路 無線區域網(Wireless LAN , WLAN):用電磁波在空氣發送和接收數據，不須網路線 例子： WIFI 那Router接WAN的口和LAN的口有何區別？WAN：接外部IP address 轉發來自內部的LAN發出的IP封包 LAN: 接內部IP address 內部為switch，可不接WAN 網路核心由互相連結成網狀的router所組成，資料在網路中傳送的方式分為3種: Circuit Switching( 線路交換)在兩個通訊的端點之間建立實體線路連線。一旦建立兩端之間的連線後， 佔用線路並傳輸資料(即他人無法使用)。直到通信結束之後，這條專用路徑才停止使用，並讓出供他人繼續使用。目前的電話與電報交換系統就是使用這種技術。 特色：在傳輸過程中，傳輸線路不能分享給其它節點(node)使用，即頻寬不共用。優點： 傳輸速度快延遲小。 不會產生線路衝突，錯誤率低。 缺點： 需花時建立線路連線。 因需等待傳輸完成才會釋放線路，容易形成 佔線而浪費資源。 訊息交換(Message Switching)可視線路的忙碌狀況選擇不同的路徑來傳送 資料，不用建立專用線路。其中傳遞的資料包含來源位址與目的地位址， 網路中間裝置會將訊息先儲存再傳送出去。 優點： 每個節點都會檢查資料是否完整，可降低傳 輸的錯誤率。 整體線路的使用率提升。 缺點： 當傳輸的資料量龐大時，會長時間佔用所選 擇的傳輸路徑，造成該段線路出現壅塞情形。 分封交換(Packet Switching)先將欲傳遞的訊息分割成許多大小固定的小封包，其中包含目的地的「位址」。 網路節點可依封包所指定的目的位址來決定傳輸路徑，傳送至目的地後重新組合，是世界上網際網路通訊、數據和語音通訊中最重要的基礎。 再舉個例子，好比今天在一條網路的高速公路(共用的頻寬)上，一個一個的packet可以同時在網路上進行傳輸。 優點： 封包資料量小，傳輸快速可避免壅塞，具有 Message Switching與Circuit Switching 技術的優點。 缺點： 封包不會計算所有路徑的節點(node)，只管傳遞給下一個節點，故不會按順序送達，接收端需花時間重整資料。 網際網路一些名詞:IPv4:IPv4的ip共32個bit, 分成NetID 與 HostID。Network Mask即所謂的網路遮罩。 網路遮罩的最主要用途在於子網路（Subnetwork）的切割，並使電腦在彼此建立通訊管道之前，可先行判斷通訊對象是否可 直接連通（Directly Reachable），再決定是否須轉送服務。 因為傳統網段的切割方式會造成ip浪費, 故發展以HostID給NetID以增加NetMask的方法稱為SubNet。 IPv6:IPv6的是出現主要是為了解決可用的IPv4 位址將會不夠用的問題。因為原來的網路位址設計方法並不能提供給全球網路使用者足夠的地址空間。 IPv6是一個長度為 128 位元的識別名稱，比IPv4又在更長。 為了解決IP Address不夠的問題，除了未來轉用IPv6外，還有兩種主要方式: 網路位址轉換(NAT,Network Address Translation)字面上的意思是『網路位址的傳送』，他主要的功能就是在提供內部私有網路的電腦之頻寬分享，如一般常聽到的”IP分享器”。 每個裝置若要連上網就需要一組公共IP，假設今天公司內部有20台電腦，如果買台電腦都配一組公共IP，要相當一筆花費!站在公司角度，希望只要一組IP就能讓公司所有電腦都能上網，那就需要一台IP分享器，並註冊一組公共IP，IP分享器會配給每個公司電腦一組虛擬IP(通常看到192.168開頭的就是了)，形成一個內部網路。 公司電腦今天要上網時，雖然在內部是虛擬IP，但是透過NAT轉址，連到外網時會變成註冊的公共IP(即所有電腦連出去都是同一組公共IP)，從外部網站來看，就是一組公司的公共IP。 鳥哥的這篇文章有更詳細的解說。 動態主機組態協定(DHCPD,Dynamic Host Configuration Protocol)為了節省子網路中 IP 位址的使用量，可以設定網路中的一台主機做為指揮中心，稱為「動態主機組態協定伺服器（DHCP server）」 DHCP server負責動態分配 IP 位址、 子網路遮罩（Subnet mask）、預設閘道器（Default gateway）、 DNS 伺服器的 IP 。 當網路中有任何一台電腦要連線時，才向 DHCP server要求一個 IP 位址， DHCP 伺服器會從資料庫中找出一個目前尚未被使用的 IP 位址提供給該電腦使用，使用完畢後電腦再將這個 IP 位址還給 DHCP 伺服器，提供給其他上線的電腦使用，所以說IP是會不停變動的!相關文章參考這篇。 網域名稱系統（DNS,Domain Name System）一般人使用網址名稱(Domain Name)來連接網路主要是為了方便人類記憶，可以從Domain Name猜出可能是什麼單位，或是網站大致內容。 DNS最主要的功能是將造訪的網站域名轉成難記的IP位置，因為電腦只看得懂數字，所以需要透過DNS Server進行查詢，查到和電腦溝通的一連串數字(IP Address)，並回傳給電腦。 打個比方，今天小明要撥電話給小華，小明不可能只對電話呼叫對方名字就撥通電話，而是撥小華的電話號碼(同IP Address)，撥出電話後，配對撥出的號碼，才能找到小華(域名)這個人。","link":"2019/07/14/Network/Internet(Basic)/"},{"title":"[SSL] Nginx 整合 Certbot 替網站加上 SSL","text":"前言上一篇架設完 Server 後會發現網站是未加密的狀態，因此瀏覽器會將該網站標示為 “不安全”，本文記錄如何替網站加上 SSL 憑證進行加密。 環境 OS: Ubuntu 18.04 Server: Nginx 1.14 下載 Certbot12sudo add-apt-repository ppa:certbot/certbotsudo apt install python-certbot-nginx 確認 Nginx’s 設定檔上一篇有提到Nginx的相關設定，查看一下 1cat /etc/nginx/sites-available/project_name.conf 確認填寫的網址server_name example.com www.example.com; 若遇到inactive的狀況，則執行sudo ufw enable 12sudo ufw enablesudo ufw status 取得 SSL Certificate使用 nginx 執行 certbot，並使用-d指定我們希望的網域名稱，對其發行 certificates。 1sudo certbot --nginx -d example.com -d www.example.com 系統會要求輸入email，輸入完畢後再選擇Agree。接著會詢問選擇是否要將所有的資源請求導向HTTPS的網域，故選擇2 更新 SSL certificates1sudo cerbot renew --dry-run 若出現錯誤訊息: sudo: cerbot: command not found，可以採用以下方式。 找出certbot路徑 1which certbot 接著執行下方指令，將certbot_path替換成剛剛拿到的路徑名稱 1sudo certbot_path renew --dry-run 設定成功的訊息 自動更新憑證由於 Let’s Encrypt 憑證簽發為每三個月一次，也就是每 90 天必須更新（renew）一次，雖然 SSL For Free 提供訂閱通知的機制，在憑證過期前會收到電子郵件告知你要更新憑證。 不過身為一位工程師，秉持能自動就不要手動的精神，我們可以藉由 crontab 設置排程工作定期幫我們更新 SSL 憑證。 確認憑證狀態1sudo certbot certificates 會出現類似下方訊息 12345678910Saving debug log to /var/log/letsencrypt/letsencrypt.log- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Found the following certs: Certificate Name: xxxx.xxxx.com Domains: xxxx.xxxxxx.com Expiry Date: xxxx-xxxx-xxxx 03:44:52+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/xxxxxx.xxxxxx.com/fullchain.pem Private Key Path: /etc/letsencrypt/live/xxxxxx.xxxxxx.com/privkey.pem- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 上述資訊可看出憑證距離到期還有多久的時間 設置排程工作1sudo crontab -e 寫入排程規則下方指令以固定每月1號進行 renew SSL 憑證為例，其中 --quiet 表不產生輸出結果 10 0 1 * * /usr/bin/certbot renew --quiet 想了解更多排程規則可以試試這個網站，幫助大家能快速了解自己設的規則 Reference Update: Using Free Let’s Encrypt SSL/TLS Certificates with NGINX","link":"2020/07/20/Network/%5BSSL%5D%20Nginx%20%E6%95%B4%E5%90%88%20Certbot%20%E6%9B%BF%E7%B6%B2%E7%AB%99%E5%8A%A0%E4%B8%8A%20SSL/"},{"title":"[JavaScript] 使用Google Map API","text":"筆記如何使用Google Map API 進行服務 前言Google Maps是現代人形影不離的工具，交通的部分時常都得依靠他的幫忙，這篇就來筆記這項強大服務的使用方法吧! 前置作業 Build API Key 使用方式是參考這篇。 How to use it? 使用方式有分: Maps JavaScript API、Google Maps Embed API、Google Static Maps API Maps JavaScript APIAPI key要放在&lt;script &gt; 中src=&quot;YOUR_API_KEY的位置&quot;。 ref: 官方教學 1&lt;iframe src=&quot;https://medium.com/media/05cea78661b5fbd4070f58aafb9380fd&quot; frameborder=0&gt;&lt;/iframe&gt; 在畫面上放入一個 id名為map的&lt;div&gt;標籤載入地圖，透過google.maps.Map()的方法建立地圖物件。 center定義中心點經緯度，lat 是緯度 latitude，lng是經度 longitude，zoom 指定放大比例，數字越大，放越大。 緯度與經度取得(Latitude &amp; Longitude) 可以從網站上獲得 =&gt; https://www.latlong.net/ google map上點擊位置後,從網址中可以撈到 實作: 1&lt;iframe src=&quot;https://medium.com/media/17bc327ac83126ed1f3b13af896226ed&quot; frameborder=0&gt;&lt;/iframe&gt; 右邊的map2設定無法滑鼠拖曳 &lt;補充&gt; mapTypeId: 顯示地圖種類，如:google.maps.MapTypeId.HYBRID : 衛星+街道圖google.maps.MapTypeId.ROADMAP: 一般街道圖google.maps.MapTypeId.SATELLITE: 衛星圖google.maps.MapTypeId.TERRAIN: 地形圖mapTypeControl: false表不顯示切換地圖類型的使用者元件scaleCont:rol: false表不顯示縮放地圖大小的使用者元件draggable: false 使用者無法用滑鼠進行拖曳，改變地圖的顯示位置 利用Geocoder取得經緯度Google Map提供Geocoder的服務，將地名與經緯度做對照，讓使用者可利用地名查詢經緯度，查詢結果為JSON格式。 建立Geocoder物件 new google.maps.Geocoder() 範例: 1&lt;iframe src=&quot;https://medium.com/media/ff643a563fd520906a4b07d97a87e208&quot; frameborder=0&gt;&lt;/iframe&gt; 免費的Geocoder查詢服務每日2500次的限制。 在地圖中加入標記(Marker) 1234567891011// 建立 Marker 物件var marker = new google.maps.Marker({position: latlng, // 標記的位置map: mymap, // 標記要放的地圖title: 地名 // 滑鼠移到標記上面時顯示的文字}); 範例: 獲取各縣市紫外線強度 1&lt;iframe src=&quot;https://medium.com/media/070d7b016b6e9a9d8c78b4dcce8bd85a&quot; frameborder=0&gt;&lt;/iframe&gt; WGS84是經緯度座標的一種，Google Maps也是採用WGS84，但是格式採用的是純數字格式。WGS84以資料中花蓮縣為例 WGS84經緯度格式除了度之外還有分、秒，三者之間以逗點隔開，其中分、秒都是六十進位，若要將上述WGS84經緯度格式轉換成十進位，才能將經緯度用於Google Maps，採以下作法: JS的split()方法分割字串，將&quot;23,58,30&quot;以逗號為分隔符split(',')，分割成3個數字的陣列:['23', '58','30'] 後續轉成字串陣列進行換算。 123lat = 23 + // 度58 / 60 // 1度 = 60分30 / 3600 // 1度 = 60分 = 3600秒 更換圖標在建立Maker物件中新增一個icon屬性。 1234567891011121314var marker = new google.maps.Marker({position: latlng, // 標記的位置map: mymap, // 標記要放的地圖// 滑鼠移到標記上面時顯示的文字title: this.SiteName+','+this.County+',紫外線指數'+this.UVI,label: uvi.toString() , // 將 UV 指數數值轉回字串 // 更換圖標icon: 'http://maps.google.com/mapfiles/ms/micons/sunny.png'}); 相關教學文 Google Maps Embed API啟用到Google API 服務頁面的資訊主頁，選擇Map Embed API，進入後點選啟用。 由Google Maps網站取得嵌入式地圖，選擇要的地點後，點選左邊的選單，找到嵌入地圖的位置。 點選”嵌入地圖”，複製&lt;ifram&gt;標籤內的URL，貼到&lt;body&gt;內即可顯示。 範例: 1&lt;iframe src=&quot;https://medium.com/media/2bac1b3f4d13d998f09954ce323f5829&quot; frameborder=0&gt;&lt;/iframe&gt; 可以採用自訂嵌入式地圖1&lt;iframe src=&quot;https://medium.com/media/3e66a90d33c7a67197589b7dbfd5c6a4&quot; frameborder=0&gt;&lt;/iframe&gt; 上述的code可獲得一樣結果。 place:一班表示位置的地圖，需用參數 q 指定要顯示的位置。位置字串中若有空白(如英文地名)，須改用 + 號代替。另外，URL中不同參數要用&amp; 隔開，palce之後的參數無一定順序。 view:單純檢視地圖，無其他標示，需用center、zoom來控制，center內的參數前後分別為: 緯度、經度，以逗點分開。 maptype指定地圖類型，如statellite(衛星圖)、roadmap(街道圖;為預設)。 參數zoo=0時，表示將全世界的地圖納入一個圖塊中，數字每增加1，橫向及縱向各放大2，如zoo=2 時，每個圖塊就是1/16大小的全球地圖。 directions: 顯示路線，至少需用origin、destination參數，其餘如waypoint、mode、avoid等為選擇性的參數。 origin: 指定起點destination: 指定終點waypoints: 中間經過的路線mode: 指定交通方式avoid: 避開方式 範例: 1&lt;iframe src=&quot;https://medium.com/media/ee8fc0cb51e3fc30570a1cea1db28996&quot; frameborder=0&gt;&lt;/iframe&gt; 起點名稱後面可多加一個郵遞區號的參數，可以使定位更精確，如上面的70449，若經過多個地點(waypoints)，彼此用 | 符號分開。 search搜尋模式，例如搜尋某地餐廳、商家，同樣用 q 做參數指定。 streetview街景模式，必須location指定經緯度，如一個鏡頭看世界，有幾個可選用參數，不同參數一樣用” &amp; “ 隔開。 以下三個參數都用角度(數字)表示heading: 鏡頭朝向哪個方向，北邊為0度，順時針增加pitch: 指定仰角，水平為0，向上為上，向下為負fov: 指定視野寬度，指定範圍 10~110，預設為90 1&lt;iframe src=&quot;https://medium.com/media/1e483a375d3aaaf44c8279f65d21ca95&quot; frameborder=0&gt;&lt;/iframe&gt; Google Static Maps API若不想使用&lt;ifram&gt;標籤，可改用靜態地圖(Static Maps)。 如何使用? 官網有詳細說明 建立&lt;img&gt;標籤載入網頁的靜態地圖，將src屬性設為API的URL，並加上適當參數。 基本的參數如center、zoom之外，還有其他選用參數可調整。 format: 影像檔類型，預設為png，可設為png32、gif、jpg。如果要較大的圖檔，可利用format=jpg 減少檔案大小。maptype: satellite(衛星圖)、hybrid(衛星+地名+路名)、terrian(地形圖)、roadmap(街景圖，為預設)。size: 指定地圖大小，預設為1，例如: size=100x100，即回傳100x100大小的地圖。scale: 指定圖像放大的比例(多少像素表示)，如size=100x100&amp;scale=2，會回傳200x200大小的地圖。visible: 指定要出現在地圖上的地標，使用此參數可省略zoom，若要指定多個地標，可用 | 符號分開。 1&lt;iframe src=&quot;https://medium.com/media/95b73953bc9683c317ac1a4aaa0df0c4&quot; frameborder=0&gt;&lt;/iframe&gt; Tip: 免費Google Static Map最大只會回傳640x640大小，若設scale=2可得1280x1280大小的地圖 自訂地圖樣式在靜態地圖中，可利用style參數指定地圖樣式，多個參數用|隔開。 &amp;style=參數:參數值 可選參數: hue: 設定地圖色調(RGB)，參數格式0xRRGGBB，如要紅色的話:0xFF0000lightness: 設定地圖亮度，數值範圍: -100(全黑)100(全白)saturation: 設定地圖飽和度，數值範圍: -100(飽和度最小)100(飽和度最大) 1&lt;iframe src=&quot;https://medium.com/media/1dfb9d18d0e9fbd18bdde42f8a8f5fe2&quot; frameborder=0&gt;&lt;/iframe&gt; 範例: 在地圖上加上marker(標記)我們還可以在加上標記，放入靜態地圖。語法格式如下:markers=size:value|color:value|label:value|地點 地點(必要參數): 地點可使用地名或經緯度，若有多個地點可用|分開 size: marker的大小，可設為 tiny、small、mid，預設為normal(最大)。color: marker的顏色，可使用0xRRGGBB格式或是預設的顏色名(black、white、brown、green、orange、purple、red、yellow、white)label: 顯示marker中的英文字(大寫)或數字(0~9)。 實作: 高雄市空氣汙染指標 到政府開放資料平台獲取JSON資料 1&lt;iframe src=&quot;https://medium.com/media/5b0f3ce5c9c226b40c559c02328a12f0&quot; frameborder=0&gt;&lt;/iframe&gt; 程式結果如上圖(竟然不是紅色的，真令人驚訝XD)。 在JSON格式中，PM2.5包含小數點，所以不使用object.attr(物件.屬性)的方式讀取，改採object [&quot;attr&quot;]的方法讀取值，屬性名一定要用[]括起來，類似存取陣列元素。","link":"2019/07/19/Javascript/google_map/"},{"title":"Session與Cookie差別","text":"前言其實這個疑問之前就存在很久，就去查資料了解一下，作為今天筆記對象，在記錄2者差異之前，要先了解為何需要這兩者，他們解決了什麼樣的問題? 什麼是http？http本身是個無狀態( Stateless)的協議，可以在Client與Server兩端進行溝通，但是無法紀錄網路上的行為。一般而言，今天如果要登入一個網站，每次訪問該網站時，就需要將登入帳密再輸入一次， 或是現在頁面上的資料填到一半，不小心把網頁關掉，重開頁面只好再重新輸入一次，使用起來會非常不便。Cookie和Session因此誕生，解決無紀錄狀態的問題。 Cookie他不只是一塊小餅乾，而是一段由Server送給使用者瀏覽器的一小塊資料(文檔)。瀏覽器會儲存它並且在瀏覽器下一次發送要求的時候將它送回原本送來的伺服器。 Cookie就是用來繞開HTTP的無狀態性的「額外手段」之一 基本上，它是用來區分兩個要求是來自同一個瀏覽器 — 以此去保持使用者的登入狀態。例如，它提供了保存狀態資訊的功能，來幫助HTTP這個無法紀錄狀態的通訊協定。 用實例說明的話就是我們平常逛網拍，要購買商品時都要登入會員資料，進入到登入介面，我們可以透過Cookie的方式紀錄之前輸入的帳號密碼，省去每次都要重新打帳密的不便， 只要Cookie尚未到期，瀏覽器會傳送該Cookie給伺服器作驗證憑據。這樣的方式已經解決大部分的問題。 由於這個Cookie設定值是儲存在使用者的電腦裡，我們可透過瀏覽器來檢測這個設定值是否儲存。操作如下: 開啟瀏覽器，輸入要查看網址，再點網址列前方的圖示，接著就會看到Cookie 點一下，進入後在允許的頁籤中，就會看到目前所儲存的Cooke值有那些。 點一下展開後，就可看到每個Cookie所記錄的值與內容，之後若找不到Cookie時，可以嘗試從這邊找看看。 實作原理: client 端的程式在一旦填寫的資料有變動時，就把該資訊寫入 cookie。 Cookie 由瀏覽器處理，具有兩個特性： 特定網域：只針對原本的 網域(domain) 起作用。舉例: 在 .myExample.com 存入的 cookie，不會出現在 *.not-myExample.com有生命期限: 到了所設定的生命期限之後會失效。*在向該 domain 的 server 發送請求時，也會被一併帶進去該請求中**。 這麼好用的東西當然也有缺點cookie 雖然很方便，但是使用cookie 有一個很大的弊端，cookie 中的所有數據在Client端就可以被修改，數據非常容易被偽造，那麼一些重要的數據就不能存放在cookie 中了，而且如果cookie中數據字段太多會影響傳輸效率。為了解決這些問題，就產生了session，session 中的數據是保留在Server端。 SessionSession 負責紀錄在 server端上的使用者訊息，會在一個用戶完成身分認證後，存下所需的用戶資料，接著產生一組對應的 ID，存入 cookie 後傳回用戶端。 Session泛指有始有終的系列動作/消息，好比會話一般。 試想 Cookie是一張領餐的號碼牌，而Session是一張數位會員卡， 記錄你的點餐號碼，還可以紀錄你的餐點細節，消費記錄和點餐喜好。，解決Cookie遺失的問題。 若今天替某個Client端的Request建一個Session的時候，Server會先檢查這個Client端的Request裡是否有包含了Session標識(Session id)，如果已包含一個Session id，表示這個發起Request的Client端是已經存放過的id，Server就按照Session id，把這個Session找出來使用。但如果Client端請求不包含Session id，，則表示他是新臉孔，那Server端就為此Client端創建一個Session，並生成一個Session id，並Response給Client端保存。 小結: session：帳號登錄驗證過後，Server端所發的識別證 cookie：是瀏覽器存放資料的地方，可以存放seesion之類的資料 參考連結:[不是工程師] 會員系統用Session還是Cookie? 你知道其實他們常常混在一起嗎？「帥哥~你的早餐好了」，五分鐘概述網路界的記憶大神-Sessionprogressbar.tw[不是工程師] Cookie 是文檔還是餅乾？簡述HTTP網頁紀錄會員資訊的一大功臣。從淘寶到Airbnb，為何他們總能知道我們是誰呢？progressbar.tw介紹 Session 及 Cookie 兩者的差別說明這幾年 SPA（Single Page App）當道，造就一個現象就是 Server-side 及 Client-side 壁壘分明。如果你是 Client-side 的開發者，可能沒什麼機會自己架一個 web…blog.hellojcc.tw[爬蟲] 背景知識 “ I try | MarsWWWW(World Wide Web、Web) 是一個由許多通過網際網路存取而互相連結的 hypertext documents (常用HTML) 組成的系統。 而一個獨立的 WWW 頁面，我們…tech-marsw.logdown.com","link":"2019/07/14/Network/cookie_session/"},{"title":"Proxy","text":"什麼是Proxy?根據維基百科的定義: 代理(Proxy）也稱網路代理，是一種特殊的網路服務，允許一個網路終端（一般為用戶端）通過這個服務與另一個網路終端（一般為伺服器）進行非直接的連接。一些閘道器、路由器等網路裝置具備網路代理功能。一般認為代理服務有利於保障網路終端的隱私或安全，防止攻擊。 上述一段冗長的字，自己是這樣理解 : 一種具有重要的電腦安全功能，也是特殊的網路服務，允許客戶端透過它和另一個網路服務進行非直接的連線。 舉個例子: 今天我幫家裡的父母跑腿，例如匯款， 因為我不是『申請者本人』而是『代理人』的角色，因此有時候會需要秀出一些證件，才能完成代辦事項。 將場景換至網路上面代理伺服器 (Proxy Server) 時: 當用戶端有網路的資料要求時，Proxy 會幫用戶去向目的地取得用戶所需要的資料。 這個詞最早應是出現在網路的防火牆功能中。可以用來保護網路的安全，在內部網路與外部網路之間建立一道像牆般的保護，所有的資料進出都必需經過這道牆。 Proxy 有那些好處 ?減少單點對外的網路頻寬，降低網路負載量:假設今天要造訪一個網站， 在正常的網路流程中，當使用者的瀏覽器看到 www.xxxx.com.tw的網域時，會向DNS尋找www.xxxx.com.tw所對應的IP，當DNS傳回對應的 IP後，瀏覽器會再對真正的伺服器索取資料，但如果網路塞車、網站的機器配備不好、網站的專線不夠快等不良的因素通通加在一起後，你要連接的網站就會變的很慢。 透過 Proxy Server ，可以把造訪的網頁資料暫存在一個位置，下次訪問該網站時可以直接從Proxy Server儲存的空間中(硬碟)進行資料快取( Cache)，不必再向網路要資料。 以較短的路徑取得網路資料，加快上網速度:可以指定 網路服務供應商(ISP) 提供的代理伺服器連接到國外，通常 ISP 提供的 Proxy 具有較大的對外頻寬，所以在對國外網站的資料取得上會比自己的主機連線到國外快多了。 提供防火牆內部的電腦連上網路Proxy Server可以用來「代替」外部網路的電腦連接私有網路（內部網路）的網頁伺服器， 將內部網路內網頁伺服器的內容儲存在代理伺服器的記憶體，讓外部網路的電腦由代理伺服器的記憶體中讀取資料，而不直接由私有網路的網頁伺服器讀取。 簡單實作 Proxy設定(Chrome版本): 先到網頁右上角的工具點選符號為3個點的選項後點選 “設定” 往下滾動至系統的地方 點選開啟Proxy設定 就可以開始進行相關設定啦~ 更多Proxy 相關設定可以參考鳥哥這篇文章。 Proxy Server 如何運作 ?Proxy Server 接受使用者的 request 之後會先檢查自己的 Server 上有沒有一份 Client 端要的資料，代理 Client 端到訪問的目的地去截取資料，一份給 Client 端，Proxy Server 內部也存放一份，下一個Client 端使用者來做 request 時，Proxy Server 便會一樣先在 Server 中檢查看看，檢查與目的端的資料是否相符，若相符則由 Proxy Server 直接給要求的 Client 端即可。 不過，” 向目的地再 check 一次 “ 這樣的動作，一開始在想: 不是會浪費時間嗎? 不過這是必要的，雖然要去的目的地的資料在 Proxy Server 上存放了一份，但是否是最新的是無法得知的，必需做比對，比對的時間不會長。例如: 新聞這類的網站，是隨時都在更新的，但是比對後相同的部分就不需要再向目的網站進行存取。 參考資料:鳥哥的 Linux 私房菜 – 代理伺服器的設定： squid透過 squid 來進行代理伺服器 (proxy) 的設定輔助區網的 www 瀏覽控制！linux.vbird.org什麼是Proxy?常常會聽到別人說，你的 Browser 要設 Proxy Server，這樣你上網的速度會比較快？到底什麼是 Proxy Server，他在Internet 裡扮演什麼樣的角色？www.ithome.com.twProxy 伺服器是什麼？如何應用？ - StockFeel 股感代理伺服器（Proxy server） 代理伺服器是一種防火牆成員，也是一種「應用閘道器（Application…www.stockfeel.com.twProxy 是什麼東東 ?傳統的 Proxy Server 是底下的機器先向 Proxy Server 做 request ，若 Server 中沒有就直接由 Server向目的地截取資料。這對大都數的 Proxy Server…macgyver.info.fju.edu.tw 以上為今日筆記。","link":"2019/07/14/Network/Proxy/"},{"title":"[物件導向] 入門","text":"何謂物件導向?Def: 在控制程式時，以”物件”來包裝所有的邏輯跟操作假設情境:將問題描述為物件，有兩個人分別為A、B，A要將香蕉拿給B，故物件有A、B、香蕉，物件也有屬性和行為，如A、B和香蕉的屬性為年齡、名字和價格，行為則為打招呼、走路和剝皮。以程式來看的話就會如上圖，A、B都是”實體”，並屬於”人”這個類別，今天A與B打招呼(A.打招呼())，A給B香蕉(A.給予(B,香蕉)，給予的動作傳入B和香蕉作為參數)，B去呼叫香蕉.剝皮()，最後B把香蕉吃掉(B.吃(香蕉))。 思考邏輯根據類別產生物件，也就是先定義類別(人的概念)，在以人為基礎產生A、B兩物件，定義完類別及物件之後，再來執行操作方法，如呼叫A、B的物件屬性或方法來進行互動 類別(class)一個抽象概念，定義一件事物的抽象特點，包含事物的屬性和操作行為，無實體(Instance)概念。 物件(Object)物件是類別的實例，也看的到、摸的到，屬於動態，狀態會隨時改變，但架構與行為不會改變。 案例: 票務系統有一張票作為一物件，其中票的屬性就包含相關的票務資訊，如票種、價格、手續費等。另外票的方法指的是如何操作這張票(物件)，如購票、退票等等。 來看例子: 一般寫法12345678910111213//// ticket的屬性let ticket_price = 100;let ticket_type = &quot;student&quot;;const ticket_discount = 0.3;const ticket_fee = 30;// ticket的方法Function get_ticket_price(price, type,discount,fee){ Return ticket_price * ticket_discount + ticket_fee }Function get_ticket_description(price,type,discount, fee){ console.log(“這張票是”+type+”票 有”+discount*10+”的折扣跟”+fee+”的⼿續費”)} 進階寫法(將物件進行打包)123456789101112131415//// ticket的屬性var ticket = { price = 100, type = &quot;student&quot;, discount = 0.3, fee = 30}// ticket的方法Function get_ticket_price(ticket){ Return ticket.price * ticket.discount + ticket.fee }Function get_ticket_description(ticket){ console.log(“這張票是”+ticket.type+”票 有”+ticket.discount*10+”的折扣跟”+ticket.fee+”的⼿續費”)} 物件導向寫法開始著手實作之前，需先確定幾件事: 物件有哪些屬性 物件有哪些可⽤⽅法 如何「產⽣」這個物件確定完成後我們會先定義”類別”，再根據類別產生物件。12345678// 類別開頭通常都會設大寫 var Ticket = function(初始值){ this.屬性 = 初始值, this.方法 = function(){ // 當中可用this.屬性或this.方法 .... }} 物件導向範例* 1234567891011121314 var Ticket = function(init_price, init_discount){ this.price = init_price this.type = “student” this.discount = init_discount this.fee = 30 // ticket的方法 this.get_price = function(){ return this.price * this.discount + this.fee; } this.get_description = function(){ console.log(&quot;這張票是&quot;+this.type+&quot;票 有&quot; + this.discount*10 + &quot;折扣共&quot; + this.get_price() +&quot;元&quot;); }} 上述範例中，class類別為Ticket，傳入兩個初始化參數(票價、折扣)，再做物件屬性的初始化設定。get_price、get_description分別做為取得票價及詳細資訊的方法。其中，this是參照物件本體的資訊。 定義好類別及物件之後，就可以開始產生物件。 產生物件12345// 傳入票價、折扣var myTick = new Ticket(500,0.7)console.log(myTick.price); // 500console.log(myTick.type); // studentconsole.log(myTick.get_price()); // 380 好處:如果這物件是其他開發者建立的，我們不須管物件內複雜的邏輯，只需傳需要的參數給物件即可獲得想要的結果，這樣的方法稱作封裝,程式碼較直觀，且容易理解。 物件導向有幾個重要的特性: 封裝 繼承 多型這篇只有先筆記封裝及繼承的部分封裝(Encapsulation)將物件屬性及複雜的操作邏輯包覆在class內，也就是將物件內部資料隱藏起來。按照前面的票務的例子，我們只需傳入特定的值，即可取得票價，不須了解票價如何做計算。 原型繼承(Inheritance)雖然有了物件之後變得簡單易用，但是今天有多個物件要透過函數操作方法時，函數是獨立存在於各個物件，彼此無法共用。舉例來說，今天今天有三個人(物件)要互相打招呼，執行sayhello()這個function，會說出hello,某某某…，若要把sayhello()統一改為Hi,某某某…的話，要每個物件做修改會變得相當耗時。若要解決函數無法共用的問題，我們可以使用prototype(原型)，達成統一管理函數的目的，來看個例子: 12345678910var Ticket = function(初始值){ this.屬性 = 初始值 this.方法....}// 原型繼承Ticket.prototype.方法 = function(){ this.屬性 this.方法....} 將某些要呼叫的方法放進prototype裡的東西不會被複製進物件，物件會有參考點連到prototype，找不到調用的屬性或方法時會往上找。來看下面的圖示:上圖中的Prototype獨立存在外面，假設產生A、B、C三個物件時，並不會有原型的function，若想在其中一個物件呼叫function時，發現該物件沒有被呼叫的function，便會往上找，找該物件的prototype，就找到呼叫的function。&lt;注意&gt;在prototype內一樣可以使用this.屬性或this.方法。 繼承-在類別之間的延續在javascript內所指的繼承是指類別之間的繼承，程式碼實作繼承的步驟: 建立時呼叫類別: 初始化母類別屬性 為子類別新增繼承prototype: 讓子類別可使用母類別的方法 將建構函數指向自己: 將物件建構的函數指向最底層類別 建立時呼叫類別: Parent.call(this,其他引數)12345678var Creature = function(...){ this.attr = ...}var Dog = function(...){ Creature.call(this, ....) this.attr = ...} 為子類別新增繼承prototype: Child.prototype = Object.create(Parent.prototype)1Dog.prototype = Object.create(Creature.prototype) 上述的Object.create()所代表的是建立一個空物件(Dog.prototype)，但是將該物件的上游連接到給定的Prototype。 將建構函數指向自己1Child.prototye.constructor = Child.constructor 需要執行這個步驟的原因是，今天在定義類別(class)時，都會定義一個新的function，若只有建立一個空物件(Object.create.create)，funtion會往上游尋找constructor，也就是定義所產生的function，找不到時會繼續往上游找，以下圖為例，最終變成找生物的prototype來初始化物件。所以將建構函數指向自己時就會變成狗產生的函數(建構子)等於自己的產生函數，避免往上游回溯到生物的產生函數 1Dog.prototye.constructor = Dog.constructor Codepen範例:Worker","link":"2019/07/14/OOP/OOP/"},{"title":"[Go] Go基礎","text":"前言本篇用於記錄Go一些基礎的概念，包含變數類型、迴圈及條件運算等 變數宣告Go是一種靜態類型的語言，是強型別語言。因為型別都是固定的，就算不先宣告型別，也必須要有初始值，讓編譯器來判斷這個變數的預設值是什麼型別。 Go宣告型別是放在變數之後 一般宣告範例:定義一個名為a的變數，若資料型別是int的話，預設值為0 1var a int 或是直接賦值給他 1var a = 1 短語法Go也可以使用:=的方式，用更簡短的語法來定義變數 1234567891011package mainimport &quot;fmt&quot;func main() { var i, j int = 1, 2 k := 3 c, python, java := true, false, &quot;no!&quot; fmt.Println(i, j, k, c, python, java)} :=結構不能使用在函式外。 合適的使用時機一般來說，短語法適合的使用時機有三個: 已知變數的初始值 讓程式更簡潔 用於重複宣告 範例12345678910111213141516171819202122// 變數初始值未知// bestvar number int// worstnumber := 0// 變數初始值已知// bestwidth, height := 100, 50// worstvar width, height int = 100, 50// 用於重複宣告// bestwidth, color := 70, &quot;red&quot;// worstwidth = 70color := &quot;red&quot; 宣告多個變數123var a,b,c intvar a,b,c int = 1,2,3var a,b,c = 1,2,3 括弧式宣告只要重複的宣告方式，都可以用()包起來 1234var ( name = &quot;Tom&quot; c, d = 3, 4) 宣告常數首字不一定要大寫，但為了強調其重要性，大多還是採大寫。 1const PI = 3.14 常數不能使用 := 短語法定義 重複宣告(redeclaration)在Go的程式設計中，是不允許同一變數宣告兩次，若重新對一變數進行宣告時會出現name redeclared in this block的錯誤訊息。 12345var name string = &quot;hello&quot;var name string = &quot;hey&quot;fmt.Println(name)// name redeclared in this block 解決重複宣告的問題可以採用宣告多個變數，也就是除了重複宣告的變數外，再另外以短語法的方式宣告一個(或多個)新變數。 123var name string = &quot;hello&quot;name, name1 := &quot;hey&quot;, &quot;ya~&quot;fmt.Println(name, name1) 上圖可以看出name變數被重新賦予新的值 若採用var的方式進行重複宣告也會報重複宣告的錯誤訊息 123var name string = &quot;hello&quot;var name, name1 = &quot;hey&quot;, &quot;ya~&quot;fmt.Println(name, name1) 資料型別Go主要以下幾個型別: 字串(String)相關的型別 string: byte: uint8的別名 rune int32的別名，將字串以 Unicode切開時所用的型別，代表一個Unicode碼。 數字(Number)相關的型別有號整數int(32或64位元)、int8、int16、int32、int64 無號整數uint(32或64位元)、uint8、uint16、uint32、uint64、uintptr 浮點數 float32: 32位元 float64: 64位元 複數分為實數及虛數兩部分 complex64 complex128類型轉換範例: 數值的轉換123var i int = 42var f float64 = float64(i)var u uint = uint(f) 或更簡單的形式：123i := 42f := float64(i)u := uint(f) 數字轉字串兩種int類型轉化成string類型的方法，可透過strconv這個package完成。 Itoa方法 Sprintf方法 1234567891011121314151617181920package main import ( &quot;fmt&quot; &quot;strconv&quot;) var i int = 10 func main() { // Itoa方法 str1 := strconv.Itoa(i) // Sprintf方法 str2 := fmt.Sprintf(&quot;%d&quot;, i) fmt.Println(str1) fmt.Println(str2)} %d表示 Integer 初始值Go在宣告變數時，如果沒有給定該變數初始值，Go會依照宣告變數的資料型態去給予預設的初始值，如: int: 0 bool: false float64: 0 string: &quot;&quot;12345678910111213141516var ( init_int int init_float64 float64 init_bool bool init_string string)fmt.Println(init_int)fmt.Println(init_float64)fmt.Println(init_bool)fmt.Println(init_string)/*00false*/ 不允許已宣告但未被使用的變數在Go的設計中，不允許已宣告但未被使用的變數，若有前面的情形，會在編譯時跳出declared and not used的錯誤訊息。 12345678910var ( init_int int init_float64 float64 init_bool bool init_string string) fmt.Println(init_float64)fmt.Println(init_bool)fmt.Println(init_string) 結果init_int declared and not used blank identifier上述宣高未使用的變數，Go在編譯時會跳出錯誤的訊息，若要在編譯時避免該錯誤，可以使用blank identifier，將未使用的變數賦值給_。 範例123456789101112131415var ( init_int int init_float64 float64 init_bool bool init_string string)_ = init_int // 賦值操作fmt.Println(init_float64)fmt.Println(init_bool)fmt.Println(init_string)/*0false*/ 函式()內的參數以及回傳值需要宣告型別。範例 12345678910111213package mainimport &quot;fmt&quot;func add(x int, y int) int { return x + y}func main() { fmt.Println(add(42, 13))}// 返回結果// 55 上述範例為一個add function，傳入x、y兩個資料型別為int的參數，回傳int的資料型別。 縮短同一類型參數的型別宣告當兩個或多個連續的函式命名參數是同一類型。範例: 12345678910111213package mainimport &quot;fmt&quot;func add(x, y int) int { return x + y}func main() { fmt.Println(add(42, 13))}// 返回結果// world hello 多值返回函式可以返回任意數量的返回值。 1234567891011121314package mainimport &quot;fmt&quot;func swap(x, y string) (string, string) { return y, x}func main() { a, b := swap(&quot;hello&quot;, &quot;world&quot;) fmt.Println(a, b)}// 返回結果// world hello 命名返回值如果命名了返回值參數，一個沒有參數的 return 語句，會將當前的值作為返回值返回。 123456789101112131415package mainimport &quot;fmt&quot;func split(sum int) (x, y int) { x = sum * 4 / 9 y = sum - x return}func main() { fmt.Println(split(17))}// 返回結果// 7 10 :=宣告變數的語法只能在函數內部使用。 迴圈(Loop)Go只有一種循環結構：for迴圈。Go的for迴圈沒有()範例: 123456789101112package mainimport &quot;fmt&quot;func main() { sum := 0 for i := 0; i &lt; 10; i++ { sum += i } fmt.Println(sum)}// 45 可以讓前置、後置語句為空123456789101112package mainimport &quot;fmt&quot;func main() { sum := 1 for ; sum &lt; 1000; { sum += sum } fmt.Println(sum)}// 1024 同While寫法123456789101112package mainimport &quot;fmt&quot;func main() { sum := 1 for sum &lt; 1000 { sum += sum } fmt.Println(sum)}// 1024 無窮迴圈123456package mainfunc main() { for { }} if-elseif 語句除了沒有( ) if 的便捷語句跟 for一樣， if可以在條件之前執行一個簡單的陳述式。 由這個語句定義的變數的作用域僅在 if 範圍之內。 範例:123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;math&quot;)func pow(x, n, lim float64) float64 { if v := math.Pow(x, n); v &lt; lim { return v } return lim}func main() { fmt.Println( pow(3, 2, 10), pow(3, 3, 20), )}// 9 20 switch和大多的程式語言一樣，不過switch後方不需接() 12345678910111213141516171819202122package mainimport ( &quot;fmt&quot; &quot;runtime&quot;)func main() { fmt.Print(&quot;Go runs on &quot;) switch os := runtime.GOOS; os { case &quot;darwin&quot;: fmt.Println(&quot;OS X.&quot;) case &quot;linux&quot;: fmt.Println(&quot;Linux.&quot;) default: // freebsd, openbsd, // plan9, windows... fmt.Printf(&quot;%s.&quot;, os) }}// When's Saturday?// Too far away. 沒有條件的switch沒有條件的switch 同switch true一樣。 12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() { t := time.Now() switch { case t.Hour() &lt; 12: fmt.Println(&quot;Good morning!&quot;) case t.Hour() &lt; 17: fmt.Println(&quot;Good afternoon.&quot;) default: fmt.Println(&quot;Good evening.&quot;) }}// Good evening. 參考Golang 官方教學 如何編寫Go程式 GOPATH 與工作空間 Go 程式設計導論 Go 語言的資料型別 (Data Type)","link":"2020/01/07/Go/%5BGo%5D%20Go%E5%9F%BA%E7%A4%8E%E8%AA%8D%E8%AD%98/"},{"title":"[Go] JSON 處理","text":"什麼是 JSON？JSON 全名為: Javascript Object Notation是一種輕量的資料交換格式，在網路資料傳輸領域非常常見，很多 open data 都是採這樣的格式做為資料互動的介面。 JSON 範例:表示多個使用者，每個使用者帶有 name, gender, age, Country 這幾類的資料屬性 1234567891011121314151617181920212223242526&quot;users&quot;: [ { &quot;name&quot;: &quot;Tom&quot;, &quot;gender&quot;: &quot;Male&quot;, &quot;Age&quot;: 24, &quot;Country&quot;: &quot;Taiwan&quot; }, { &quot;name&quot;: &quot;Jack&quot;, &quot;gender&quot;: &quot;Male&quot;, &quot;Age&quot;: 40, &quot;Country&quot;: &quot;Taiwan&quot; }, { &quot;name&quot;: &quot;Amy&quot;, &quot;gender&quot;: &quot;Female&quot;, &quot;Age&quot;: 30, &quot;Country&quot;: &quot;US&quot; }, { &quot;name&quot;: &quot;Jean&quot;, &quot;gender&quot;: &quot;Female&quot;, &quot;Age&quot;: 33, &quot;Country&quot;: &quot;UK&quot; }] Go 提供名為 json 的 package，可以藉由這個 package 讓我們對 JSON 做編碼、解碼等操作 產生 JSONGo 語言的 json package 裡面有個叫做 Marshal 的函式可對資料編碼成 JSON 格式。 語法結構：1func Marshal(v interface{}) ([]byte, error) 上述語法結構中： interface{}: 可用來存放任意資料型別的物件，剛好適用於解析未知結構的 json 資料格式 []byte: byte 型別的 slice 在 Go 語言裡用來編碼、解碼 error: 回傳可能的錯誤結果 Marshal 範例 12345678910111213141516171819202122232425// JSON is string data type permission map[string]booltype user struct { name, password string // permission map[string]bool permission}user := []user{ {&quot;tom&quot;, &quot;2332424&quot;, nil}, {&quot;jack&quot;, &quot;4434345&quot;, permission{&quot;admin&quot;: true}}, {&quot;james&quot;, &quot;43434343&quot;, permission{&quot;viewer&quot;: true}}, {&quot;John&quot;, &quot;34447831&quot;, permission{&quot;write&quot;: true}},}data, err := json.Marshal(user)if err != nil { fmt.Println(err) return}fmt.Println(string(data)) // [{},{},{},{}] 執行上方範例，看到輸出結果竟然是 [{},{},{},{}]??? 原因是 Go 在編碼 JSON 時，只有首字母為大寫的 key 值才會被輸出，也就是說，只有匯出的欄位才會被輸出，JSON 解析的時候只會解析能被匯出的欄位，找不到的欄位會被忽略。 我們可以利用這個特點：若接收到一個資料量很大的 JSON 資料結構而只想取得其中部分的資料時，只需將想要的資料對應的欄位名稱採大寫開頭，即可達成目的。 struct tag但 key 值需要小寫或其他的名稱怎麼辦呢？ Go 語言提供了 struct tag 來實現小寫或其他的名稱，來看改寫上面的範例: 1234567891011121314151617181920212223242526272829type permissions map[string]booltype user struct { Name string `json:&quot;name&quot;` Password string `json:&quot;password&quot;` // permission map[string]bool Permissions permissions `json:&quot;perms&quot;`}user := []user{ {&quot;tom&quot;, &quot;2332424&quot;, nil}, {&quot;jack&quot;, &quot;4434345&quot;, permissions{&quot;admin&quot;: true}}, {&quot;james&quot;, &quot;43434343&quot;, permissions{&quot;viewer&quot;: true}}, {&quot;John&quot;, &quot;34447831&quot;, permissions{&quot;write&quot;: true}},}data, err := json.Marshal(user)if err != nil { fmt.Println(err)return}fmt.Println(string(data))// output// [{&quot;name&quot;:&quot;tom&quot;,&quot;password&quot;:&quot;2332424&quot;,&quot;perms&quot;:null},{&quot;name&quot;:&quot;jack&quot;,&quot;password&quot;:&quot;4434345&quot;,&quot;perms&quot;:{&quot;admin&quot;:true}},{&quot;name&quot;:&quot;james&quot;,&quot;password&quot;:&quot;43434343&quot;,&quot;perms&quot;:{&quot;viewer&quot;:true}},{&quot;name&quot;:&quot;John&quot;,&quot;password&quot;:&quot;34447831&quot;,&quot;perms&quot;:{&quot;write&quot;:true}}] struct tag 幾個特點: 欄位的 tag 是 &quot;-&quot;: 這個欄位不會輸出到 JSON tag 中帶有自訂名稱，那麼這個自訂名稱會出現在 JSON 的欄位名中，例如上面例子中 tag 選項中如果有 &quot;omitempty&quot; ，表該欄位如果值為空值，就不會輸出到 JSON 中 若欄位是 bool, string, int, int64 等型別，而 tag 中帶有 &quot;,string&quot; ，該欄位在輸出到 JSON 候會將該欄位對應的值轉換成 JSON 字串 將上述特點套入範例: 123456789101112131415161718192021222324type permissions map[string]booltype user struct { Name string `json:&quot;name&quot;` Password string `json:&quot;password&quot;` Age int `json:&quot;age,string&quot;` Permissions permissions `json:&quot;perms,omitempty&quot;`}user := []user{ {&quot;tom&quot;, &quot;2332424&quot;, 20, nil}, {&quot;jack&quot;, &quot;4434345&quot;, 30, permissions{&quot;admin&quot;: true}},}data, err := json.Marshal(user)if err != nil { fmt.Println(err) return}fmt.Println(string(data))// output// [{&quot;name&quot;:&quot;tom&quot;,&quot;password&quot;:&quot;2332424&quot;,&quot;age&quot;:&quot;20&quot;},{&quot;name&quot;:&quot;jack&quot;,&quot;password&quot;:&quot;4434345&quot;,&quot;age&quot;:&quot;30&quot;,&quot;perms&quot;:{&quot;admin&quot;:true}}] 觀察輸出結果，name 為 tom 的 user 因為 perms 被添加了 &quot;omitempty&quot; 選項，故 perms 沒有值輸出(西相較於上個範例的 &quot;perms&quot;:null )，而 jack 則輸出 perms&quot;:{&quot;admin&quot;:true}。 另外，age 原始型別為 int ，藉由 &quot;,string&quot; 選項被轉成字串。 Marshal 函式只有在轉換成功的時候才會回傳資料，轉換的過程中需要注意幾點： JSON 物件 key 值只支援 string 型別，故編碼(encoding) 一個 map 型別必須是 map[string]T 這種型別 (補充： T 是 Go 語言中的任意型別) 巢狀資料是不能編碼 JSON 指標於編碼時會輸出指標指向的內容，而空指標則會輸出 null 解析 JSON前面已經提到如何產生 JSON 資料，接著看如何解析 JSON 吧！而json 這個 package 提供 Unmarshal 函式來解析 JSON。 於 json.UnMarshal() 方法接收的是位元組(Bytes)切片(Slice)，需先把 JSON 字串轉換成位元組切片 語法結構：1func Unmarshal(data []byte, v interface{}) error 已知 JSON 資料結構的情形下來看段範例 12345678910111213141516171819202122232425type User struct { ID int Name string Money float64 Skills []string Relationship map[string]string Identification Identification}type Identification struct { Phone bool `json:&quot;phone&quot;` Email bool `json:&quot;email&quot;`}var jsonData = []byte(`{&quot;ID&quot;:1,&quot;Name&quot;:&quot;Tony&quot;,&quot;Money&quot;:10.1,&quot;Skills&quot;:[&quot;program&quot;,&quot;rich&quot;,&quot;play&quot;],&quot;Relationship&quot;:{&quot;Dad&quot;:&quot;Hulk&quot;,&quot;Mon&quot;:&quot;Natasha&quot;},&quot;Identification&quot;:{&quot;phone&quot;:true,&quot;email&quot;:false}}`)var user Usererr := json.Unmarshal(jsonData, &amp;user)if err != nil { fmt.Println(&quot;error:&quot;, err)}fmt.Printf(&quot;%+v\\n&quot;, user)// {ID:1 Name:Tony Money:10.1 Skills:[program rich play] Relationship:map[Dad:Hulk Mon:Natasha] Identification:{Phone:true Email:false}} 未知 JSON 資料結構的情形下若不知道被解析的來源 JSON 資料結構，可採用 interface{} 來存任意資料型別的物件。 json 套件採用 map[string]interface{} 和[]interface{} 結構來存放任意的 JSON 物件和陣列。 Go 型別和 JSON 型別的對應關係整理成下方資訊： bool: JSON booleans, float64: JSON numbers, string: JSON strings, nil: JSON null. 範例:假設有如下的 JSON 資料 1jsonData := []byte(`{&quot;Name&quot;:&quot;Eve&quot;,&quot;Age&quot;:6,&quot;Parents&quot;:[&quot;Alice&quot;,&quot;Bob&quot;]}`) 在不知其結構情況下，將其解析到 interface{} 裡 1234567var v interface{}json.Unmarshal(jsonData, &amp;v)jdata := v.(map[string]interface{})fmt.Println(&quot;jdata after parsing json: &quot;, jdata) // jdata after parsing json: map[Age:6 Name:Eve Parents:[Alice Bob]] 這時 f 變數裡等同存放了一個 map 型別，key 值為 string，值存在空的 interface{} 裡，同下方範例 123456v := map[string]interface{}{ &quot;Name&quot;: &quot;Eve&quot;, &quot;Age&quot;: 6, &quot;Parents&quot;: []interface{}{&quot;Alice&quot;, &quot;Bob&quot;},}fmt.Println(&quot;v: &quot;, v) // v: map[Age:6 Name:Eve Parents:[Alice Bob]] 接著透過斷言的方式來提取 JSON 資料 Type assertions 型態斷言型態斷言於官方文件有細部說明，本篇只會些微帶過 語法結構: 1x.(T) 12345jdata := v.(map[string]interface{})fmt.Println(&quot;jdata after parsing json: &quot;, jdata)// fmt.Println(&quot;jdata after parsing json: &quot;, jdata) 接著用 for loop 印出所有資料 123456789101112131415161718192021for k, v := range jdata { switch v := v.(type) { case string: fmt.Println(k, v, &quot;(string)&quot;) case float64: fmt.Println(k, v, &quot;(float64)&quot;) case []interface{}: fmt.Println(k, &quot;(array):&quot;) for i, u := range v { fmt.Println(&quot; &quot;, i, u) } default: fmt.Println(k, v, &quot;(unknown)&quot;) }}// Name Eve (string)// Age 6 (float64)// Parents (array):// 0 Alice// 1 Bob 再來看另一個範例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type user struct { Name string `json:&quot;username&quot;` Permissions map[string]bool `json:&quot;perms&quot;`}func main() { input := []byte(` [ { &quot;username&quot;: &quot;inanc&quot; }, { &quot;username&quot;: &quot;god&quot;, &quot;perms&quot;: { &quot;admin&quot;: true } }, { &quot;username&quot;: &quot;devil&quot;, &quot;perms&quot;: { &quot;write&quot;: true } } ]`) var users []user if err := json.Unmarshal(input, &amp;users); err != nil { fmt.Println(err) return } fmt.Println(&quot;users: &quot;, users) // users: [{inanc map[]} {god map[admin:true]} {devil map[write:true]}] for _, user := range users { fmt.Print(&quot;+ &quot;, user.Name) switch p := user.Permissions; { case p == nil: fmt.Print(&quot; has no power.&quot;) case p[&quot;admin&quot;]: fmt.Print(&quot; is an admin.&quot;) case p[&quot;write&quot;]: fmt.Print(&quot; can write.&quot;) } fmt.Println() }}// users: [{inanc map[]} {god map[admin:true]} {devil map[write:true]}] 利用 *json.RawMessage 延遲解析有時會在解析 JSON 時才會知道其資料結構，可透過使用 json.RawMessage 的方式來延遲解析，讓資料以 byte 的形式繼續存在，等待下次解析。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type Engineer struct { Skill string `json:&quot;skill&quot;` Description string `json:&quot;description&quot;`}type Manager struct { Experienced bool `json:&quot;experienced&quot;`}type user struct { Name string `json:&quot;username&quot;` Permissions map[string]bool `json:&quot;perms&quot;` Role string `json:&quot;role&quot;` Responsibility json.RawMessage}func main() { input := []byte(` [ { &quot;username&quot;: &quot;inanc&quot;, &quot;role&quot;: &quot;Engineer&quot;, &quot;Responsibility&quot;:{ &quot;skill&quot;:&quot;Python&amp;Golang&quot;, &quot;description&quot;:&quot;coding&quot; } }, { &quot;username&quot;: &quot;god&quot;, &quot;role&quot;: &quot;Manager&quot;, &quot;Responsibility&quot;:{ &quot;experienced&quot;: true }, &quot;perms&quot;: { &quot;admin&quot;: true } }, { &quot;username&quot;: &quot;devil&quot;, &quot;role&quot;: &quot;Engineer&quot;, &quot;Responsibility&quot;:{ &quot;skill&quot;:&quot;Infra&amp;Network&quot;, &quot;description&quot;:&quot;coding&quot; }, &quot;perms&quot;: { &quot;deploy&quot;: true } } ]`) var users []user if err := json.Unmarshal(input, &amp;users); err != nil { fmt.Println(err) return } // fmt.Println(&quot;users: &quot;, users) // users: [{inanc map[]} {god map[admin:true]} {devil map[write:true]}] for _, user := range users { fmt.Print(&quot;+ &quot;, user.Name) switch r := user.Role; r { case &quot;&quot;: fmt.Println(&quot; has no power.&quot;) case &quot;Manager&quot;: fmt.Println(&quot; is an Manager.&quot;) var responsibility Manager if err := json.Unmarshal(user.Responsibility, &amp;responsibility); err != nil { fmt.Println(&quot;error:&quot;, err) } fmt.Println(&quot;Manager's responsibility: &quot;, responsibility.Experienced) case &quot;Engineer&quot;: fmt.Println(&quot; is an Engineer.&quot;) var responsibility Engineer if err := json.Unmarshal(user.Responsibility, &amp;responsibility); err != nil { fmt.Println(&quot;error:&quot;, err) } fmt.Println(&quot;Engineer's responsibility: &quot;, responsibility.Description) fmt.Println(&quot;Engineer's skill: &quot;, responsibility.Skill) default: fmt.Println(&quot;No Role&quot;) } fmt.Println() }}","link":"2020/01/18/Go/%5BGo%5D%20JSON%20%E8%99%95%E7%90%86/"},{"title":"[Go] Map","text":"前言本文主要紀錄 Go 語言中的 Map Golang 中的 mapmap 為 Golang 中鍵值對(key-value)的資料結構，左側為 key ，右側為 value，有以下幾個特性: 排列無一定順序 key 在 map 是唯一的，而 value 可能不是 適合用在： 基於 key 快速尋找、取得和刪除資料 map 的零值為 nil 相關操作宣告 map語法結構 1var m map[KeyType]ValueType 說明 KeyType: 鍵的資料型別 ValueType: 值的資料型別 map 的零值前面提到過 map 的零值為 nil，而值為 nil 的 map 沒有 key，來看以下範例: 1234567var m map[string]intfmt.Println(m)if m == nil { fmt.Println(&quot;m is nil&quot;)} 輸出 1m is nil 若將 key 加到值為 nil 的 map 的會導致 Golang 於執行時期發生錯誤 123var m map[string]intm[&quot;hello&quot;] = 1 彙報如同下方的錯誤 1panic: assignment to entry in nil map 初始化 map 實例使用 make() 函示即可建一個 map 實例，該函式會回傳已初始化及可以使用的 map 值語法結構 1make(map[KeyType]KeyType) 來看範例 123456789101112131415m := make(map[string]int) // 等同 m := map[string]int {} or var m = map[string]int{}fmt.Println(m) // map[]fmt.Println(len(m)) // 0if m == nil { fmt.Println(&quot;m is nil&quot;)} else { fmt.Println(&quot;m is not nil&quot;)}m[&quot;hello&quot;] = 1fmt.Println(m) // map[hello:1]// 取得特定 key 對應的 valuefmt.Println(m[&quot;hello&quot;]) // 1 輸出結果為： 12345map[]0m is not nilmap[hello:1]1 初始化 map 時給值遇到已知 map 中會有 key-value 的情形，可以如下方範例建立 map 123456789var m = map[string]int{ &quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3, &quot;four&quot;: 4, &quot;five&quot;: 5, }fmt.Println(m) // map[five:5 four:4 one:1 three:3 two:2 注意: 最後一個必需加上逗號，否則將出現編譯錯誤若是最後一個 key-value 項目後不換行，最後一個就不需要逗號 12t := map[string]int{&quot;t1&quot;: 1, &quot;t2&quot;: 2}fmt.Println(t) // map[t1:1 t2:2] 可用來做為 key 的值Golang 裡可用來做為 key 的值，須為 comparable 型態，如：數值、字串、布林值、channel、pointer、struct、interface 等等，注意：函式、切片(slice)、map 皆不能做為 key map 為參考型別若將 map 指派給新變數時，它們皆參考同樣底層的資料結構 123456789101112131415mm1 := map[string]int{ &quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3, &quot;four&quot;: 4, &quot;five&quot;: 5,}mm2 := mm1fmt.Println(&quot;mm1 = &quot;, mm1)fmt.Println(&quot;m2 = &quot;, mm2)fmt.Println(&quot;========&quot;)mm2[&quot;ten&quot;] = 10fmt.Println(&quot;mm1 = &quot;, mm1)fmt.Println(&quot;mm2 = &quot;, mm2) 由下述結果可知，將 mm1 賦值給 mm2 後(mm2 := mm1)，只改變 mm2 的 key 對應的值，mm1 相同名稱的 key 也跟著改變 -&gt; 一個改變，另一個也相應的改變 12345mm1 = map[five:5 four:4 one:1 three:3 two:2]mm2 = map[five:5 four:4 one:1 three:3 two:2]========mm1 = map[five:5 four:4 one:1 ten:10 three:3 two:2]mm2 = map[five:5 four:4 one:1 ten:10 three:3 two:2 key-value 的操作map 存取寫過 Python 的人對這個用法: m[key] 一點也不陌生，類似於對 dictionary 的操作 12345678910111213141516// 初始化 mapvar person = make(map[string]string)// 把 key, value 加到 map 裡person[&quot;name&quot;] = &quot;Tom&quot; person[&quot;gender&quot;] = &quot;male&quot;person[&quot;country&quot;] = &quot;ROC&quot;fmt.Println(person) // // map[country:ROC gender:male name:Tom]// 取得目標 key 對應的值fmt.Println(person[&quot;name&quot;]) // Tom// 若是指定的 key 存在，則會覆寫該 key 原先對應的值 person[&quot;name&quot;] = &quot;Jack&quot;fmt.Println(person) // map[country:ROC gender:male name:Jack] 取得未分派給 map 中 key若分派得 key 尚未存於 map ，則會得到 map 值型別的零值 12city := person[&quot;city&quot;]fmt.Println(city) // &quot;&quot; 在上面的範例中，由於名為 city 的 key 不存於 map 中，得到 map 值型別對應的零值。由於 map 值的型別是 string，因此輸出的結果為 &quot;&quot; 所以在Golang 中即便 key 不存於 map 裡，也不會出現執行時期錯誤 如何檢查 map 中不存在的 key?其實使用 mapName[key] 時，除了得到分派給特定的 key 對應的值，同時回傳一個布林值。換句話說，若是沒有該 key ，即回傳該值的資料型別的零值，第二個是布林值，指出鍵是否存在。拿上述範例來看 12345name, ok := person[&quot;name&quot;]fmt.Println(&quot;name: &quot;, name, ok)city, ok := person[&quot;city&quot;]fmt.Println(&quot;city: &quot;, city, ok) 回傳結果 12name: Jennifer truecity: false 從結果可知，若該 key 是存在的，回傳布林值為 true，反之則為 false。藉由上述方法，我們也能單純做檢查 key 是否存在，使用 _ 略過回傳的值 1234567891011if _, ok := person[&quot;name&quot;]; ok { fmt.Println(&quot;Name existed&quot;)} else { fmt.Println(&quot;No name&quot;)}if _, ok := person[&quot;city&quot;]; ok { fmt.Println(&quot;City existed&quot;)} else { fmt.Println(&quot;No city&quot;)} 結果 12name: JenniferNo city 刪除 map 中的 key使用內建函式 delete() 刪除 map 中的 key，而函式不會回傳任何值。若該 key 不存於 map中，也不會執行任何操作。 語法結構1delete(map, key) 範例 12345678910person := map[string]string{ &quot;name&quot;: &quot;Tom&quot;, &quot;gender&quot;: &quot;male&quot;, &quot;country&quot;: &quot;ROC&quot;,}fmt.Println(person) // map[country:ROC gender:male name:Tom]delete(person, &quot;gender&quot;)fmt.Println(person) // map[country:ROC name:Tom] 迭代 map透過 for 迴圈搭配 range 迭代 map 123456789101112131415161718192021person := map[string]string{ &quot;name&quot;: &quot;Tom&quot;, &quot;gender&quot;: &quot;male&quot;, &quot;country&quot;: &quot;ROC&quot;,}fmt.Println(&quot;====== 迭代 key, value ======&quot;)for k, v := range person { // 迭代 key, value fmt.Println(&quot;key: &quot;, k) fmt.Println(&quot;value: &quot;, v)}fmt.Println(&quot;====== 只迭代 key ======&quot;)for k := range person { // 只迭代 key fmt.Println(&quot;key: &quot;, k)}fmt.Println(&quot;====== 只迭代 value ======&quot;)for _, v := range person { // 只迭代 value fmt.Println(&quot;value: &quot;, v)} 結果 123456789101112131415====== 迭代 key, value ======key: namevalue: Tomkey: gendervalue: malekey: countryvalue: ROC====== 只迭代 key ======key: namekey: genderkey: country====== 只迭代 value ======value: Tomvalue: malevalue: ROC 排序 map本文開頭有提及 map 排列無一定順序，若要將結果做排序，必須另外處理 123456789101112131415person := map[string]string{ &quot;name&quot;: &quot;Tom&quot;, &quot;gender&quot;: &quot;male&quot;, &quot;country&quot;: &quot;ROC&quot;,}keys := make([]string, 0, len(person))for key := range person { keys = append(keys, key)}sort.Strings(keys)for _, key := range keys { fmt.Printf(&quot;%s : %q\\n&quot;, key, person[key])} 結果 123country : &quot;ROC&quot;gender : &quot;male&quot;name : &quot;Tom&quot;","link":"2020/01/10/Go/%5BGo%5D%20Map/"},{"title":"[Go] 陣列(Array)","text":"前言陣列是一個有著編號的序列(索引值0為開頭)，陣列裡的每個元素都有相同的單一型別，元素的型態及個數決定了陣列的型態。 宣告宣告陣列時，在[]內放入元素個數，並且宣告元素的資料型態，索引值由0開始。如:宣告一個放3個integer的陣列(容器) 1var arr [3]int 也可在上述範例放入{}，必須採短語法的方式。 1arr := [5]int{0, 1, 2} 如果賦值的數量比陣列大小還少，會自動給予初值，就是從編號0開始填。 也可以使用...，或者給予一個空陣列，只寫[]，讓編譯器自動判斷數量 12345arr := [...]int{1, 2, 3, 4, 5}fmt.Println(arr) // [1 2 3 4 5]// 或是arr := []int{1, 2, 3, 4, 5}fmt.Println(arr) // [1 2 3 4 5] 分行宣告有時陣列可能會太長而無法用一行來表示，可以用下面的方式來分行: 1234567x := [5]float64{ 1, 2, 3, 4, 5,} 如果宣告的元素數量超過[]中指定的數量，那麼會有out of bounds的編譯錯誤。 錯誤宣告若採用一般宣告的方式，會報錯。 1var arr [5]int{0,1,2} 檢視長度使用len()檢視陣列長度(或做容器大小) 12var arr [5]int{0,1,2}fmt.Println(len(arr)) // 5 指定元素指定某個位置的值可針對某個位置的元素進行賦值 123456789package mainimport &quot;fmt&quot;func main() { var arr [5]int arr[1] = 100 fmt.Println(arr) // [0 100 0 0 0]} 搭配for loop12345var arr [10]intfor i := 0; i &lt; 10; i++ { arr[i] = i}fmt.Println(arr) // [0 1 2 3 4 5 6 7 8 9] for range除了一般方法，也可以用for index, value range 12345678var total float64x := [5]float64{98, 93, 77, 82, 83}for index, value := range x { fmt.Println(index) total += value}fmt.Println(total / float64(len(x))) 比較簡潔的方式若for不需要索引的情況下，可以採用_避免因為定義index卻未使用，導致編譯器報錯的問題。 123456var total float64x := [5]float64{98, 93, 77, 82, 83}for _, value := range x { total += value}fmt.Println(total / float64(len(x))) _為Go中的blank identifier 陣列的比較要比較不同陣列長度與陣列內的元素，需要型態相同才可以做比較，如果將 [5]int 與 [10]int 做比較，編譯器編譯時會發生 mismatched types 的錯誤訊息，而指定陣列給另一陣列時，也必須是相同型態的陣列。 巢狀陣列如果想要做一個多維陣列，可以使用巢狀陣列來完成。如: 建立一個2X2的陣列 12345678package mainimport &quot;fmt&quot;func main() { var arr [2][2]int fmt.Println(arr) // [[0 0] [0 0]]} 參考身為複合值的陣列","link":"2020/01/08/Go/%5BGo%5D%20%E9%99%A3%E5%88%97(Array)/"},{"title":"[Go] 環境安裝與設定","text":"圖片源 前言本篇用於記錄Go的安裝、環境設定等前置工作。 安裝GoMac OSX的話可以直接從Terminal用Homebrew進行安裝： 1brew install go 或是透過官方下載 Go會在系統內預設一個專屬於放置所有Go專案的資料夾 查看相關資訊及設定查看版本1go version 查看Go語言的環境變數與使用工具的配置等資訊。1go env 執行指令後可以看到許多相關資訊 查看Go工作目錄go命令仰賴一個重要的環境變數:GOPATH，為Go的工作目錄，集中管理code, package和執行檔，執行下面的指令可以看到目前go的工作目錄 1go env GOPATH 或是執行以下方法 1echo $GOPATH 1/Users/tsungyuchen/go 如果想要在非預設工作區的路徑工作，那麼你需要設定GOPATH環境變數指向那個目錄 GOPATH 路徑問題 解決方法 GOROOTGolang主程式安裝的位置 設置的環境變數如果是bash中設置 1vim .bash_profile 使修改立刻生效 1source .bash_profile 編譯成二元檔執行go build將檔案進compile成二元的執行檔(給機器讀的) 執行為執行檔如:./main: 執行名為main 的執行檔 查看編譯後的二進制檔案指令: ls -l Packages為該檔案的標題，同時也表示該檔案的內容摘要，必須寫在第一行。package main代表這個檔案內容標題為main，這是Go內建的規則，在執行.go的程式時，一定要執行名稱為main的package，若沒有按照規則，執行程式會出現以下錯誤訊息： 重要觀念: Packages: 每個 Go 程式都是由package組成的，為了方便維護，盡量將package名稱和目錄名稱一致)圖片來源 自定義一個packageGo可以自己定義一個package，在主要檔案引入該package時，加入import該package的資料夾名稱，而自定義的package若要匯出給其他使用，先定義該檔案下的package名稱、函式名稱。 若是自定義的檔案名稱，funtion名稱必須要是大寫。 範例:若今天要自己定義一個package，在src目錄下建立名為add的資料夾名稱，並在其資料夾底下建立add.go的檔案，檔案內容如下add.go 12345678package add // 定義package名import &quot;fmt&quot;// function 必須為&quot;大寫&quot;func Add() { fmt.Println(&quot;This is add&quot;)} main.go匯入add 1234567891011package mainimport ( &quot;add&quot; &quot;fmt&quot;)func main() { fmt.Println(&quot;main is here!&quot;) add.Add() // 呼叫Add()} package 有兩種：執行用的package、函式庫的package比較函式庫的package 不可被編譯，但可被不同專案引入 package名可以自訂 function名可以自訂，但必須要大寫 執行用的package 用於執行整支程式 不可被引入 需有名為main的package名 需有名為main的function名 匯入模組import 套件名稱 fmt為format縮寫的套件名稱，主要用於調整及顯示內容。也可自訂的package名稱。 Go預設搜尋package是從src目錄底下開始搜尋 import自定義package時注意的點 由於import只能指定資料夾，無法指定檔案 同個資料夾底下只能有一個package，如：資料夾底下所有檔案的package名稱都統一是test_package 檔案主要執行的函式若檔案內的package名稱是main，則一定要有一個是main名稱的function作為執行的函式。 若沒有的話，會出現錯誤訊息： 除了main之外，也可自定義其他funcion，但這些function不會主動執行，而是需要在main function內進行呼叫。如下行範例 1234567891011121314package mainimport ( &quot;fmt&quot;)func main() { fmt.Println(&quot;main here!1&quot;) test()}func test() { fmt.Println(&quot;test here!&quot;)} 一次執行同個資料夾下多個.go檔案當同個資料夾下有多個.go檔案時，在其中一個程式裡面呼叫其他檔案所定義的函式可以不需要import該檔案而直接呼叫，並執行 1go run *.go 範例假設今天名為test的資料夾下分別有一個main.go及test.go檔test.go檔內的程式碼: 1234567package mainimport &quot;fmt&quot;func test() { fmt.Println(&quot;test here!&quot;)} main.go檔內的程式碼: 1234567891011package mainimport ( &quot;fmt&quot;)func main() { fmt.Println(&quot;main here!&quot;) test()} main.go檔內的程式碼在不引入test.go檔的情況下執行go run *.go時的執行結果: 成功呼叫test.go檔案裡面的test()函式。 但是！！！！ 如果單獨執行main.go會出現undefined: test的錯誤訊息 原因：go在run之前會先進行編譯操作，而在此處的編譯它只會以這個main.go為準，導致其他幾個引用文件中的方法出現找不到的情況(但採用go build的方式又不一樣，go會自動找引用文件並打包) 參考Golang 官方教學 如何編寫Go程式 GOPATH 與工作空間 Go 程式設計導論 Go起步走 - 檔案基本結構","link":"2020/01/06/Go/%5BGo%5D%20Go%20%E7%92%B0%E5%A2%83%E5%AE%89%E8%A3%9D%E8%88%87%E8%A8%AD%E5%AE%9A/"},{"title":"[Go] Pointer (指標)","text":"什麼是指標？指標是以變數的形式來存另一個變數的記憶體位址。一般情況下，不會直接使用指標的值，而會透過指標間接操作另一個值。 1234567n := 2// 參考變數 n 的記憶體位置nPtr := &amp;n// 印出記憶體位址fmt.Println(nPtr) 指標宣告語法結構： 12// A pointer of type Tvar p *T 說明： 型別 T 是指標指向的變數的型別， T 可替換成其他資料型別 12// A pointer of type intvar p *int 上述範例表 p 指標只能儲存 int 類型的變數記憶體位址。 指標的零值：不管指向的型別為何，任何未初始化的指標都會是 nil → 指標的零值為 nil 1234var p *intvar s *stringfmt.Println(&quot;p = &quot;, p) // p = &lt;nil&gt;fmt.Println(&quot;s = &quot;, s) // s = &lt;nil&gt; 指標初始化123456789var x = 10var y *int = &amp;x// 由於編譯器可推斷出指標變數的型別，所以可省略上面範例中指標 y 的型別宣告(*int)：var y = &amp;xfmt.Println(&quot;Value stored in variable x = &quot;, x) // 10fmt.Println(&quot;Address of variable x = &quot;, &amp;x) // 0xc000012078fmt.Println(&quot;Value stored in variable p = &quot;, y) // 0xc000012078 解參考指標解參考又作間接取值，只要於指標前面加個 * 符號，可存取存在指標所指向變數中的值。 1234var x = 10var y = &amp;xfmt.Println(&quot;y = &quot;, *y) // 10 修改指標設定存在變數中的值解參考除了前述的間接取值的用途外，亦可對其做修改 123456var x = 10var y = &amp;xfmt.Println(&quot;y before assigned a new value = &quot;, *y) // 10*y = 20fmt.Println(&quot;y after assigned a new value = &quot;, *y) // 20 new() 函數建立指標透過 new() 函數將型別作為參數，配置足夠的記憶體來裝該型別的值，回傳指向該型別的指標 1234z := new(int) // 指標接收 int 型別的參數*z = 10000fmt.Println(&quot;z and *z: &quot;, z, *z) // 0xc000116020 10000 指標指向指標指標除了能指向任何型別的變數外，亦可指向另一個指標 123456789101112131415a := 1b := &amp;ac := &amp;bfmt.Println(&quot;a: &quot;, a) // a: 1fmt.Println(&quot;address of a: &quot;, &amp;a) // address of a: 0xc0000ac038fmt.Println(&quot;b: &quot;, b) // b: 0xc0000ac038fmt.Println(&quot;address of b: &quot;, &amp;b) // address of b: 0xc0000b0020fmt.Println(&quot;c: &quot;, c) // c: 0xc0000b0020// 將指標的指標進行解參考fmt.Println(&quot;*c: &quot;, *c) /* *c: 0xc0000ac038 */fmt.Println(&quot;**c: &quot;, **c) /* **c: 1 */ &gt; 注意：Go 沒有指標運算，但可進行比較","link":"2020/01/13/Go/%5BGo%5D%20Pointer%20%E6%8C%87%E6%A8%99/"},{"title":"[Go] Struct(結構) 基礎","text":"前言在 Go 語言中，提供了像 struct 這樣的複合式型別，先前幾篇文章裡，範例中的變數都是存單一的值，若想用變數表示較複雜的概念，例如： 建立一個自訂型別 Person 表一個人的實體。 這個實體擁有其屬性：姓名(name)、性別和年齡(age) ，對照現實世界的實體都可以使用結構表示，而範例包含已命名欄位&amp;屬性，將相關資料分組在一起形成一個單位。 Go 語言使用 type 定義一新型別根據前面提及的範例轉換成程式碼如下： 12345678910111213// 定義一個 Person 實例// 未簡化type Person struct { Name string Gender string Age int}// 針對同資料型別的欄位進行簡化type Person struct { Name, Gender string Age int} struct 的宣告和初始化宣告 struct前面已經有初步示範如何定義一個 struct 結構，而宣告 struct 型別跟一般變數一樣 1var p Person // p 現在為 Person 型別的變數 struct 預設值為零。對於 struct 來說，零表所有欄位均設定為其對應的零值。以上述定義好的 Person 舉例，欄位 Name 和 Gender 因型別為 string ，故預設值為 &quot;&quot;，而 Age 型別為 int ，故預設為 0。 12345var s Personfmt.Println(&quot;Person s: &quot;, s) // Person s: { 0}s.Age = 22s.Name = &quot;Jack&quot;fmt.Println(&quot;Person s: &quot;, s) // Person s: {Jack 22} 初始化 struct我們可以在初始化時給值 1234p := Person{&quot;Tom&quot;, &quot;Male&quot;, 25}// 存取 p 的 name 屬性fmt.Printf(&quot;The person's name is %s , gender is %s , age is %d\\n&quot;, p.Name, p.Gender, p.Age) // The person's name is Tom , gender is Male , age is 25 需注意的是： 不能僅初始化一部分欄位 1var p = Person{&quot;Tom&quot;} // Compiler Error: too few values in struct initializer 初始化 struct 時對欄位命名 (無換行符號分隔多個欄位)透過 field:value 的方式初始化 struct，這樣欄位順序就無關緊要。將上個範例加上欄位命名做改寫： 1234p := Person{Age: 25, Name: &quot;Tom&quot;, Gender: &quot;Male&quot;}// 存取 p 的 name 屬性fmt.Printf(&quot;The person's name is %s , gender is %s , age is %d\\n&quot;, p.Name, p.Gender, p.Age) // The person's name is Tom , gender is Male , age is 25 比較兩者的輸出結果並無差異。 初始化 struct 時對欄位命名 (有換行符號分隔多個欄位)為提高可讀性，可以用換行符號分隔多個欄位，需注意該情形下必須以逗號結尾 12345p := Person{ Age: 25, Name: &quot;Tom&quot;, Gender: &quot;Male&quot;,} 僅初始化一部分欄位採用欄位命名來初始化 struct 允許只有初始化一部分欄位，其他未初始化的欄位均設定為其對應的零值 123456p := Person{ Age: 25,}fmt.Printf(&quot;The person's name is %s , gender is %s , age is %d\\n&quot;, p.Name, p.Gender, p.Age) // The person's name is , gender is , age is 25 存取 struct 的欄位對 struct 結構使用點 . 來存取 struct 的各個欄位所對應的值，也可以做賦值 12345678910111213141516171819type VideoGame struct { Title, Genre string Published bool}pacman := VideoGame{ Title: &quot;Pac-Man&quot;, Genre: &quot;Arcade Game&quot;, Published: true,}fmt.Printf(&quot;pacman: %+v\\n&quot;, pacman) // pacman: {Title:Pac-Man Genre:Arcade Game Published:true}fmt.Println(&quot;VideoGame Title: &quot;, pacman.Title) // VideoGame Title: Pac-Manfmt.Println(&quot;VideoGame Genre: &quot;, pacman.Genre) // VideoGame Genre: Arcade Game// assgin 新的值給 Published 欄位pacman.Published = falsefmt.Println(&quot;VideoGame: &quot;, pacman) // VideoGame: {Pac-Man Arcade Game false} 傳遞 struct： 值型別struct 本身是值型別，若將一個 struct 的變數 assign 給另一個變數時，會複製原有的struct 變數且分派給一個新的 struct 。 同樣地，將 struct 傳遞給另一個函數時，該函數將取得複製後的 struct。 12345678910111213type Point struct { X, Y int}p1 := Point{10, 20}p2 := p1 // 複製 p1 的 struct 結構給 p2fmt.Println(&quot;p1 = &quot;, p1) // p1 = {10 20}fmt.Println(&quot;p2 = &quot;, p2) // p2 = {10 20}p2.X = 15fmt.Println(&quot;\\n =========== After modifying p2 ===========&quot;)fmt.Println(&quot;p1 = &quot;, p1) // p1 = {10 20}fmt.Println(&quot;p2 = &quot;, p2) // p2 = {15 20} 傳遞 struct： 指向 struct 的指標(pointer)Go 允許透過指標直接存取 struct 的欄位，使用 &amp; 符號取得指向 struct 的指標 1234567891011121314151617181920212223242526type Rental struct { Address string Rooms, Size, Price int}r := Rental{ Address: &quot;Taipei&quot;, Rooms: 111, Size: 222, Price: 9999,}r1 := &amp;rfmt.Printf(&quot;r1: %+v\\n&quot;, r1) // r1: &amp;{Address:Taipei Rooms:111 Size:222 Price:9999}fmt.Printf(&quot;r1 with *: %+v\\n&quot;, *r1) // r1 with *: {Address:Taipei Rooms:111 Size:222 Price:9999}// ===============fmt.Printf(&quot;with * -&gt; Address: %s ; Price: %d ; Rooms: %d ; Size: %d \\n&quot;, (*r1).Address, (*r1).Price, (*r1).Rooms, (*r1).Size) // with * -&gt; Address: Taipei ; Price: 9999 ; Rooms: 111 ; Size: 222// 與上面相同// r1.Address 等同於 (*r1).Address -&gt; 以此類推fmt.Printf(&quot;Address: %s ; Price: %d ; Rooms: %d ; Size: %d \\n&quot;, r1.Address, r1.Price, r1.Rooms, r1.Size)// Address: Taipei ; Price: 9999 ; Rooms: 111 ; Size: 222 有無使用指摽(pointer) 傳遞 struct 的差異 若指定或傳遞 struct 結構時，並非想要複製值域，可以使用指標 new() 函數建立 struct使用 Go 的 new() 函數來建立 struct 的實例。new() 函數分配足夠的記憶體來符合所有的 struct 欄位，各自設為零值，回傳指派新的 struct 的指標 1234567891011type Point struct { X, Y int}// 建立Point 的 struct 實例p3 := new(Point) // 此處 p3 的型別為*Pointfmt.Println(&quot;p3: &quot;, *p3) // p3: {0 0}p3.X = 1p3.Y = 3fmt.Println(&quot;p3: &quot;, *p3) // p3: {1 3} struct 的匿名欄位若匿名欄位為一個 struct 的時候，該 struct 所有欄位都會跟著(隱性)被引入當前定義的另一個 struct 12345678910111213141516171819202122232425262728293031323334type Human struct { Name string Age, Weight int}type Student struct { Human // 匿名欄位，Student 預設會包含 Human 下的所有欄位 speciality string}// 初始化一個學生tom := Student{Human{&quot;Tom&quot;, 25, 120}, &quot;Computer Science&quot;}// ===== 存取相應的欄位 =====fmt.Println(&quot;His name is &quot;, tom.Name) // His name is Tomfmt.Println(&quot;His age is &quot;, tom.Age) // His age is 25fmt.Println(&quot;His weight is &quot;, tom.Weight) // His weight is 120fmt.Println(&quot;His speciality is &quot;, tom.speciality) //His speciality is Computer Science// ===== 修改欄位相應的值 =====// 修改主修科目tom.speciality = &quot;Finance&quot;fmt.Println(&quot;Tom changed his speciality&quot;)fmt.Println(&quot;His speciality is &quot;, tom.speciality) // His speciality is Finance// 修改年齡fmt.Println(&quot;Tom become old&quot;)tom.Age = 46fmt.Println(&quot;His age is&quot;, tom.Age) // His age is 46// 修改體重fmt.Println(&quot;Tom is not an athlet anymore&quot;)tom.Weight += 60fmt.Println(&quot;His weight is&quot;, tom.Weight) // His weight is 180 由上述範例可知，Student 組合了 Human struct 和 string 這些基本型別，實現欄位的繼承。 值得注意的是： 若繼承與被繼承的 struct 發生欄位欄位名稱衝突(field names conflict)，以較上層的 struct 優先次序較高 另外，Student 亦可存取 Human 這個欄位作為欄位名 123tom.Human = Human{&quot;Marcus&quot;, 30, 70} tom.Human.Age -= 1fmt.Println(&quot;tom.Age: &quot;, tom.Age) // tom.Age: 29 除 struct 欄位之外，所有的內建型別和自訂型別都可以作為匿名欄位 1234567891011121314151617181920212223242526272829type Human struct { name string age, weight int}type Student struct { Human // 匿名欄位，struct Skills // 匿名欄位，自訂的型別 string slice int // 內建型別 int 作為匿名欄位 speciality string}// 初始化學生 Jennyjenny := Student{Human: Human{&quot;Jenny&quot;, 35, 50}, speciality: &quot;Biology&quot;}// 存取相應的欄位fmt.Println(&quot;Her name is &quot;, jenny.name) // Her name is Jennyfmt.Println(&quot;Her age is &quot;, jenny.age) // Her age is 35fmt.Println(&quot;Her weight is &quot;, jenny.weight) // Her weight is 50fmt.Println(&quot;Her speciality is &quot;, jenny.speciality) // Her speciality is Biology// 修改 skill 技能欄位jenny.Skills = []string{&quot;anatomy&quot;}fmt.Println(&quot;Her skills are &quot;, jenny.Skills) // Her skills are [anatomy]jenny.Skills = append(jenny.Skills, &quot;pyhon&quot;, &quot;golang&quot;)fmt.Println(&quot;Her skills now are &quot;, jenny.Skills) // Her skills now are [anatomy pyhon golang]// 修改匿名內建型別欄位前， int 預設初始值為 0fmt.Println(&quot;Her preferred number is&quot;, jenny.int) // Her preferred number is 0// 修改匿名內建型別欄位後jenny.int = 3fmt.Println(&quot;Her preferred number is&quot;, jenny.int) // Her preferred number is 3 透過上述範例可知， struct 既可以將 struct 作為匿名欄位，自訂型別、內建型別都可以作為匿名欄位，還能於對應的欄位上面做函式操作（如例子中的 append()） struct 的比較若兩個 struct 變數的所有對應欄位都相等，則兩者相等 1234567891011121314type Point struct { X, Y int}p1 := Point{3, 4}p2 := Point{3, 4}if p1 == p2 { fmt.Println(&quot;p1 and p2 相等&quot;)} else { fmt.Println(&quot;p1 and p2 不相等&quot;)}// output: p1 and p2 相等 匯出 struct 和 struct 欄位在 Go 設計的規則中，有幾個是一定要知道的: 大寫字母開頭的變數、函式、struct 型別和 struct 欄位都是可匯出的，可供外部的 package 中存取 -&gt; 公有變數 反之小寫字母開頭的變數、函式是不可匯出的，僅能在同一 package 中可見 -&gt; 私有變數 Ref Golang - Pointer, Structs, Methods 使用 Golang 打造 Web 應用程式 - struct Golang struct 教學與範例 Golang 結構入門 golang 傳值、傳指標 觀點","link":"2020/01/15/Go/%5BGo%5D%20Struct(%E7%B5%90%E6%A7%8B)%20%E5%9F%BA%E7%A4%8E/"},{"title":"[Go] Slice(切片)","text":"前言Slice是在一個陣列中的一個區段，與陣列一樣，slice 可透過索引的方式存取，同時也具有長度。但與陣列不同的是，slice 長度是可以改變的，若只想處理陣列中某片區域可以使用slice。 slice 在中括號[]之間沒有表示長度的數字 slice 底層實際上還是個陣列 參考的預設值都是nil slice 唯一可以用 == 比較的對象為nil，儲存slice參考的變數也無法進行== 比較 Slice 基礎用法宣告 sliceslice宣告方法有兩種： 像array一樣宣告, 不須指定 slice 大小 使用內建函數make 像 array 一樣宣告123a := []int{1, 2, 3, 4, 5}fmt.Println(len(a)) //5fmt.Println(cap(b)) //5 使用內建函數 make除了上述方法外， Golang 提供了一個名為 make() 的函數來建立 slice。 它分配 長度與給定容量相同的底層陣列，並返回參考該陣列的 slice。 語法結構:1make([]T, len, cap) 參數說明： T: 該 slice 存放的資料類型 len: 該 slice 的長度 cap: 該 slice 的容量，此參數是非必要的。若省略，則預設為指定的長度 範例:有指定 slice 的容量： 1234567func main() { s := make([]int, 5, 10) fmt.Println(s) // [0 0 0 0 0] fmt.Println(len(s)) // 5 fmt.Println(cap(s)) // 10} 沒有指定 slice 的容量： 1234567func main() { s := make([]int, 5) fmt.Println(s) // [0 0 0 0 0] fmt.Println(len(s)) // 5 fmt.Println(cap(s)) // 5} Slice 的零值slice 的零值為 nil。帶有零值的 slice 沒有任何底層陣列，且長度和容量為 0 12345678910111213var slice []int// zero value of a slice is nilfmt.Println(&quot;slice == nil?&quot;, slice == nil) // truefmt.Printf(&quot;slice = %v, len = %d, cap = %d\\n&quot;, slice, len(slice), cap(slice)) // slice = [], len = 0, cap = 0 var games []stringgame := []string{}fmt.Printf(&quot;games == nil? : %t\\n&quot;, games == nil) // truefmt.Printf(&quot;game == nil? : %t\\n&quot;, game == nil) // falsefmt.Printf(&quot;game == nil? : %t\\n&quot;, game) // [] 常見用法re-slicing 重新切片使用冒號間隔兩個參數，此方式可擷取 slice 特定範圍的值。 語法結構1slice[start:end] 說明 start: 起始位置，預設值為 0 end: 終點，預設值為該 slice 的長度(len(slice)) 需要注意的是: [start:end] 取出的範圍是 start 到 end - 1 的範圍 start, end 值可不給，如: [:] 12345678910x := []int{1, 2, 3, 4, 5}y := x[:] fmt.Println(&quot;y: &quot;, y) // y: [1 2 3 4 5]y = x[:2]fmt.Println(&quot;y: &quot;, y) // y: [1 2]y = x[2:] fmt.Println(&quot;y: &quot;, y) // y: [3 4 5]y[2] = 0 fmt.Println(&quot;y: &quot;, y) // y: [3 4 0]fmt.Println(&quot;x: &quot;, x) // x: [1 2 3 4 0] 重新切片後的 slice 底層陣列不變，僅改變指標位址 觀察到上述重新切片後的 slice 底層陣列不變的情況後，若不想兩個 slice 共用同一個陣列，則要使用另一個內建函數 copy() 拷貝: copy()copy() 將一個 slice 的內容，複製至另一個 slice (複製 slice 中原始指向的底層陣列至另一個新的 slice ，且新slice 指向新陣列 語法結構1copy(dst-slice, src-slice) 結合 re-slicing 指定要複製的位置123456x := []int{1, 2, 3, 4, 5}y := []int{6, 7, 8}copy(y, x[2:]) // 把 x 中從第 2 個數至最後一個數值，複製進 yfmt.Println(&quot;x:&quot;, x, &quot;y: &quot;, y) // x: [1 2 3 4 5] y: [3 4 5]y[2] = 0fmt.Println(&quot;x:&quot;, x, &quot;y: &quot;, y) // x: [1 2 3 4 5] y: [3 4 0] 注意以下情況 len(src-slice) &lt; len(dst-slice) 時: 會覆蓋 dst-slice的前 len(src-slice) 個數123456x := []int{1, 2, 3, 4, 5}y := []int{6, 7, 8}copy(x, y) // 把y複製進xfmt.Println(&quot;x:&quot;, x, &quot;y: &quot;, y) // x: [6 7 8 4 5] y: [6 7 8]y[2] = 0fmt.Println(&quot;x:&quot;, x, &quot;y: &quot;, y) // [1 2] len(src-slice) &gt; len(dst-slice) 時: 複製src-slice 與 dst-slice 等長的值123456x := []int{1, 2, 3, 4, 5}y := []int{6, 7, 8}copy(y, x) // 把 x 複製進 yfmt.Println(&quot;x:&quot;, x, &quot;y: &quot;, y) // x: [1 2 3 4 5] y: [1 2 3]y[2] = 0fmt.Println(&quot;x:&quot;, x, &quot;y: &quot;, y) // x: [1 2 3 4 5] y: [1 2 0] 擴增: append()在給定的 slice 尾端擴增的新元素，回傳一個新的 slice 若給定的 Slice 無足夠的容量容納這些新元素，則會新配發具有更大容量的底層陣列。原有的 slice 底層陣列中所有元素都會被複製到新陣列內，再添加新元素。 反之，若給定的 slice 有足夠容量來容納新元素，則使用其底層陣列並將新元素附加到同一陣列中。 語法結構1append(s []T, x ...T) 範例擴增單一元素 123456789nums = []int{1, 2, 3}_ = append(nums, 4)fmt.Println(nums) // [1 2 3]nums = append(nums, 4)fmt.Println(nums) // [1 2 3 4] ellipsis: 將一個 Slice 添加到另一個 slice使用運算子: ... 將一個 slice 直接添加至另一 slice 1234567nums = []int{1, 2, 3}tens := []int{12, 13}nums = append(nums, tens...) fmt.Println(nums) // [1 2 3 12 13] slice 中放 slice我們亦可於 slice 中放另外一個 slice，類似二維的概念 123456789number := [][]int{ {1, 2}, {3, 4}, {5, 6},}fmt.Println(&quot;slice number: &quot;, number) // slice number: [[1 2] [3 4] [5 6]]fmt.Println(&quot;length: &quot;, len(number)) // length: 3fmt.Println(&quot;capacity: &quot;, cap(number)) // capacity: 3 slice literals可用與迭代陣列相同的方式對 slice 做迭代。 for-loop 的形式 (without range)123for i := 0; i &lt; len(numb); i++ { fmt.Println(numb[i])} for-loop 的形式 (with range)123for i, v := range numb { fmt.Println(i, v)} 需注意之處slice 底層有個指標指向一個 arrayslice 本身是一個引用型別，底層會有個指標指向一個array slice 的長度 == slice 中元素的數量slice 的長度是 slice 中元素的數量 slice 為 nil 時，不會於 loop 中的 range 執行123456var games []stringfor i, game := range games { fmt.Println(&quot;nil!!!&quot;) fmt.Println(&quot;game in range: &quot;, game)} 上述範例會發現宣告 games 為 slice 型別後，初始值為 nil ，嘗試用迴圈讀取裡面的值，發現沒有印出任何東西，程式仍能夠正常運作。空的 Slice 值等同於 nil，來看下述範例： 1fmt.Println(&quot;equal? &quot;, games == nil) 執行的結果為 true，表兩者同等。 array v.s slice 差異array 固定長度，長度在編譯時期(complie time)已經建立 array 長度屬於型別的一部分 宣告後無法改變陣列長度 宣告 array 內的元素型別為 int 且未給值時，array 內的元素值為 0 array 在長度相同時可進行比較 array 在長度相同時可進行賦值(assign: =)操作 slice 長度可變動 長度不屬於型別的一部分 長度於執行期(runtime)才變動 宣告 slice 而未給值時，slice 內的值為 nil slice 只可對 nil 值做比較(比較的對象是 nil) slice 在元素型別相同時即可進行賦值(assign: =)操作，跟長度無關 範例1234567891011121314151617func main() { { // its length is part of its type var nums_arr [5]int // 宣告長度為 5 的空 array fmt.Printf(&quot;nums array: %#v\\n&quot;, nums_arr) // [5]int{0, 0, 0, 0, 0} } { // its length is not part of its type var nums_slice []int // 宣告長度為 5 的空 slice fmt.Printf(&quot;nums slice: %#v\\n&quot;, nums_slice) // []int(nil) fmt.Printf(&quot;len(nums_slice) : %d\\n&quot;, len(nums_slice)) // []int(nil) // won't work: the slice is nil. fmt.Printf(&quot;nums_slice[0]: %d\\n&quot;, nums_slice[0]) // panic: runtime error: index out of range [0] with length 0 fmt.Printf(&quot;nums_slice[1]: %d\\n&quot;, nums_slice[1]) // panic: runtime error: index out of range [1] with length 0 } Ref [Golang] Array v.s. Slice Golang Slice 介紹 底層為陣列的 slice","link":"2020/01/09/Go/%5BGo%5D%20Slice(%E5%88%87%E7%89%87)/"},{"title":"[Mac&#x2F;Linux] bash shell筆記- 檔案權限與目錄","text":"鼠年全馬鐵人挑戰 - WEEK 04 前言本文紀錄如何在bash shell做檔案權限的配置。 檔案具有的三種身份Linux檔案的基本權限有九個，分別是owner、group、others三種身份各有自己的read、write、execute權限 檔案擁有者(user) 群組(group) 其他人(other) 如果對所有開啟檔案所有權限，顯示的字元為：-rwxrwxrwx，需要把這九個權限(不包含-)，以三個為一組做區分。 相關指令查看vim是否存在vi 查看vim的路徑which vim或是which is vim或whereis vim 建立檔案vim fileName或是vim fileName.sh，.sh可加可不加。 範例1vim pb_do 會進入vim的編輯模式，看到新增的pb_do檔，輸入echo &quot;hi!&quot;後，執行:wq!保存並退出。 查看系統變數$PATH或是echo $PATH 執行檔案1./pb_do 執行上方指令會跳出權限不足的訊息 1sudo ./pb_do 執行上方指令會跳出sudo: ./pb_do: command not found，表示無法執行該檔案，所以要查看該檔案內容判斷是否可執行 1ls -l pb_do 打開發跳出的訊息只有r、rw，表示此檔案只可讀取(r)、寫入(w)，而沒有x(執行) 修改檔案/目錄的權限 - chmod在Linux或其他類Unix作業系統中, 每個檔案及目錄都會有一個權限, 這個權限會定義誰可以讀取(r)、寫入(w)及執行(x) 該檔案。檔案權限的改變需下chmod指令，設定方法有兩種： 數字類型 符號類型 上一個pb_do的例子可以看到vim寫入的新檔案沒有執行的權限，所以需要修改檔案目錄權限chmod，更多說明可翻閱鳥哥這篇文章 符號類型修改檔案權限範例： 加入執行的權限延續上個例子，針對pb_do加入執行的權限 1chmod +x pb_do 上圖可發現原本檔案資訊只有-rw-r--r--@變成-rwxr-xr-x，新增了x執行權限。 現在擁有執行權限後，執行： 1./pb_do 成功執行剛剛加入的檔案！ 範例： 移除執行的權限延續上個例子，針對pb_do移除執行的權限。 1chmod -x pb_do 將+x替換成-x即可移除 如果檔案權限為-rwxr-xr-x表示: user(u)：u表示檔案擁有者才具有可讀、可寫、可執行的權限 group 與 others (g/o)：表示group與others即具有可讀與執行的權限。 再看一個例子： 只對檔案擁有者修改執行的權限1chmod u+x pb_do u表示檔案使用者 修改group的權限1chmod g+x pb_do 同理可以應用在新增寫入的權限上，例如 1chmod g+w pb_do 加入w寫入的檔案權限-rwxrwxr-- 修改others執行的權限1chmod o+x pb_do 加入o執行檔案的權限-rwxrwxr-- 修改所有的執行權限a表示所有，指令替換成a，例如刪除所有身份的使用權限 1chmod a-x pb_do 刪除所有身份的執行權限 數字類型修改檔案權限除了透過符號來標示檔案權限之外，也可以使用數字來代表各個權限，個人是不太喜歡用死背的，稍微用推的很快就可以知道數字對應的權限。 文章開頭有提到檔案的基本權限有九個，三個看作一組，如果拆開了看就是rwx為一組(rwx三個權限都有的情況下)，數字加總是7，以二進位來看的話就是111。來看段範例:假設今天要配置檔案權限是檔案擁有者可讀、寫、執行，其餘兩個身份只開放讀、執行，所以設定權限的變更時，輸入的數值就是755，詳情如下 123owner = rwx = 4+2+1 = 7group = r-x = 4+0+1 = 5others= r-x = 4+0+1 = 5 執行下面指令 1chmod 755 pb_do 輸出結果：-rwxr-xr-x上圖結果證實數值也可以做檔案權限管理。 當然也可以把三個身份的三個權限都開啟，指令會變成: 1chmod 777 pb_do 結果： -rwxrwxrwx 簡單歸納數值代表的權限 r:4 w:2 x:1 回顧一下，掌握幾個原則就可以完成配置檔案權限囉！ 每個檔案的九個基本權限(三個身份與各自擁有的權限) 三個字元看作一組，分別代表的三個身份 符號類型修改檔案權限(r/w/x) 數字類型修改檔案權限(用二進位去思考，或是直接記對應的數值)。 若內容或觀念有誤，歡迎在下面留言給我。 參閱Linux 的檔案權限與目錄配置","link":"2020/03/08/OS/%5BLinux%5D%20bash%20shell%E7%AD%86%E8%A8%98-%20%E6%AA%94%E6%A1%88%E6%AC%8A%E9%99%90%E8%88%87%E7%9B%AE%E9%8C%84%E9%85%8D%E7%BD%AE/"},{"title":"[Mac&#x2F;Linux] bash shell筆記- 用shell script執行你的 Python程式","text":"鼠年全馬鐵人挑戰 - WEEK 06 前言本篇紀錄如何用shell script執行寫好的Python檔案。 實作範例假設一個檔案裡面有一支由Python撰寫的script，名為echo.py。如果要利用shell去執行echo.py，記得先新增檔案權限給echo.py: 1chmod u+x echo.py 執行Python檔 1python echo.py 印出python print，但是無法用bash的指令來執行。 若要使用bash指令來執行Python檔案，需先確認python主程式的位置 1which python 回傳Python主程式的位置 在檔案內容的開頭加上#!，後面加上執行主程式的所在位置 12#!/Users/tsungyuchen/anaconda3/bin/pythonprint(&quot;python print&quot;) 接著執行./echo.py Hashbang是一個由井號(#)和驚嘆號(!)構成的字元，需寫在文字檔案的第一行的前兩個字元，作業系統的程式載入器會分析Hashbang後的內容，將這些內容作為直譯器指令，並呼叫該指令。 如: 以指令#!/bin/bash開頭的檔案在執行時會實際呼叫位於/bin/bash程式。 以上範例為簡單用Shell Script來執行Python程式碼","link":"2020/03/22/OS/%5BMac&Linux%5D%20bash%20shell%E7%AD%86%E8%A8%98-%20%E7%94%A8shell%20script%E5%9F%B7%E8%A1%8C%E4%BD%A0%E7%9A%84%20Python%E7%A8%8B%E5%BC%8F/"},{"title":"[OS] 作業系統筆記-Process","text":"前言上篇有稍微提到關於Process的基本概念，本篇要近一步探討Process。 什麼是Process?中文又作『行程』;簡單來說，Process就是正在運行中的程式。也就是說，當在執行的檔案載入記憶體時，程式就成為行程(Process)。 一個Process主要包含有： Code Section(程式碼、程式區間) Data Section(資料區間) Stack(儲存暫時性資料) processor register Program Counter(程式計數器，擺放下一個要執行程式的地址) Process VS. Program來比較一下兩者差別 Process Program 「主動」儲存在硬碟裡 被動的，被存在硬碟中(等待執行) Process的5種狀態Process會隨著當下的情況改變狀態 new：產生新個Process running：運行中的Process wating：當有其他事件(Event)發生時，如: 週邊設備的I/O，會進入暫時等待的狀態。 注意：Process此時雖然還在記憶體中，但不在Ready Queue ready： 準備好被分配至CPU執行。當I/O事件結束或執行期間被Interrupt都會Process回到ready狀態 terminated：Process執行結束 Job Queue: 系統中的所有Process所形成的隊伍Ready Queue: 放在記憶體中多個Process所形成的隊伍，準備隨時可以被分配至CPU內執行 Process Management當系統有多個Process時，就要進行管理，而Process Control Block (簡稱PCB)就是用來管理Process。毎個Process皆有自已的PCB，PCB包含以下資訊： Process state: Process 在哪一個狀態 Process ID Program counter: 指明該Process下一個要執行的指令位址 CPU registers CPU scheduling information： Process優先順序 Memory-management information Accounting information： 用掉多少CPU的時間、使用CPU的最大時間量 I/O status information: 尚未完成的I/O Request還有哪些、還在I/O Queue中排隊之Process的編號 process scheduling (排程)為了要讓CPU能發揮最大的效益，需要process scheduler來決定 如何分配哪個process能使用CPU process scheduler分成三種 short-term scheduler: 又稱『CPU scheduler』，負責決定記憶體中的哪個process能排進CPU執行，決定的時間極短。 long-term scheduler: 又稱『job scheduler』，負責決定系統中哪些process能排進記憶體，控制記憶體內process的數量，相較之下有較長的時間可以決定。不過這個過程是單向的，意味著無法從記憶體的Ready medium-term scheduler: 保留long-term scheduler功能外，還可以將放在記憶體(Ready Queue)中的Process搬回Disk(Job Queue)，採Swap(交換)的形式 Context Switching (內容轉換)CPU在執行時，只能運用一個process，如果切換給另一個Process時，須將舊Process的相關資訊 (e.g.PCB內容) 儲存起來，並載入新Process的相關資訊，此過程稱『Context Switching』。 困難點在Context Switching的過程中，系統做的事是不具有生産力的工作，會浪費系統效能。 解法 增加Register Set: 因為Context Switching的速度取決的硬體支援程度，所以增加Register數量，盡可能讓每個Process分到一個resgister 以Thread來代替Process： 因為毎個Process都有其私有的資訊(PDB)，這些私有資訊會佔用Register。而Threads之間彼此可以共享Memory Space (如：Code Section,Data Section, Open File…)，私有的資訊量不多。所以進行Context Switching時不須對記憶體進行大量存取，可降低Context Switch負擔。 Scheduling Criteria如何衡量Scheduling的效能？ CPU Utilization (CPU使用率): 在CPU花的所有時間中，真正花在執行Process的時間占比，公式會是: (CPU Use Time) / (CPU Use Time + CPU Idle Time) Throughput (產能): 單位時間所能執行完的Process數量 Waiting Time (等待時間): 從Process待在Ready Queue到被放入CPU執行，這過程中的等待時間 Turnaround Time(完成時間): 從一個Process到完成工作所耗費的時間 Response Time (反應時間): 從Process進入系統，到系統產生第一個回應的時間 延伸閱讀 Course 4 行程管理","link":"2020/03/21/OS/%5BOS%5D%20%E4%BD%9C%E6%A5%AD%E7%B3%BB%E7%B5%B1%E7%AD%86%E8%A8%98-Process/"},{"title":"[Mac&#x2F;Linux] Command Line指令","text":"本篇紀錄Mac常用的指令(會持續更新) 基本指令基本查詢man 指令加上要查詢的指令來閱讀線上手冊，透過線上手冊可以查詢相關指令或是函數的名稱，如查詢ls的用法： 1man ls 按下鍵盤的q鍵即可離開。 查詢隱藏的檔案-a可配合其他指令來查詢隱藏的檔案，如： 1ls -a 上圖可看出，我電腦的家(home)目錄底下有許多隱藏的檔案 建立空檔案執行touch並指定檔案名稱，當指定的檔案不存在時，touch就會自動建立一個空檔案，並將檔案的時間設定為目前的時間touch 資料補齊如果文件名稱過長，或是指令只記得一部分的情形，按下鍵盤上的Tab鍵，會看到相似檔名的候選名單。而如果只有一個，它就會自動全部補上。 資料夾移除資料夾後面加個 -r 的指令，就是指要移除資料夾以及裡面全部內容，-r為--recurise的縮寫。 1rm -r 資料夾 複製資料夾1cp -r 舊資料夾名稱 新資料夾名稱 範例假設桌面有一新建的料夾test，內含test.txt的檔案如果要複製test資料夾，並命名新資料夾為test_folder，執行 1cp -r test test_folder 上面可看出成功複製新的名為test_folder的資料夾。 若改成存在兩個資料夾，分別為test、test_folder，將test_folder複製到test資料夾內，可以執行 1cp -r test_folder/ test 上圖可發現成功將test_folder複製到test資料夾！ 萬用字元萬用字元的好處是可以節省的時間，其中*代表”0個到無窮多個”任意字元，利用*搭配bash其他常用指令，處理資料就更方便快速！更多萬用字元的說明查閱鳥哥的文章。 *常用於刪除大量同個副檔名的檔案，如某個專案資料夾裡的.log檔，就可以使用*.log一次刪除所有log檔。 萬用字元*在做檔案或資料夾刪除時要特別小心，有時會誤刪部分相同的檔案及資料夾。 誤刪的情況目前桌面上的資料夾有test、test1_folder、test_folder三個資料夾，以及test.txt、test1.txt兩個.txt檔案目標要刪除三個資料夾，如果採萬用字元的做法會是 1rm -r test* 執行上述命令會連同test.txt、test1.txt兩個.txt檔案刪除！所以使用萬用字元做刪除要特別小心！ 移除文件1rm 檔案名 拷貝檔案1cp 被拷貝的檔案名 拷貝後的檔案名 如: 拷貝 hi.txt 到 hello.txt 1cp hi.txt hello.txt 檔案的移動與更名更名1mv 原檔案名 新檔案名 範例更名前:更名後: 將 hi.txt 改為 hello.txt 1mv hi.txt hello.txt 移動1mv 檔案路徑 目錄路徑 建立目錄1mkdir 目錄名 檢視當前目錄的文件1ls 顯示目錄下檔案12ls -al : 顯示目錄下隱藏的檔案ls -l : 顯示目錄下檔案 上圖的訊息包含:權限、檔案大小、上次修改時間等 退回上一層1cd .. 回到根目錄1cd ~ 開啟根目錄資料夾1open / 開啟當下電腦使用者根目錄1open ~ 開啟當前目錄1open . 顯示當前使用者目錄名稱1echo ~ 顯示當前目錄的路徑1pwd 切換路徑1cd 目標資料夾 切換至根目錄1cd / 根目錄V.S.家(home)目錄Mac 打開Terminal預設路徑會在家目錄下，可以看到~的符號若想知道當前目錄的路徑，可輸入pwd 如果是要切換至根目錄，可以輸入指令: cd /，切換路徑至根目錄夾下。 輸入ls可查看當前目錄下所有的檔案 如果要回到家目錄，輸入指令cd ~ 觀念釐清波浪線～等於電腦的名字，也就是說，cd ~與cd /Users/tsungyuchen兩者相等 絕對路徑 V.S. 相對路徑絕對路徑延續剛才上一個問題，cd /Users/tsungyuchen 路徑為斜線開頭，表示從根目錄開始。 相對路徑從目前所在目錄開始算起 進階指令找指定的檔案find 指令可在執行指令的目錄下做搜尋，找指定的檔案，並回傳路徑。 在目前的目錄底下不分英文大小寫1find -iname 要被搜尋的檔案名稱 區分英文大小寫1find -name 要被搜尋的檔案名稱 在 /home 目錄底下，找尋檔案不分英文大小寫1find -iname 要被搜尋的檔案名稱 區分英文大小寫1find -name 要被搜尋的檔案名稱 快速查看某個檔案的內容1cat 要查看的檔案內容 其實cat指令原始功能是將檔案合併，再顯示合併後的檔案，如果cat後方只接一個檔案，則直接顯示該檔案內容。 查詢檔案內的文字不用打開文件，就能查詢檔案內的文字。 1grep &quot;被搜尋的文字名稱&quot; 你的檔案名稱 如:text檔內有”hello”的文字內容執行指令 1grep &quot;he&quot; text.txt 不區分大小寫的模式搜尋字詞前面加前綴詞 -i 1grep -i &quot;被搜尋的文字名稱&quot; 你的檔案名稱 apt-getapt-get 是專門給 ubuntu, debian 等 Linux 系統使用的套件下載軟體 ssh常用來遠端連線 寫入1echo &quot;要寫入的內容&quot; &gt; 被寫入的檔案 其中&gt;寫入時會覆蓋原本檔案的內容重新寫入。 範例(重新覆蓋):假設今天桌面上有個test.txt檔，執行寫入方法: 1echo &quot;hello test&quot; &gt; test.txt 查看被寫入的檔案內容： 1cat test.txt 覆蓋剛剛寫入的檔案 1echo &quot;hello test will be cover&quot; &gt; test.txt 查看被寫入的檔案內容： 1cat test.txt 若要不覆蓋原本的檔案，將上個範例的&gt;改為&gt;&gt;即可。 範例(不覆蓋):寫入1echo &quot;add new test line&quot; &gt;&gt; test.txt echo輸出的內容會斷行，若不想斷行可以改執行printf 查看1cat test.txt 合併檔案可以透過cat指令將檔案進行合併顯示 輸出合併檔案(不影響原始檔案)如果要將兩個內容合併輸出，可使用cat 檔案1 檔案2的指令如：建立一個名為cat.txt的檔案與剛剛的test.txt進行合併輸出。 1echo &quot;content will be concat&quot; &gt; cat.txt 1cat cat.txt 輸出合併結果 cat只有單純輸出合併結果，並不影響原始檔案內容 將合併檔案後的檔案輸出成新檔案1cat 檔案1 檔案2 &gt;&gt; 合併後的新檔案 合併目標檔案，並產出合併過後的新檔案。如: 1cat test.txt cat.txt &gt;&gt; cat2.txt 上圖例子產出test.txt和cat.txt合併過後的新檔案，名為cat2.txt。 移動檔案將檔案進行移動。 1mv 目標的絕對路徑 範例假設今天桌面有個test_folder目標資料夾，要將剛剛建立的test.txt檔移至目標資料夾。 1mv test.txt /Users/tsungyuchen/Desktop/test_folder/ 補充Mac如何清除系統上被佔用的Port?查詢 PID如: 查詢 Port:3000 狀態 1sudo lsof -i:3000 清除 PID查詢PID後，找到佔用該port對應的PID 1kill PID 如對應PID為32952，則: 1kill 32952 參考文章[Day22] Linux 介紹與基礎指令 [Day23] Linux 進階指令","link":"2020/01/22/OS/%5BLinux%5D%20%E6%8C%87%E4%BB%A4%E6%93%8D%E4%BD%9C/"},{"title":"[OS] 作業系統筆記-電腦系統架構","text":"前言本篇用於紀錄這學期修作業系統的筆記，會先從基本概念開始。 什麼是作業系統?可以從兩個面向來討論 系統為資源分配者(Resource Allocator) 如何有效利用資源(CPU、Memory) 如何解決資源利用的衝突監控User Program的運行User端可能會有一些不當行為的操作，如: 不小心刪除系統檔，此時就需要作業系統來替我們把關，例如透過管理使用權限來決定是否有權做某個重要檔案的讀寫，甚至刪除。使用者可以看作電腦使用者(User)與電腦硬體(Hardware)之間的溝通橋樑，並提供一個讓User Program易於執行的環境 作業系統做什麼主要功能分為下列三項: 資源的管理 工作的管理 讓使用者使用方便 電腦系統大致上可分為四個單元 硬體(hardware) 作業系統(OS) 應用程式(application program) 使用者(user) 每個device controller皆有自己的local buffer還有registers。 register: 用來儲存指令、變數的值 local buffer: 用於暫存資料，傳送至Memory進行讀取 系統內運行的工作分兩種 I/O Bound Job 需要大量的I/O運作時間，對於CPU計算時間的需求量較少。 效能好壞是取決於I/O Device的速度 CPU Bound Job 需要大量的CPU計算的運作時間，對於I/O的需求量較少。 效能好壞是取決於CPU的速度 電腦系統的架構種類Single-Processor Systems一台電腦只有單一顆CPU Multiprocessor Systems一台電腦有多顆CPU可以處理執行的程式(Process)，又作parallel systems(平行系統) or tightly coupled systems(緊密耦合系統) 特點 共享相同的記憶體空間、I/O Device、Bus 多個CPU之間的溝通(指Data交換)，大部份是採Share Memory技術 優點 穩定度高 處理效率較佳 種類Multiprocessor Systems分兩種種類: Symmetric Multiprocessing: 對稱式多元處理 Asymmetric Multiprocessing: 非對稱式多元處理 Symmetric Multiprocessing每個Processor都有相同的工作(功能)，當某一個Processor壞了，該Processor上未完成的工作可以轉移到其它的Processor繼續執行。好處: 系統不會整個Crash Asymmetric Multiprocessing每個(或某群) Processor 各自負責不同的工作(功能)，其中有一個Processor負責控制、協調及分配Process到其它的Processors去運作，這個負責指揮的Processor稱作Master。Asymmetric類似Master/Slave，除了MasterProcessor外，其餘的Processors稱為Slave Processor。 補充Bootstrap program當電腦開機時，電腦顯示載入資訊的畫面，此時是正在檢查環境資源，Bootstrap program並非放置在硬碟，而是燒錄在Bios上。 什麼是Bios?Ref從按下電源開關開始，到可以開始操作電腦為止，這中間電腦自動執行一連串的動作 開機大致分為五個過程階段，每個階段循序漸進，必需完成這些程序，電腦才能正常運作。五個階段如下 : 初始階段（Initial Phase） 開機載入階段（Boot Loader Phase） 核心載入階段（Kernel Load Phase） 核心初始化階段（Kernel Initiation Phase） 登錄階段（Logon Phase） BIOS 為初始階段過程的執行者 BIOS 的全稱為 “ Basic Input/Output System “，從字義上來解釋就是 : 基本的輸入及輸出系統。也就是說這個微系統控制著電腦的基本輸出及輸入裝置。開機時第一個啟動的程序就是 BIOS，必須先跑完 BIOS 這個程序，電腦才能繼續開機載入階段的後續動作。 在電腦的主機板上都會有 BIOS 晶片，而上面提到的BIOS就是寫在這個晶片中的程式。 程式(Program)指的是一段靜態且可以被執行的指令集，簡單來說就是一個檔案(file)啦。 Process(行程)正在執行中的程式(Program)，也就是正在執行，已經載入到記憶體執行的程式碼。 Interrupt(中斷)CPU收到來自硬體或軟體發出的訊號(或稱事件; event)，進行相對應的處理。上圖可以發現平時CPU主要在處理使用者端的程式，當I/O Device發出訊號，要求CPU暫時中斷來處理這個訊號時，就會發生中斷(Interrupt)。 軟體的中斷又作trap 優點：相對於忙碌等待(busy waiting)、輪詢(polling)有更好的效率，因為不需要額外的資源去確認是否有事件要處理，使用中斷可以專心於正在處理的事件，不需要時也可以進入休眠狀態節省資源，亦可實現分時多工。 Interrupt 的處理流程Setps 暫停目前process 之執行。 保存此process 當時執行狀況。 OS 會根據Interrupt ID 查尋Interrupt vector。 取得ISR（Interrupt Service Routine）的起始位址。 ISR 執行。 ISR 執行完成，回到原先中斷前的執行。 作業系統的開機過程按下開關(power on) -&gt; Program Counter(程式計數器命令CPU run起來) -&gt; Bootloader(載入Kernel，做初始動作) -&gt; Disk -&gt; Main Memory 記憶體的儲存單元比較廣泛來分的話主要分 Register(暫存器)：用來暫時存放資料、指令的地方 Cache(快取)：將CPU運算的部份結果先放置於快取記憶體裡，待CPU要繼續運算時，能夠快速地讀取 Main Memory(主記憶體): CPU執行程式時暫存資料的地方，會讀取、寫入記憶體，Main Memory大小會影響CPU處理的速度 Disk(硬碟)Ref Register、Cache位於CPU內部進行管理 更細部的討論看這篇 Process同時執行的方式 Concurrent(並行) 在單一時間點只有一個Process在執行!! 所強調的是一段執行時間內，有多Process同時執行，而非單一時間點。 單一顆CPU即可做到。 範例: Multiprogramming System Parallel(平行) 在單一時間點有很多的Process在執行!! 需多顆CPU方可做到。 範例:Multiprocessing System, Distributed System 參考 陳士杰-作業系統(Operating Systems) (Operating Systems)","link":"2020/03/19/OS/%5BOS%5D%20%E4%BD%9C%E6%A5%AD%E7%B3%BB%E7%B5%B1%E7%AD%86%E8%A8%98-%E7%B3%BB%E7%B5%B1%E6%9E%B6%E6%A7%8B/"},{"title":"常用的VSCode擴充套件","text":"前言本篇筆記自己平常會使用到的VSCode擴充套件(Extensions)。要寫程式之前，若有一套好工具，可以加速寫程式的效率。 Guides 在你的程式開關符號（例如左右大括號）拉一條線，方便你識別程式區塊，避免過多的括號搞得開發者混淆。 Auto Close Tag這個功能會幫你把右括號或結束標籤補上。即使 VS Code 有內建基本補完功能了，但是他支援更多符號和設定，例如打 &lt;/ 的時候也幫我補上 HTML 的結束標籤。 Autoprefixer可以自動幫你把支援其他瀏覽器的CSS樣式自動補齊，不用另外去查有哪些瀏覽器的語法需要支援。 Bookmarks可以在你的cod標註一個書籤符號到你指定的位子， 之後就可以在VSCode右側的scrollbar 看到藍色提示。 Bracket Pair Colorizer把括弧包的一層又一層的時候用不同顏色區分開來，避免混淆，是非常棒的工具。 CSS Peek這是我非常喜歡擴充套件，他有可以直接顯示出該元素標籤的選擇器所設定的CSS做顯示，還可以直接跳到該文件底下CSS位置，這樣就省去找來找去的麻煩。 filesizeVSCode視窗的右下角會顯示檔案案目前大小。 Git HistoryGit是非常重要的版本控管工具，我們可以透過這個功能查看 Git 紀錄以及檔案歷史，可直接連結到變更的檔案。 Live Server有了這個套件，只要一按下保存，我們就可以同步更新瀏覽器上的畫面，不用再到瀏覽器上刷新頁面。 Material Icon Theme不同的檔案有不同的圖案，一眼就可以辨識出檔案類型，看起來也比較沒那麼乏味。 有些人可能之前是用Sublime的編輯器，習慣一些Sublime上的操作，VSCode有一些套件是將Sublime的功能鍵移植過來，可以快速適應不同的編輯器。 Sublime Text Keymap and Settings ImporterSublime Text 好用的游標功能搬過來 VS Code，如:選取整行、行列合併、快速指定多行游標等。 Sublime Commands把 Sublime Text 的快速鍵對應到 VS Code 的相對功能上","link":"2019/07/14/Tool/vscode/"},{"title":"[AWS] Global Infrastructure","text":"前言前一篇初步理解AWS的架構及市場之後，接著探討AWS在全國佈建的基礎建設吧！ ConceptRegion &amp; Available Zone &amp; Edge LocationAWS的基礎設施是以區域(Region)與可用區域(Available Zone)為中心來建置。 區域(Region)地球上有多個可用區域的實體位置，多個Region之間由多條海纜佈建成一個全球網。案例: 選擇客戶的客群節點靠近的區域，降低延遲 可用區域(Available Zone; 簡稱AZ): 由一或多個分散的資料中心(Data Center)所組成，而每個AZ就是一個可獨立運作的資料中心(可視為一個building)，放置於不同的獨立機構。 端點(Edge Location)為AWS服務裡面的最尾端。它可以與可用區域(AZ)互動，對所需資料進行快取，加速資料內容的讀取和使用，同時也是AWS CloudFront這個服務可運作的最小單位，目前分佈在42個國家/地區、84 個城市共 216 個連接點。 幾個重點AWS 的Global Infrastructure有幾個特點: 提供較高的穩定性目前有已推出22個區域, 69個可用區域及200多個節點。由於每個Region都是各自獨立，有助於提升伺服器的穩定性及容錯力。 計價差異不同區域所提供的服務價格會有些微差異，故選擇區域時，通常都是看在哪裡能提供最快的服務或是挑選最便宜的區域 高可用性(High Availability; 簡稱: HA)一個區域(Region)可能包含多個AZ，而多個AZ提供異地同步備份，達到高可用性，同時也有較低的延遲性圖片源以上圖為例：上圖範例是AWS RDS(關聯式資料庫服務)進行異地備份，主要資料庫實體(Instance)會跨AZ，同步備份到其他AZ進行待命(Stanby)，達到資料備援的作用。 值得注意的是，不同的等級的基礎設施(Infra)則會影響用戶的花費以及對該區域的服務品質(quality)，所以在使用服務前務必慎選區域，減少不必要的問題。","link":"2020/03/03/aws/%5BAWS%5D%20Global%20Infrastructure/"},{"title":"[AWS] 初探AWS","text":"前言近幾年雲端供應商大量投資雲端基礎建設及雲端計算，為了解決客戶的痛點，不斷地推出更多更完善的服務，隨著雲端服務在市場的接受度及普遍度提升，越來越多企業將自家服務上雲，乘著這股潮流來多了解一下雲端服務! Cloud Computing雲端運算式透過網路連線進行利用網路資源，做各式的資源運算，我們可以透過租用的方式共享軟硬體，並在不同終端設備及裝置上享有這些服務。 企業或是一般大眾可依據自身需求，向雲端服務的供應商購買能夠滿足他們需求的服務，不須從頭開始採購硬體設備,配置網路及架設環境等，購買服務後可立即享有目標資源。 另一方面來說，用戶其實可以不需要了解複雜的雲計算所需的基礎設施，甚至不需要有深厚的專業知識，大幅降低用戶的使用門檻，同時提升用戶的營運效率，另外，雲服務有個”用多少, 付多少”的特性，解決傳統用戶因使用效率不佳而造成資源浪費的問題。 指標供應商目前雲服務供應商前三大影響力的分別是: Amazon(AWS), Microsoft(Azure), Google(GCP)，這三家大廠佔雲端市場極大的比例。來看下圖2019的調查報告可窺知一二。Ref 雲服務架構種類 IaaS: 基礎架構即服務 PaaS: 平台即服務 SaaS: 軟體即服務 IaaS雲端服務供應商提供的服務(如AWS, GCP)包含網路建置, Server採購等硬體設施，或是運用虛擬化的技術，公司只需專注在硬體設備外的項目即可，如作業系統 , 應用程式等等。 傳統公司作法可能會是內部自建機房，但伴隨而來的維護問題，大幅提高企業成本，加上雲端虛擬技術逐漸蓬勃發展，開始推動這類服務，解決公司在基礎建設方面所遇到的困難點。 優點 靈活度高且可以擴展 可多人使用 優化資源的利用率 範例服務: EC2為AWS提供了虛擬服務器，EC2的用戶不需擁有實體服務器。 PaaSPaaS服務通常會包含IaaS的範圍，也就是除了基礎架構服務器，儲存和網路外，還將作業系統, 開發環境交由廠商管理，企業可以專注在Application的開發與部署。 優點 靈活度高且可以擴展 可多人使用 無需具備廣泛的系統管理知識即可輕鬆運行 範例服務: Elastic Beanstalk SaaSSaaS服務則是連同Application都幫你管理好，用戶可以直接使用。 雲服務的類型與傳統相比可看下圖圖片源 上面的比較圖可以概略知道傳統的本地部署(On-Premises)採用虛擬化技術的管理工具，軟硬體的管理,維護都是企業自己做。 如果以分層的角度來看，金字塔最底層為IaaS往上依序為PaaS, SaaS 圖片源 這篇文章有更詳細的介紹。 AWS成本定價AWS的費用計算可以簡單用一句話總結: “用多少算多少”計算的種類大略分幾類: 使用時間 使用單位 占用的資源 使用方式 以EC2為例:圖片源如果是有長期穩定的需求，相較於On Demand，可以選擇RI(Reserved Instance)或是Spot方案，享有更好的折扣。 官方認證考試為了推廣自家服務，AWS官方推出一系列的考證制度，另一方面也可以作為對服務了解程度的參考依據。 免費試用帳號AWS推出為期一年的免費帳號(註冊連結點我)，想玩玩看AWS服務的話由此註冊。 費用計算官方很貼心的提供兩種計算機，讓用戶可以快速計算費用 每月成本簡易計算器可讓用戶估計單一或多個服務的價格，另外也提供使用範本來估算完整服務價格。 TCO 計算器預估使用 AWS所節省的費用，並提供比較後的詳細報告，屬於全面性的。 參閱Overview of Amazon Web Services","link":"2020/03/02/aws/%5BAWS%5D%20%E5%88%9D%E6%8E%A2AWS/"},{"title":"[AWS] 用 ssh-agent forwarding 登入 EC2 instance","text":"鼠年全馬鐵人挑戰 - WEEK 17 前言在實習做的專案中，要用Terraform撰寫.tf腳本建置VPC，具體的架構類似下方的圖，實作的過程中因為要用ssh連EC2 Instances，藉此機會筆記一下用ssh連機器的正確做法，避免犯相同錯誤。另外，本篇的做法適用於Linux/MacOS，Windows作法可參考本文最後附上的參考連結。 情境假設今天要建一個VPC環境，在此環境下有兩台EC2 Instances，位於Public subnet內的EC2可以供外部進行連線，而Private subnet內的EC2只能透過Public subnet內的EC2來連線，Public subnet下的EC2稱之為「跳板機」(bastion)，可看下圖說明Resource要實作ssh連入bastion再連到Private EC2，之前的作法都是:private key 傳入 bastion，再把bastion內的private key用 ssh -i private key 的方式登入 Private EC2。 不過… ssh 的 Private key 是非常機密的資訊，應只保留在本地電腦，不應放在 bastion 主機內使用。 更安全的做法是: 使用 ssh-agent 做forwarding參考本篇文章中強調的重點: You should enable SSH agent forwarding with caution. When you set up agent forwarding, a socket file is created on the forwarding host, which is the mechanism by which the key can be forwarded to your destination. Another user on the system with the ability to modify files could potentially use this key to authenticate as you. 從「本地端」的 Private key 在 bastion 進行 forwarding，在 bastion 使用 ssh private key 的時候就不需要再使用 -i 來指定連接的 key。 ssh-agentssh-agent是一個讓你不把Private key上傳到伺服器上，就可以完成遠端登入的工具，使我們可在多個伺服器之間來去自如。 開啟ssh-agent1eval $(ssh-agent -s) 執行上述指令會回傳Agent pid *** 添加Private key將key pair 加入keychain 1ssh-add myKeyPair.pem 查看已存儲的Private key1ssh-add -L 執行上述指令會顯示Private key轉成 public key的資訊 遠端登入以前的登入方式都採ssh -i *.pem的方式 1ssh -i &quot;myKeyPair.pem&quot; ami@ec2publicDNS 改成下方的方式連 1ssh –A user@&lt;bastion-IP-address or DNS-entry&gt; bastion-IP-address是放Public Subnet的Instance IP上圖範例來說，就是在終端機執行下方指令連到bastion。 1ssh -A ubuntu@ec2-3-235-159-222.compute-1.amazonaws.com 成功連入bastion的畫面 連入Private Instance1ssh ami@Private IP 以我的測試的Private EC2 Instance為例 1ssh ubuntu@10.0.2.171 成功連入Private EC2 Instance的畫面 參閱 Securely Connect to Linux Instances Running in a Private Amazon VPC AWS 建議用 ssh-agent forwarding 登入你的 EC2 instance","link":"2020/05/25/aws/%5BAWS%5D%20%E7%94%A8%20ssh-agent%20forwarding%20%E7%99%BB%E5%85%A5%20EC2%20instance/"},{"title":"[AWS] AWSome Day Online Conference","text":"前言AWSome Day是由官方所舉辦AWS Cloud的免費培訓課程，今年因為疫情的關係不同以往，採用Online Conference的方式，課程中會有專業講師將會深入淺出地以實作示範帶大家了解AWS的核心服務。 課程安排其中課程講解內容會包括: 運算(Compute) 儲存(Storage) 資料庫(Database) 網路(Networking) AWS 資安、身份及訪問管理(Security) AWS 資料庫(Database) 大數據和機器學習(Big Data &amp; Machine Learning) AWS 擴展及管理工具 課程前面會提及AWS的歷史、益處還有概略說一下架構上面的圖片可以看到左邊是傳統可能在地端會使用的工具或服務，AWS也有提供相對應功能的雲服務。以Security來說，公司的防火牆(Firewalls) 對應到AWS的服務叫做Security Group，權限管理(Administraors)的部分則是使用AWS IAM 另外補充一下AWS常見服務 AWS Route53: AWS的DNS服務。 AWS Cloudfront: 是AWS Edge location上的一個服務，類似CDN，加速網路交付的內容。 AWS的全球基礎建設(AWS Global Infrastructure)可以參考我之前寫過的一篇 AWS 核心服務接著是討論AWS幾個比較重要且常見的核心服務 計算方面EC2雲端上的虛擬機(Virtual Machine)，創建EC2可以客製化不同的規格，例如選擇AMI(看要哪種作業系統)、規格(CPU、Memory、Storage)、配置網路(IP address, security groups、key pair)等，操作流程可參考我之前寫的[AWS] 用SSH連接EC2EC2其中一個好處是自動擴展，可以依需求做Scale In/Scale Out，也就是會依照所需流量調整EC2的多寡，做有效的資源利用。EC2的計費方式有很多種 AWS Serverless ServiceServerless為無伺服器的服務 Lambda採用Event Trigger，依據code的內容去執行，未執行即showdown，AWS推出Lambda並非用來取代EC2，Lambda也有其限制，EC2還是有自己的市場。優點： 省去管理Server的成本 只有被trigger才會計費流程範例 VPC每個Region都有預設的VPCApp Server混合雲架構 DB從AWS Gateway來連接客戶的網路 AWS 的儲存服務S3儲存空間無上限耐久性高，預估是99.999999999%object storage的形式儲存，可儲存多種不同形式的資料，如： Application file Media 結構Bucket類似folderobject類似檔案S3屬於託管的服務，不需要花心思在維護上，如:故障 原因放在Region中跨AZ，需要該Region的所有AZ都故障才可能會使資料遺失 =&gt; 保存三個以上的備份Region內有多個Region AZ 安全性設置Bucket policy，來做權限控管。 Versioning保留紀錄，預設是關閉的(因為要另外儲存使用紀錄，造成額外費用) S3 等級迎合不同屬性的資料分不同的等級(Class)，主要下方三者考量點:performance、Accessibility LifeCycle Policy節省管理時間、有效控制成本 Bucket Name必須是Global Unique， Demo選lifecycle EBS(Elastic Block Store)儲存作業系統、應用程式類似本地的硬碟，冗餘(redundant)備份是在一個AZ EBS與EC2兩者的lifecycle可以分開，看個人設定。好比把電腦硬碟拔下來，裝在別台電腦上 AWS資安相關的安全合規: AWS Artifact 共同責任模型(Shared Responsibility Model)AWS與客戶之間的責任歸屬，會依選擇的服務不同，承擔的責任界線(圖片中的虛線)會跟著改變，如EC2，使用者要負責的地方就多一些。這個模型是相當重要的，這會關係到問題發生時，判斷責任歸屬很重要的依據，而這在AWS Certificate也是幾乎必考，權重占比較多的重點考題。 範例模型 SSL 傳送資料 IAM驗證 Cloudtrail: 監控API使用的情形 Multi-Tier Security Groups(多層的Security Groups)兩種SG，決定Server要採哪種方式連接 HTTP Bastion Host: 俗稱跳板機 IAM主要做認證與授權認證方式： Console CLI SDK API User個別使用者 Group可以將擁有相同權限的User Policies 採JSON格式 用於assign給Users、Groups或Roles 用於assign給Roles RolesRole裡面放的是AWS的資源，可以attach不同的policyIAM Role會發有時效性的Token，S3 Service User、Group做驗證(你是誰)，Policies做授權(你可以做什麼) Best Practice Delete AWS root account access keys Activate multi-factor authentication (MFA):雙重認證，如綁定其他的軟體，輸入驗證碼。 Only give IAM users permissions they need:即最小權限原則 =&gt; principle of least privilege Use roles for applications 官方提供的IAM最佳實踐 辨認是root account還是IAM User登入方式是否用AcoountID AWS Database服務RDS(Relational Database Service)為何要使用RDS?RDS是託管的服務 自動備份(Multi AZ、可跨Region) 穩定性高(跨AZ 做備份)RDS會綁定VPCDynamoDBAWS NoSQL的資料庫AuroraAWS 基於自己的平台上開發的，可與MySQL、PostgreSQL兩種DB HA架構: 跨AZ做replica Aurora ServerlessAurora新推出的無伺服器服務 AWS 跨入AI領域 Amazon Go 無人機 推薦系統 物流 智慧音箱 Amazon Fraud Detector : 偵測詐騙問題 AI的難題 大量的資料 訓練模型：要用哪種演算法？如何去tune trainning model 評估預測結果SageMakerML的託管平台Prepare、Build、Train &amp; Tune 、Deploy &amp; Manage AWS 擴展/管理工具Use Case ELB(附載均衡器)可用於多個目標 (例如 Amazon EC2 instance、IP Address) 之間自動分配傳入的應用程式流量，而客戶(Client)端與ELB溝通時，會透過DNS。另外在創建ELB時，可在單一或跨AZ，處理應用程式的流量。 可作健康偵測(確保資料派送給非故障的EC2) 分散流量 Auto Scaling 自動調整EC2的容量 透過CloudWatch來判定EC2要Scale In或scale Out(監控CPU使用量) 透過Scheduling，事先規劃(Scheduled Event) AWS CloudWatch架構 ELB+Auto Scaling+CloudWatch的組合 AWS Trusted Advisor提供最佳實踐的建議，可以看到的服務多寡會跟Support Plane level有關 Cost optimization Security Fault tolerance Performance improvement. 以上圖片多數取自於官方投影片","link":"2020/04/29/aws/%5BAWS%5DAWSome%20Day/"},{"title":"[OS] 作業系統筆記-Process間的溝通","text":"鼠年全馬鐵人挑戰 - WEEK 18 前言上篇筆記過Process的狀態及管理，本篇筆記Process間的溝通 Process間的溝通現代作業系統中，通常不會只有一個Process存在於作業系統內，通常有好幾個Processes同時存在並同時執行。這些執行的Process可以分成兩大類 independent process(獨立行程)： 該Process無法影響其它Process的執行，同時它也不受其他Process影響，獨立的Process之間不會有任何共享資料。 cooperating process(合作行程)：該Process能夠影響其它Process，或是受其它Process影響，故Process之間會有共享的資料，需要有進行資訊交換的管道 簡單做個整理： independent process cooperating process Process之間不會有任何共享的資料 Process之間會有部分共享的資料 Process間的溝通需透過IPC(interprocess communication) ，IPC有兩種模式設計: Share Memory Message Passing 可以用生產者(Producer)跟消費者(Consumer)間的關係來解釋這兩種模式，Producer會產生資料放在有限或是無限的buffer中等Consumer來消費。 Process在傳輸資料時，buffer有三種型態: zero capacity：一定要收完之後才能再送，沒有地方給資料排隊。 bounded capacity：有限度的空間給資料排隊，若是滿了就必須要等。 unbounded capacity：無限的空間給資料，發送者可以一直送資料。 Share Memory (共享記憶體)Process之間共享一部分的記憶體(共享變數;Shared Variables)，透過存取記憶體達到彼此溝通、交換資訊的目的。shared memory是用read跟write資料來完成資訊交換 也可以這麼說:producer會把資料放進buffer內(write)，而consumer會去同一個buffer把資料取出來(read) Message Passing (訊息傳遞)Process間會建立連接通道(Communication Link)來溝通，非借助共享變數過程會是： 建立Communication Link 互傳訊息 (Message) 傳輸完畢，中斷連接通道 (release link) 建立連接通道時，會分做傳送(send)方與接收(receive)方，而通訊(Communication)的方式也分成兩種: 直接傳訊息(Direct) 間接傳遞(Indirect) Direct Indirect 建立link用send跟receive來傳送訊息 訊息是從 mailbox 裡直接接收(只能共享mailbox資料) 為自動建立 每個mailbox都有個獨特的ID 一個Link剛好連接一對Process 一對process之間，可能存在多條Link 每個行程必須要明確地命名 要建立連結，只能是行程共享郵箱 間接傳遞的過程中，通訊的同步非常重要，分作兩種形式： blocking Blocking send：訊息傳遞出去，Process被Block阻擋，直到對方訊息收到才可再傳送。 Blocking receive：不做任何動作，直到訊息送來，再回傳收到的資訊。 non-blocking Non-blocking send：不管對方有無收到訊息，持續發送訊息給對方。 Non-blocking receive：接收者只接收有效訊息，或是沒有訊息。 將兩者的比較做個整理： Share Memory Message Passing 溝通方式 共享一部分的記憶體(透過共享變數存取資料) Process 之間建立Communication Link 共享性 共享變數所有process皆可存取 process間有專屬的Link，不會隨意被其他Process共用 多個Process間，如何確定是哪個Process接收到訊息？ 規定在某一時間內，只有一個Process可以接收訊息。 由系統決定，是哪個Process接收，再回傳訊息告知是誰收到。 延伸閱讀 行程間的溝通","link":"2020/06/07/OS/%5BOS%5D%20%E4%BD%9C%E6%A5%AD%E7%B3%BB%E7%B5%B1%E7%AD%86%E8%A8%98-Process%E9%96%93%E7%9A%84%E6%BA%9D%E9%80%9A/"},{"title":"[AWS] 用AWS Elastic Beanstalk 部署你的第一個Django應用","text":"鼠年全馬鐵人挑戰 - WEEK 05 前言本篇著重在如何使用AWS Elastic Beanstalk佈建你的Django專案，相較於EC2，Elastic Beanstalk讓開發者更能專注在撰寫程式上，不需花費額外時間建置環境。 前置作業 AWS Free Tier(一年期的免費帳號) Python 3.6 pip virtualenv awsebcli Hands On Lab本地建置Django專案建立名為eb_django的專案資料夾123mkdir eb_djangocd eb_django 在該資料夾下建立虛擬環境，eb-virt可替換成自己要的名稱。 1virtualenv eb-virt 開啟虛擬環境 1source eb-virt/bin/activate 下載並建立django專案1pip install django==2.1.1 這邊值得注意的是，AWS官方文件有提到版本相容的問題: For Django version compatibility with Python, see What Python version can I use with Django? Django 2.2 is incompatible with the Elastic Beanstalk Python 3.6 platform. The latest compatible version is Django 2.1. 因為平台上的Python3.6以上版本與Django2.2不相容，所以Djanogo版本要指定在2.1.1(現在Django官方都已經出到3.0了…) 建立django專案 1django-admin startproject ebdjango 現在的專案案目錄結構會是 123456789101112eb_django/ | - eb-virt | | -- bin | | -- include | | -- lib | - ebdjango |-- ebdjango | |-- __init__.py | |-- settings.py | |-- urls.py | `-- wsgi.py `-- manage.py 執行Django專案 123cd ebdjangopython manage.py runserver 運行後會看到Starting development server at http://127.0.0.1:8000/的訊息，訪問http://127.0.0.1:8000/網頁後就會看到django預設畫面 保存相依套件保存相依套件的資訊在requirements.txt，之後Elastic Beanstalk會依照requirements.txt這個檔案內容來判斷執行您應用程式的EC2 Instance應該需安裝哪些套件。 1pip freeze &gt; requirements.txt 查看內容 1cat requirements.txt 配置.ebextensions 目錄建立 .ebextensions 的目錄 1mkdir .ebextensions 確認專案目錄結構 1ls -a 開啟目錄 1open .ebextensions/ 在.ebextensions目錄下建立配置的檔案django.config 1touch django.config 寫入下方指令 123option_settings: aws:elasticbeanstalk:container:python: WSGIPath: ebdjango/wsgi.py WSGIPath 設定會指定 Elastic Beanstalk 用於啟動應用程式的 WSGI 指令位置。 離開虛擬環境 1deactivate 以資訊安全來說，這邊我會比較建議用IAM建立一個User來進行服務的建置，盡量不使用Root Account直接使用CLI操作服務，使用IAM建立User，並給予User相對應的使用權限與特定的AWS服務，如果加上MFA的多重認證機制，安全性會更高，不過本篇只先做到用IAM建立一個擁有特定服務的User。 IAMIAM是AWS提供權限控管的一項服務，你可以透過IAM來創建User，指派特定權限或服務資源給該名User。當然，他也可以以群組的方式做集體的權限管理，不過不在本篇討論範圍，只需要知道它可以幫助我們做權限管理。 建立User先登入註冊好的AWS免費帳號，點擊右上角的個人帳號，會出現下拉選單，選擇My Security Credential， 進入頁面後點選左方選單的Users，右方的畫面有個Add User按鈕進入Add User畫面這個頁面主要是設定User名稱、AWS的操作方式，本篇是兩個都選，而AWS Management Console access，方便我們之後可以從AWS的管理介面查看專案情況，你可以自訂密碼，或是自動產生。 配置User權限Elastic Beanstalk會使用到EC2、S3等服務，所以我們也要同時給予這些服務的權限政策給建立的User，分別在搜尋欄找AWSElasticBeanstalkFullAccess、AmazonEC2FullAccess、AmazonS3FullAccess三項服務的所有權限。後續得Add tags可忽略。 Review確認上述勾選的權限都被列在上面後就可以建User囉記得將Key保留在本地哦！另外，下載完的.csv裡有附IAM帳號登入的連結，點擊後輸入剛剛自訂的密碼即可以IAM的形式進行登入，登入時會再要求你更改一組新密碼。 ebcli接下來我們要透過Elastic Beanstalk提供的CLI來建置環境 確認專案目錄的結構1234567891011~/ebdjango/|-- .ebextensions| `-- django.config|-- ebdjango| |-- __init__.py| |-- settings.py| |-- urls.py| `-- wsgi.py|-- db.sqlite3|-- manage.py`-- requirements.txt 下載ebcli1pip install awsebcli AWS ebcli登入1aws configure 執行上方指令後會要求輸入AWS Access Key ID和AWS Secret Access Key，將剛才載下來的檔案，裡面有這兩者的資訊，確定一下兩者是否正確輸入！ 初始化EB CLI 儲存庫透過下方指令初始化EB CLI儲存庫。 1eb init -p python-3.6 django-project 終端機會提示Application django-project has been created.建立成功的訊息，接著查看當前檔案結構變化 建立部署環境1eb create django-env 查看部署環境1eb status 複製CNAME的訊息，它代表你的網域位置。 配置domain將剛剛複製的網址貼到Django專案中的settings.py檔內 1ALLOWED_HOSTS = ['django-env.eba-mjgjyqkj.us-west-2.elasticbeanstalk.com', '127.0.0.1:8000'] 後面加上127.0.0.1:8000的原因是實際開發時，都是先在本地測試，確定沒問題之後，在push到repository上，未加上'127.0.0.1:8000'的話，本地是無法進行訪問的哦。 部署1eb deploy 看到Environment update completed successfully表示部署成功！ 開啟瀏覽畫面1eb open 配置儲存靜態檔案如果要儲存靜態檔案，只要在settings.py中增加下方程式碼 1STATIC_ROOT = 'static' 後台管理的畫面1python manage.py collectstatic 關掉Elastic Beanstalk如果暫時不需要使用這個專案的話，記得關掉，不然還是會一直使用AWS的資源，這些消耗的資源還是要算錢的XD所以務必記得關掉 1eb terminate django-env 使用eb terminate終止Elastic Beanstalk環境，不過上面的指令只有終止環境及於其中執行的所有AWS資源，但它不會刪除應用程式，所以隨時能夠再次執行eb create，以同一組態(config)建立更多的環境。 移除專案資料夾和虛擬環境如果不再需要此應用程式，執行下指令移除專案資料夾和虛擬環境。 12rm -rf ~/eb-virtrm -rf ~/ebdjango 建立自動化佈署(Continuous Deployment; CD) 這個是另外補充的，如果要跑CD流程的話記得回到Root Account將CodePipelineFullAccess，賦予給User，不然User是沒有權限使用這項服務的喔XD，或是直接從Root Account 來做CodePipeline設定(懶人法) 剛才部署好Django程式之後，接著我們可以利用AWS的CodePipeline來幫我們做自動化部署。我們將剛剛本地建置好的Django專案push至Github上 建Repository到自己的Github上建立新的Repository CodePipeline建置好專案的Repository後至CodePipeline主頁面點選Create pipeline 設定設定Pipeline name後直接點選Next Add source stage選擇Github及剛剛建立的Repository Add deploy stage Review設定完成後會至Review頁面，點擊Create 建置完成之後只要每次程式碼改動，push到Github上就會自動部署到Elastc Beanstalk。 參閱Official Doc","link":"2020/03/15/aws/%5BAWS%5D%20%E7%94%A8AWS%20Elastic%20Beanstalk%20%E9%83%A8%E7%BD%B2%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E5%80%8BDjango%E6%87%89%E7%94%A8/"},{"title":"[AWS] 備份 MySQL 資料至 AWS S3 Bucket","text":"鼠年全馬鐵人挑戰 - WEEK 20 前言現實生活中的系統，為了避免資料遺失，系統平時都該備份資料庫的資料。當系統發生問題時，能在最快的時間點還原原始資料。本篇文章紀錄如何將既有的MySQL資料庫內資料，藉由 Crontab 指令定期備份至 AWS S3 前置作業 既有的MySQL資料庫，裡面有多張資料表 OS: Ubuntu 18.04 MySQL 5.7+ AWS 帳號 下載 AWS Cli tools 流程本文會依照下方流程實作備份: 什麼是 S3 Bucket 建立S3 Bucket 建立 IAM User 依照政策 賦予 IAM User 權限 撰寫備份用的 shell script 制定 Cron job 定期任務排程 什麼是 AWS S3S3 是 AWS 提供的儲存服務，用於存放和擷取任意數量的資料，資料會以物件的形式進行儲存，花費的成本低廉，所以備份至S3是不錯的選擇。 建立S3 Bucket進入已經創建好的 AWS 帳號，選擇 S3 服務，點擊Create bucket，接著輸入自訂的 bucket 名稱，下方選單選擇想要存放的Region輸入完畢後點擊Create bucket 建立 IAM User輸入User Name 且自訂密碼新建policy貼上下方的JSON格式資料，並將資料內的mysqlsourcebackup替換成自己創建S3 Bucket 所取的名稱，修改完畢後點擊Review Policy 123456789101112131415161718192021222324252627282930{&quot;Version&quot;: &quot;2012-10-17&quot;,&quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [&quot;s3:ListAllMyBuckets&quot;], &quot;Resource&quot;: &quot;arn:aws:s3:::*&quot;},{ &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:ListBucket&quot;, &quot;s3:GetBucketLocation&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::mysqlsourcebackup&quot;},{ &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:PutObject&quot;, &quot;s3:GetObject&quot;, &quot;s3:DeleteObject&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::mysqlsourcebackup/*&quot;}]} 接著替自己創建的policy取名後，點擊Create Policy回到剛剛創建User的介面，搜尋新創建的policy名稱進行勾選，就可以繼續執行一步到創建完成。下載個人金鑰置個人電腦，金鑰為機密資訊，務必好好保管！也可以寄信至個人信箱 撰寫備份用的 shell script建立runbackup.sh1sudo vim runbackup.sh 填入下方程式碼，並修改=後方的值： your_access_key、your_secret_key: 為剛才創建帳號時下載的金鑰資訊 s3_region: S3 bucket 所在之區域 S3_BUCKET: S3 bucket 名稱 其餘為MySQL相關資訊: host_name(e.g. localhost)、MYSQL_PORT(e.g. 3306) 123456789101112131415#!/bin/bash## 填入 AWS User Credential 的資訊AWS_ACCESS_KEY_ID=your_access_key \\AWS_SECRET_ACCESS_KEY=your_secret_key \\## 填入 S3 資訊AWS_DEFAULT_REGION=s3_region \\S3_BUCKET=your_buket_name \\## 填入MySQL資訊MYSQL_HOST=host_name \\MYSQL_PORT=db_port \\MYSQL_USER=db_user \\MYSQL_PASS=db_password \\MYSQL_DB=db_name \\## 執行 backup.shbash -x backup.sh 修改完畢後按下ESC+:wq!儲存關閉。 建立backup.sh1sudo vim backup.sh 寫入下方程式碼 1234567891011121314151617#!/bin/bashcd /tmpfile=$(date +%A%d%B%Y).sqlmysqldump \\ --host ${MYSQL_HOST} \\ --port ${MYSQL_PORT} \\ -u ${MYSQL_USER} \\ --password=&quot;${MYSQL_PASS}&quot; \\ ${MYSQL_DB} &gt; ${file}if [ &quot;${?}&quot; -eq 0 ]; then gzip ${file} aws s3 cp ${file}.gz s3://${S3_BUCKET} rm ${file}.gzelse echo &quot;Error backing up mysql&quot; exit 255fi 修改完畢後按下ESC+:wq!儲存關閉。 測試腳本1bash -x runbackup.sh 執行上述指令執行runbackup.sh這支腳本，到 S3 Bucket 的管理介面查看有沒有上傳成功！ 制定 Cron job 定期任務排程下載1sudo apt update &amp; sudo apt install cron 確保有在背景執行 1sudo systemctl enable cron 成功的話會提示跟下方相同的訊息 123OutputSynchronizing state of cron.service with SysV service script with /lib/systemd/systemd-sysv-install.Executing: /lib/systemd/systemd-sysv-install enable cron 編輯 crontab1crontab -e 執行上方指令，會跳出下方的提示資訊 12345678910Outputno crontab for sammy - using an empty oneSelect an editor. To change later, run 'select-editor'. 1. /bin/nano &lt;---- easiest 2. /usr/bin/vim.basic 3. /usr/bin/vim.tiny 4. /bin/edChoose 1-4 [1]: 個人習慣用Vim，故輸入2，可依個人習慣自由選擇，選擇好之後就會進入新建立的 crontab在下方新增排程時間，以及要執行的指令，假設是 每天凌晨12:00 進行排程任務，執行runbackup.sh這支檔案，就可以寫成下方的指令： 10 0 * * * root bash -x /home/coupon/runbackup.sh 修改完畢後按下ESC+:wq!儲存關閉。 補充 bash -x /home/coupon/runbackup.sh 為要執行的檔案，要確認檔案的所在位置是正確的！ Crontab 時間結構 欄位 允許範圍 minute 0-59 hour 0-23 day_of_month 1-31 month 1-12 or JAN-DEC day_of_week 0-6 or SUN-SAT crontab 執行規則如下:1minute hour day_of_month month day_of_week command_to_run 更多細節參考Digital Ocean Community所撰寫的文章，還蠻清楚的！","link":"2020/09/30/aws/%E5%82%99%E4%BB%BD%20MySQL%20%E8%B3%87%E6%96%99%E8%87%B3%20AWS%20S3%20Bucket/"},{"title":"[AWS] 用SSH連接EC2","text":"鼠年全馬鐵人挑戰 - WEEK 07 前言本篇文章紀錄如何開啟AWS的EC2，採用SSH的方式連接，並在Ubuntu的作業系統環境下架設Apache Server。 電腦配備：Mac AWS免費帳號(一年期) 步驟進入AWS Management Console點選EC2 建立Instance 選擇AMI以ubuntu為例： 選擇Instance Typetab3、4、5可以先略過，到6.Configure Security Group配置Security Group Add Rule 下拉選單選擇HTTP Review and Launch 建立Key Pair點擊Review and Launch會進入設定Key Piar的畫面，如果是初次建Instance，選單內無法選擇existing key pair，點選Create a new key pair 設定&amp;下載Key Pair可替自己的Key Pair命名，命名完成後點擊Download Key Pair將檔案下載至本地後再點選Launch Instance 建置成功！ 查看建立的Instance回到EC2的主畫面，點選左方的Instances欄位。進入Instance的管理介面後即可看到剛剛開設的Instance，點擊該Instance再點擊上方的Connect 連接Instance 更改檔案權限剛才download下來的Key Pair會下載至本地，可將.pem的檔案放置在自己的專案資料夾。開啟終端機，將路徑切換至該專案資料夾下，輸入下面的指令，更改檔案權限為Read by owner: 1chmod 400 你的key_pair SSH連接複製example給的指令進行SSH連接 1ssh -i &quot;yourpem.pem&quot; ubuntu@yourinstance.compute-1.amazonaws.com 成功連接! 安裝Apache Server分次執行下方指令，安裝Apache 123sudo apt-get updatesudo apt-get install apache2sudo apt-get install libapache2-mod-wsgi 訪問網站回到Instances管理介面，點選該Instance會看到Public DNS (IPv4)，複製網址後即可訪問 訪問預設的畫面 完成上述所有步驟就完成環境的架設囉！","link":"2020/03/25/aws/%5BAWS%5D%20%E7%94%A8SSH%E9%80%A3%E6%8E%A5EC2/"},{"title":"[AWS] 我收到AWS寄來免費帳號的帳單","text":"鼠年全馬鐵人挑戰 - WEEK 14 前言本篇為個人經驗分享，會寫下這篇的原因是我在AWS註冊Free Tier帳號後，在使用過程中意外收到90美金的帳單，內容將涵蓋我為何會收到帳單到成功全額退款，給有遇到相同問題的人一個參考。 起因有天收到來自AWS的帳款通知信，信中顯示總金額為90美金，剛開始收到信還疑惑為何被收這麼高的費用(2700台幣對我來說負擔不小啊…..) 心想完了…月初就要面臨吃土，可憐哪。圖片源仔細想想，當初也是辦理免費帳號，怎會突然被收費了呢？而且一直以為我應該有把沒用的服務關掉(？)打開帳單明細發現不得了…… Database Migration Service這項服務收了我75美金？？？ 記得之前玩的時候明明有關掉，細看服務啟用的區域才發現，天阿…原來開在Oregon的服務被我漏掉了…而且我還開Multi-AZ(傻眼貓咪)，看完帳單後就立刻先把帳號關閉，避免再被收費。上網搜一下是否有人跟我遇到相同問題，看到Quora上有不少人遇到這種情況，原來我不孤單(?)看到有人收到千元的帳單頓時覺得我只是小錢嘛～而且也有成功撤銷費用，看起來我應該也有機會，所以就發Issue給AWS Support囉！ 如何發issue?進入Support Center登入AWS帳號後，右上角有個Support下拉選單，點擊Support Center，選擇Account and billing support -&gt; Billing -&gt; Charge Inquiry 建立並填寫Case描述一下自己被收費的情況，下方可以上傳檔案，建議把收到的帳單附上去，Support可以比較快針對問題去解決填寫完成之後就可以點擊最下方的Submit進行提交！ Support回應看完AWS Support回信內容才了解產生費用的原因是我使用非免費帳號所涵蓋的服務範圍，才被收取費用。當時心想…怎麼沒有一個機制是提醒使用者這是非免費的服務範圍，收到帳單後詢問才知道…好啦，一部分原因可能是我在使用每個服務前沒有特別去查該服務是否在免費範圍內，不過如果能多一個警示機制會不會更好呢？不用每次都去查。點我看AWS免費方案後續照AWS Support給的指示完成後，馬上收到好消息除了原本被收90美金的費用全額撤銷，連五月份目前所產生的費用也都被免除了！整個流程三天內搞定！查看帳單，成功全額退款，我不必月初吃土了！另外AWS Support還有提醒可以開啟費用警示的功能(我現在才知道原來有這功能)，一開始還抱怨說怎麼可以無預警收我錢，AWS太可惡了！不過AWS回覆算還不錯，整個處理流程速度很快，值得讚美一下！(恩….真香) 費用查看如果要查看帳戶當前產生的費用可至My Billing Dashboard選擇左方的Cost Explorer可以查看每天或每月使用服務情形或是到Bills也可以查看帳單明細 透過帳單警示來監控自訂的預估費用根據AWS Support的指示，可以利用CloudWatch這項服務來監控AWS服務產生的費用，啟用帳單提醒，並寄信通知！官方教學 開啟帳單提醒若要建立預估費用警示，必須先啟用帳單提醒打開Billing的頁面，點擊左方選項Preferences勾選Receive Billing Alerts.當然你要勾選其他的也可以，選好後點Save。 建立帳單警示開啟CloudWatch選擇左方列表中的Alarm，並點擊Create Alarm選擇Select metric -&gt; All metrics tab -&gt; Billing -&gt; Total Estimated Charge -&gt; USD完成上述步驟點選Next，選擇Static接著看你想選擇哪個條件，設定完你要的條件後按Next再來是選擇In alarm -&gt; Create new topic -&gt; 填寫topic name、Email endpoints -&gt; 點擊Create topic它會結合AWS SNS的發信服務，所以要到剛才自己填寫的信箱去收信，點擊確認信中用來開通服務的連結，再回到剛剛Alarm的畫面，點擊Next。填寫Alarm Name後點點擊Next會進入Preview and create的頁面確認無誤後點Create alarm即可完成設定！當Status顯示綠色就OK囉！ 後記有這次的經驗後，在玩雲服務時都特別注意一下相關的條款，還有利用一些警示功能來避免意外被收取大量費用，如果真的不幸收到大筆帳單，只要發Issue給Support，描述一下誤用的情形(他們會查看帳號使用服務的情形是否符合你的描述)，基本上有很高的機率能收到全額退款！","link":"2020/05/09/aws/%E6%88%91%E6%94%B6%E5%88%B0AWS%E5%85%8D%E8%B2%BB%E5%B8%B3%E8%99%9F%E7%9A%84%E5%B8%B3%E5%96%AE/"},{"title":"[Vue.js] Props - 父子組件間溝通","text":"前言在 Vue中，每個組件都有單獨作用域，是各自獨立的，我們可以通過prop 由父組件向子組件傳遞數據，在組件上註冊的一些自定義屬性。當一個值傳遞給一個prop屬性的時候，它就變成了那個組件實例的一個屬性。Ref 目的: 拆分個別的功能，並達到複用效果 避免內部元件改變外部元件 資料更集中，管理上更便利 基礎範例:Parent12345678910111213141516&lt;template&gt; &lt;div class=&quot;Parent&quot;&gt; &lt;child msg='parent here'&gt;&lt;/child&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Child from '@/components/Child';export default { components: { Child, }, name: 'app',};&lt;/script&gt; Child12345678910111213&lt;template&gt; &lt;div class=&quot;Child&quot;&gt; &lt;span&gt;Message: { {msg} }&lt;/span&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { props: { msg: 'child here' },};&lt;/script&gt; camelCase vs. kebab-case 命名使用HTML 不區分大小寫，而 JavaScript 是嚴格區分大小寫的，使用 HTML 模版時，屬性名稱必須使用以dash分隔的kebab-case命名，如範例msg-parent的屬性名稱。12345&lt;template&gt; &lt;div class=&quot;Parent&quot;&gt; &lt;child msg-parent='parent here'&gt;&lt;/child&gt; &lt;/div&gt;&lt;/template&gt; 若是使用JavaScript中的字串模版，則使用camelCase寫法，參考此篇文章。12345Vue.component('child', {// 在 JavaScript 中使用 camelCaseprops: ['myMessage'],template: '&lt;span&gt;{ { myMessage } }&lt;/span&gt;'}) 靜態、動態傳遞兩者的差異在於處理傳遞資料型別，如果沒有使用動態，那就會全部資料型別視為string，而動態使用v-bind進行屬性綁定（簡寫為:），做動態賦值，將來會與 Vue Instance 結合，解析模版會當成 JavaScript 表達式做計算。12345678910// 靜態&lt;post title=&quot;My journey with Vue&quot;&gt;&lt;/post&gt;// 動態&lt;post v-bind:title=&quot;post.title&quot;&gt;&lt;/post&gt;Vue.component('post', { props: ['title'], template: '&lt;h3&gt;{ { title } }&lt;/h3&gt;'}) 父子組件溝通原則圖片來源單項數據流props是單項傳遞資料的，只會從父層傳至子層，並且Prop的值會隨父層更動設定而改變，避免子組件無意修改了父組件資料。$emit若子組件要在資料異動時傳給父組件只能通過自定義事件: 使用$emit(&quot;父組件要接收的參數&quot;,要發送的數據)Prop 驗證可以為props傳遞的資料指定型別。1234567891011121314151617181920212223242526272829303132333435export default { name: &quot;child&quot;, data() { return{ } }, // props: ['title', 'age'], props: { // 指定對應得類型 title: String, age: Number, nick: String, nickName: { // 設定預設值 若父組件無傳遞值時即採用預設值 type: String, default: &quot;天籟歌手&quot; }, parent: { type: String, require: true }, friends: { // 若預設值為陣列或物件，必須回傳一個function， type: Array, default: function() { return [&quot;Frank&quot;, &quot;Tonny&quot;, &quot;Jack&quot;]; } } }, methods: { sendTarget() { // target 為自定義事件 this.$emit(&quot;target&quot;, &quot;流行歌手&quot;); } } } 訪問子組件實例或子元素通過ref特性為這個子組件賦予一個ID引用，有的時候你仍可能需要在JavaScript裡直接訪問一個子組件，直接做DOM操作。定義這個ref的組件裡，可以使用1this.$refs.usernameInput","link":"2019/07/20/Vue/Vue_props/"},{"title":"[Vue.js] Lifecycle Hooks","text":"Vue生命週期 每個 Vue 實體被創建之前，會經過一系列初始化的過程，同時會呼叫這些生命週期的掛鉤(hook)，我們可以在這些掛鉤上做額外的處理 流程建立Vue物件 -&gt; 初始化Vue資料 -&gt; 編譯模板 -&gt; 掛載DOM -&gt; 更新數據 -&gt; 渲染數據(mounted) -&gt; 卸載數據。圖片源: 官方文件說明(紅框表鉤子函數): 細節 new Vue(): 在main.js檔有new Vue()這段code，即建立Vue的實例。 Init Event &amp; Lifecycle: Vue內部初始化事件。 beforeCreate: 在實例初始化之後，數據觀測(data) 和event/watcher 事件配置之前被調用。 Init injecttions&amp;reactivity: 初始化data、method created:此時發起ajax請求，資料 $data 已可取得，但 $el 屬性還未被建立 先判斷是否有el選項，再判斷是否有template選項，接著準備生成html。 beforeMount: 此時尚未生成html到頁面上(還看不到頁面效果) Create vm.$el: 此階段做替換操作，將渲染好的html替換el屬性，也就是DOM的替換操作 Mounted: 此時完成掛載，即$el 被建立，只會執行一次 後續掛載點會時時監控數據變化，若監測到數據變化，就會去更新DOM，做監聽操作，當中會執行兩個鉤子函數。 beforeUpdate：在更新DOM之前，資料變化時被呼叫，頁面此時尚改變，這裡適合在更新之前訪問現有的DOM，如手動移除已添加的事件監聽器。 activated：如果有設定 keep-alive，這個hook會被呼叫 deactivated：停用 keep-alive時被呼叫。 updated:更新數據完成 beforeDestroy：在銷毀之前，調用此函數，但此時尚未銷毀，實體還可使用。 destroyed：實體銷毀，所有綁定、監聽事件被移除。 Note所有的生命週期鉤子自動綁定this上下文到實例中，因此你可以訪問數據，對屬性和方法進行運算。這代表不能使用箭頭函數來定義一個生命週期方法 (例如created: () =&gt; this.fetchTodos())","link":"2019/07/17/Vue/Vue_lifeCycle/"},{"title":"[AWS] 初識AWS中的VPC","text":"鼠年全馬鐵人挑戰 - WEEK 13 前言本文做為有關VPC的閱讀筆記 何謂VPCVPC全名是Virtual Private Cloud，是一個建立在雲端上的封閉區域網路，一般來說，基於安全考量，公司都會有自己的一套內部網路環境，對外網路會有一台防火牆保護，避免外部隨意連進來，在防火牆內就像是一個VPC。想像一種情況，若有公司內部的資料庫開放讓外部進行連線，只要有正確的帳號密碼，誰都可以連進來，那將是非常危險的事情。若是即使帳號密碼正確，但只有某幾台機器可以連進來，安全性相對提高，後者即是VPC的主要功能。VPC中可以選擇自己的 IP 地址範圍、建立子網路(subnet)、配置路由表(Route Table)和網路閘道(Internet Gateway)，以及選擇公有和私有網路 每個Region的網路互相獨立，同一個Region可同時建立多個VPC，VPC間彼此獨立不干擾。 Amazon VPC 包含哪些部分？Elastic IP(EIP):即固定IP，以AWS EC2來說，預設是使用變動的IP，每次重啟EC2時都會賦予新的IP，若要讓EC2綁定一組固定IP，就可以在EC2的管理介面中配發一組EIP給他。 需注意的重點：Elastic IP在每個Region剛開始只會給5個額度，用完需另外申請。 Subnet(子網路):Subnet就是在VPC的網段下，再細分不同的子網段。Subnet可區分為Public、Private和Vpn-Only三種，以公司內部網路來看，會切成不同的子網段。Public: 直接對外服務，擁有Elastic IP(EIP)，透過 Internet Gateway可直接訪問InternetPrivate: 私有的子網段，該網段只能與內部網路溝通，無法直接訪問 InternetVPN-Only：只允許特定的VPN連接 Subnet需注意的幾個重點： 每個subnet的CIDR Block不能重複，也不能大於VPC 一般來說，subnet除了切開CIDR外，還會區分不同的AZ(可用區域)，避免單一個區域內機房失效的問題 Route Table(路由表):一般網路封包在傳送時，起點到終點位置的傳輸路徑由Router來決定，而Route Table可決定往特定網段(Destination)的封包如何傳送(Target) 常見Target類型： local NAT Portal internet gateway(簡稱igw) virtual gateway(簡稱vgw)可用在連接企業內部的VPN 幾個注意的重點 每個 subnet 只能指定零或一張 route table 可以設其中一張route table為預設值；讓未指定的subnet都參照它 Internet Gateway:讓VPC與外部網際網路溝通的通道，Route Table會將封包往 Gateway送，即可對外進行溝通。 NAT全名為Network Address Translation，主要的功能是連結內部與外部的網路，如區域網路內的服務器，只允許內對外的連線，但不允許外對內的連線，皆透過同一個對外IP來進行對外部的溝通。 注意的重點: 在Public subnet建立一個NAT Gateway NAT Gateway需指定一組EIP，建立外部連線 Endpoint(端點)在Private subnet內，連接AWS某些Service時 e.g. S3，可透過建置Endpoint來串接。 VPC需注意的幾個重點： VPC在設定之後不能改，要改只能重建 每個區域的每個AWS帳戶最多5個VPC，要更多的話需要跟AWS發ticket VPC 的subnet可以從最小/28到最大/16，即最少可以開14個IP addresses的VPC，以及最大65534個IP addresses的VPC。 每個VPC可擁有200 subnets 每個VPC都是獨立環境，可透過NAT來連接不同VPC VPC的計費：如果是建立、使用VPC本身的話不收其他費用。但VPC內包含其他AWS服務的話，如：EC2，則會收取其他Services的使用費，依照這些資源公佈的費率計算，可能還需支付資料傳輸費用。 範例討論最後以官方文件的範例來做討論。圖片取自官方文件上圖為官方給的預設VPC架構圖，可從AWS Console進行點擊預設的架構會是： 預設VPC會發的CIDR為172.31.0.0/16 預設替每一個AZ分配一個/20的Subnet: 172.31.0.0/20、172.31.16.0/20 兩個Subnet內各有一台EC2 instance，即172.31.0.5、172.31.16.5 EC2 instance會自動被分配一組外部IP，即圖片中的Public IP: 203.0.113.17、203.0.113.23，只要重新開機，會自動重新分配新的IP。 透過Internet Gateway建立對外網的連線，即igw-id 兩個Subnet都會遵循Main route table建立的路徑，只要收件者IP是172.31.0.0/16的網段，網路封包就會往內網送；其餘封包(0.0.0.0/0表任意連線)，就往Internet Gateway發送。 參考文件 Official Docs AWS 內 VPC 與 Subnet 規劃、理解","link":"2020/04/28/aws/%5BAWS%5D%20%E5%88%9D%E8%AD%98AWS%E4%B8%AD%E7%9A%84VPC/"},{"title":"[Vue.js] Basic","text":"什麼是Vue?Vue 是一個前端框架(framework)，他的出現目的是為了更有組織性且簡化Web開發。在這之前其實有其他的框架，如Google所支持的Angular，或是Facebook所開發的React框架，不過Vue在社群的活絡程度不遜於前面兩者，是有潛力的一套framework。模板語法是 Vue 的主要特色，同時有雙向數據綁定的功能，採用MVVM的結構。 為何選Vue?主要原因是簡單好上手，會基本的html、css、JavaScript就可以進行學習，再來是Vue需載入的檔案小，使用 Virtual DOM加快載入速度，網站載入不須花太多時間，。 Vue主要分成三部分組成 Vue 模板 Vue 實例 Vue 組件 模板:v-if、v-show、v-for…. 實例:data、methods、computed 元件:Vue有元件的概念，將網頁上的區塊拆成一個個的元件(或叫組件)，最後將這些元件組合成一個網頁，就好比拼拼圖一般。 個別詳細內容會記錄在下篇 模板(Template)語法Vue.js 使用基於HTML的模板語法，允許開發者使用聲明式將DOM綁定Vue實例的數據。Vue 將模板編譯成虛擬DOM，再渲染函數，Vue 能夠智能地計算出最少需要重新渲染多少組件，並把DOM 操作次數減到最少。 雙向綁定雙向是指：HTML標籤數據綁定到Vue物件，另外反方向數據也是綁定的。Vue物件的改變會直接影響到HTML的標籤的變化，而且標籤的變化也會反過來影響Vue物件內屬性的變化，改變是即時性的。 MVVM 由Model,View,ViewModel 三部分構成 Model 層代表資料模型，Model中定義資料修改和操作邏輯，簡單來說，我們獲取到的資料是一個JavaScript 的物件，透過Directives指令對DOM進行封裝。 View代表UI組件，當資料發生改變時，對DOM進行監聽(DOM Listener)操作，從而回去修改Model的資料。 ViewModel是一個同步View 和Model的物件，可以將資料模型轉化成UI介面。 View 和Model 之間並沒有直接的聯繫，而是通過ViewModel做連結，Model 和ViewModel 彼此是雙向互動，同步工作完全是自動， 因此View 資料的變化會同步到Model中，而Model資料的變化也會立即反應到View 上。 Virtual DOM因為每次操作DOM的時候，頁面都必須要載入一次，使用者才能看到最新的頁面效果，但當有大量的 DOM 節點需要替換或更新的時候，這時網站載入效能的差距就會越來越明顯。 Virtual DOM透過以 JavaScript 物件模擬特定的 DOM tree結構，他會自動地去幫你處理這些瑣碎的事，再來他會去計算上一次 Virtual DOM 跟這一次的差異，兩者進行比較，最後把差異的部分處理後輸出到頁面的DOM上。 Vue 採用的是宣告式(聲明式)的渲染。 如: 1234567891011// 建立一個vue物件 (內部採JSON格式) const app = new Vue({ el: &quot;#app&quot;, // Vue 物件的掛載點 // data 為存取的資料 data: { // 可自行定義屬性名稱 message:&quot;hello&quot;, error: &quot;error&quot;}}); Vue組件 一個組件由三個部分組成: html css js 三者透過 webpack 進行打包，編譯成對應的檔案。 安裝Vue: 透過CDN 透過npm 通過Vue-cli腳手架 透過CDN從官方載入CDN到&lt;script&gt;標籤。 透過npm$ npm install vue 透過腳手架Vue-cli方法在cmd切換到目標目錄，輸入 npm install -g vue-cli(3.x前版本)下載官方版本 vue init webpack執行npm run dev詳細查閱這篇教學 其他教學文 Vue CLIVue CLI 是一個基於Vue.js 進行快速開發的完整系統，好處: 方便創建項目 部署方便 功能豐富 程式碼修改完畢後及時更新，直接預覽效果，不須手動更新 可單元測試 安裝操作官方寫的很明確，唯一要注意的是，npm install -g @vue/cl是安裝Vue3.0之後的版本 創建一個項目 vue create選擇default使用官方設定的模板 使用圖形化界面(UI) 實作: 在目標資料夾執行命令列vue create qsyj，建一名稱為qsyj的專案。 到專案資料夾找index.html、main.js兩個檔案。 index.html檔內&lt;div id=&quot;app&quot;&gt;&lt;/div&gt;為掛載點 main.js檔內 分別導入兩組件由上圖說明App組件從App.vue檔導入，並建一名為Vue的新物件，掛載在 #app上，對應至index.html檔的app掛載點。 App.vue專案的組件，組件由三部分組成: template: html script: JavaScript style: CSS 組件基本操作步驟: 導入組件 註冊組件 使用組件 專案資料夾底下文件說明 src: 放置組件&amp;數據文件 assets: 放置靜態文件 component: 放置組件好的開發方式: 先在component下建立新的資料夾，再新增對應組件。 移動端字體大小的解決方案:透過rem依照畫面調整根元素字體大小，如根元素大小為16px，1rem = 16px，2rem = 32px….. Vue Router官方的路由管理器，安裝方式參考官方。Vue Router官方文件(zh)Vue Router官方文件(en) 好用的UI library for Vue: Vant","link":"2019/07/14/Vue/Vue/"},{"title":"[Database] MongoDB安裝與連接","text":"MongoDBMongoDB是一個NoSQL的資料庫，相較傳統RDBMS，NoSQL資料庫不需事先定義schema，設計上面較為彈性，MongoDB也有類似SQL語法對資料庫進行資料操作的方法，本篇著重於紀錄MongoDB的安裝與連接。 安裝MongoDB因為自己是用Mac，所以本篇以Mac為主，安裝的是社群版本。 CLI安裝使用CLI安裝方式 1brew tap mongodb/brew 1brew install mongodb-community@4.2 官方教學 手動安裝官方載點相關教學 安裝Mongo Compass在本地操作MongoDB除了透過Shell指令之外，也可使用MongoDB官方的GUI工具進行管理，到下方的官方載點選擇對應版本及作業系統後即可下載。官方載點 管理介面 連接遠端MongoDB的方式連接方式可採以下幾種常見方式 Connect to Cluster0進入MongoDB官網，登入個人帳號， 方法一: Application 點擊Connect Instructions，選擇Connect Your Application 選擇程式語言，並複製下方指令 打開Mongo Compass，貼上剛才複製的指令，並將password替換成自己的用戶密碼 成功連上 方法二: Fill in connection fields individually可輸入主機名稱、用戶帳號、密碼等欄位，如果是純粹在本地測試，Hostname輸入localhost，port預設為27017。 方法三: Mongo Shell點擊Connect Instructions，選擇Connect with the Mongo Shell 複製官方給的mongo shell 打開終端機，輸入剛剛複製的指令，並輸入用戶密碼 成功登入 以上為MongoDB安裝及連接的方式","link":"2019/09/11/Database/MongoDB/%5BMongoDB%5D%20MongoDB%E5%AE%89%E8%A3%9D%E8%88%87%E9%80%A3%E6%8E%A5/"},{"title":"[計概] 編譯器(Compiler)與直譯器(Interpreter)","text":"前言目前接觸過C++ 、 Python、JavaScript，雖然知道他們屬於哪種特性的程式語言，但一直沒有好好了解編譯器、直譯器 兩者差異，藉此機會查資料筆記一下。 編譯編譯意思指程式原始碼會經編譯器(compiler) 轉換成目的碼(object code) 後，再編譯成計算機所看的懂的機器碼(machine language)，最後再執行。使用編譯器的語言稱為編譯式語言，多半是靜態型語言(static language) 靜態語言的特點: 會事先定義的型別，做型別檢查。 著名例子 C C++ 直譯直譯意思指原始的程式碼只要經過直譯器(Interpreter) 即可轉換成可執行碼，因為它們不需經由編譯器，在執行時才會將原始碼直譯成執行碼。直譯式語言好處在開發上具有較彈性靈活的型別處理(不需事先定義資料型別)，因為可以立刻看到指令的執行結果，有錯誤可迅速修正。 使用直譯器時，所使用的程式語言就像變成一個會和你互動的環境，每當輸入一行程式，直譯器會即時執行該行程式命令，通常又被稱作腳本語言。 著名例子 JavaScript Python Ruby PHP 兩者差異執行速度大部分在相同的邏輯下比較兩者執行速度，使用編譯語言的速度會比使用直譯語言來得快，原因在編譯語言已經先預先編譯過了，因此在執行期間相較於直譯語言少了一行一行執行程式碼的時間。 開發速度編譯語言的程式開發、除錯速度會較編譯語言來的慢，因為編譯語言無法像直譯語言一樣，在開發完一段程式碼就可以馬上執行並且除錯，且直譯語言也給予軟體開發者更有彈性以及快速的開發流程。 獨立執行與否編譯式語言產生的程式幾乎都可獨立執行，因為它們都是由Compiler進行型別／語意等檢查，以及經過連結器的處理，程式碼幾乎可以直接存取系統服務(system service)。 直譯式語言則是必須依賴一個執行環境(execution context)，如PHP、Python等腳本語言不需要各平台的編譯器，但是需要先安裝在各個平台上的運行環境以及相應的package才能保證程式跨平台特性 也就是說 想把寫好的程式放到另外一台機器上跑， 只要將編譯器編譯出來的可執行檔(.exx)，拿到新機器上便可以執行， 而直譯器則必須要求新機器上，必須要有跟另一台機器上相同的直譯器， 才能組譯執行你的程式！ 來源文章[Programming] 編譯 vs 直譯","link":"2019/07/01/%E8%A8%88%E6%A6%82/%5B%E8%A8%88%E6%A6%82%5D%20%E7%B7%A8%E8%AD%AF%E5%99%A8(Compiler)%E8%88%87%E7%9B%B4%E8%AD%AF%E5%99%A8(Interpreter)/"},{"title":"[Redis] Redis - Transaction","text":"前言 為確保資料的正確性， Redis 也提供了類似於關聯式資料庫的 Transaction 機制，但 Redis 提供的 Transaction 有一些相異之處 e.g. 不支援 rollback，本篇文章紀錄 Redis Transaction 的概念與使用方式。 TransactionRedis Transaction 允許一次執行多條指令(批次操作)，Transaction 在運作時主要會圍繞在 MULTI, EXEC, DISCARD and WATCH 這四個指令，以下是 Transaction 幾個重點： 進行批次操作的流程中，在發送 EXEC 指令 前 會先被序列化且放在 Queue 裡按順序等待執行 Transaction 擁有原子性 (Atomicity)：只有兩種狀態：全部都執行 或 一個都不執行 。如： client 端在執行 EXEC 指令前發生連線中斷導致無法正常，則不會執行任何操作 或是 client 端在執行 EXEC 指令前輸入錯誤的指令(e.g 語法) 也不會執行任何操作。一旦 Client 端發送 EXEC 指令後，所有的指令通通會被執行，即使之後 Client 端斷線也沒關係，因為 Redis 已經記錄所有要執行的指令 有別於傳統的關聯式資料庫，Redis 不支援 rollback 機制(減少對 Redis 效能影響) Redis Transaction 具有隔離性 (Isolation)：指的是同一筆資料，保障不會被兩個 Transaction 同時更改，產生競爭條件(Race Condition)，一個 Transaction 完成之前，其它 client 端送出的各種操作指令都不能被執行，保證了隔離性。 應用Transaction 的隔離性可以確保資料不會在同一時間被多個人進行改動，確保資料正確性。 舉格生活例子： 甲乙兩人同時查詢同班火車同個座位，兩人都發現後訂購此座位，甲先完成付款，乙後續也完成付款，會造成甲拿到座位而乙付了錢沒有拿到座位。 加入 Transaction 機制變成甲先完成交易，乙需等甲完成交易後得知座位數量再進行交易。 用法MULTI 指令建立一個 Transaction，收到 “OK” 的提示後可開始輸入其他要執行的指令放入 Transaction，最後再執行 EXEC。 範例1:執行兩次 set 分別建立 bank1, bank2 兩個 key 123456789&gt; MULTIOK&gt; set bank1 5000QUEUED&gt; set bank2 6000QUEUED&gt; exec1) OK2) OK 接續 MULTI 後輸入的兩個 SET 指令得到的結果為 QUEUED 表該指令已被序列化且放在 Queue 裡按順序等待執行，最後從 EXEC 收到 2 個 “OK” 表放在 Queue 裡的兩個 SET 指令被成功執行！ 接著看另一個例子，如果發生 Transaction 裡的指令有錯誤的情形 e.g. 指令拼錯， Redis 會偵查到這個錯誤，並將先前已放入 QUEUE 裡的指令都捨棄掉。 範例2:將範例 1 的 bank1, bank2 的值都加上 100，其中對 bank2 下的指令語法是錯誤的 12345678&gt; multiOK&gt; incrby bank1 100QUEUED&gt; incrbyy bank2 100(error) ERR unknown command `incrbyy`, with args beginning with: `bank2`, `100`,&gt; exec(error) EXECABORT Transaction discarded because of previous errors. 由於 incrby 是拼錯的指令，Redis 跳出 “(error) ERR unknown command incrbyy, with args beginning with: bank2, 100,” 的錯誤提示，最終執行 EXEC 時也提示 EXECABORT Transaction discarded 最後透過 MGET 檢查 bank1, bank2 是否有變動： 123MGET bank1 bank21) &quot;5000&quot;2) &quot;6000&quot; 從結果來看剛才 Transaction 裡下的指令沒有對 bank1, bank2 做任何變動，證明只要有一個以上的指令在 執行EXEC 前 被 Redis 偵測出來，其他的指令即便是沒問題的也會被捨棄掉，保持執行前的狀況 Transaction 裡的錯誤實務上可能發生 Redis 沒辦法事先於 QUEUE 裡偵查到這類的錯誤，如EXEC 執行 之後 才引發錯誤，表示 Transaction 裡等待被執行的指令套用錯誤的使用情境。 常見例子：針對 Lists 操作的指令，目標 key 的資料類型卻是 String 範例3:替換 範例2 對 bank2 下的指令，改為 ZADD。 123456789101112&gt; incrby bank1 100QUEUED&gt; zadd bank2 1 100QUEUED&gt; exec1) (integer) 51002) (error) WRONGTYPE Operation against a key holding the wrong kind of value&gt; MGET bank1 bank21) &quot;5100&quot;2) &quot;6000&quot; 由於 bank2 資料類型是 string，ZADD 則是操作 sortedset 類型，相異類型的指令操作無法在放入 QUEUE 時且執行 EXEC 之前被 Redis 偵測出錯誤。 若將ZADD 的執行順序與 INCRBY 對調也會得到一樣的結果 12345678910111213&gt; multiOK&gt; zadd bank2 1 100QUEUED&gt; incrby bank1 100QUEUED&gt; exec1) (error) WRONGTYPE Operation against a key holding the wrong kind of value2) (integer) 5200&gt; MGET bank1 bank21) &quot;5200&quot;2) &quot;6000&quot; 相較於前面範例 2 指令的語法錯誤，範例 3 的類型錯誤讓 Transaction 依舊正常執行，但是透過 MGET 查詢 bank1, bank2 的結果會發現 bank1 已經被 incrby 改動，表示這類 只有在執行 EXEC後 ，跑完整個 Transaction 才發生的錯誤，除了錯誤的那個指令之外，其他指令仍能對資料進行改動。 截自官方文件的描述：It’s important to note that even when a command fails, all the other commands in the queue are processed – Redis will not stop the processing of commands. DISCARD執行 DISCARD 指令時，會放棄 Transactions，同時 QUEUE 裡面的所有指令會被清空，並退出整個狀態： 範例4新增 bank3, bank4 兩個 key 1mset bank3 1000 bank4 2000 個別對上面兩個 key 的值在 Transactions 裡執行 set 增加 100，接著加上 DISCARD 1234567891011&gt; multiOK&gt; incrby bank3 100QUEUED&gt; incrby bank4 100QUEUED&gt; discardOK&gt; MGET bank3 bank41) &quot;1000&quot;2) &quot;2000&quot; 透過 MGET 得知 bank3, bank4 因為 DISCARD 捨棄原有的 incrby ，而沒有任何變動 如果是加上 DISCARD 後再執行 EXEC 則會得到錯誤提示： ERR EXEC without MULTI。 WATCH前面討論了 Redis 的 Transaction 概念和操作流程，本節會討論 Redis Watch 指令及在 Transaction 中的角色。 WATCH 提供一個名為 check-and-set (CAS) 的機制給 Transaction，用於偵測指定的 key 是否在 Transaction 執行之前發生變動， 是 EXEC 指令的執行條件，也就是說，若 WATCH 指定的 key 有發生改動，整個 Transaction 就會被終止，並回傳 null 值。 範例1：對 bank1 下 WATCH 指令監測，再對該 key 做改動，最後於 Transaction 中對 bank1 再做一次改動 12345678910&gt; WATCH bank1OK&gt; incrby bank1 100(integer) 5200&gt; multiOK&gt; incrby bank1 100QUEUED&gt; exec(nil) 在 Transaction 之前對 bank1 下WATCH，最後執行 EXEC 時回傳 (nil) 讓整個 Transaction 終止。 範例2：延伸範例1的方式，這次改成在自己的電腦上開兩個終端機視窗，左邊視窗先執行 watch 監控 bank1 是否有被改動，接著於右方視窗下指令 incrby bank1 200 ，模擬其他的 user 將 bank1 的值加上 200。再回到左方視窗執行 multi 開啟 Transaction 後輸入指令 incrby bank1 300 將 bank1 的值加上 300，執行 EXEC 後得到回傳結果為 (nil)。 從這個範例可以了解 watched key 在另一個 Client 端進行改動後，確保了沒有競爭條件(Race Condition)時才能正確執行。 若想消除針對 Transaction 的 watched key 可執行 UNWATCH 的指令終止。 Note由於 WATCH 只有當被監控的 key 被修改後阻止之後 一個 Transaction 執行，不能保證其他 Client 端不修改這個 key，故一般情況下需要 EXEC 執行失敗後重新執行整個函數。 小結本篇討論 Transaction 在 Redis 的重要概念以及MULTI, EXEC, DISCARD and WATCH 這四個指令，有效地管理 Transaction 執行，才能保證資料完整性。 Ref 4.4 Redis transactions | Chapter 4: Keeping data safe and ensuring performance Redis - Transaction","link":"2022/01/11/Database/Redis/%5BBackend%5D%20Redis%20-%20Transction/"},{"title":"[Redis] 提高 Redis 執行效率的方法 - Pipeline","text":"前言 過去在使用 Redis 指令時，都是一條一條指令發送給 Redis ，每條指令都會經過 發送指令 -&gt; Redis server 接收指令 -&gt; 處理資料 -&gt; 回傳結果 的流程，這樣一來一回花費的時間稱作 round-trip time (簡稱RTT)，在傳送過程中還需考量網路每次建立連線耗時與延遲問題。 若同時有多條指令要處理時，RTT 就會拉長，為縮短多個指令在同時間排隊分別執行造成的效能問題，Redis 提供 Pipeline 的機制，讓多個指令在同時間執行且不需相互等待，一次回傳所執行完的結果。 既然這項機制對於效能提升有幫助，來了解一下 Redis Pipeline 的概念及使用上要注意的項目吧！ Pipeline如前言所描述，在未使用 Pipeline 之前，是多條指令依序去對 Redis 發送指令，從發送指令到收到執行結果，整個過程隨著指令的數量變多，等待時間跟著變長，而引入 Pipeline 機制，可讓多個指令一次發送給 Redis server，Pipeline 實現的原理是採用 Queue (排隊的方式)，以先進先出的方式確保資料的順序性，最後執行 exec 指令將 Queue 裡所有的指令一次發送給 Redis。 依序發送(未使用 Pipeline) 如上圖所示，有四條指令依序對 Redis 進行發送，整體花費的時間是四條指令來回花費時間的加總。 批次發送(使用 Pipeline) 上圖用咖啡色的 Pipeline 包起來的所有指令會一次發送給 Redis，只花費一次發送的來回時間，相較於前面的方式，批次發送花更少的時間處理 Client 端送來的指令，也意味著能夠縮短系統回應時間。 除了 RTT 之外，Pipeline 也提高了 Redis server 中每秒可以執行的指令數量。 這是因為在未使用 Pipeline 一條發送指令的情況下 I/O 成本會很高，這牽涉到系統呼叫 read() and write() 的轉換，頻繁的 context switch 對 server 會是很大的負擔。 舉例:未使用 Pipeline 的情形下發送 10 條指令，系統呼叫發生 10 次 context switch，若於 Pipeline 裡面將 10 條指令一次發送，只會發生一次 context switch 注意 單個 Pipeline 大小:儘管 Pipeline 能有效降低 RTT，減少 I/O 次數，若 client 端使用 Pipeline 將大量指令以類似群組的方式，一次發送給 Redis server，會消耗大量的記憶體(群組裡的指令越多，消耗的記憶體資源越大)，同時會增加 client 端的等待時間，及造成一定程度的延遲。因此仍須注意 Pipeline 容量不可過大，過大時盡可能採用多個 Pipeline 分次發送，減少單次 Pipeline 的大小(受限於server的記憶體大小)。舉例: 比較2萬條指令不同的發送方式一次性發送和分兩次發送(每次發1萬條指令，讀完資料收到回應後再發另外1萬條指令)。對 client 端來說速度是差不多，但是對 server 端來說，記憶體佔用卻差了1萬條指令回應的大小。 適用於執行連續且無相依性的指令(不需仰賴前一個指令的回傳結果) 不擁有原子性(Atomic): 發送的多條指令裡面可能部分成功，一部分失敗; Pipeline 在 server 上是非阻塞的，意味者若有來自其他 client 發送的 pipeline 不會被阻止，產生交錯執行的狀況。 (如下圖所示，圖片取自 Thomas Hunter 的簡報) 使用時機 需要減少網路延遲，提升效能 需要發送多條指令給 Redis，且指令之間沒有相依性(不需等待上個指令的結果)，一次獲得所有結果 可靠性要求較低的需求，允許一定比例的失敗(可後續補償) e.g. 大量發送簡訊 與 Transactions(multi) 的差異multi 用於開啟 Transactions。 Transaction 裡多條指令會按照先後順序被放進一個 Queue 裡，最後執行 EXEC 指令完成 Transaction。 兩者差別: 請求次數不同： multi 需要每個指令都發送一次請求給 server 端，Pipeline 則是最後一次性發送給 server 端，請求次數相較 multi 少 原子性(Atomic): Pipeline 不保證原子性，Pipeline 中發送的每條指令都會被 server 立即執行，若執行失敗，將會在回應裡面得到對應得錯誤資訊； Transactions 擁有原子性，不會發生與其他 client 發送指令交互執行的情況(如下圖所示) 範例Redis 提供各個熱門程式語言函式庫，下方提供 Python 的範例，使用 redis-py 這個官方支援的函示庫。 下方範例會先建立名為 product 的範例資料，裡面包含不同的 t-shirt 樣式，目標是要將範例資料透過 hset 的方式寫入 Redis 裡面。 範例的資料結構如下: 提示: 保持介面乾淨可以善用下方箭頭收起程式碼區塊 1234567891011121314151617181920212223{ &quot;shirt:1&quot;: { &quot;color&quot;: &quot;black&quot;, &quot;price&quot;: 49.99, &quot;style&quot;: &quot;fitted&quot;, &quot;quantity&quot;: 5, &quot;nPurchased&quot;: 0 }, &quot;shirt:2&quot;: { &quot;color&quot;: &quot;maroon&quot;, &quot;price&quot;: 60, &quot;style&quot;: &quot;Office Shirt&quot;, &quot;quantity&quot;: &quot;6&quot;, &quot;nPurchased&quot;: 0 }, &quot;shirt:3&quot;: { &quot;color&quot;: &quot;Pink&quot;, &quot;price&quot;: 79.99, &quot;style&quot;: &quot;Over Shirt&quot;, &quot;quantity&quot;: &quot;3&quot;, &quot;nPurchased&quot;: 0 }} Python code 範例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 引入 redis-py import redisimport time# ======= 建立範例資料 =======product = [ { &quot;color&quot;: &quot;black&quot;, &quot;price&quot;: 49.99, &quot;style&quot;: &quot;fitted&quot;, &quot;quantity&quot;: 5, &quot;nPurchased&quot;: 0, }, { &quot;color&quot;: &quot;maroon&quot;, &quot;price&quot;: 60, &quot;style&quot;: &quot;Office Shirt&quot;, &quot;quantity&quot;: &quot;6&quot;, &quot;nPurchased&quot;: 0, }, { &quot;color&quot;: &quot;Pink&quot;, &quot;price&quot;: 79.99, &quot;style&quot;: &quot;Over Shirt&quot;, &quot;quantity&quot;: &quot;3&quot;, &quot;nPurchased&quot;: 0, }]shirts = dict()id = 1for i in product: key = f&quot;shirt:{id}&quot; shirts[key] = i id += 1print(shirts)# ======= 建立 Redis Connection Pool =======pool = redis.ConnectionPool(host='127.0.0.1', decode_responses=True, db=0)r = redis.StrictRedis(connection_pool=pool)starttime = time.time()# ======= 建立 Redis Pipeline，將多條 hset 指令放入 Pipeline 裡等待執行 =======with r.pipeline(transaction=False) as pipe: for s_id, shirt in shirts.items(): for field, value in shirt.items(): pipe.hset(s_id, field, value) pipe.execute()output = f'It took {time.time() - starttime} seconds to work.'print(output) 上方範例呼叫函式庫 redis-py 裡的 pipeline()，將每條 hset 指令放入 Pipeline 裡等待最後 execute() 呼叫時一次送出。 最後透過 Redis Desktop Manager 這類的視覺化介面工具可以看到被寫入的 t-shirt 資料！ 另外也可以嘗試不使用 Pipeline 的做法，比較兩者所花費時間。 總結本篇文章討論了 Pipeline 概念、好處、使用時機以及使用上要注意的地方，除此之外也和 Transactions 比較差異，最後實際用程式語言演練一次範例。 Reference Redis pipelining Atomicity In Redis: Thomas Hunter Redis: Pipelining, Transactions and Lua Scripts Redis uses pipeline to speed up query speed","link":"2022/01/15/Database/Redis/%5BBackend%5D%20%E6%8F%90%E9%AB%98%20Redis%20%E5%9F%B7%E8%A1%8C%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%20-%20Pipeline/"},{"title":"[Github Action] 整合 AWS OIDC 進行 CI&#x2F;CD 安全強化","text":"前言目前公司的專案大量使用 Github Action 跑自動化 CI/CD 的 pipelines 去部署服務到 AWS 環境，近期將原本 CI/CD pipelines 上與 AWS service 驗證的 workflows 做調整，驗證方式從原本藉由 IAM User 進行 assume role 的方式改成透過 AWS ODIC 的方式完成 assume role。 相較於以前的作法，使用 IAM user 的 secrets 驗證，OIDC 的作法能幫助我們省去管理金鑰的麻煩。 本文會 AWS 作為 cloud provider，設定方法也是以 AWS 為範例，以下內容建議有 GitHub Action 及 AWS IAM 這兩項先備知識比較能理解。 OIDCOpenID Connect 以 OAuth 2.0 為基礎設計，藉由一組短期的 token 交換作為驗證方式，用於認證使用者登入，GitHub Actions 提供 OIDC 的驗證/授權機制，與其他第三方的雲服務供應商 (如： AWS, Azure, Google Cloud Platform 等) 進行整合，提供 CI/CD 工作流程上更簡便的設計。 使用 OIDC 好處不需要提供 secrets以前的作法都是從 cloud service IAM 產出驗證的 secrets，將這些 secret 存放在 GitHub secrets 裡面，在 workflow 透過變數的方式帶入。 OIDC 的作法可以省去這些 secrets，只要 OIDC 與 Cloud provider 上的信任政策設定好即可，不需要額外產生驗證的 secrets，也避免 secret 可能外洩的問題。 簡化身份驗證和授權管理試想如果今天有多個 workflows 需要與不同 cloud service 互動，要限縮權限的話勢必需要產生擁有 could service 相應權限的 secrets，最終它們可能會四散在不同 repo 裡，管理的數量也會隨需求越來越多。 OIDC 因為不需要產生額外的 secrets 驗證，就不用考慮管理問題。 省去輪換 secrets 的工作大部分的組織政策會要求 secret 要定期輪換，要換這麼多 secrets 也是相當耗時的事情。 而 OIDC 完全不必考慮 secrets 輪換。 權限控制的範圍OIDC 在 cloud provider 上的信任政策設定能將授權範圍限縮在某個 repository 甚至到某個 brach。 流程 OIDC 在 cloud 之間的交換流程上分為幾個步驟： 在 cloud provider 上建立 OIDC 信任政策，設定 IAM Role 與 GitHub provider workflows 間的存取政策，讓 GitHub 的 OIDC Provider 之後送來的 token 做驗證。 每次 GitHub Action 的 workflow 被觸發時，GitHub 的 OIDC provider 會自動生成一組獨立的 OIDC token (即 JSON Web Token)，作為 workflow 的身份驗證，將其發送至 cloud provider。 Cloud provider 對收到的 Token 內容與 OIDC 信任政策的設定進行驗證 一旦驗證成功，Cloud provider 會提供 GitHub OIDC provider 一組效期短的 access token，且僅在這個 workflow 運行期間有效。 注意:GitHub Actions 使用 OIDC 作為驗證管道時，務必確認對接的服務提供商支援這類的驗證方式。 設定方式要在 AWS 上設定 OIDC 與 GitHub Actions 互動，會需要先到 AWS console 頁面，選擇 IAM 這項服務，並於左方導覽列找到 “Identity providers”。 點擊後畫面右方有個 “Add provider” 按鈕，新增我們要的 provider 接著勾選 “OpenID Connect” 並於 “Provider URL” 輸入匡輸入驗證用的 OIDC URL 及 Audience 這個設定步驟要注意兩個地方: Provider URL:如果是使用官方維護的 GitHub server，填：https://token.actions.githubusercontent.com若為組織內部自己架設的，則填寫 OIDC connector 的 endpoint。 Audience:採用 AWS 官方的 action，填 sts.amazonaws.com 都填好後即可新增 provider，畫面如下： 接著我們要建立一個 for assume role 用途的 IAM role，這樣 CI/CD workflow 執行時才能有權限與 AWS 上的服務互動。 一樣在 IAM 頁面左方導覽列找到 Roles → Create role → Trusted entity type 選 “Web identity” → Identity provider 選剛剛建好的 provider 後進入下一頁選擇綁定的權限。 將 role 希望擁有權限的相關 Policies 在此步驟裡面都加進來，例如想要操作 S3，我們就需搜尋 S3 相關的 Policies。 最後是訂定 role 的名稱，下方 Federated 裡會自動帶入 OIDC provider 的 arn，確認好後就能新增 for S3 權限的 role。 建好之後回到剛才 role 裡面，編輯 trust policy (信任政策)。 一開始建立好的 role 並沒有針對 GitHub repository 做存取權範圍的設定，所以要在 trust policy 裡的 Condition 定義範圍。 trust policy 定義範圍的方法有許多種，也支援 wildcard (*) 符號，範圍可以選擇特定的 repo 、某個 repo 下的 branch 等，通用格式如下：repo:&lt;orgName/repoName&gt;:environment:&lt;environmentName&gt; 1234567891011121314151617181920{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;Federated&quot;: &quot;arn:aws:iam::&lt;accountId&gt;:oidc-provider/token.actions.githubusercontent.com&quot; }, &quot;Action&quot;: &quot;sts:AssumeRoleWithWebIdentity&quot;, &quot;Condition&quot;: { &quot;StringEquals&quot;: { &quot;token.actions.githubusercontent.com:aud&quot;: &quot;sts.amazonaws.com&quot; }, &quot;StringLike&quot;: { &quot;token.actions.githubusercontent.com:sub&quot;: &quot;repo:&lt;orgName/repoName&gt;:environment:&lt;environmentName&gt;&quot; } } } ]} Note: aud 描述的是剛剛在 id provider 填入的內容; sub 則是指定驗證/授權的 GitHub repo。 StringEquals 與 StringLike 兩者在使用上稍有不同，StringEquals 適用於完全相符的名稱，例如希望指定某個 repo 下的 main branch，而 StringLike 搭配 wildcard 可選取某個特定範圍，例如某個 repo 下所有的 branch。 sub 裡指定的 repo 如果有多個時，改成 [ &quot;repo:&lt;orgName/repoName&gt;:environment:&lt;environmentName&gt;&quot;, &quot;repo:&lt;orgName/repoName&gt;:environment:&lt;environmentName&gt;&quot;, ...... ] 的寫法。 範例：指定個人 GitHub 帳號下 repo 名為 gh-action-demo 的所有 branchrepo:ChenTsungYu/gh-action-demo:* 未來在這個 repo 下觸發 GitHub Action 的 workflow 時，OIDC provider 便有權與設定好的 IAM role 互動，更多範例可參考官方文件 - Example subject claims 在 GitHub workflow 加入權限於 OIDC 驗證的 workflow 裡務必要設置權限 123permissions: id-token: write # This is required for requesting the JWT contents: read # This is required for actions/checkout 範例：在目標要觸發 CI/CD 的 GitHub repo 下建立 Action workflow，透過 Action assume 到前面建好的 IAM role: github-actions-role-s3 ，查詢所有的 S3 buckets。 GitHub repo 下的資料夾結構： 123|-- .github| -- workflows| -- aws-oidc.yaml aws-oidc.yaml 便是我們要觸發的 Action workflow。 將下方範例的 &lt;account ID&gt; 替換成自己的 AWS account ID 123456789101112131415161718192021222324252627282930name: AWS OIDC connectoron: workflow_dispatch:# permissions settings for the token.permissions: id-token: write contents: readjobs: oidc-s3: runs-on: [ubuntu-latest] steps: - uses: actions/checkout@v3 - name: OIDC config of github-actions-role for aws credential uses: aws-actions/configure-aws-credentials@v1-node16 with: role-session-name: GithubActionsTerraform role-skip-session-tagging: true role-to-assume: arn:aws:iam::&lt;account ID&gt;:role/github-actions-role-s3 aws-region: ap-northeast-1 - name: check aws identity run: aws sts get-caller-identity # Check all buckets from AWS s3 - name: list s3 run: | aws s3 ls 上面的 workflow 範例分別進行了 AWS 驗證，assume 到建立好的 IAM role - github-actions-role-s3 ，查詢 account 下所有的 S3 buckets。 將新增的 workflow 加進 git commit 後推上 GitHub，並於 repo 的 Action 分頁點選剛剛自訂的 workflow - AWS OIDC connector，找到畫面右方按鈕 “Run workflow” 觸發 workflow 等 workflow 跑完的結果 點進去 workflow 可以看到 job 裡每個 step 執行結果，在 list s3 這個 step 能與 AWS S3 正常互動，列出了 AWS account 下所有的 S3 buckets。 總結前面介紹 OIDC 設置的整個流程中，與 AWS service 之間的互動沒有一個地方需要管理驗證用的 secret，GitHub provider 與 AWS 之間互相傳遞 token 進行驗證的過程都在背後默默進行，我們沒有另外產生額外的 secret 來驗證。 如此一來，後續有其他的 GitHub repos 要使用相同 IAM role 執行別的任務時，只需將 role 的 trust policy 設定加上指定的 repos 即可，不僅減少管理 secret 的工作，同時也避免 secret 可能外洩的問題。 參考 Creating a role for web identity or OpenID Connect Federation (console) https://github.com/aws-actions/configure-aws-credentials#assuming-a-role https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services#adding-the-identity-provider-to-aws","link":"2022/11/27/DevOps/CICD/GitHub%20Action%20OIDC/"},{"title":"[Redis] Redis 資料結構 - Hash","text":"前言 上一篇探討了 Redis Lists 資料結構，本篇將紀錄 Redis 儲存物件用的資料結構 - Hash 什麼是 Hash？屬於 field-value 集合，適合用於儲存物件，與 string 不同的點在於 Hash 可以是多個 field - value 成對存在 HSET &amp;&amp; HGET &amp;&amp; HGETALL &amp;&amp; HSETNXRef: HSET、Ref: HGET、Ref: HGETALL HSET 用於設置 hash，若指定的 field 已存在於 Redis，原有的 field 會被覆寫掉。而 HGET 則是取出指定的 hash field 對應的值。 HGETALL 則是取得指定的 hash 下所有 field-value 使用 HSETNX，只有在該 field 不存在指定的 hash 時才可以設置(回傳值為 1)，反之則不影響原來的 field 對應的 value (回傳值為 0) 語法：HSET 1HSET key field value [ field value ...] HGET 1HGET key field HSETNX 1HSETNX key field value HGETALL 1HGETALL key 範例：建立名為 student 的 hash，同時給定 name, gender, age 這些 field 對應的值 1HSET student name &quot;Bob&quot; gender male age 22 取得 student name 的值 1234HGET student nameOutput:&quot;Bob&quot; 取得 student 這個 hash 下的所有 field - value 對 123456789HGETALL studentOutput:1) &quot;name&quot;2) &quot;Bob&quot;3) &quot;gender&quot;4) &quot;male&quot;5) &quot;age&quot;6) &quot;22&quot; 使用 HSETNX 對 student 新增名為 hobby 的 field 12345678910HSETNX student hobby tennis# 查看 HSETNX 執行後的結果HVALS studentOutput:1) &quot;Bob&quot;2) &quot;male&quot;3) &quot;22&quot;4) &quot;tennis&quot; 再執行一次 HSETNX 對 student 新增同個名為 hobby 的 field，由於 hobby 這個 field 先前已存在 student 裡面，故回傳值為 0，且 hobby 還是保持原本的值 123HSETNX student hobby basketball(integer) 0 HMGETRef: HMGET 相較於 HEGT 只能指定一個 field，HMGET 允許一次指定多個 field，取得對應的 value。 若指定的 field 已存在於 Redis，原有的 field 會被覆寫掉; 不存在 Redis 裡時，回傳值為 nil 語法： 1HMGET key field [field ...] 範例：延續上個 hash 範例的 student，這次同時指定 name, age 兩個 field 的值 1234567HSET student name &quot;Bob&quot; gender male age 22HMGET student name ageOutput:1) &quot;Bob&quot;2) &quot;22&quot; field 不存在 Redis 裡時，回傳值為 nil。 123456HMGET student name age testOutput:1) &quot;Bob&quot;2) &quot;22&quot;3) (nil) 上方範例中 test 為原本不存於 student 的 field，故回傳值為 nil HVALS &amp;&amp; HKEYSRef: HVALS、Ref: HKEYS HVALS用於取得指定的 Hash 底下所有的 value，而 HKEYS 則是取得指定的 Hash 底下所有的 key 語法： 123HVALS keyHKEYS key 範例：延續上個 hash 範例的 student，取得 student 下的所有 values 123456HVALS studentOutput:1) &quot;Bob&quot;2) &quot;male&quot;3) &quot;22&quot; 取得 student 下的所有 keys 123456HKEYS studentOutput:1) &quot;name&quot;2) &quot;gender&quot;3) &quot;age&quot; HEXISTSRef: HEXISTS 用於檢查指定的 field 是否存在指定的 key 裡面。 回傳值為 1：該 field 存在指定的 key 裡面 回傳值為 0：該 field 不存在指定的 key 裡面 or key 本身就不存在 Redis 語法： 1HEXISTS key field 範例：延續 student 的範例，分別檢查 name, test 這兩個 field 是否存在 12345678910HEXISTS student nameOutput:(integer) 1HEXISTS student testOutput:(integer) 0 HDELRef: HDEL 於目標 hash 中刪除一個至多個指定的 field 語法： 1HDEL key field [field ...] 範例：除除 student 裡的 hobby, age 這兩個 field 12345678910HDEL student hobby ageOutput:(integer) 2HKEYS studentOutput:1) &quot;name&quot;2) &quot;gender&quot; 總結OK! 透過前面的指令和範例了解如何對 Hash key 裡的 field 取值、修改、查詢及刪除，下一篇會進入到 Redis 資料結構 - SET Reference An introduction to Redis data types and abstractions","link":"2022/01/07/Database/Redis/%5BRedis%5D%20Redis%20%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%20-%20Hash/"},{"title":"[Redis] Redis 資料結構 - Lists","text":"前言 延續 上篇 討論到 Redis 基礎的資料結構 - String，本篇要討論另一個資料結構 - Lists 什麼是 Lists？Ref: Lists Redis 的 Lists 為有順序的列表，可於列表的起始或末端添加 or 刪除裡頭的元素 來看看 Redis 對 Lists 提供哪些常用的指令吧！ LPUSHRef: LPUSH 將元素添加到指定 key 裡的列表的第一個位置，可一次寫入多筆元素。 回傳值: 列表的長度 語法： 1LPUSH key element [element ...] 範例：於 mylist 裡一次寫入三筆元素 a, b, c 1LPUSH mylist a b c 透過 LRANGE 將資料列出來 123456LRANGE mylist 0 -1Output:1) &quot;c&quot;2) &quot;b&quot;3) &quot;a&quot; 結果得知，c 在 LPUSH 指令裡面是最尾端，從 LRANGE 得出的結果是放在第一位 LRANGERef: LRANGE 語法： 1LRANGE key start stop start 索引的起始位置，預設起始點為 0 stop 索引末端的位置，可用 -1 表示最尾端 注意: 超出範圍的索引(Out-of-range indexes)超出範圍的索引不會產生錯誤，若 start 大於列表的尾端，則回傳一個的空列表。若 stop 超過列表末端的實際索引值，Redis 會將其視為列表的最後一個元素。 start &gt; end stop 超過列表末端的實際索引值 RPUSHRef: RPUSH 將元素添加到指定 key 裡的列表的末端位置，可一次寫入多筆元素。 回傳值: 列表的長度 語法： 1RPUSH key element [element ...] 範例：於 pushlist 裡一次寫入三筆元素 d, e, f 1RPUSH pushlist d e f 透過 LRANGE 將資料列出來 123456LRANGE pushlist 0 -1Output:1) &quot;d&quot;2) &quot;e&quot;3) &quot;f&quot; RPUSHX &amp;&amp; LPUSHXRef: LPUSHX、Ref: RPUSHX RPUSHX 類似前述的 RPUSH 方法，於列表的末端插入一個 or 多個元素，只是 RPUSHX 需指定的 key 是已存在 Redis 的情況下才會添加新元素，而 LPUSHX 也是一樣的概念。 回傳值: 列表的長度 語法： 12345# LPUSHXLPUSHX key element [element ...]# RPUSHXRPUSHX key element [element ...] 若原始的 key 不存在 Redis, 回傳值為 0 反之若 key 存在則會添加元素 12345678910RPUSHX pushlist a b cOutput:LRANGE pushlist 0 -11) &quot;d&quot;2) &quot;e&quot;3) &quot;f&quot;4) &quot;a&quot;5) &quot;b&quot;6) &quot;c&quot; 123456789101112LPUSHX pushlist 123 456Output:LRANGE pushlist 0 -11) &quot;456&quot;2) &quot;123&quot;3) &quot;d&quot;4) &quot;e&quot;5) &quot;f&quot;6) &quot;a&quot;7) &quot;b&quot;8) &quot;c&quot; RPOPRef: RPOP、Ref: LPOP LPOP：刪除並回傳存在 key 的列表裡 第一個元素 RPOP：刪除並回傳存在 key 的列表裡 最後一個元素 若元素不存在，回傳值為 (nil) 可指定移除元素的數量(指定個數超過原有數量時表 全部移除) 語法： 1RPOP key [count] [count] 為刪除的個數， 範例1： 移除單一元素將 pushlist 裡的最後一個元素 &quot;c&quot; 移除 123456789101112131415161718192021222324252627282930# 前述的 pushlist 範例LRANGE pushlist 0 -1Output:1) &quot;456&quot;2) &quot;123&quot;3) &quot;d&quot;4) &quot;e&quot;5) &quot;f&quot;6) &quot;a&quot;7) &quot;b&quot;8) &quot;c&quot;# 移除 pushlist 裡的元素RPOP pushlistOutput:&quot;c&quot;# 查看移除元素後的 pushlistLRANGE pushlist 0 -1 Output:1) &quot;456&quot;2) &quot;123&quot;3) &quot;d&quot;4) &quot;e&quot;5) &quot;f&quot;6) &quot;a&quot;7) &quot;b&quot; 範例2： 移除多個元素把語法裡的 count 參數加進來，指定要移除的元素個數 12345678910111213141516171819# 前述的 pushlist 範例LRANGE pushlist 0 -1Output:1) &quot;456&quot;2) &quot;123&quot;3) &quot;d&quot;4) &quot;e&quot;5) &quot;f&quot;6) &quot;a&quot;7) &quot;b&quot;# 指定移除 pushlist 裡最後 3 個元素RPOP pushlist 3Output:1) &quot;b&quot;2) &quot;a&quot;3) &quot;f&quot; LTRIMRef: LTRIM LTRIM 用來擷取特定範圍的元素 語法： 1LTRIM key start stop start 以 0 為起始點開始索引的位置 stop 索引的終點，可用 -1 表最後一個元素 範例：在 trimlist 裡有三個元素：“one”, “two”, “three” 1RPUSH trimlist &quot;one&quot; &quot;two&quot; &quot;three&quot; 取出 “two”, “three” 兩個元素 12345LTRIM trimlist 1 -1Output1) &quot;two&quot;2) &quot;three&quot; Note:超出範圍的索引不會產生錯誤如： start 大於列表的尾端，或者 start &gt; end，回傳值是一個 空列表（這會導致 key 被刪除）。如果 end 大於列表的尾端，Redis 會將其視為列表的最後一個元素。 LSETRef: LSET 指定索引位置所在的元素進行替換 語法： 1LSET key index element 範例：於 lset 裡放置三個元素：”one”, “two”, “three” 1RPUSH lset &quot;one&quot; &quot;two&quot; &quot;three&quot; 分別對第0、倒數第2個元素做替換 12345678910LSET lset 0 &quot;four&quot;LSET lset -2 &quot;five&quot;LRANGE lset 0 -1Output:1) &quot;four&quot;2) &quot;five&quot;3) &quot;three&quot; LINDEXRef: LINDEX 查找指定索引位置所在的元素，回傳找到的元素，若超過 list 索引的位置則回傳 (nil) 語法： 1LINDEX key index 範例：list 添加三個元素 “one”, “two”, “three” 1RPUSH list &quot;one&quot; &quot;two&quot; &quot;three&quot; 查找索引位置在 2 的元素 1234LINDEX list 2Output:&quot;three&quot; LINSERTRef: LINSERT 於列表裡挑出一個元素作為參考點，選擇於參考點的前 or 後添加新元素 語法： 1LINSERT key BEFORE | AFTER pivot element pivot 指定作為參考點的元素 範例： 1RPUSH list &quot;one&quot; &quot;two&quot; &quot;three&quot; 於元素 “one” 前方插入新的元素 “zero” 123456789LINSERT list BEFORE &quot;one&quot; &quot;zero&quot;LRANGE list 0 -1Output:1) &quot;zero&quot;2) &quot;one&quot;3) &quot;two&quot;4) &quot;three&quot; 於元素 “three” 後方插入新的元素 “four” 12345678910LINSERT list AFTER &quot;three&quot; &quot;four&quot;LRANGE list 0 -1Output:1) &quot;zero&quot;2) &quot;one&quot;3) &quot;two&quot;4) &quot;three&quot;5) &quot;four&quot; 若參考點不存在時，回傳值為 -1 1234LINSERT list AFTER &quot;djrjtlret&quot; &quot;five&quot;Output:(integer) -1 若 key 不存在時，回傳值為 0 LLENRef: LLEN 查找存在 key 的列表的長度。 語法： 1LLEN key LREMRef: LREM 用於刪除 key 列表中出現特定次數的指定元素 1LREM key count element count 參數表指定的次數 規則如下： count &gt; 0: 刪除 key 列表中 從起始點到終點出現特定次數的指定元素 count &lt; 0: 刪除列表中 從終點到起始點 出現特定次數的指定元素 count = 0: 刪除 所有 存於 key 列表中的指定元素 範例1： 從終點到起始點移除元素建立 mylist 列表，列表內的值包含 4 個 “hello”, 1 個 “world” 的元素 12345678910LPUSH mylist &quot;hello&quot; &quot;hello&quot; &quot;world&quot; &quot;hello&quot; &quot;hello&quot;LRANGE mylist 0 -1Output:1) &quot;hello&quot;2) &quot;hello&quot;3) &quot;world&quot;4) &quot;hello&quot;5) &quot;hello&quot; 現在要 mylist 裡從 終點開始 移除 2 個 hello 元素 12345678LREM mylist -2 &quot;hello&quot;LRANGE mylist 0 -1Output:1) &quot;hello&quot;2) &quot;hello&quot;3) &quot;world&quot; 重新查看 mylist 得到新的結果是最後兩個 “hello” 元素已從 Redis 內移除 範例2： 從起始點到終點移除元素建立 fruit 列表，列表內的值包含 3 個 “mango”, 1 個 “peach”, 1 個 “peach”, 1 個 “banana” 和 1 個 grape 的元素 1234567891011RPUSH fruit &quot;mango&quot; &quot;mango&quot; &quot;mango&quot; &quot;peach&quot; &quot;banana&quot; &quot;grape&quot;LRANGE fruit 0 -1Output:1) &quot;mango&quot;2) &quot;mango&quot;3) &quot;mango&quot;4) &quot;peach&quot;5) &quot;banana&quot;6) &quot;grape&quot; 現在要 fruit 裡從 起點開始 移除 2 個 mango 元素 123456789LREM fruit 2 &quot;mango&quot;LRANGE fruit 0 -1Output:1) &quot;mango&quot;2) &quot;peach&quot;3) &quot;banana&quot;4) &quot;grape&quot; 重新查看 fruit 得到新的結果是最前面的兩個 “mango” 元素已從 Redis 內移除 範例3： 移除所有元素重複範例二的資料，只是這次將 count 設為 0 12345678LREM fruit 0 &quot;mango&quot;LRANGE fruit 0 -1Output:1) &quot;peach&quot;2) &quot;banana&quot;3) &quot;grape&quot; 總結看完前面所有的指令及範例，大概能了解如何在 Lists 裡新增、刪除、查詢及修改元素，下一篇紀錄 Redis 儲存物件用的資料結構 - Hash Reference An introduction to Redis data types and abstractions","link":"2022/01/06/Database/Redis/%5BRedis%5D%20Redis%20%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%20-%20Lists/"},{"title":"[Redis] Redis 資料結構 - SET","text":"前言 昨日的文章討論到 Redis 儲存物件用的資料結構 - Hash，本篇接著探討 Redis 的另一個資料結構 - SET 什麼是 SET？SET 是 Redis 裡 string 的集合，故有無序、唯一(不重複)等特點， Redis 有支援多個 Set 之間取交集，差集，聯集的操作 SADD &amp;&amp; SMEMBERSRef: SADD、Ref: SMEMBERS SADD 添加新的值至指定的 key set，SMEMBERS 查詢指定的 key set 裡所有的值 語法： 123SADD key member [member ...]SMEMBERS key 範例： 1234567891011&gt; SADD members &quot;Bob&quot; &quot;Allan&quot; &quot;Jack&quot;Output:(integer) 3&gt; SMEMBERS membersOutput:1) &quot;Jack&quot;2) &quot;Allan&quot;3) &quot;Bob&quot; SISMEMBERRef: SISMEMBER 用於檢查某個值是否存在指定的 key set 裡。 回傳值為 1 表存在; 為 0 則表不存在 語法： 1SISMEMBER key member 範例：沿用 SADD 範例資料 123456789&gt; SISMEMBER members JackOutput:(integer) 1&gt; SISMEMBER members TomOutput:(integer) 0 SCARDRef: SCARD 計算指定的 key set 裡的 element 數量，回傳值為計算後的結果 語法： 1SCARD key 範例：沿用 SADD 範例資料 1234&gt; SCARD membersOutput:(integer) 3 SMOVERef: SMOVE 將某個 key set 裡的元素移到另一個指定的 key set 裡，回傳值為 1 表該元素成功移至指定的 key set 裡，反之若回傳值為 0 則表示該元素不在來源 key set or 未執行 Note:這是具有原子性(Atomic) 的操作 語法： 1SMOVE source destination member source：移出元素的來源 set key destination: 移入元素的目標 set key member：要搬動的元素 範例：新增兩個 key set，分別是 sourcememeb, destinmemeb 123&gt; SADD sourcememeb &quot;A&quot; &quot;B&quot; &quot;C&quot;&gt; SADD destinmemeb &quot;D&quot; &quot;E&quot; 將 sourcememeb 裡的 “B” 元素移動至 destinmemeb 裡面 1234567891011&gt; SMOVE sourcememeb destinmemeb &quot;B&quot;Output:(integer) 1&gt; SMEMBERS destinmemebOutput:1) &quot;B&quot;2) &quot;E&quot;3) &quot;D&quot; SPOPRef: SPOP從指定的 key set 隨機移除一個 or 多個元素 語法： 1SPOP key [count] [count]: 指定移除的數量，屬於可選(Optional)參數 Note除非有在 SPOP 指令後面加上參數指定數量，預設情況下會是移除一個元素 範例：指定移除 popsets 裡的兩個元素 12345678SADD popsets &quot;one&quot; &quot;two&quot; &quot;three&quot; &quot;four&quot;(integer) 4&gt; SPOP popsets 2Output:1) &quot;two&quot;2) &quot;four&quot; SREMRef: SREM 用於移除一個 or 多個指定的元素，回傳值為移除的元素數量。若 key set 不存在 or key 裡的元素皆不存在，則回傳值為 0 語法： 1SREM key member [member ...] 範例：指定 “two” “three” 兩個元素於 popsets 裡移除 123456789101112&gt; SADD popsets &quot;one&quot; &quot;two&quot; &quot;three&quot; &quot;four&quot;&gt; SREM popsets &quot;two&quot; &quot;three&quot;Output:(integer) 2SMEMBERS popsetsOutput:1) &quot;one&quot;2) &quot;four&quot; SDIFF &amp;&amp; SDIFFSTORERef: SDIFF、Ref: SDIFFSTORE SDIFF 可取得多個 set 間的 差集，而 SDIFFSTORE 則是取得差集後存放至指定的新 key set。 語法： 123SDIFF key [key ...]SDIFFSTORE destination key [key ...] 範例描述：key1 = {a,b,c,d}key2 = {c}key3 = {a,c,e} 取得 key1 key2 key3 三者的差集 {b,d} 範例1： SDIFF回傳值為： 差集裡的所有 elements 123456789101112&gt; SADD key1 a b c d&gt; SADD key2 c&gt; SADD key3 a c e# 取差集&gt; SDIFF key1 key2 key3Output:1) &quot;b&quot;2) &quot;d&quot; 範例2： SDIFFSTORE沿用 SDIFF 的範例資料，回傳值為：差集裡的 element 數量，並將回傳值放進新的 key set 裡面 12345678&gt; SDIFFSTORE new_key key1 key2 key3(integer) 2&gt; SMEMBERS new_keyOutput:1) &quot;b&quot;2) &quot;d&quot; SINTER &amp; SINTERSTORERef: SINTER、Ref: SINTERSTORE 概念與 SDIFF &amp;&amp; SDIFFSTORE 兩者類似。SINTER 可取得多個 set 間的 交集 ，而 SINTERSTORE 則是取得交集後存放至指定的新 key set。 語法： 123SINTER key [key ...]SINTERSTORE destination key [key ...] 沿用 SDIFF &amp;&amp; SDIFFSTORE 的範例資料：key1 = {a,b,c,d}key2 = {c}key3 = {a,c,e} 取得 key1 key2 key3 三者的差集 {c} 範例1： SINTER 1234&gt; SINTER key1 key2 key3Output1) &quot;c&quot; 範例2： SDIFFSTORE將回傳值放進新的 key set 裡面 12345&gt; SINTERSTORE new_inter_key key1 key2 key3(integer) 1&gt; SMEMBERS new_inter_key1) &quot;c&quot; SUNION &amp; SUNIONSTORERef: SUNION、Ref: SUNIONSTORE SUNION: 取得所有集合裡的元素; SUNIONSTORE 將所有取得的元素放入新的 key set 語法： 123SUNION key [key ...]SUNIONSTORE destination key [key ...] 沿用 SDIFF &amp;&amp; SDIFFSTORE 的範例資料：key1 = {a,b,c,d}key2 = {c}key3 = {a,c,e} 取得所有 key1, key2, key3 集合: {a,b,c,d,e} 範例: SUNION 12345678&gt; SUNION key1 key2 key3Output:1) &quot;a&quot;2) &quot;b&quot;3) &quot;e&quot;4) &quot;d&quot;5) &quot;c&quot; 範例: SUNIONSTORE 1234567891011&gt; SUNIONSTORE unkey key1 key2 key3(integer) 5&gt; SMEMBERS unkeyOutput:1) &quot;a&quot;2) &quot;b&quot;3) &quot;e&quot;4) &quot;d&quot;5) &quot;c&quot; 總結前述列出了多個常見 Redis SET 的指令，透過範例了解如何變動 SET 裡的資料，進階一點還可以對多個 SETS 之間取差集、聯集等。 下篇來討論一下與 SET 擁有相似特點，但又不同的 Sorted Sets 吧！ Reference An introduction to Redis data types and abstractions","link":"2022/01/08/Database/Redis/%5BRedis%5D%20Redis%20%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%20-%20SET/"},{"title":"[Redis] Redis 資料結構 - Sorted Sets","text":"前言 上篇談到 Redis 的 SET 資料結構，本篇會探討擁有與 SET 相似特性的 Sorted Sets！相比較兩者之間的差異及用途。 什麼是 Sorted Sets？Ref: Sorted SetsSorted Sets 是 Redis 裡其中一種資料結構，類似於 Set 與 Hash 的混合型。 除了擁有 Set 的 唯一(不重複)的特性之外，Sorted Sets 裡的元素是 有序的!Sorted Sets 裡每個 element 都會對應的一個浮點數的值，這個值稱作 score，以 score 的值由低到高進行排序 藉由 Sorted Sets 按順序存放的特性，可以快速地新增、刪除、修改裡面的 element XX: 只更新已經存在的元素，不增加新元素 NX: 與 XX 相反，只增加新元素。不更新已存在的元素。 LT: 只有當新的 score 值 低 於當前 score 時才更新現有元素，仍可增加新元素 GT: 只有當新的 score 值 高 於當前 score 時才更新現有元素，仍可增加新元素 CH: CH 是 changed 的縮寫，用於添加、修改元素 INCR: 用於增加被指定的 element 的 score 注意: GT, LT,NX 三者是互斥的 ZADDZADD 將 element 添加至指定的 key 裡面，預設情況下 ZADD 指定的 key 不存在 Redis 時會自動建一個新的。 使用上指令和 Set 相似，只要把開頭的 S 改成 Z，ZADD 本身也提供一些參數，可根據使用情境在指令裡加入這些參數。 語法： 1ZADD key [ NX | XX] [ GT | LT] [CH] [INCR] score member [ score member ...] 範例：建立一個 students 的 Sorted Sets 12&gt; ZADD students 1 Rob 2 John 3 Smith(integer) 3 透過 ZRANGE 將 students 裡的元素從頭至尾(0,-1)取出來 123456&gt; ZRANGE students 0 -1Output:1) &quot;Rob&quot;2) &quot;John&quot;3) &quot;Smith&quot; 於 ZRANGE 後方加上 WITHSCORES 的參數可以連同 element 對應的 score 一同取出 123456789&gt; ZRANGE students 0 -1 WITHSCORESOutput:1) &quot;Rob&quot;2) &quot;1&quot;3) &quot;John&quot;4) &quot;2&quot;5) &quot;Smith&quot;6) &quot;3&quot; 範例： 加上 CH 參數加上CH 於指定的 key 裡添加新元素，Sorted Set 會根據指定 score 的大小對 element 做排序 123456789101112131415161718&gt; ZADD students CH 0 Alex 2 Ted(integer) 2&gt; ZRANGE students 0 -1 WITHSCORESOutput:1) &quot;Alex&quot;2) &quot;0&quot;3) &quot;Rob&quot;4) &quot;1&quot;5) &quot;John&quot;6) &quot;2&quot;7) &quot;Ted&quot;8) &quot;2&quot;9) &quot;Smith&quot;10) &quot;3&quot;11) &quot;Tom&quot;12) &quot;4&quot; 範例： 加上 INCR 參數將 Rob 的 score 的值加 2 1234567891011121314151617181920&gt; ZADD students INCR 2 Rob&quot;3&quot;&gt; ZRANGE students 0 -1 WITHSCORESOutput:1) &quot;Alex&quot;2) &quot;0&quot;3) &quot;John&quot;4) &quot;2&quot;5) &quot;Ted&quot;6) &quot;2&quot;7) &quot;Rob&quot;8) &quot;3&quot;9) &quot;Smith&quot;10) &quot;3&quot;11) &quot;Tom&quot;12) &quot;4&quot;13) &quot;Tommy&quot;14) &quot;4&quot; 從結果可觀察到，Rob 因為 score 增加至 3，順序變成 Ted (score 為2) 之後(上個範例還在 Ted 之前) ZRANGEZRANGE查詢 sorted set 裡指定範圍的元素，查詢的方式包含: 按 index(索引;或稱排名 - rank)、按 score 、按 字典順序(lexicographical order) 語法： 1ZRANGE key min max [ BYSCORE | BYLEX] [REV] [LIMIT offset count] [WITHSCORES] BYSCORE: 藉由 score 作為指定範圍篩選 elements BYLEX: 按照 字母 範圍篩選，- 表起始字母; + 表尾端字母。 ( 符號表 排除; [ 表 包含 REV: 表顛倒排序，元素改為從最高分到最低分進行排序 LIMIT: 指定偏移的數量 範例： 查詢 score 為於 1~3 的所有 elements於指令裡加上參數 BYSCORE 即可篩選出指定範圍的所有 elements 1234567891011ZRANGE students 1 3 BYSCORE WITHSCORESOutput:1) &quot;John&quot;2) &quot;2&quot;3) &quot;Ted&quot;4) &quot;2&quot;5) &quot;Rob&quot;6) &quot;3&quot;7) &quot;Smith&quot;8) &quot;3&quot; 範例： 以 BYLEX 為條件篩選出所有 elements可用 - 表起始字母; + 表尾端字母篩選 key 裡的元素 1234&gt; ZRANGE students - + BYLEX1) &quot;Alex&quot;2) &quot;John&quot;3) &quot;Ted&quot; 範例： 以 BYLEX 搭配特殊符號篩選 elements前面提到 ( 符號表 排除; [ 表 包含 可以利用特殊符號 ( 搭配 BYLEX 的方式來過濾出指定的 elements。 如：篩選值為 非 Alex 及 Ted 的元素 1234&gt; ZRANGE students (Alex (Ted BYLEXOutput:1) &quot;John&quot; 於指令裡加上 (Alex (Ted BYLEX 的篩選條件，我們就可以過濾掉 Alex, Ted 這兩個元素。 同理，可以用特殊符號 [ 作為納入篩選範圍的條件 如：篩選值為 非 Alex 且包含 Ted 的所有元素 12345&gt; ZRANGE students (Alex [Ted BYLEXOutput:1) &quot;John&quot;2) &quot;Ted&quot; ZREMZREM移除指定的 Sorted Set key 裡一個 or 多個 element 語法： 1ZREM key member [member ...] 範例：移除 Rob 123456789101112131415161718&gt; ZREM students Rob(integer) 1&gt; ZRANGE students 0 -1 WITHSCORESOutput:1) &quot;Alex&quot;2) &quot;0&quot;3) &quot;John&quot;4) &quot;2&quot;5) &quot;Ted&quot;6) &quot;2&quot;7) &quot;Smith&quot;8) &quot;3&quot;9) &quot;Tom&quot;10) &quot;4&quot;11) &quot;Tommy&quot;12) &quot;4&quot; ZSCOREZSCORE 回傳指定 element 對應的 score 語法： 1ZSCORE key member 範例： 1234&gt; ZSCORE students JohnOutput:&quot;2&quot; ZCOUNT &amp; ZLEXCOUNTZCOUNT、ZLEXCOUNT ZCOUNT 根據 score 計算 sorted set key 裡的所有元素數量; ZLEXCOUNT 根據 ZLEXCOUNT 一樣適用前述提到的規則: - 表起始字母; + 表尾端字母篩選 key 裡的元素; ( 符號表 排除; [ 表 包含 語法： 123ZCOUNT key min maxZLEXCOUNT key min max 其中 min, max 這兩個參數表指定的最大和最小值，若想要計算整個 key 裡的所有元素數量則是分別加上: -inf, +inf 範例：計算 students 所有元素數量 12&gt; ZCOUNT students -inf +inf(integer) 6 ZREMRANGEBYLEXZREMRANGEBYLEX 透過 BYLEX 的規則移除指定的 element BYLEX 的規則： 表起始字母; + 表尾端字母篩選 key 裡的元素; ( 符號表 排除; [ 表 包含 語法： 1ZREMRANGEBYLEX key min max 範例：移除從 Alex 至 Ted 的所有元素 123456789&gt; ZRANGE students - + BYLEX1) &quot;Alex&quot;2) &quot;John&quot;3) &quot;Ted&quot;&gt; ZREMRANGEBYLEX students [Alex [Ted(integer) 3&gt; ZRANGE students 0 -1(empty array) ZPOPMAXZPOPMAX 移除並回傳最高 score 的元素 語法： 1ZPOPMAX key [count] count: 移除的數量，大於 1 的話會由 score 最高至次高的element 開始移除 範例： 未指定數量 1234567891011121314151617181920&gt; ZRANGE students 0 -1 WITHSCORES 1) &quot;Alex&quot; 2) &quot;0&quot; 3) &quot;John&quot; 4) &quot;2&quot; 5) &quot;Ted&quot; 6) &quot;2&quot; 7) &quot;Smith&quot; 8) &quot;3&quot; 9) &quot;Tom&quot;10) &quot;4&quot;11) &quot;Tommy&quot;12) &quot;4&quot;&gt; ZPOPMAX studentsOutput:1) &quot;Tommy&quot;2) &quot;4&quot; 範例： 指定數量 12345&gt; ZPOPMAX students 21) &quot;Tom&quot;2) &quot;4&quot;3) &quot;Smith&quot;4) &quot;3&quot; 常見的案例 線上遊戲的積分排行榜:善用 ZADD 指令可以在每次玩家提交遊戲積分時，於 Redis 內更新該名玩家的積分，依積分高低用 ZRANGE 做排序，列出即時積分排名。 商城的熱銷排行榜 總結看完了本篇開頭對 Sorted Set 的解釋，以及透過範例實際操作更能了解與 Set 之間的差異，藉由 Sorted Set 的有序性，在實際應用上提供更多的用途！ Reference An introduction to Redis data types and abstractions","link":"2022/01/09/Database/Redis/%5BRedis%5D%20Redis%20%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%20-%20Sorted%20Sets/"},{"title":"[Vue.js] 模版語法","text":"前言筆記一下Vue的模板語法 模板語法Mustache: { {variable} } 只能用於單行語句 e.g. if-else，且雙大括號會將數據解析為一般文字 由於Hexo解析”雙大括號”會發生錯誤，所以文章涉及”雙大括號”都會以{ {} }表示 指令監聽DOM事件，並改變 data內的資料，若傳入多個參數時，事件名稱需加上 $ 陣列更新append、unshift，注意陣列是返回原陣列，或是新陣列。 若改變原陣列，可使頁面更新。 若不改變原陣列，建一新陣列，則無法使頁面刷新。 methods:表示調用函數，呼叫函式需添加 “()” computed:計算屬性，亦可呼叫函數，但不須添加 “()” watch:計算屬性 vs 方法屬性的相關內容不持續變動時，建議使用computed，只在相關響應式依賴發生改變時它們才會重新求值，只要屬性的相關內容還沒有發生改變，多次訪問計算屬性會立即返回之前的計算結果，而不必再次執行函數。 表單輸入綁定v-model 進行雙向數據綁定，輸入內容的同時，同步將數據更新到頁面上，重要修飾符:.lazy.number.trim 資料渲染 v-text、v-html、{ {} }透過模板語法直接將指令寫在html中 { {} } 使用{}將掛載的物件內容顯示出來123&lt;div id=&quot;app&quot;&gt; { { message } } &lt;/div&gt; 123456var app = new Vue({ el: '#app', data: { message: 'Hello Vue!' }}) v-text更新元素的textContent123&lt;div id=&quot;app&quot;&gt; &lt;p v-text=&quot;title&quot;&gt;&lt;/p&gt;&lt;/div&gt; 123456var app = new Vue({ el: '#app', data: { title: &quot;&lt;h1&gt;模板指令&lt;/h1&gt;&quot;, }})// &lt;h1&gt;模板指令&lt;/h1&gt; v-html更新元素的innerHTML文字內容會套用html標籤的特性 123&lt;div id=&quot;app&quot;&gt; &lt;p v-text=&quot;title&quot;&gt;&lt;/p&gt;&lt;/div&gt; 123456var app = new Vue({ el: '#app', data: { title: &quot;&lt;h1&gt;模板指令&lt;/h1&gt;&quot;, }})// 模板指令 控制顯示、隱藏 v-if 、 v-show差別:若不顯示的話v-if 則不進行渲染v-show 元素始終會被渲染並保留在DOM中。v-show只是簡單地切換元素的CSS屬性display。 123&lt;p class=&quot;show&quot; v-if=&quot;isShow&quot;&gt;模組的顯示、隱藏&lt;/p&gt;&lt;p class=&quot;show&quot; v-show=&quot;isShow&quot;&gt;模組的顯示、隱藏&lt;/p&gt; 123456var app = new Vue({ el: '#app', data: { isShow: false, }}) 渲染循環列表 v-for似for.. in 的JS方法，可用於陣列或物件，良好的習慣是添加key屬性，key的作用主要是為了高效的更新虛擬DOM，因為是根據key值去判斷某個值是否修改,如果修改,則重新渲染這一項,否則重複使用之前的元素; 12345&lt;ul&gt; &lt;li v-for=&quot;item in arr&quot;&gt; { { item } }&lt;!--調用item--&gt; &lt;/li&gt;&lt;/ul&gt; 123456var app = new Vue({ el: '#app', data: { arr: [&quot;1、html&quot;, &quot;2、CSS&quot;, &quot;3、JavaScript&quot;], }}) 事件綁定v-on事件綁定 v-on:event，搭配method方法，event 表示點擊後所觸發的事件可用簡寫: @ 代替 v-on: 123&lt;div class=&quot;show&quot; v-on:click=&quot;speak&quot;&gt;&lt;/div&gt;&lt;!-- 與上方相同 --&gt;&lt;div class=&quot;show&quot; @click=&quot;speak&quot;&gt;&lt;/div&gt; 12345678var app = new Vue({ el: '#app', methods: { // 方法 speak: function() { alert(&quot;hello&quot;); } }}) 屬性綁定v-bindv-bind: 綁定綁定的目標為標籤屬性，為一物件，往後只需要修改變數的值即可，&lt;標籤 v-bind:屬性名=&quot;要绑定Vue物件的data內的屬性名&quot;&gt;&lt;/標籤&gt;由於v-bind使用非常頻繁，所以Vue提供了簡單的寫法，簡寫: : 代替v-bind: 12345&lt;img src=&quot;angry_25.jpg&quot; v-bind:src=&quot;imgName&quot; alt=&quot;&quot; style=&quot;width: 200px; height: 200px;&quot;/&gt;&lt;!--兩者相同--&gt;&lt;img src=&quot;angry_25.jpg&quot; :src=&quot;imgName&quot; alt=&quot;&quot; style=&quot;width: 200px; height: 200px;&quot;/&gt; 123456var app = new Vue({ el: '#app', data: { imgName: &quot;angry_18.jpg&quot;, // 圖片名稱 }}) 樣式綁定v-bindVue專門加強了class和style的屬性的綁定。可以有複雜的物件綁定、陣列綁定樣式。 123456&lt;div class=&quot;view&quot; v-bind:class=&quot;{active:isActive}&quot;&gt;{ {message1} } &lt;/div&gt; &lt;!-- &lt;div class=&quot;view&quot;&gt; 樣式綁定 &lt;/div&gt; --&gt; 123456789// isActive為真， 即 添加class名稱給該div// isActive為假，不 添加class名稱給該divvar app = new Vue({ el: '#app', data: { message1: '樣式綁定', isActive:false }}) 雙向數據綁定 v-model上面的例子基本都是單向的js物件向HTML進行綁定，Vue提供了一個新的指令：v-model進行雙向數據的綁定。 1234&lt;div id=&quot;app&quot;&gt; &lt;input type=&quot;text&quot; v-model=&quot;title&quot;&gt; &lt;p&gt;{ {title} }&lt;/p&gt; &lt;/div&gt; 1234567// 雙向數據綁定const app = new Vue({ el: &quot;#app&quot;, data: { title: &quot;Vue入門&quot; }}); 原理:輸入框input(v-model)內發生改變，會同時去改變 title屬性 Vue組件中重要選項data數據代表vue物件的數據，創建的Vue物件中的data屬性就是用來綁定數據到HTML的，Vue框架會自動監視data裡面的數據變化，自動更新數據到HTML標籤上去。 123&lt;div id=&quot;app&quot;&gt; { { message } }&lt;/div&gt; 123456var app = new Vue({ el: '#app', data: { // data數據選項 message: 'Hello Vue!' } }) methods方法代表vue物件的方法，不過要注意的是這個方法自動綁定this 12345&lt;div id=&quot;app&quot;&gt; &lt;div class=&quot;test&quot; @click=&quot;run&quot;&gt;&lt;/div&gt; &lt;div class=&quot;test&quot; @click=&quot;speak&quot;&gt;&lt;/div&gt;&lt;/div&gt; 123456789101112131415var app = new Vue({ el: '#app', methods: { // 方法選項 run: function() { alert(&quot;button1&quot;); }, speak: function() { alert(&quot;button2&quot;); }, add: function() { // 訪問data(數據選項)中的內容 this.i++; console.log(this.i); } }) computed計算屬性計算屬性，屬性可以是一個方法在計算屬性中定義的函數裡面可以直接使用this。注意:採用return回傳值到{ {expression} }中 12345&lt;div id=&quot;app&quot;&gt; &lt;div class=&quot;test&quot; @click=&quot;add&quot;&gt; { { strFn } } &lt;/div&gt;&lt;/div&gt; 12345678910111213computed: { // 計算屬性(方法) strFn: function() { if (this.i &lt;= 5) { return &quot;多點幾次&quot;; } else if (this.i &lt;= 10) { return &quot;再多點幾次&quot;; } else if (this.i &lt;= 15) { return &quot;再比之前多點幾次&quot;; } else if (this.i &lt;= 20) { return &quot;目前點很多次&quot;; }} watch監聽選項設定物件的監聽方法，用於監聽數據變化，針對data內的屬性進行監聽，不過不適合用於複雜的計算邏輯。 12345&lt;div id=&quot;app&quot;&gt; &lt;div class=&quot;test&quot; @click=&quot;add&quot;&gt; { { strFn } } &lt;/div&gt;&lt;/div&gt; 123456789101112131415161718const app = new Vue({ el: &quot;#app&quot;, data: { i:0 },methods: { // 方法選項 add: function() { // 訪問data(數據選項)中的內容 this.i++; console.log(this.i); }, watch: { // 監聽屬性 // 針對data內的屬性進行監聽 // 傳入兩個參數，分別為新的值和舊的值 i: function(newValue, oldValue) { console.log(newValue, oldValue); } }});","link":"2019/07/16/Vue/Vue_templateSyntax/"},{"title":"[Redis] Redis 資料結構 - String","text":"前言 Redis 是熱門且開源的資料庫，以記憶體為主(in-memory)進行資料存取，並以鍵值 (key-value) 的形式存放資料庫內。 由於資料是基於記憶體進行讀寫，記憶體讀取的速度較一般硬碟來得快！Redis 這項優勢被廣泛地運用在大型系統裡做資料快取，加快整體系統效能，不僅有助於提高系統回應的速度，同時能減少關聯式資料庫的工作量(前面 Redis 可以應付使用者送來的請求，就不需要再到後方主資料庫讀取資料)。 Redis 本身提供多種資料結構，如: Strings, List, Set, Hash, Sorted Set 等。 常見服務應用: 快取：借助記憶體高效能讀取的快取方式，減少硬碟 I/O 的延遲時間，在大型的分散式系統裡幾乎是後端快取的首選。 流量 &amp; 速率限制：有些搶票系統為避免短時間流量暴增，會在系統裡面採用 Redis 做統計，讓網站或線上服務可以視流量狀況作自動化的調整。 排行榜功能：常見於電商、遊戲裡的排行榜活動，藉由 Redis 高效讀取資料的優勢達成近乎即時更新資料，實現即時排名的功能，後續有篇關於 Sorted Set 的文章會討論到！ 了解 Redis 常見的用途後，接著進入本篇討論重點: Redis 資料結構 - Strings 什麼是 Strings？STRING Strings 是 Redis 最基礎的儲存型態，一個鍵(key)對一個值(value)，可存放任何形式的資料 e.g. JPEG 圖片或已序列化的物件等，官方提示最大可以儲存 512 MB 的資料量 接著來看常見的幾個 Redis 支援對 String 的操作吧！ SETSET STRING SET 指令後方的必填項目分別是 key 名稱、key 的值，成功新增時會回傳 OK，規則如下： 1SET key value [EX seconds|PX milliseconds|EXAT unix-time-seconds|PXAT unix-time-milliseconds|KEEPTTL] [NX|XX] [GET] 範例 - 新增一個 key &amp; value:新增名為 test 的 key 且值為 test key 12// set 指令新增set test &quot;test key&quot; 取得 key 對應的值: get &lt;key_name&gt; 12345// 取得 test key 的值get test// 回傳&quot;test key&quot; 若 set 指令指定的 key 已存在，則會 覆寫 掉原本的 key 值 Options for SetSet 指令後面可以添加額外的參數達成不同的需求，擷取幾個常用的: EX(in seconds): 設置 key 的存續時間(TTL)，到期後自動從 redis 刪除(回傳 nil)，單位以 秒 計算。常見用法： 儲存 user 登入的 session NX: 指定的 key 只有原本不存在 redis 時才可設置，若 key 已存在則回傳 nil XX: 指定的 key 只有已存在 redis 時才可設置，若 key 不存在則回傳 nil Sample查看當前擁有的 key： 1keys * Output: 123451) &quot;test2&quot;2) &quot;jsondata&quot;3) &quot;test&quot;4) &quot;test1&quot;5) &quot;test3&quot; 接著於 Set 指令後方加上個別參數做比較。 範例：設置新 key 名為 test4，且值為 4 EX:設置 exkey 並給定 TTL 為 5 秒1set exkey &quot;test ex key&quot; EX 5 5 秒之後自動從 Redis 刪除 NX:12345sample 1:set test1 4 nxsample 2:set test4 4 nx 回傳結果為 (nil) 表不符合指令裡的 XX 參數條件，反之則成立 XX:12345sample 1:set test4 4 xxsample 2:set test1 4 xx 回傳結果為 (nil) 表不符合指令裡的 XX 參數條件，反之則成立 APPEND如果 key 已經存在並且是字串(string)，想在該 key 的值後面添加新的字串可用 APPEND 指令完成，該指令的回傳值為: 更新後的字串總長度 範例:設置一個名為 greeting 的 key，其當前值為 &quot;Hello&quot; 123set greeting Helloget greeting 透過 APPEND 指令添加新的值 &quot; World&quot; 到 greeting 裡 123APPEND greeting &quot; World&quot;get greeting Output: 1&quot;Hello World&quot; 回傳值的字串總長度為: 11 INCR &amp;&amp; INCRBY若想將存於 key 裡的數字做加法，可透過 INCR 或是 INCRBY 指令完成。 Ref: INCR、Ref: INCRBY INCR 與 INCRBY 兩者差異在於： INCR 每次增加的值為 1 INCRBY 可指定增加的值 若是 key 原本不存在於 Redis 而執行 INCR 與 INCRBY 指令， 指令執行前，Redis 會生成 key 之後給定預設值為 0，再執行 INCR 與 INCRBY 指令。 INCR 語法如下: 1incr &lt;key&gt; 下方範例會看到原不存於 Redis 的 testkey，執行 INCR 指令後得到的結果為 1 這是因為 Redis 先產生 testkey 並給該 key 的值為 0，接著再進行INCR 指令對 testkey +1 。 INCRBY 也是類似的概念，語法如下: 1incrby &lt;key&gt; &lt;increment&gt; 其中 &lt;increment&gt; 為想要增加的值 範例： 將名為 score 的 key 值加 3 原 score 值為 2，執行 incrby score 3 指令後，得到的結果為 (integer) 5 注意:由於 Redis 沒有專用的數值型別，所以存在 Redis 裡的字串是以 10 為底的 64 位元形式做處理。 Note: this is a string operation because Redis does not have a dedicated integer type. The string stored at the key is interpreted as a base-10 64 bit signed integer to execute the operation. DECR &amp;&amp; DECRBYRef: DECR、Ref: DECRBY 與 INCR &amp;&amp; INCRBY 相似，運算方式由加法改為減法，使用方法相同。 MSETRef: MSET 前述 SET 指令皆是針對單一個 key 做設置，若想要一次設置多個 key，可用 MSET 來達成。 語法： 1MSET key value [ key value ...] 範例：同時建立 key1, key2 兩個 key 並給值 “Hello”, “World” 1MSET key1 &quot;Hello&quot; key2 &quot;World&quot; 透過 MGET 同時取得 key1, key2 兩個 key 的值 12345&gt; MGET key1 key2&gt; Output1) &quot;Hello&quot;2) &quot;World&quot; 注意:MSET 具有關連式資料庫的 原子性(Atomicity)，其中一個 key 改動失敗時整個操作就會宣告失敗，故同個操作裡面涉及多個 key 改動時，不會發生只有一部分的 key 變動的情形。 Note: MSET is atomic, so all given keys are set at once. It is not possible for clients to see that some of the keys were updated while others are unchanged. MSETNXRef: MSETNX MSETNX 是 MSET 與前述 NX 的結合，表 MSETNX 指定的 key 只能是原本不存在 Redis 裡的情況下才能建立。 若 MSETNX 指定的 key 皆不存在 Redis 時，回傳值為 (integer) 1，反之，只要有一個以上指定的 key 已經存於 Redis 時，回傳值為 (integer) 0 語法： 1MSETNX key value [ key value ...] 範例： 1MSETNX key3 &quot;k3&quot; key4 &quot;k4&quot; key3, key4 原不存在 Redis 裡，執行 MSETNX 後回傳結果為 (integer) 1，若再重複執行一次則會得到 (integer) 0 的結果 若嘗試用 key5 替代 key3 同時保留 key4 執行 MSETNX，由於 key4 先前已存在 Redis，故回傳結果一樣是 (integer) 0 用 GET 檢查 key5 可發現 key5 沒有被寫入 Redis 裡面，證明剛剛提到 MSET 具有原子性 GETRANGERef: GETRANGE從 key 裡提取某段字串，可用 GETRANGE 來完成。 語法： 1GETRANGE key &lt;start&gt; &lt;end&gt; &lt;start&gt; 起始位置(從0開始) &lt;end&gt; 終點位置(-1 表字串的末端) 範例：提取 range key 裡所有的值 123SET range helloGETRANGE range 0 -1 其他範例: 123456789101112131415&gt; GETRANGE range 0 3&gt; Output&gt; &quot;hell&quot;&gt; GETRANGE range -3 -1&gt; Output&gt; &quot;llo&quot;&gt; GETRANGE range 0 1000&gt; Output&gt; &quot;hell0&quot; SETEXRef: SETEX 用於設置具有時效性的 key 語法: 1SETEX key seconds value 設置 exkey 並給定 TTL 為 5 秒 1setex exkey 5 &quot;test ex key&quot; 5 秒之後自動從 Redis 刪除 SETRANGERef: SETRANGE 用於覆寫被指定的 key 內容，該指令會從指定的偏移量開始，覆寫整個值 語法： 1SETRANGE key &lt;offset&gt; &lt;value&gt; &lt;offset&gt; 表偏移量 範例：設置 k1 的值為 “hello world!” 1SET k1 &quot;hello world!&quot; 目標是將後面的 world 替換成 Redis，故於偏移量設定為 6 (w 開頭的位置) 1setrange k1 6 Redis Output: 1&quot;hello Redis!&quot; STRLENRef: STRLEN 計算存於 key 裡的值的長度，回傳結果為該字串的總長度 語法： 1STRLEN key 總結前面探討了幾個 Redis 裡常見對 String 的操作，以及不同情境下可使用的方式，下篇將討論 Redis 資料結構 - List Reference An introduction to Redis data types and abstractions","link":"2022/01/05/Database/Redis/%5BRedis%5D%20Redis%20%E8%B3%87%E6%96%99%E9%A1%9E%E5%9E%8B%20-%20String/"},{"title":"[Database] Microsoft SQL Server 操作","text":"如何連接至別人的SQLServer 確定自己的Server是否有新增sysuser(SQL Server的安全性-&gt;登入-&gt;創建，設定密碼、勾選sysadmin)。 知道對方IP Address。 查看SQLServer的portC: -&gt; window -&gt; system32 -&gt; drivers -&gt; etc -&gt; service，將service這個檔案貼到記事本，查看MS SQL Server的port number。 設定port 到電腦的防火牆進階設定 新增輸入規則 選連接埠 勾選TCP協定，指定port no. 1443 自動流水號設定:點選該資料欄位，將下方的表格往上拉(資料行屬性)，點選識別規格，狀態改為”是”，起始值(識別值種子)設100000，增量數值為9 新增資料1234insert into IDTest(ch)values('Test')select @@IDENTITY 線上叢書滑鼠點在兩個@@之間後按下F1，可開啟線上叢書。 索引:查詢指令功能 到上方工具列的 “工具” 下拉點選 “選項” -&gt; Designer -&gt;取消勾選”防止儲存資料表重建的變更” 公式運算練習:計算回報日(resDate) = 詢價日(reqDate) + 3天 點ReqDate欄位，至下方表格找預設欄位輸入 (GetDate()) 點ResDate欄位，設定 (ReqDate + 3) 12345678910// 新增insert into DTest(ReqDate, ch)values('2019-5-19 14:00:00', 'Alex')select * from DTest// 修改Update DTestSet ReqDate= ('2019-5-19 16:00:00')Where ch = 'Alex'select * from DTest Note以天為單位使用”整數”，時分秒以”小數點”表示，如15分鐘: 15./24*60 Join合併表格def:用於反正規化，將原先參照的table順著Reference合併為一個大的table，(小表格併為大表格)。 問題：哪一個客戶市交易量最大的客戶?需要的表格有訂單、訂單明細、客戶 說明將Order table叫出來，並將Order Details與Customers合併至Order 步驟一：1select * From Orders as O 說明:O 為 as所命名的別名，可簡化物件名稱，圖中O為Order的別名。as可以省略 步驟二:123select * From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderID //合併條件 說明 :將orders及order details 兩張表作合併(join)，分別命名為O及OD 步驟三:12345select * From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerID //合併條件 說明:on作為合併條件，圖中是將O的OrderId與OD的OrderId做合併條件 步驟四:12345select C.CompanyName, UnitPrice*Quantity*(1-Discount) From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerID 說明:將Customer這張表納入作合併，UnitPriceQuantity(1-Discount)為總和運算式。 步驟五:12345select C.CompanyName, UnitPrice*Quantity*(1-Discount) as LineTotal From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerID 說明:查詢合併後的資料表，欄位名稱為Companyname，以及經過運算式所得的值，命名為LineTotal。 步驟六:12345select O.OrderID,C.CompanyName, UnitPrice*Quantity*(1-Discount) as LineTotal From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerID 說明:查詢 O 的OrderID、Companyname、LineTotal (注意: OrderID需指定為哪張表的OrderID，若無指定會報錯誤訊息: 模稜兩可 ) 步驟七:1234567select O.OrderID,C.CompanyName, UnitPrice*Quantity*(1-Discount) as LineTotal From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerIDGroup by CompanyName 說明:錯誤原因：OrderID 非Groupby條件或總合運算所以必須拿掉 123456select C.CompanyName, SUM( UnitPrice*Quantity*(1-Discount) ) as Total From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerIDGroup by CompanyName 說明:刪除OrderID即可正常執行，Group by 為群聚條件，依指定條件合併，將多筆record合併成單一record 步驟八:排序(由大到小)1234567select C.CompanyName, SUM( UnitPrice*Quantity*(1-Discount) ) as Total From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerIDGroup by CompanyNameOrder by Total Desc //反序 說明:Order by作為排序條件，Desc為反排序 步驟九:挑出前幾筆資料(在select後面加上”Top 數字”)1234567select Top 1 C.CompanyName, SUM( UnitPrice*Quantity*(1-Discount) ) as Total From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerIDGroup by CompanyNameOrder by Total Desc 顯示第一筆資料 顯示前五筆資料 新增Viewdef:檢視: 將常用的select查詢建成虛擬資料來源，以方便查詢使用，實際上不存放資料，只存放select，使用時才查詢資料。 說明:將以上複雜的查詢建立成一個View(方便以後快速查詢)12345678910create view dbo.TopCustomersasselect C.CompanyName, SUM( UnitPrice*Quantity*(1-Discount) ) as Total From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerIDGroup by CompanyNameselect * From TopCustomers 說明:Create view 建立view，alter view修改view。 1select Top 10 * From TopCustomers //從View中挑選前10筆資料 建立有排序(大到小)且取前10筆資料123456789create view dbo.Top10Customersasselect Top 10 C.CompanyName, SUM( UnitPrice*Quantity*(1-Discount) ) as Total From Orders as Oinner join [Order Details] ODOn O.OrderID = OD.OrderIDinner join [Customers] COn C.CustomerID = O.CustomerIDGroup by CompanyNameOrder by Total Desc 1select * from Top10Customers clustered index 查詢: WHERE比對完整比對12select * from ProductsWHERE ProductName = 'Ipoh Coffee' 特殊情況若資料有單引號，例如：Bon app’在單引號裡，則用雙引號表示 -&gt; ‘ Bon app’’ ‘ 模糊比對1234567891011121314select * from ProductsWHERE ProductName like 'c%' //字串開頭為cselect * from ProductsWHERE ProductName like 'c_a%' //第一個字元為c，第二個字元為任意，第三個字元為aselect * from ProductsWHERE ProductName like '[A-F]%' //開頭為A或B或C或D或E或F字元的字串select * from ProductsWHERE ProductName like '[^A-F]%' //開頭不為A或B或C或D或E或F字元的字串select * from ProductsWHERE ProductName like '[^A-F, ^M-Q]%' //開頭為G或H或I或J或K或L字元的字串 like 關鍵字 % : 不管任何字 _ : 忽略任一字元 []: 該字元為指定的區間 [^ ]: 該字元不為指定的區間 Q：哪些客戶沒有消費?說明：選出沒有在Orders裡出現的CustomerID1234select * from Customerswhere CustomerID Not In( select Distinct CustomerID from Orders)//Distinct-&gt;不重複 Q：哪些產品沒有售出?說明：選出沒有在Orders裡出現的ProductID123select * from Productswhere ProductID Not In( select Distinct ProductID from Orders) Q：哪些產品未曾售出?(課堂小考)12345select * from ProductsWHERE ProductID Not In (select Distinct ProductID From [Order Details]) 複製原有table 至新的table123456789101112// 建立相同的schema&amp;資料的tableselect * into product2 from Productsselect * from product2// 建立一個相同schema但資料為空的tableselect * into product3 from Productswhere 1 = 2select * from product3// 複製products內的資料到product3這個空的tableinsert into product3select * from Products Inner Join：合併條件為兩邊都有的欄位123select E.EmployeeID, O.EmployeeID from Employees Einner join [orders] OOn E.EmployeeID = O.EmployeeID (Right/Left/Full) Outer Join：以(右邊/左邊/一邊)的Data Object為基礎全部顯示，(右邊/左邊/一邊)有而另一邊沒有的顯示為Null。 123select E.EmployeeID, O.EmployeeID from Employees ELeft Outer join [orders] OOn E.EmployeeID = O.EmployeeID Union：將兩個結構相容(欄位數相同，資料格式相容)的資料集疊加，欄位數不動，資料筆數增加。 範例一：A+B資料123select * from Products Where ProductID &lt; 10 //-&gt;A資料union //合併select * from Products Where ProductID &gt;30 AND ProductID &lt; 50 //-&gt;B資料 範例二：B+A資料12345select * from Products Where ProductID &gt;30 AND ProductID &lt; 50 //-&gt;B資料unionselect * from Products Where ProductID &lt; 10 //-&gt;A資料 範例三：僅取 ProductID [ID], ProductName [Name]，兩個欄位合併。合併後的欄位名稱為：ID、Name123456select ProductID [ID], ProductName [Name] from Products Where ProductID &lt; 10unionselect ProductID [No.], ProductName [User] from Products Where ProductID &gt;30 AND ProductID &lt; 50 合併後的欄位名稱為：NO.、User12345select ProductID [No.], ProductName [User] from Products Where ProductID &gt;30 AND ProductID &lt; 50unionselect ProductID [ID], ProductName [Name] from Products Where ProductID &lt; 10 Cross Join將Left資料物件的每一筆record都和Right資料物件的每一筆record做合併 =&gt;欄位數相加，資料數相乘。 操作分別建立 Name1、 Name2 、Name3 三個table，在三個table中個別新增10筆資料。 Name1| 欄位名稱 | 資料結構 || ——– | ——– || 姓 | NVarChar(2) | Name2| 欄位名稱 | 資料結構 || ——– | ——– || 名1 | NChar(1)|Name3| 欄位名稱 | 資料結構 || ——– | ——– || 名2 | NChar(1)| 123456select [姓]+ [名1] + [名2] [姓名] from Name1 cross join Name2 cross join Name3 //Cross Join後總共會產生1000筆資料。 以XML作為格式作查詢1select * from Customers for XML auto Stored Procedures預存程序：儲存在DBMS端的程式碼，方便重複執行一些動作，程式碼也是SQL語法寫成。位於”可程式性”資料夾之下。 1234select * from Ordersexec [dbo].[Sales by Year] ' 1996-07-04 00:00:00.000', ' 1996-11-26 00:00:00.000' //exec -&gt; 執行//[dbo].[Sales by Year] -&gt; 預存程式的名稱","link":"2019/07/14/Database/SQL%20Server/Database(%E6%93%8D%E4%BD%9C)/"},{"title":"[Kubernetes] Kubernetes 基礎(三) Pod Controller - ReplicaSet","text":"前言上篇文章 - [Kubernetes] Kubernetes 基礎(二) Pod 操作 討論如何透過 kubectl 指令對 K8s 做一系列的操作，本篇主要記錄 Pod Controller 中的 ReplicaSet 什麼是 ReplicaSet？上篇文章有提到 Pod 是 K8s 的最小運算單元，若今有負載平衡的需求時，是無法只單靠 Pod 來達成的，因為一個 Pod 即一個應用程式，只會運行一份(本身無複製能力)。 某些情況下會需要可以運行多份應用程式，做負載平衡、分散流量，而 ReplicaSet 可以幫助我們達成這件事。 ReplicaSet 幾項重點： 副本的概念、管理相同的 Pod 確保可在任何時間點 Pod 可以保有指定數量的副本 -&gt; 會事先在 ReplicaSet 裡定義好數量，超過定義好的數量就砍掉多的，反之則補回來。 確保 Pod 是可用的、可存取的 Pod 和 ReplicaSet 是不同的資源，透過 selector 將兩者綁一起 在實作之前，我們可先透過 kubectl api-resources 指令列出所有支援的 API 資源，以及該項資源的縮寫，後續針對不同資源操作時，可以用縮寫做替換。 由於本文重點在討論 ReplicaSet 這項 API 資源，可搭配 grep 只擷取 ReplicaSet 相關資訊 1kubectl api-resources | grep replicasets output 12AME SHORTNAMES APIVERSION NAMESPACED KINDreplicasets rs apps/v1 true ReplicaSet 實作列出 ReplicaSet1kubectl get rs &lt;ReplicaSet Name&gt; 範例replicasets.yml 12345678910111213141516171819apiVersion: apps/v1kind: ReplicaSetmetadata: # 定義 ReplicaSet 名稱 name: myapp-rs-demo labels: app: myapp-rs-demospec: # 描述 ReplicaSet 規格 replicas: 3 selector: # 指定目標 Pod matchLabels: app: myapp-nginx-demo template: # 定義 Pod 的 Template metadata: labels: # 定義 Pod 名稱 app: myapp-nginx-demo spec: containers: # 定義 Pod 裡的 container 資訊 - name: myapp-rs-demo image: nginx 需注意幾個上方範例中的欄位: seletor: ReplicaSet 透過 seletor 裡定義的 matchLabels 與 Pod 的 labels 對應。上方範例是對應到 app: myapp-nginx-demo 這個 Label 第一層的 spec: 用於描述 ReplicaSet 第二層的 spec: 用於描述 Pod 裡的 Container template: 用於定義 Pod 將上述範例進行 apply 1kubectl apply -f replicasets.yml get 查看剛剛建立的 ReplicaSet 1kubectl get rs myapp-rs-demo output 12NAME DESIRED CURRENT READY AGEmyapp-rs-demo 3 3 3 2m56s 輸出結果裡面，DESIRED 表期望跑多少個 Ready 的 Pod; CURRENT 表目前跑多少個 Pod; READY 表目前多少個 Pod 是處於 Ready 狀態。 成功建立 ReplicaSet 後看一下 Pod 資訊看是不是有三個 Pod 1kubectl get pods -o wide 試著砍掉其中一個 Pod 1kubectl delete pod &lt;Pod Name&gt; 過一段時間後再下 get 指令會發現 ReplicaSet 已生出新的 Pod，並把數量控制在 3 個。 若把 get 改為 describe 列出 Pod 細部資訊： 1234567891011Labels: app=myapp-nginx-demoAnnotations: kubernetes.io/psp: eks.privilegedStatus: RunningIP: 10.132.110.154IPs: IP: 10.132.110.154ｘ: ReplicaSet/myapp-rs-demoContainers: myapp-rs-demo: . . 由於 Pod 是由 ReplicaSet 去管理，故有一個名為 Controlled By 的欄位用來記錄哪個 ReplicaSet 來管理資源，透過 yaml 的方式辨識該 Pod 是單獨的 Pod 還是上頭(範例是ReplicaSet)有其他元件控制。 概念圖上圖解釋 ReplicaSet 的概念與流程，包含 Pod 數量，以及 seletor 對應的 Pod label 一般在定義 ReplicaSet 的時候，Pod 的 label 與 seletor 的 label 都會設定一樣 總結最後簡短定義 ReplicaSet: 確保相同的 Pod 在任意時間內皆會有符合目標的 Pod 數量於 Cluster 中運行 相較於後面會談論到的 Daemonset ，Daemonset 是確保節點數量要一致且只能有一個 本篇文章記錄了如何透過 ReplicaSet 來建立多個 Pod，由 ReplicaSet 幫我們控制好 Pod 數量。 下一篇會針對 Pod 底下的 Controller - Deployment 做討論。 Reference Introduction to Kubernetes ReplicaSet Kubernetes Documentation - ReplicaSet","link":"2021/09/14/DevOps/K8s/%5BKubernetes%5D%20Kubernetes%20%E5%9F%BA%E7%A4%8E(%E4%B8%89)%20Pod%20Controller%20-%20ReplicaSet/"},{"title":"[Database] Microsoft SQL Server 概念整理","text":"前言這是本學期在課堂紹上學習的關聯式資料庫，他是微軟開發的一套資料庫管理系統。以下簡稱:MS SQL Server；資料庫簡稱DBMS SQL Server主要分兩種DB System databaseSQL Server 運作所需的DB，隨系統安裝時自動建立。底下有多個子類別: masterSQL Server的核心DB，存放所有user帳號&amp;密碼、紀錄所有DB實體存放路徑。 msdb負責系統自動化管理所需資訊，如: 工作排程(job)、警示(alert)等。 model使用者資料庫的範本，DBA(資料庫管理師)建DB時，系統會先複製此DB再做調整，用於設定DB初始狀態。 tempdbSQL Server運作時，做運算或存放的DB，每次啟動時都會重新建立。 User database由DBA(資料庫管理師)建立，存放user資料。 補充幾個名詞:DBA:資料庫管理師，在SQL Server中稱作System Administrator(SA)，在任何DB中都是DBO(資料庫擁有者)。 DBO(Database Owner):資料庫擁有者，擁有資料庫的最高權限。 SQL Server Profiler用於監看SQL Server所收到的指令，須具備SA(System Administrator)權限。 SQL 語言主要分三大類: DDL、DCL、DMLDDL(Data Definition Language): 資料定義語言用於管理容器，為DBA操作介面，語法分三類: CREATE 建立 ALTER 調整 DROP 摧毀 DCL(Data Control Language): 資料控制語言用於管理權限，為DBA操作介面，語法分三類: GRANT 授權 DENY 禁止 REVOKE 中立 DML(Data Manipulation Language): 資料操作語言用於管理權限，是DB程式設計師操作DB時使用，語法分四類: Insert 新增 Delete 刪除 Update 修改 Select 查詢 SQL Server Data Type在進入SQL Server 處理 data type的方式之前，先簡單了解一下字元碼。 ASCII為美國標準字源碼，主要用於顯示現代英語和其他西歐語言。 一個字元 = 1byte -&gt; 處理一個英文字或數字 兩個字元處理一個中文字 Big 5處理繁體中文 Unicode統一字元，又稱”標準萬國碼” 一個字元 = 2byte - &gt; 中文、英文字或數字皆可處理 它可以使電腦得以呈現世界上數十種文字的系統 概略了解字元編碼後就正式進入SQL Server的data type，在文字處理上，使用ASCII、Unicode作範例: ASCII處理 char() : 用於處理固定長度的字，若宣告的空間未用完會填入空白-&gt; 節省時間 varchar(): 用於處理變動長度的字，若宣告的空間未用完則不會將剩餘空間填入空白 text : 處理長文字，可放入2G大小的字元。 Unicode處理N表Unicode處理 Nchar(): 用於處理固定長度的字 Nvarchar(): 用於處理變動長度的字 Ntext:處理長文字 有些比較特殊的中字無法使用ASCII(Big5)處理，會顯示”?”。 補充UTF-8一種針對Unicode的可變長度字元編碼，用來表示Unicode標準中的任何字元其編碼中的第一個位元組仍與ASCII相容，使得原來處理ASCII字元的軟體無需或只作少部份修改後，便可繼續使用。 數字處理數字資料型態主要分兩種: 整數、實數 整數以int表示其資料型態。 實數可帶有小數點，主要分三類應用: 科學記號: 用於表示極大的數，以指數的方式儲存，以float表示其資料型態。 精確數字: 指定所需的整數及小數精確位數，以decimal(t,n)表示其資料型態，t表全部有幾位精確數字，n表多少位小數。 錢: 錢這個種類比較特別，在真實世界中不會有人使用大於4位小數的金錢單位，所以在數字處理上獨立出一個錢的種類，money表示其資料型態。 時間、日期處理 DateTime: 儲存資料型態為日期&amp;時間 Date: 儲存資料型態為日期 Time: 儲存資料型態為時間 檔案種類MS SQL Server中的檔案種類分作2種: Data File Transction Log File Data File存放資料內容，檔案依照順訊細分2類 mdf(master data file):第一個資料檔，副檔名為mdf。 ndf(secondary data file):第二個以上的資料檔，副檔名為ndf。 Transction Log File儲存交易紀錄，副檔名為ldf。 交易一個以上的動作，具有要就完全完成，否則就當作一切未發生的狀態稱作交易，ACID可以用來描述交易的特性。 A: Atomicity(單元性)參與交易的所有動作只能有兩種結果，要就全部完成，否則就未曾發生過 C: Consistency(一致性)參與交易的每一個動作，若交易成功，則全部停留在交易成功後的狀態，若交易失敗，則全部回到交易前狀態。 I: Isolation(孤立性)當交易進行時，若讀取資料，則其他交易不可修改資料，若交易修改資料，則其他交易不可讀寫資料。 D: Durability(永久性)交易成功時，參與交易的資料會被正確反應到資料庫，不會消失。 舉個生活中的常見案例:ATM提款: 從插卡開始~列印明細表前都算是交易。 ACID與確保機制:A: 顯性交易 Begin 宣告交易 隱性交易 不必宣告即具有交易特性，如: Insert、Update、Delete C: Rollback 交易失敗藉此指令回到交易前狀態。 Rollforward 交易成功，藉此指令更新到DB中。 I: lock:S鎖定: 又稱共享鎖定X鎖定: 又稱獨佔鎖定 D:Write: 寫入DBRead: 讀取DB資料 ODBC:微軟所提出的開放DB連接介面，用來連接各種DBMS，即各DBMS共用。 index:索引值，針對指定欄位事先排序，方便查詢。 優點: 查詢快速 缺點: 更改或維護的成本較高(增加、刪除、修改速度慢) 種類:cluster index:在table中選最常被查詢或排序的欄位或欄位組合作為cluster index，資料實際以此(index)做排序。 non cluster index:將指定欄位或欄位組合作為索引值，並將欄位內容複製到table中且排序，將每筆資料的索引後的cluster index值複製到索引後的欄位中。 join用於反正規化，將原先拆解的table順著Reference合併為一個較大的table。join有4種方式: inner join、left outer join、right outer join、full outer join union將兩個結構相同(欄位數相同、資料類別相同)的資料集進行疊加。","link":"2019/07/14/Database/SQL%20Server/Database/"},{"title":"[Database] 資料庫入門","text":"前言開始認識資料庫前，先知道一下什麼是資料?資訊? 資料(data): 指未經處理的原始紀錄e.g. 學生作業、考試成績 另外，資料又分為結構化、半結構化、非結構化三種 結構化:有明確格式和內容限制 e.g. 資料庫 半結構化:有明確格式，無內容限制 e.g. Excel、E-mail、Facebook 非結構化:無明確格式和內容限制 e.g. 圖片、影片 資訊(information): 指經過”資料處理”後的結果，產出有用的資訊。 e.g. 班級成績排名 好的資訊可以幫助決策者做出好決定! 要產出好的資訊，需透過好工具來達成，我們可以透過資料庫系統做統整。 什麼是資料庫(DataBase,DB)? 根據定義是指 有方法且有組織性的將一群相關的資料集合起來並儲存在一起 我會把它擬作一個容器，儲存程式、系統運作所需的資料，使用者可以使用SQL語法對容器中的檔案進行新增(Create)、查詢(Read)、更改(Update)、刪減(Delete)等操作，在CS領域稱這四大基本操作為CRUD。 另外資料庫有分關聯式和非關聯式資料庫，主要根據處理的資料格式來決定用哪種資料庫。 什麼是資料庫管理系統(DataBase Management System, DBMS )?DBMS是一套提供多位使用者管理資料庫的軟體系統，負責資料存取和控制。一個DBMS會包含1~多個DB。常見的DBMS為: 關聯式資料庫管理系統:MS(微軟) SQL Server、Oracle、MySQL(免費) 非關聯式資料庫管理系統:MongoDB 資料庫系統(DataBase System) 的組成:一般來說一個資料庫系統主要包括: 硬體、軟體(DBMS)、資料(DB)、使用者 使用者主要分三類: 1.一般終端使用者(end user) 2.程式設計師(Programmer) 3.資料庫管理師(DBA) 下面這張圖來說明彼此間的關係 資料庫、資料庫管理系統、資料庫系統間的關係 資料庫的出現及設計目的為何?集中管理資料，增加資料的完整性和一致性，並建立一個整合的管理機制，把資料管理和程式設計分開，使用標準化的查詢語言(SQL語法)。 為了解決傳統檔案處理系統資料的方式，資料庫主要提供了以下優點: 減少資料的重複或不一致: 傳統的方式可能造成大量資料重複，或是更新的時候不完整，導致資料不一致 讓資料具共享性: 將資料維護在單一的倉庫(Repository)中它只需要定義一次，就可讓不同的使用者存取。 減少維護成本及開發時間: 資料的安全性: 資料庫均有完善的保密系統，透過資料庫管理師進行管理 資料獨立性: 資料庫中每一項資料都具有「獨立性」， 資料的結構和存取方法是固定的，不因用途不同而有所不同。 缺點: DBMS成本較高 當DBMS發生故障時，比較難復原(集中控制) 另外，課堂主要介紹兩個常用的資料分析方式: 正規化法(傳統) 個體關係模型(ER-model) 參考網址: http://www.angle.com.tw/File/Try/51MGA02103-2.pdf 筆記傳統的分析模型:** 正規化** 正規化( Normalization) 透過蒐集原有作業的表單進行分析、拆解，避免重複和不一致，得出Data Schema 資料庫是存大量資料的地方，內含多個資料表(table)，我們的目標是要找出這些表格之間的關係，將大的資料表拆成小的資料表。順便來認識一些名詞。 資料表(table): 由1~n個欄位(column或稱field)及資料錄(record或稱row)，每個row表一筆資料，而每個field表一筆資料的屬性。 Data Schema: 資料庫本身的描述，包括資料庫結構的描述，以及在資料庫上應該遵守的限制。資料庫實例 (database instance)： 在某個特定時刻所儲存的實際資料，也稱作資料庫狀態 (database state)。鍵值屬性:在關聯式資料庫中，每一個關聯(表格)會有許多不同的鍵值屬性 (Key Attribute) ，可以分成兩個部份來探討： 一、屬性(Attribute)：是指一般屬性或欄位。 二、鍵值屬性(Key Attribute)：由一個或一個以上的屬性所組成， 並且在一個關聯中，必須要具有「唯一性」的屬性來當作「鍵 (Key)」。 關聯式資料庫(RDBMS)中，常見的鍵(Key)可分為：候選鍵(Candidate)、主鍵(Primary Key)、外來鍵(Foreign Key)及替換鍵。 候選鍵:可唯一識別資料表(Table)中的每一筆資料屬性的組合。 主鍵(Primary Key):從候選鍵中挑一個最適合或常用到的作為主鍵，如果沒有合適的，就定義一組流水號。 主鍵要求: 不允許重複、不允許為null(無法進行邏輯運算)*註 外來鍵(Foreign Key):兩個資料表(Table)具有關係(Relationship)時，會產生參照關係，將被參照的表格(Table)中的Primary Key，納入參照的Table中做為Foriegn Key。 外來鍵要求: 在被參照的Table中必須為Primary Key。 當參照的Table新增一筆資料時，Foriegn Key的值在被參照的Table中必須已經存在。 Foreign Key允許為null，但修改值時會檢查是否存在Primary Key。 當被參照的Table要刪除一筆資料時，DBMS會檢查該筆資料是否被Foreign Key所參照，如果是，就不能被刪除。 替換鍵:其他落選的候選鍵。 正規化的形式第一正規化: 去除多值每個Field只允許放一個單位，若有多個值則分成多筆資料(Row)，並決定Table中的Primary Key。 第二正規化: 去除部分相依 Primary Key可能不只一個Field所構成，若Primary Key只有一個Field，則不須另外做第二正規化(因為已經滿足)。 檢查所有非Primary Key的Field，確認該Field必須由所有Primary Key的Field共同決定，不能只有部分決定。 若部分Primary Key的Field就能決定的話，需要另外拆出一個新的表格。 第三正規化: 去除遞移關係 先完成第二正規化 檢查所有Field是否有間接決定的現象，意思是Primary Key決定某個Field，而且這個Field可決定其他的Field。 將發生決定的遞移現象的Field拆成新的Table。 以上為正規化的流程，之後再補上實作的例子。 註: NULL – 「虛值」，在資料庫中為了識別某一屬性是使用者未給值的特殊情況，記為Null，NULL因為是未定值，無法與其他值做比較。 再來筆記另一種常用的資料庫分析模型: 實體關係模型( Entity-relationship model, ERD)最早由美籍華裔電腦科學家陳品山所提出的概念模型。 目的: 在導出Database Schema，並提供資料儲存及業務規則間的圖型化檢驗 機制。 先說明一下ERD的符號: Entity(實體): 用一矩形表示， 現實世界事物的一種抽象表示，大多是名詞， 如: 客戶與商品都是個體。 Attribute(屬性): 用橢圓表示， 描述一個個體會有的特徵、特性。如: 客戶明、客戶住址、客戶編號。 Relationship(關係): 用菱形表示，描述或傳達個體與個體之間的關聯性。 例: 客戶和商品之間有一『銷售』關聯，因此兩個體間存在一銷售關係。 作法: 觀察使用者情境或需求描述，找出重要的人、事、時、地、物，畫作Entity。 依Entity找出重要的Attribute，以直線連接Entity。 找出Entity之間找出重要的關係，在Entity間畫出Relationship直接連接Entity。 範例: &lt;注意&gt; 正確的ERD可以自動滿足正規化的所有流程。 陳品山的ERD可以允許多對多、多元關係，且只描述重要屬性。 不描述外來鍵，只描述主鍵。 不適合表達複雜的資料庫結構(Schema) 概念資料模型(Conceptual Data Model,CDM)亦稱作鳥爪圖，用於資料模型(Data Model)中的概念分析，CDM處於系統分析階段，還不需要決定使用哪個資料庫管理系統(DBMS)。 範例圖示: 實體關係的描述可為一對一、多對多、一對多。 “+”表一定要有值，空心圓表沒有值，像鳥爪一樣的圖示表示多個。 &lt;注意&gt; 畫底線者表示該實體的主鍵(Primary Key)。 畫CDM時，只允許二元關係，不描述外來鍵，但可以設定主鍵。 若兩個實體間有多對多的關係(都是鳥爪圖案)，則需要拆成2個一對多關係的實體。 例如上圖的訂單和產品之間的關係是多對多，那我們還可以拆分成下圖 中間新增一個訂單明細，跟其他兩者關係成一對多的關係。 當要把多對多的關係拆出更細節的一對多關係時，就開始進入系統設計階段。 筆記一下系統開發的生命週期: 實體資料模式(Physical Data Model,PDM)實體資料模式是依實際運作上的考量，在特定資料庫系統上實現的結果，和上篇CDM不同的是， CDM是用來表達真實資料庫的抽象概念。 上篇最後有提到，具有多對多關係的兩個Entity需拆出兩組一對多關係的Entity。另外，因為需在特定的資料庫系統上實現，所以在畫PDM前一定要先選定哪種資料庫管理系統(DBMS)，選定之後就不可再做修改。 PDM示意圖(By Power Designer): &lt;注意&gt; 此階段需選定哪個資料庫管理系統。 PDM中的Entity可以設定外來鍵(Foreign Key)。 箭頭指向被參照的Entity，箭尾為參照Entity，將被參照Entity中的主鍵拉到參照Entity內作為外來鍵。 關係: 箭頭指向為一，箭尾為多 另外紀錄模型內常用的資料型態: char(): 表字元，有固定長度，()內可填入字元的最大長度，用於較有固定長度的資料，例如: 名字。 優點: 處理省時間 varchar():表字元，變動長度，可隨著不同輸入的資料長度，對最大長度做彈性調整，例如: 地址。 優點: 省空間 Integer: 整數 date: 日期 time: 時刻 datetime: 時間(包含日期、時間)","link":"2019/07/14/Database/SQL%20Server/database(introduction)/"},{"title":"[Kubernetes] Kubernetes 基礎(ㄧ) 架構及元件","text":"前言 Kubernetes 是一個用於管理多個容器的大型管理平台，原先是 Google 內部自行研發的系統，後來開源出來，讓世界各地的開發者都能加入開發、優化的行列，近期工作上開始接觸 Kubernetes，藉此記錄一下學習到的知識。 常見的容器部署模型 (Deploying Model)以下列舉幾個常見的容器部署模型： 單一節點部署一個容器 (Single Container/Single Node) 單一節點部署多個容器 (Multiple Container/Single Node) 多節點部署多個容器 (Multiple Container/Multiple Node) =&gt; Kubernetes 主要解決的問題 在單一節點上的容器部署，可以用 Docker 來實作，藉由撰寫 Dockerfile 以及 docker-compose 來完成。 但是遇到多節點的容器部署問題時，考慮的事情就變得很多(如：跨節點的網路溝通)，架構設計跟實作上會變的複雜且困難。 其實 Docker 有推出 Docker Swarm 這樣的方案來解決多節點的容器部署問題，但非本文記錄的重點，而 Kubernetes 的誕生也是為了解決多節點部署多個容器的問題，來了解一下 Kubernetes 的架構以及必須知道的元件吧！ Kubernetes Cluster ArchitectureKubernetes Cluster 是由一個主要節點(Master Node) 與多個 Worker Node 所構成的叢集架構，Cluster 架構主要由下述兩大項所構成： Control Plane(控制平面)：也就是主要節點(Master Node)，扮演 Kubernetes 大腦的角色 Node (節點; 又作 Worker Node)：可部署於虛擬機 or 實際的 Server 上，甚至能將 worker 放置於 container 裡面(藉由 container in container 的技術)。 Master Node (主要節點)Kubernetes 運作的指揮中心，可負責管理其他 Woker Node。一個 Master Node 中有四個組件：API Server、Etcd、Scheduler、Controller。 Control Plane (控制平面)Control Plane 裡有不同的應用程式，這四個角色組合成 Kubernetes 最重要的大腦功能，負責管控整個 Kubernetes 叢集(Cluster)，四個角色分別是： API Server Scheduler Controller Etcd Kubernetes 可以在不同的節點(Node)來運行容器，Worker Node 可以部署在虛擬機、實際的 Server 甚至是容器(Container)上(將 Container 部署在 Container 上)。 多個 worker nodes 組成 Data Plane Worker Node 上有的元件 kubelet：基於 PodSpec 來運作，用於描述 Pod 的物件。 kube-proxy：集群中每個節點上運行的網路代理(Agent)程式，負責與 Control Plane 的 API Server 溝通 Container Runtime：支援多個容器的運行環境，只要符合 Kubernetes CRI 標準，都能介接進行實作 Worker Nodes 與 Control Plane 之間可藉由安裝在 Worker Node 上的 代理程式(Agent) 與 Control Plane 裡的 API Server 進行溝通，同步目前 Cluster 內最新的狀況。 整個 Control Plane + 所有的 Worker nodes (或作 Data Plane) = Kubernetes Cluster Control Plane 如同 Kubernetes 的大腦，Data Plane 如同身體的四肢，撐起整個 Kubernetes Cluster 另外，使用者端要與 Kubernetes Cluster 互動，一般有三種方式: API: 習慣撰寫程式的開發者可藉由 API 的方式與 Kubernetes 溝通 CLI (Command Line Interface)：Kubernetes 提供一系列的工具列指令來溝通，這也是最常見的方式 UI (使用者介面)：網頁的方式操作 Kubernetes 加入使用者後的整個 Kubernetes 架構圖： 接著探討 Control Plane 裡的四個重要角色: API ServerAPI Server 是管理 API 的伺服器，即 Control Plane 的前端，前述提到三種與 Kubernetes 互動的方式，所有的請求都是透過 API Server 第一個處理，由上方的架構圖可以看出： 每個 Node 彼此間的溝通都必須要透過 api server 代為轉介。 換言之，若 API Server 無法正常運作，使用者使用的所有工具都無法對 Kubernetes 內部的資源進行存取 Etcd以 key-value 為儲存形式的資料庫，儲存 Kubernetes Cluster 的所有資源以及狀態，因為是儲存資料的地方，故相對應的資料備份、災難還原等措施相當重要 Scheduler替 API Server 從 container 裡面尋找合適的節點來部署，將資訊回傳給 API Server Scheduler 如何運作？ 假設有多個候選節點，Scheduler 從 API Server 收到 Container 資訊時，將 Container 相關資訊進行過濾(filtering)，根據需求(e.g. 最低的 CPU 數量)淘汰不適合的節點，第一次過濾後留下符合條件的節點。 接著 Scheduler 根據特定的算法對剩下的節點進行加權，最後選出加權分數最高的節點，再透過 Scheduler 回傳給 API Server。 Controller整個 Control Plane 的控制中心，是一個持續於背景執行的應用程式，監聽 Cluster 內的各種事件和狀態，根據事件立即反應，做出對應的處理，通過 API Server 將結果回傳出去。 目前 Controller 分四種: Node: 管理節點 Replication Endpoints Service Account 四種 Controller 存放於同個執行檔內 節點(Worker Node)作為 Kubernetes 的硬體最小單位，每個節點上都會運行代理程式用於跟 API Server 溝通，代理程式分三類： Kubelet Kube-proxy Container-runtime Kubelet跟 API Server 進行溝通的應用程式，同時確保節點上 container 的運行狀態。少了它，該節點就無法被 Kubernetes 管理，進行監控。 需要注意的是：Kubelet 只會管理跟 Kubernetes 有關的 container，也就是由 Kubernetes 建立的 container。其餘像是透過 docker command 建立的 container 等等一蓋不管 Kube-proxy提供基本的網路功能給運行中的 container，在 Node 上扮演傳遞資訊的角色。 Container Runtime負責容器執行的程式 Kubernetes 的標準化介面Kubernetes 是個開源軟體，其架構也極為複雜，為了能有效銜接各式各樣的解決方案，提供不同的介面標準，兼容不同的 container 實作，只要是符合標準的解決方案，就能銜接到 Kubernetes 上。結構如下圖: 以下列出最常見的標準: CRI (Container Runtime Interface) CNI (Container Network Interface) CSI (Container Storage Interface) Device Plugin (跟硬體有關，不在文討論範圍) Container Runtime Interface (CRI)Kubernetes 支援運算資源的標準化介面。以 Kubelet 為例：上圖所示，Kubelet 透過 CRI 與 Container Runtime 溝通，後面的 Implement Methods 表示每個 Container Runtime 實作方法皆不相同，而最終會產生 Container，這些建立好的 container 皆是基於 OCI (Open Container Initiative) 的標準。 Kubelet 本身透過 CRI 去呼叫 Container Runtime，而 Container Runtime 可以看作是額外的一個應用程式，接收從 Kubelet 發送出來的請求，負責建立、管理運行中的 container(符合 Container Runtime Interface;CRI)。 Container Network Interface (CNI)Kubernetes 管理多個節點的容器平台，節點之間該如何溝通？Kubernetes 提供支援網路架構的標準化介面，確保 containers 能夠順利的在跨節點進行溝通，為所有的 containers 提供基本的網路能力。 CNI 可以做的事情很多，本文列舉常見的: Container 間的網路連接 Container to Container Container to WAN WAN to Container In-Cluster communication (跨節點溝通) IP 位置的配發/移除 固定 IP 浮動 IP 接續上面得 Kubelet 流程，當 Kubelet 透過 CRI 呼叫 Container Runtime 啟用 container，container成功啟用後，Container Runtime 會將 Container 資訊帶入 CNI，故 CNI 是以 Container 為單位進行處理(啟用 Container 時，CNI也會被跟著呼叫一次;移除Container時亦同)。 Container Storage Interface (CSI)Kubernetes 提供支援儲存方面的標準化介面，可讓使用者可以更容易地將各式各樣的儲存設備(e.g. 檔案系統)整合進 Kubernetes 中。 目前 Kubernetes 提供兩種方式進行儲存: In-tree configuration (早期) CSI configuration Kubernetes 的運算資源前述提到 Kubernetes 的架構以及標準化介面，接著討論的是 Kubernetes 運算資源，在 Kubernetes 裡，運算單元可分為兩大類： Pod Pod Controller Pod 最小的運算單元，一個 Pod 即一個應用程式 Pod 裡面可擁有 一個或多個 containers (但一般來說一個 Pod 最好只有一個 container) 同個 Pod 裡的所有 containers 彼此共享資源: 網路、儲存、IPC(Inter Process Communication; 透過 shard memory 的方式在不同應用程式之間進行溝通) Pod Controller基於 Pod 去構築不同的使用邏輯，用於各式情境。 加入 Pod 之後，Kublet 建立資源的流程 上圖的流程大致如下： Client 端將撰寫好的檔案透過指令或是使用介面發出請求，告訴 API Server： 幫我 建立一個 Pod ，以及 Pod 的相關資訊。 接著 API Server, Scheduler, Controller 相互合作後得到一個合適的節點(Node)來部署這個 Pod，並將 Pod 資訊(e.g. 名稱、container 數量) 送至該節點上的 Kubelet。 接著 Kubelet 將解析收到的資訊，透過 CRI 將 container 資訊送給 Container Runtime，Container Runtime 收到 Pod 內的資訊(一個 or 多個 Container)，最後再依照不同的實作方式建立出對應的 container。 上圖以 Container Runtime 為界劃分的話，Container Runtime 往後即 Container(有可能是 docker，或是其他類型的 Container)，而Container Runtime 經由 CRI 一路往前推至 API Srever 都是 以 Pod 為單位 進行溝通。 Pod 本身是一個抽象概念，由一個 or 多個 Container 所組成，Kubernetes 讓這些 Containers 在 Pod 中以下共享資源: Network Storage IPC NetworkPod 內 containers 共享的網路包含 IP, port 等，故要注意同一個 Pod 裡面部署不同的 Webserver 在多個 container 時， port 號要記得切開 Storage可共用相同的檔案系統(可選) IPC (Inter Process Communication)透過 shard memory 的方式共享資源 Pod 概念圖 如同前面所提到，Pod 本身是一個抽象概念，每個 Pod 借助 CNI 擁有對外的存取能力(如圖片中 Network Interface 所示)，大部分的情況 CNI 會協助準備一張網卡分配 IP，，Pod 內的所有 container 對外IP為 10.244.1.2(共享 Network)，而 container 之間用 127.0.0.1 進行溝通。 另外，Storge 的共享如圖片所示的 volume，不同的 container 儲存的資料雖然掛在不同路徑，但儲存來源相同。 Pod 裡的 container 狀態Pod 裡的 container 擁有自己的狀態，如： Running: 運行中 Terminated: 結束，可能的結果為成功(任務順利結束)或失敗(container crash)。 Waiting: Container 仍處於等待的狀態(e.g. 等待 Image 下載) Pod 本身的狀態Pod 本身也有狀態描述，會和 Container 有關係(因為 Pod 是一個抽象層，而 Kubernetes 都是看 Pod，但實際運行的是 Container)。 實際部署 container 到 Pod 上時，能夠正確辨識 Pod 狀態有助於理解問題，Pod 分以下幾種狀態: Pending Running Succeeded Failed Unknown Pending只要ㄧ個 container 尚未建立起來，整個 Pod 就會處於 Pending 狀態，未能成功運行可能的原因是： container 沒有 CNI，沒有 CNI，container 就沒有辦法正常運作。 Running只要ㄧ個 container 正常運作，整個 Pod 就會顯示 Running。 SucceededPod 裡所有的 container 都正常結束，就稱整個 Pod 成功結束 Failed反之，Pod 裡只要有一個 container 非正常結束，整個 Pod 會呈現 Failed 狀態 Unknown扣除前面的四種狀態，剩下的歸在 Unknown Pod 的重啟政策(Restart Policy)Pod 提供幾項重啟政策，跟 docker 概念類似，有使用過 docker 的人對這些重啟政策肯定不陌生，設定政策決定要不要重啟 container: Never: 永不重啟 Always: 總是重啟 OnFailure：失敗才重啟 Pod 的排程策略 (Schedule Strategy)Pod 提供相關屬性決定如何部署。 Node Affinity: 希望讓 Pod 靠近節點 Label: 用於辨識 Pod 配置在哪些節點上(e.g. 混合式的 Cluster 架構) Affinity Anti-Affinity Node Taints: 希望讓 Pod 遠離節點 注意:預設情況下，Control Plane 的節點不允許部署任何 Pod(No Schedule)，避免一般在使用的 container 與 Control Plane 的節點爭奪資源 總結寫到這邊大致可以了解 Kubernetes 的基礎架構、所需的元件，以及每個元件在 Kubernetes 所扮演的角色，下篇文章紀錄如何在 Kubernetes 上操作 Pod 元件","link":"2021/09/07/DevOps/K8s/%5BKubernetes%5D%20Kubernetes%20%E5%9F%BA%E7%A4%8E(%E3%84%A7)%20%E6%9E%B6%E6%A7%8B%E5%8F%8A%E5%85%83%E4%BB%B6/"},{"title":"[Kubernetes] Kubernetes 基礎(五) Pod Controller - Daemonset, StatefulSet","text":"前言 上篇討論 Deployment 做滾動式部署，本篇則會接著探討另外兩種 Controller - Daemonset, StatefulSet 。 Daemonset 是什麼Daemonset 用來確保所有符合資格的節點(e.g. 節點被標示為有污點就不具資格)都有一份運行的 Pod，故每個節點上的 Pod 數量就只有一份。 案例 Cluster storage daemon CNI daemon Logs collection daemon Monitoring daemon 概念圖 從上圖來理解 Daemonset 的概念，圖中有三個 符合資格 的節點，Daemonset 便會在這三個節點上各產生一個 Pod，以此類推，若有第四個節點產生時，Daemonset 也會在這個節點上產生一個新的 Pod。故即便節點數量無法事先估計，但 Daemonset 能根據當前的節點數量動態產生所需的 Pod。 相較於前面提及的 Deployment，Deployment 須先設定要幾個副本，無法事先估計好節點上數量，Deployment 部署的 Pod 同時也無法保證能均勻地散落在不同節點上(Deployment 是透過 scheduler filtering and scoring 來選擇合適節點做部署)，故有可能出現多個 Pods 部署於相同節點上面 範例daemonset.yml 1234567891011121314151617181920212223242526272829apiVersion: apps/v1kind: DaemonSetmetadata: labels: app: nginx name: test-dsspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: nginx-server image: nginx imagePullPolicy: IfNotPresent resources: limits: cpu: 200m memory: 500Mi requests: cpu: 50m memory: 50Mi 注意: yaml 檔裡不需描述 replica 數量: K8s 本身有一套算法偵測目前有幾個節點可部署 Pod 如果部署的是 master server 且沒有拔掉 Taints 的話，Daemonset 不會起作用(因為 Daemonset ㄧ樣是去部署 Pod，所以 Taints 的 Noschedule 會阻擋部署)。當然也可以藉由設定拿掉 Taints，或是設定 Daemonset 可容忍(tolerate) Taints，忽略 Noschedule 部署 Daemonset將上述範例的 yaml 檔進行 apply 1kubectl apply -f daemonset.yml output: 1daemonset.apps/tets-ds created 接著觀察一下啟動的 Pods 資訊，可知 Pod 分別部署在不同節點上 1kubectl get pods -o wide 透過 kubectl tree 來查看 DaemonSet 結構關係 123456NAMESPACE NAME READY REASON AGE stg DaemonSet/test-ds - 2m16sstg ├─ControllerRevision/test-ds-ffc67f7fb - 2m14sstg ├─Pod/test-ds-99hlm True 2m14sstg ├─Pod/test-ds-jfdvh True 2m13sstg ├─Pod/test-ds-pjf5t True 2m12s 注意:ControllerRevision 控管相關的版本資訊(因為不能使用 ReplicaSet 來管理，ReplicaSet 是確保任何時間點維持著特定的 Pod 數量) StatefulSetStateful 表有狀態的意思，故 StatefulSet 是用來存放 有狀態的 Pods 的集合。 相較於先前用 Daemonset 或是 Deployment 所部署的 Pod 本身都是無狀態的，意味著每次 Pod 被砍掉時，重新產生的 Pod 都是全新的，無任何狀態資訊在裡面，每次可能都要透過項 DB 的服務額外存取。 有些情況下會希望 Pod 本身是有狀態的，Stateful 的 Pod 本身可以不停地重啟，每次重啟都不影響功能運作，確保 Pod 都擁有自己的獨立狀態 Stable, unique network identifiers: 如獨立的 DNS Name 做網路存取 Stable, persistent storage Order, graceful deployment and scaling Ordered, automated rolling updates StatefulSet 在使用上有個特性: 每個 Pod 的名稱後面都會帶一組有續性的流水號(並非如 deployment 一樣，採 hash 方式產生亂碼): 帶有流水號的 Pod 名稱可用來辨識 Pod 身份(or 狀態)，管理員能根據這些 Pod 有先後處理的順序。 部署方式採 one-by-one，依序進行部署 更新方式也是採 one-by-one，以倒過來的順序對 Pod 做更新 (對比 deployment 的 rolling update，事先建新的 Pod 再砍掉舊的) 常見案例:當 StatefulSet 結合網路、儲存功能時，即使原本的 Pod 被砍掉，被重新部署在不同節點上，仍然可藉由相同的 DNS 名以及相關 Storage 資料去存取相同名稱的 Pod 。 以網路為例:每個 Pod 都有各自的 DNS，可根據需求藉由 DNS 存取不同的 Pod 上的應用程式，採一對一的方式，一個 DNS name 對到固定的 Pod。即使 Pod 重啟跑到別的節點上，固定的 DNS 仍會指向重啟後的 Pod。 儲存功能也是相同的道理，每個儲存空間對應到固定的 Pod，確保 Pod 能拿到相同的儲存空間 範例statefulset.yml注意: StatefulSet 需要表明多少個副本(Replica) 12345678910111213141516171819202122232425262728apiVersion: apps/v1kind: StatefulSetmetadata: labels: app: nginx name: test-stsspec: replicas: 2 serviceName: &quot;nginx&quot; selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx-server image: nginx imagePullPolicy: IfNotPresent resources: limits: cpu: 100m memory: 100Mi requests: cpu: 50m memory: 50Mi 將上述範例的 yaml 檔進行 apply 1kubectl apply -f statefulset.yml 接著觀察一下啟動的 Pods 時資訊 1kubectl get pods -o wide output 123NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-sts-0 1/1 Running 0 2m12s 10.xxx.xxx.xxx ip-xx-xxx-xxx-xxx.us-west-2.compute.internal &lt;none&gt; &lt;none&gt;test-sts-1 1/1 Running 0 2m7s 10.xxx.xxx.xx ip-xx-xxx-xxx-xxx.us-west-2.compute.internal &lt;none&gt; &lt;none&gt; 根據結果可知藉由 statefulset 建立出來的 Pod 名稱後面都有帶有流水號，範例中定義 replicas 為 2，創造兩個帶有編號，且號碼為 0 開始的 Pod 名稱 也可以藉由 tree 指令列出 statefulset 結構，了解 statefulset 是如何管理的 1kubectl tree sts test-sts output: 12345NAMESPACE NAME READY REASON AGEstg StatefulSet/test-sts - 33sstg ├─ControllerRevision/test-sts-7f9b576867 - 31sstg ├─Pod/test-sts-0 True 31sstg └─Pod/test-sts-1 True 14s 總結Daemonset 的使用時機: 希望在每個節點上都只跑一支應用程式，且是自動隨著節點數量動態調整(產生新節點時 Pod 自動部署 or 節點減少時，主動移除 Pod)，確保每個節點上都有部署一支應用程式 statefulset 的使用時機:StatefulSet 因為是用來存放 有狀態的 Pods 的集合，故搭配網路、儲存功能時會更有意義，具體案例可參考 K8s 官方部落格曾發布 MongoDB 的案例，文章內容大概是描述如何透過 K8s 的 StatefulSet 產生多個副本的 MongoDB，舉例來說有三個 Pods，三個 Pods 存放相同資料，彼此相互同步，使用者可以隨時存取任何一個，確保拿到的資料都是一致的，更多細節可看官網文章。 下一篇將探討 K8s 一次性的運算單元 - Job/CronJob Reference Kubernetes Documentation - DaemonSet Kubernetes Documentation - StatefulSets","link":"2021/09/25/DevOps/K8s/%5BKubernetes%5D%20Kubernetes%20%E5%9F%BA%E7%A4%8E(%E4%BA%94)%20Pod%20Controller%20-%20Daemonset,%20StatefulSet/"},{"title":"[Kubernetes] Kubernetes 基礎(二) Pod 操作","text":"前言 延續上一篇[Kubernetes] Kubernetes 基礎(ㄧ) 架構及元件討論 Kubernetes 的架構與元件後，接著來探討如何操作 Kubernetes 的 Pod 元件吧！ 以下簡稱 Kubernetes 為 K8s。 在正式操作前，先認識一下什麼是 kubectl Kubectlkubectl 是 Kubernetes 的命令列工具(Command Line tool)，透過指令的方式來管理整個 Kubernetes Cluster，如：取得 Cluster 各種不同資源資訊, 配置運行資源等，使用 Kubectl 前要先了解幾個常用的參數: Namespace Completion 命名空間 (Namespace)透過命名空間在 Cluster 內將不同資源(Container, storage, Network 等)區分開來 自動補全 (Completion)Kubernetes 提供自動補全 bash 指令的功能，透過 Tab 鍵幫助我們在使用 Kubectl 指令時，快速地把指令補完，執行下述指令就能啟用這項功能 1source &lt;(kubectl completion bash) 讀取 Kubernetes 資源的相關指令 - Get讀取某個 NameSpace 下的所有 Pods 資訊1kubectl -n &lt;NameSpace&gt; get pods 讀取某個 NameSpace 下特定的 Pods 資訊1kubectl -n &lt;NameSpace&gt; get pods &lt;PodName&gt; 若想看更詳細的資訊(e.g. NODE, IP..)，可以在指令後方加上參數 -o=wide 1kubectl -n &lt;NameSpace&gt; get pods &lt;PodName&gt; -o=wide 也可改以 yaml 的形式描述 container ，參數改為 -o=yaml or JSON 形式: -o=json Kubernetes 有提供 json path 做較為複雜的輸出方式，如 -0=jsonpath='...' 監聽 Pod - Watch監聽 container 的變動，在部署的時候，可透過 watch 的方式去看某些 container 的變化是否如預期。在指令裡加上參數 -w 即可 1kubectl -n &lt;NameSpace&gt; get pods &lt;PodName&gt; -w 讀取 Kubernetes 資源的相關指令 - Describe用更上層的角度去看待資源，將多個事件、資源的資訊整合在一起，統一回傳給使用者，在 debug 時挺好用的指令 1kubectl -n &lt;NameSpace&gt; describe pods &lt;PodName&gt; Kubeconfig 的管理Kubeconfig 包含各式各樣的資訊 e.g. Cluster(一個 or 多個), user，可藉由 kubectl 來幫助我們管理這些資訊，kubectl 是一支用來與 k8s 叢集溝通的二進位 (binary) 工具。 我們可以運用 kubectl 來，除此之外，Kubeconfig 有個重要概念: Context Context以怎樣的身份(user)、基於預設的 Namespaces 去存取特定的 Cluster資訊，是 Kubeconfig 的最小單元，故操作 Kubeconfig 時都是以 Context 作為最小原件去操作。 Kubeconfig 範例格式主要分三大類別: Cluster, Context, User 123456789101112131415161718apiVersion: v1 # 該元件的版本號Kind: # 該元件屬性 e.g. Pod, Deployment, Service, Namespace, ReplicationControllerclusters: # 描述多個 clusters- cluster: certificate-authority-data: # 描述 Certificate 的資訊 server: # 紀錄連接的 Cluster 的位置 name: # Cluster 名稱 contexts:- context: # 把 user 和 cluster 資訊整合至 context cluster: namespace: # user: #users:- name: # 此處定義 user 名稱 user: client-certificate: # user 相關的 credential client-key: # user 相關的 credential Kubeconfig 相關指令部署 Service 到 K8s Cluster 時，可把相關部署資源等資訊先定義於 yaml 上，再透過 kubectl 的指令建立所需資源 對 Pod 操作 (Imperative Management; 命令式管理)通過這種方法告訴Kubernetes API你要創建，替換或刪除的內容 建立&amp;查看 Pod要在 K8s 上部署一項資源到 Pod 上，可以對事先定義好的 yaml 檔案執行 kubectl 的指令，yaml 檔照下方範例，部署一個 Nginx 服務到 Pod 上:pod.yaml 1234567891011121314151617apiVersion: v1kind: Pod # 指定為 Podmetadata: name: myapp-pod-nginx-demo labels: app: myapp-pod-nginx-demo # 定義好 Label 用於辨認spec: containers: - name: myapp-pod-nginx-demo # 自訂的容器名稱 image: nginx # container 指定的 Image resources: # 給定索取資源的上限 limits: cpu: 200m memory: 200Mi requests: cpu: 100m memory: 64Mi 搭配 kubectl create 指令加上參數 -f，後面接定義好的檔案部署資源: 1kubectl create -f pod.yaml 如果要查看 Pod 狀態，可以下 get pod 指令，後面接剛剛件好的 Pod 名稱 1kubectl get pod myapp-pod-nginx-demo output 12NAME READY STATUS RESTARTS AGEmyapp-pod-nginx-demo 1/1 Running 0 1m 想看更細部的資訊(name space, Node, Label, Containers等等)可以用 describe pod 的指令 1kubectl describe pod myapp-pod-nginx-demo 刪除 Pod若不需要這個 Pod 了，要將其移除可下 delete pod，或是 delete -f 接定義好的 yaml 檔 123kubectl delete pod myapp-pod-nginx-demo# orkubectl delete -f pod.yaml 編輯 Pod透過 edit pod 針對當前運作中的資源進行更新/替換，不需重新部署 1kubectl edit pod myapp-pod-nginx-demo 雖然上面定義好的 pod.yaml 很簡短，但實際部署到系統時， K8s 的 API Server 會自動補上其他資訊，大部分都是系統預設值 e.g. DNS 設定、重啟政策 對 Pod 操作 (Declarative Management; 聲明式管理)根據配置文件裡面列出的内容進行資源部署、修改及刪除等操作，讓 K8s 幫你維護資源狀態，概念比較偏向是告訴 Kubernetes 希望擁有的資源及狀態，確認資源應該要長什麼樣子，相較於 create 單純是創造的概念。 故根據資源狀態產生兩個對應的動詞: apply, diff kubectl apply語法 1kubectl apply -f &lt;file&gt; or 1kubectl apply -f &lt;folder&gt; 透過 apply 指令根據已經定義好的一個 or 多個 yaml 檔，也可針對資料夾用遞迴的方式，把資料夾內的所有 yaml 檔送到 Kubernetes 裡面，告訴 Kubernetes 確保 yaml 描述的狀態與 Kubernetes 裡面完全一致。 kubectl diffdiff 指令是在 apply 檔案時，跟目前 Kubernetes 檔案描述的狀態有哪些差異，修改哪些地方？有哪些變化？ Work Flow接著看張圖理解 apply 的流程： 圖片上半部分: 左邊的 Config yaml 為定義 K8s 資源的 yaml 檔，描述 A ~ E 等多項資源，接著透過 apply 指令寫到 K8s 裡，K8s 會根據 yaml 檔描述的內容及預設值建立對應的資源，其中某個欄位會用於記錄原始的檔案內容(用紅色的F標示)，剩餘的部分(如 G ~ K)則是 K8s 根據本身的預設值自動建立資源。 圖片下半部分: 若對原始定義的 Config yaml 內容作修改(如圖中橘色的 B ~ C)，經第二次 apply 後，K8s 會根據紀錄在F欄位的物件，將修改後的物件與原始存在K8s裡的物件進行比對。 如此一來，使用這變得方便許多，不需要取得完整的 yaml 檔內容(包含K8s 預設自動建立好的資源)，即可針對變動的檔案內容更新 K8s 裡的資源，實務上都採此法更新 K8s 資源，故 apply 與 create 的含意不同。 kubectl create 表創造資源，而 kubectl apply 則是維護資源狀態，希望狀態是一致的。 範例將前面 create 的 Nginx 範例改用 apply 來執行 1kubectl apply -f pod.yaml output 1pod/myapp-pod-nginx-demo created 把 image 改為 httpd ，將部署的服務改為 Apache Server 1234567891011121314151617apiVersion: v1kind: Pod # 指定為 Podmetadata: name: myapp-pod-nginx-demo labels: app: myapp-pod-nginx-demo # 定義好 Label 用於辨認spec: containers: - name: myapp-pod-nginx-demo image: httpd # 從 nginx 改為 httpd resources: # 給定索取資源的上限 limits: cpu: 200m memory: 200Mi requests: cpu: 100m memory: 64Mi 在 apply 之前，可以先透過 diff 指令來觀察資源變化 1kubectl diff -f pod.yaml 或是透過 get 指令加上參數 -o yaml 以 yaml 形式列出檔案內容 1kubectl get -f pod.yaml -o yaml 觀察一下 metadata 裡的 annotations 區塊，可發現有個欄位名稱: kubectl.kubernetes.io/last-applied-configuration，此欄位用於記錄先前的使用檔案內容 1234metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;labels&quot;:{&quot;app&quot;:&quot;myapp-pod-nginx-demo&quot;},&quot;name&quot;:&quot;myapp-pod-nginx-demo&quot;,&quot;namespace&quot;:&quot;xxxx&quot;},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;image&quot;:&quot;nginx&quot;,&quot;name&quot;:&quot;myapp-pod-nginx-demo&quot;,&quot;resources&quot;:{&quot;limits&quot;:{&quot;cpu&quot;:&quot;200m&quot;,&quot;memory&quot;:&quot;200Mi&quot;},&quot;requests&quot;:{&quot;cpu&quot;:&quot;100m&quot;,&quot;memory&quot;:&quot;64Mi&quot;}}}]}} 重新 apply 一次 1kubectl apply -f pod.yaml output 1pod/myapp-pod-nginx-demo configured 接著用 get 再次檢查annotations 區塊的 kubectl.kubernetes.io/last-applied-configuration 欄位: 1234metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;labels&quot;:{&quot;app&quot;:&quot;myapp-pod-nginx-demo&quot;},&quot;name&quot;:&quot;myapp-pod-nginx-demo&quot;,&quot;namespace&quot;:&quot;xxxx&quot;},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;image&quot;:&quot;httpd&quot;,&quot;name&quot;:&quot;myapp-pod-nginx-demo&quot;,&quot;resources&quot;:{&quot;limits&quot;:{&quot;cpu&quot;:&quot;200m&quot;,&quot;memory&quot;:&quot;200Mi&quot;},&quot;requests&quot;:{&quot;cpu&quot;:&quot;100m&quot;,&quot;memory&quot;:&quot;64Mi&quot;}}}]}} 確認 image 資訊從 nginx 更新為 httpd。 當然也可以透過 describe 的方式來查看該 Pod 當前運行的 image 是哪個 1kubectl describe pod myapp-pod-nginx-demo 經過上述幾個範例實作後，大部分的情況下都會藉由 apply 的方式來維護描述 K8s 資源的檔案。另外列出使用聲明式管理的優劣優: 直接對物件作修改，易於管理資源變化(可搭配 git 做版控) 支援整個資料夾 劣:在開發環境較為缺乏彈性(並非所有環境都能拿到最初的 yaml 檔案做 apply) 總結聲明式管理透過檔案的方式維護資源(下載、更新資源)，有效搭配版控追蹤每次修改的紀錄，能更有系統地除錯、追蹤及部署。 更多細節可查閱文件1 or 文件2，再根據自身需求進行調整 Pod Controller (Workload Controller)Pod 底下擁有多種類型的 Controller，每種 Controller 都有合適的應用場景: ReplicaSet: 管理多個 Pod 的副本 Deployment: 提供聲明式的方法來更新 Pods Daemonset: 確保每一個 node 上都會有一個指定的 Pod 來運行特定的工作 StatefulSet: 處理有狀態 Container Job: 在特定時間完成批次工作 CronJob: 定期排程工作 之後會針對 Pod 底下不同的 Controller 分篇做紀錄，本篇只有先單純列出 Pod 底下不同類型的 Controller 總結本篇記錄如何透過 Kubectl 來對 Pod 元件進行常見的操作，並比較 命令式管理與聲明式管理 兩者的差異，最後透過幾個範例實際演練，下一篇會針對 Pod 底下的 Controller - ReplicaSet 做討論。 Reference Workload Resources Kubernetes Documentation - Pod 在 Minikube 上跑起你的 Docker Containers - Pod &amp; kubectl 常用指令","link":"2021/09/10/DevOps/K8s/%5BKubernetes%5D%20Kubernetes%20%E5%9F%BA%E7%A4%8E(%E4%BA%8C)%20Pod%20%E6%93%8D%E4%BD%9C/"},{"title":"[Kubernetes] Kubernetes 基礎(六) Pod Controller - Job&#x2F;CronJob","text":"前言 上篇談到 Daemonset, StatefulSet 兩種 Pod controller，本篇將會探討 Kubernetes 一次性的運算單元 - Job/CronJob Job/CronJob 的命名跟先前已經不同，因為是一次性的運算，以 Job 為基本單元，已經沒有任何 Set 概念，在正式討論 Job/CronJob 之前，先了解到應用程式的生命週期分兩大類： 不會結束 e.g. 持續運行的 Daemon前述提到的 DeamonSet, StatefulSet, Deploymnet, ReplicaSet 都屬於此類型 會結束的 e.g. 一次性的任務 Job, CronJob 都屬於此類一次性的運算單元 Job由於 K8s 最基本的運算單元是 Pod，故以 Pod 來描述 Job。 Job 的定義: 於週期內有多少數量的 Pods 成功地結束任務，跑 Job 時，可指定 Job 數量、分配方式如: 一次跑一個(one by one) 或是平行分配(parallelism) 流程: 上圖範例是 Job 在執行的流程，我們定義: completions 為 2 parallelism 為 1 上述設定預期 Pod 成功結束的數量為2，Job controller 會先建立一個 Pod， 待這個 Pod 成功結束之後，Job controller 會偵測到結果，接著再建立第二個 Pod 執行 Job，結束後 Job controller 也會知道結果，當 Job 收到成功的 Pod 數量與預期的相同時，代表 Job 順利成功結束。 換而言之，若將 parallelism 改為 2，表同時創造兩個不同的 Pods 各自處理，最後收到成功的 Pod 數量與預期的相同時，也代表 Job 順利成功結束。 簡單小結 one by one 與 parallelism 兩者: completions != 1, parallelism = 1-&gt; One by one， 無平行化，一次跑一個 completions = N, parallelism = N-&gt; parallelism，有設定平行化，一次全部執行 相關設定說明: completions: 預期成功的 Pod 數量 parallelism: 預期同時執行的 Pod 數量。預設為 1 backoffLimit: 嘗試失敗的次數。超過指定次數，整個 Job 就會被視為 failed activeDeadlineSeconds: 嘗試失敗的時間。超過指定的時間整個 Job 就會被視為 failed， Job 會把創造出來的 Pod 都砍掉回收 Job 會持續產生 Pod 直到達到預期的成功數量，為了避免 Job 無止盡地產生 Pod 來重新嘗試執行任務，我們可藉參數調整對 Job 定義成功或失敗的條件。 這邊有個注意的點是: Pod 是否為 Deamon 還是 Job/CronJob 是由 Container 去決定，故 Pod 裡的 Container 是應用程式包成 container image 時，預先設定好讓應用程式執行的 command 是持續運行還是一次 or 批次性的任務，Kubernetes 只是使用其結果。 範例範例源自官方範例微幅改寫job.yml 12345678910111213141516171819202122apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: spec: containers: - name: pi image: perl command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] resources: limits: cpu: 100m memory: 100Mi requests: cpu: 50m memory: 50Mi restartPolicy: Never backoffLimit: 4 completions: 5 activeDeadlineSeconds: 5 # Job 跑超過 5 秒視為失敗 上述範例是定義 Job 執行一個 Perl 語言的任務，根據 completions 設定預期會完成的 Pod 數量為 5，由於 yaml 檔中未設定 parallelism (平行)，所以是一次跑一個 Pod，需等第一個 Pod 跑起來 -&gt; 執行 -&gt; 結束 回報給 Job controller 後才會再往下建立第二個 Pod 接續後面的任務，直到第 5 個 Pod 結束。 可藉由 --watch 來觀察 Job 建立 Pod 的變化 1kubectl get jobs --watch output: 123456NAME COMPLETIONS DURATION AGEpi 1/5 2m8s 2m10spi 2/5 2m44s 2m46spi 3/5 3m40s 3m42spi 4/5 4m36s 4m38spi 5/5 5m37s 5m39s 也可透過 describe 查看 Job 細節 1kubectl describe jobs.batch pi output: 123456789Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulCreate 5m37s job-controller Created pod: pi-q6vg8 Normal SuccessfulCreate 4m6s job-controller Created pod: pi-fgfpf Normal SuccessfulCreate 2m54s job-controller Created pod: pi-xsfp4 Normal SuccessfulCreate 119s job-controller Created pod: pi-m2vjz Normal SuccessfulCreate 62s job-controller Created pod: pi-hg6cj Normal Completed 1s job-controller Job completed 從 describe 輸出的內容可知當五個 Pod 都成功結束後，最終結果為 Job completed。 再透過 tree 指令觀察 Job 結構關係 1234567NAMESPACE NAME READY REASON AGEstg Job/pi - 14mstg ├─Pod/pi-fgfpf False PodCompleted 13mstg ├─Pod/pi-hg6cj False PodCompleted 10mstg ├─Pod/pi-m2vjz False PodCompleted 11mstg ├─Pod/pi-q6vg8 False PodCompleted 14mstg └─Pod/pi-xsfp4 False PodCompleted 12m 在 Job 裡，Pod 是一個批次性的任務，任務跑完就結束，結束的 Pod 狀態都會被標記成 False 接著看一下 Job 1kubectl get jobs pi output: 12NAME COMPLETIONS DURATION AGEpi 5/5 5m37s 21m 定義好的 5 個 Pod 都成功完成任務，COMPLETIONS 這欄就會顯示 5/5 CronJob相較於前述提到的 Job，CronJob 其實就是 Job 加上 schedule 的概念，可以在某個固定時間點去執行 Job，如：希望每天(固定時間點)清理節點上不必要的資料(單次性工作)，而 schedule 設置的規則跟 Linux 的 crontab 是一模ㄧ樣的方式(五個符號去描述時間點) 範例123456789101112131415161718192021222324apiVersion: batch/v1kind: CronJobmetadata: name: pispec: schedule: '*/1 * * * *' # 執行 Job 的時間 jobTemplate: spec: template: spec: containers: - name: pi image: perl command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] resources: limits: cpu: 100m memory: 100Mi requests: cpu: 50m memory: 50Mi restartPolicy: Never backoffLimit: 4 completions: 5 apply 定義好的 cronjob 檔案 1kubectl apply -f cronjob.yml 透過 tree 觀察結構: 1kubectl tree cronjob pi output 12345678910NAMESPACE NAME READY REASON AGEstg CronJob/pi - 3m37sstg ├─Job/pi-27320665 - 3m26sstg │ ├─Pod/pi-27320665-c5pnf False PodCompleted 3m24sstg │ └─Pod/pi-27320665-l9pnh True 100sstg ├─Job/pi-27320666 - 2m25sstg │ ├─Pod/pi-27320666-r6l6h False PodCompleted 2m23sstg │ └─Pod/pi-27320666-tksn2 True 42sstg └─Job/pi-27320667 - 89sstg └─Pod/pi-27320667-fhjqr True 88s 以 CronJob 的角度來看，CronJob 管理 Job，而 Job 管理底下的 Pod，由一個個抽象層往上疊加，每一層專注在自己的功能。 總結Job/CronJob 適合用在一次性的工作，而 CronJob 提供了排程的功能，可以讓 Job 在某個固定時間點執行，透過額外的參數設定可滿足不同需求，如: 是否要平行執行 Job？或是 Job 之間有依賴關係必須依序進行，或重新嘗試的次數等等，增加使用上的彈性！ 參考 Kubernetes - Job Kubernetes - CronJob","link":"2021/10/01/DevOps/K8s/%5BKubernetes%5D%20Kubernetes%20%E5%9F%BA%E7%A4%8E(%E5%85%AD)%20Pod%20Controller%20-%20Job_CronJob/"},{"title":"Kubernetes 基礎(四) Pod Controller - Deployment","text":"前言 上篇文章 - [Kubernetes] Kubernetes 基礎(三) Pod Controller - ReplicaSet 探討如何透過 ReplicaSet 管理多個 Pod 副本，確保 K8s 在任何時間點能保有特定數量的 Pod 於 Cluster 中運行。 本文接著討論 Pod 的另一種 Controller - Deployment 什麼是 Deployment Controller？相較於先前討論 ReplicaSet 用於管理多個 Pod 副本（多個相同的 Pod），Deployment 則是利用 ReplicaSet 來更新 Pod 的版本。 Deployment 提供更動版本的功能，可以決定升級為新版或是退回舊版(rollback)，概念像是告訴 K8s Cluster 要什麼版本的 Pod，Deployment 負責變更且維持該版本的 Pod，一般用於處理版本更新與降版的流程。 實作範例跟前幾篇文章一樣用 nginx 服務作為範例，撰寫一個 Deployment 的 yaml 檔:deployment.yaml 1234567891011121314151617181920212223242526apiVersion: apps/v1kind: Deploymentmetadata: # 定義 Deployment 的名稱 name: myapp-deployment-demo labels: app: myapp-deployment-demospec: # 描述 ReplicaSet 的規格 replicas: 3 selector: matchLabels: app: myapp-nginx-demo template: # 定義 Pod 的 Template metadata: labels: # 定義 Pod 名稱 app: myapp-nginx-demo spec: containers: # 定義 Pod 裡的 container 資訊 - name: myapp-nginx-demo image: nginx resources: limits: cpu: 200m memory: 200Mi requests: cpu: 100m memory: 64Mi 進行 apply 1kubectl apply -f deployment.yml 下 get 指令查看 Pod 狀態 1kubectl get deployments myapp-deployment-demo output 12NAME READY UP-TO-DATE AVAILABLE AGEmyapp-deployment-demo 3/3 3 3 2m8s Deployment 如何更新(Rollout Update)？前面有提到 Deployment 最主要的功能就是負責變更、維持 Pod 的版本，那 Deployment 是如何對 Pod 做更新的？ Deployment 更新的流程圖片源 從上面的 gif 圖來看，Deployment 會先創造一個 ReplicaSet，裡面有三個 Pod，若想把 Pod 裡的 Image 由 nginx 改成別的 image，如: httpd，或是想更新 image 版本，原始的 ReplicaSet 底下有多個相同版本的 Pod，當 Deployment 進行更新時採取的策略是盡可能安全： 先起一個新版 ReplicaSet (如圖中的 ReplicaSet v2) ReplicaSet v2 會循序地創造新的 Pod 當新的 Pod 啟動，變成 Runing 的狀態時，舊版對應的 Pod 才會被砍掉，照這個循環去迭代新的 Pod Rollout Update 的過程中有些是新版，有些是舊版 舊的 ReplicaSet (如圖中的 ReplicaSet v1) 可以選擇要不要保留。 保留的好處在於，若有退版需求，將前述步驟反過來，循序地降回舊版 如何觀察 Rollout Update 的變化？kubectl 有提供相關指令可以觀察 Deployment 的變化。語法 1kubectl rollout status deployment &lt;deployment_name&gt; 執行 rollout status 的指令前，先把 myapp-deployment-demo 的 yaml 檔裡的 image 從 nginx 改為 http，接著重新 apply。 建議先開兩個終端機的視窗，一個執行 apply，一個執行 rollout status，於 rollout status 的終端機視窗觀察變化 apply 1kubectl apply -f deployment.yml rollout status 1kubectl rollout status deployment myapp-deployment-demo 看到輸出類似下方結果: 12345678910Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 0 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 old replicas are pending termination...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 old replicas are pending termination...deployment &quot;myapp-deployment-demo&quot; successfully rolled out 如何降版(Roll Back)？執行 rollout undo 的指令即可降版(Roll Back)回去。語法 1kubectl rollout undo deployment &lt;deployment_name&gt; 將剛剛的 Deployment 範例降回上一個版本 1kubectl rollout undo deployment myapp-deployment-demo 觀察 rollout status 的輸出結果 123456789Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 old replicas are pending termination...Waiting for deployment &quot;myapp-deployment-demo&quot; rollout to finish: 1 old replicas are pending termination...deployment &quot;myapp-deployment-demo&quot; successfully rolled out 總結前面幾個範例中，已透過 kubectl apply 指令去操作 Deployment，更新服務的版本。 大部分的情況下都會採用 Deployment 的方式進行部署，可以滾動式地更新不同環境裡的服務，避免服務因為部署的關係(等待新的 image 下載等等)而突然中斷。 下篇文章會接著討論 Pod 底下的 Controller - DaemonSet Reference Kubernetes Documentation - Deployment Kubernetes Deployment Performing a Rolling Update Kubernetes Rolling Update Configuration","link":"2021/09/18/DevOps/K8s/%5BKubernetes%5D%20Kubernetes%20%E5%9F%BA%E7%A4%8E(%E5%9B%9B)%20Pod%20Controller%20-%20Deployment/"},{"title":"[Docker] Docker 實作篇 - Image、Container","text":"鼠年全馬鐵人挑戰 - WEEK 11 前言之前簡單的介紹過Docker後，本篇文紀錄Docker系統架構及操作Image、Container的基本指令。 Docker 系統架構Docker系統架構主要是Client-Server架構，Client 端稱為Docker Client，Server端稱為Docker Daemon當我們對docker下指令時，會發request給Docker Daemon去執行指令對應的工作。 Docker Daemon做哪些事? 管理多個container 管理多個從DockerHub pull下來或是在本地由dockerfile建立的Image 將本地建立好Image推到雲端上的repository Hands on Lab初步了解Docker 系統架構後，接著來著手學習相關指令吧！ Docker 登入1docker login 執行上述指令後，輸入自己在Docker Hub上建立的帳號密碼就可以登入了 Docker image相關的基本指令查看相關指令說明1docker run --help 查看所有的image執行下方指令會列出所有local端的image 1docker images 遠端下載imageDocker Hub 上有大量的Image可以用，如果要從遠端的Docker Registry 下載至本地端，可以執行 1docker pull image_name docker pull Image名稱的格式有兩種: Docker Registry位址：位址的格式一般是 &lt;網域名/IP&gt;[:連接埠號碼]。 預設位址是 Docker Hub。 Repository name：Repository name是兩段式名稱: &lt;使用者名稱&gt;/image_name:image_tag。對於 Docker Hub，若未給定使用者名稱，則預設為從官方的image，也就是library 範例: pull非官方的Image例如今天我的docker hub上已經有個自己build好的image(如上圖)，我要將其pull下來，我可以執行下方指令 1docker pull tom861012/imagedemo:0.0.1.RELEASE tom861012為我的docker hub帳號，imagedemo為image名稱而0.0.1.RELEASE為tag名。 範例： 從官方的Image pull MySQL Image將image_name替換成目標image，例如要下載MySQL這個image 1docker pull mysql 查找相關的image若要查找存放在remote repository的image，可以用search這個指令 1docker search image_name 範例： MySQL Image將image_name替換成目標image，例如要查找MySQL相關image 1docker search mysql 查看目標image的歷史紀錄1docker image history image_name 查看目標image的相關數據資料1docker image inspect image_name 刪除local端的image123docker image remove image或是docker rmi 一次刪除不必要(未使用)的image1docker rmi $(docker images --filter &quot;dangling=true&quot; -q --no-trunc) 替image加上tag1docker tag Image ID repository_address:image_tag 若在沒有指定 TAG 是哪個版本的情況下，預設會是latest表示最新版本，當然我們也自訂tag 名稱，如：加入Repository 版本號，打包出來的 Docker Image，後面的TAG 就會從latest 變成指定的版本號了。實務上為了易於辨識，通常會在Tag中加入版本號。 Container相關的基本指令建立並執行docker container1docker run -p port:container_port repository:image_tag_name -p: 為--publish 的簡寫 repository 為DockerHub所存放Repository，其中包含多個Image，每個Image有不同的標籤(tag) image_tag_name : image的tag name 執行docker run時，若本地端無此Image存在時，會從DockerHub上找目標Repository拉下來(pull down)到本地 docker run中間的過程 先在local image cache尋找該image 若找不到該image，會往遠端的image repository尋找(預設為Docker Hub) 拉下(pull)下載最新版本的image 根據pull下來的image來建新的container 在 docker engine 裡面給 container 私有網路上的虛擬 ip 開啟主機端的port(看你設定哪個port)並轉址到 containe的port(若沒有下--publish指令就不會打開任何 port) 背景執行: detach在docker run的指令中加上--detach(或是簡寫-d)，可以讓docker在背景執行。 1docker run -p port:container_port -d repository:image_tag_name 這個指令會印出container ID 查看執行中的 Docker Container1docker container ls 執行上述指令可以查看container相關的資訊，如ID、名稱、執行的Command、建立時間、所在的Image及對應的port等等。或是執行下方指令也可以 1docker ps 停止docker container1docker container stop containerID(可以取前四個) 或是將stop指令改為kill也可以 1docker container kill containerID(可以取前四個) 雖然stop、kill都可以將container停止，兩者的區別在於kill指令是強行終止container，而stop是循序的，會先给container發送一個TERM訊號(signal)，讓container做一些退出前必须的安全性操作，container自动停止運作，相對之下較為優雅(graceful) 刪除 container1docker rm containerID 清理所有停止運行的container1docker container prune 啟動已終止容器利用start指令，將一個已經終止的容器啟動執行 1docker start container_name或id 觀察 container 的資源使用量1docker stats stats指令會顯示目前所有執行中的 container所吃掉的 CPU, 記憶體, 網路和磁碟 I/O 等等，它是即時性的！讓使用者可以知道每個 Container 使用掉多少的系統資源。 限制container記憶體的使用量加上-m這個指令參數表示--memory，可以指定記憶體的容量限制，如下方範例為限制512m 1docker run -p port:container_port -d -m 512m repository:image_tag_name 限制container CPU的使用量加上--cpu-quota這個指令參數可以指定 CPU 資源限制，最大為1000000，下方範例為上限的一半: 500000 1docker run -p port:container_port -d -m 512m --cpu-quota=500000 repository:image_tag_name 查看log查看container id的log 1docker logs containerID(可以取前四個) docker system相關的基本指令查看docker系統資訊1docker system info 查看硬碟使用情況用了一段時間Docker後，會發現它佔用了不少硬碟空間，如果想知道硬碟的使用情況可以加上df指令 1docker system df 監控事件活動Docker 有提供events指令用來監聽Docker的事件紀錄，可用來查找問題，例如容器一直執行不起來的時候，就可以使用 docker events 來觀察到底是失敗在哪一個階段。 1docker system events 下這個指令時，記得要開另外一個終端機，因為這個指令是一直持續監控事件的狀態，所以要一直讓他run才有辦法監聽事件 刪除所有未使用的 containers, networks, images1docker system prune 參考教學docker 快速學習自我挑戰 Day1 docker入門觀念 手把手教你安裝、使用 docker 並快速產生 Anaconda 環境 (1)","link":"2020/04/19/DevOps/Docker/%5BDevOps%5D%20Docker%20%E5%AF%A6%E4%BD%9C%E7%AF%87%20-%20Image%E3%80%81Container/"},{"title":"[Ansile] 入門概念","text":"什麼是 Ansile?Ansile 是由 Red Hat(紅帽) 公司所提供，經開放原始碼社群進行開發，秉持基礎設施即代碼為其中一項理念，專注在 IT 自動化領域，透過撰寫 YAML 腳本對 IT 基礎設施進行操作及管理。 主要的優點： 以 YML 格式編寫，容易上手與維護 無代理(Agentless)程式 透過 SSH 進行連線，用於與遠端 Server 溝通。 不需要安裝在 Client 端 特色這裡列舉幾項 Ansible 的特色 無代理(Agentless)程式簡單說明什麼是無代理(Agentless)程式，選擇一台裝有 Ansible 作為中央控管的主機，可藉由該主機遠端登入其他的目標主機。 列點整理: 於中央主機讀入寫好要 Ansible 進行相關操作的腳本 Ansible 透過網路作遠端連線，直接對其他目標節點上的主機執行腳本下達的行為 遠端連線方式採用 SSH 採 “推播” 型的架構 也就是說，Ansible 能夠跟人為進行登入的行為相同 下圖解釋無代理(Agentless)程式的過程：圖片源 Ansile 組成及常見名詞Ansible 組成主要仰賴以下幾個要素: Ansile 本體 Inventory: 用於定義目標機器的連線資訊，撰寫遠端 Server 的資訊 -&gt; “在哪裡” 來執行 Ansible Module: 在 Client 端執行的指令或一組類似指令 Playbook: 照字面的意思為劇本。可以藉由事先定義好的Playbooks 來讓各個 Managed Node 進行指定的動作 (Plays) 和任務 (Tasks) -&gt; 將需要自動化的東西都會寫在裡面 Task: 單個需要自動化執行的任務 Handler：用來觸發服務的狀態，e.g. 重啟，停止服務 ansible.cfg：Ansible 主要的設定檔 Role：將 Playbooks 跟其他相依檔案一同整合起來，作為 Module 使用 另外，Ansile 這套工具是基於 Python 所撰寫，許多設計哲學參考 Python。 區分機器角色在 Ansible 裡，會將所有機器的角色區分成兩種 Control Machine (控制主機)：這類主機需安裝 Ansible 且透過執行 Playbook 對 Managed Node (被控節點)進行部署。 Managed Node (被控節點)：又作遙控節點 (Remote Node)。相對於控制主機，這類節點為透過 Ansible 進行部署的目標。 這類節點不需要安裝 Ansible ，但須確保該節點可透過 SSH 與 control machine 溝通 LinterAnsible 有對應的 linter 叫做 Ansible-lint，幫助開發者在撰寫的過程中維持 Ansible 的撰寫風格。 安裝 1sudo pip install ansible-lint 查看版本 1ansible-lint --version output 1ansible-lint 4.2.0 Hands on Lab12345678910111213141516171819202122- name: Install nginx &amp; PostgreSQL # hosts: dev1 become: true tasks: - name: Run command to update shell: apt upgrade -y; apt update - name: Install nginx apt: name: nginx state: latest - name: Start NGINX service: name: nginx state: started - name: Install PostgreSQL apt: name: postgresql state: latest - name: Start PostgreSQL service: name: postgresql state: started","link":"2021/03/17/DevOps/ansible/%5BAnsile%5D%20%E5%85%A5%E9%96%80%E6%A6%82%E5%BF%B5/"},{"title":"[Docker] Docker入門","text":"圖片源 前言『Docker』這個名詞近幾年討論熱度非常高，許多大型公司都持續在導入這樣的技術，既然導入docker是趨勢，那總該來了解一下什麼是docker，它帶來哪些正面效益。 上圖為Docker近五年在Google搜尋上的變化，整體來說，年年都在攀升。 什麼是Docker?我滿喜歡網路上某個教學的白話說法: Docker is a tool that allows developers, sys-admins etc. to easily deploy their applications in a sandbox (called containers) to run on the host operating system i.e. Linux. Ref: A Docker Tutorial for Beginners 簡單來說: Docker是一種工具，可讓開發者，系統管理員等輕鬆地在沙盒（稱為容器）中部署其應用程序，以在主機操作系統即Linux上運行。 為何Docker會出現?Docker的出現可以先從虛擬化技術的歷史開始追溯，網路興起，建立網站應用需要一台實體機器(這只是其中一個例子)，企業可能會建置自家的實體主機，或定期向主機商租賃。 但是……傳統的虛擬機帶來幾項缺點: 硬體(機器)的維護成本: 實體機器是會折舊的RRR，有時候還要考量天災問題。 建置機器繁複 維護人員需要隨時待命 隨著雲端技術發展起來，實體機器開始走向虛擬化，而虛擬化造成機房的革命，讓機房空間、電力能更有效的利用，以應付不斷成長的業務需求。對於企業來說，不斷買機器建置專屬應用系統所花費的成本是一筆不小的開銷，虛擬化技術是減少成本的一個解方。 一般情況，雲端服務是由實體伺服器(Host)上的虛擬機(VM)所提供。這些應用程式，是在開發者發佈完成後，轉給負責IT維運人員，在VM上運行。 在軟體開發流程裡面，開發測試會需要某些特定環境上運行，傳統的做法是利用虛擬化技術建立一個包含作業系統在內的獨立執行環境(虛擬機器)，例如VirtualBox、VMware。 雖然VM解決實體機器的問題，VM本身也有缺點: 耗費許多系統資源：每台虛擬機都需要有自己的操作系統，虛擬機一旦被開啟，預分配給它的資源將全部被佔用 佔用不少主機硬碟空間 花費許多時間在多個專案之間轉換 Container(容器)是什麼？容器(container)是一項虛擬化技術與傳統虛擬化(Virtual Machine)相同，但不同於傳統需要安裝作業系統(OS)，容器技術採共用OS的做法，虛擬化層級從OS的轉為應用程式，讓原本消耗的資源大幅降低，同時也加快執行速度。 比較Container 與 VM圖片源 使用Docker會帶來哪些好處 更有效率的利用資源 統一環境 輕量：容器利用並共享了主機CPU，在系統資源方面比虛擬機更加有效。 可移植：可以在本地構建，部署到雲端並在任何地方運行。 架構(Docker architecture)Docker是一個Client-Server架構 使用Docker必懂相關的名詞要學習Docker前，必須要先知道下面三個名詞 Image(映像檔)Docker Image是用來啟動容器(container)=&gt;實際執行應用程式環境。簡單列點整理: 一個唯讀的檔案 作為建立Container的模板 不同Image可堆疊(如Ubuntu+Postgresql+Application) 可用性：Docker 提供了一個簡單的機制來建立Image或者更新現有的Image，使用者甚至可以直接從遠端儲庫(Docker Hub)下載一個已經做好(別人或自己的)Image來直接使用。Image 如何取得? 自己寫Dockerfile Docker Hub pull下來 別台電腦上輸出Docker image，import(匯入)自已的電腦 Container容器是從映像檔建立的執行實例。它可以被啟動、開始、停止、刪除。每個容器都是相互隔離的、保證安全的平台。可以把容器看做是一個簡易版的 Linux 環境（包括root使用者權限、程式空間、使用者空間和網路空間等）和在其中執行的應用程式。 用來執行應用程式 讀寫模式 (R\\W) 將軟體執行所需的所有資源進行打包 每個Container環境獨立，相互不影響(如兩個不同的container開在8000port不會衝突) 一個Image可啟動多個不同的container Registry Docker Registry為存放Images的地方Registry分為兩種形式: 公開(Public)和私有(Private) 最大的公開Registry是 Docker Hub，存放了大量的images讓使用者pull下來 使用者可以在本地端內建立一個私有 Registry Repository(倉庫，儲存庫) vs Registry (倉庫註冊伺服器)兩者稍稍不同，實際上倉庫註冊伺服器(Registry)上存放著多個倉庫(Repository)，每個倉庫中(Repository)又包含了多個Image，每個Image有不同的標籤(tag)簡單歸納: Registry：儲存image的服務，Docker預設Registry 是Docker Hub Repository：提供不同版本(tag)的相同應用程式或服務 docker repository 伺服器，像是 GitHub 一樣，Docker Hub 就是 docker 官方提供的 registry Dockerfile是用來描述image的文件。 參考教學docker入門觀念Docker官方文件What is a Container?Docker 入門淺談虛擬機(VM)與容器(Container)之差異","link":"2020/02/28/DevOps/Docker/%5BDevOps%5D%20Docker%E5%85%A5%E9%96%80/"},{"title":"[Docker] Docker化你的Python Flask APP 並上傳至Docker Hub","text":"鼠年全馬鐵人挑戰 - WEEK 12 前言本篇將透過撰寫Dockerfile來打包自己的 Docker Image，用於建置Python Flask 環境，並將打包好的Docker Image上傳至DockerHub。 Hands on Lab建Dockerfile、requirements.txt建立Dockerfile 1touch Dockerfile 在requirements.txt寫入flask，docker run的時候會下載flask這個相依套件 1echo &quot;flask&quot; &gt; requirements.txt 撰寫DockerfileDockerfile 開頭必須是FROM指定一個底層映像檔(image)Dockerfile 12345678910111213141516FROM python:alpine3.10 WORKDIR /app COPY . /app RUN pip3 install -r requirements.txt EXPOSE 5000 CMD python3 ./index.py #COPY requirements.txt /app/requirements.txt#ENTRYPOINT [&quot;python&quot;, &quot;./index.py&quot;]# 指令：docker build -t tom861012/imagedemo:0.0.1.RELEASE . 注意最後面的&quot;.&quot;為當前目錄&quot;# FROM https://hub.docker.com/_/python# WORKDIR 工作目錄# COPY 複製的位置# RUN Build 時會執行的指令，下載相依套件# EXPOSE container 啟動時會監聽的port# CMD 執行 Container 時的指令 接著建立index.py 1234567from flask import Flaskhelloworld = Flask(__name__)@helloworld.route(&quot;/&quot;)def run(): return &quot;{\\&quot;message\\&quot;:\\&quot; Flask App Demo v1\\&quot;}&quot;if __name__ == &quot;__main__&quot;: helloworld.run(host=&quot;0.0.0.0&quot;, port=int(&quot;5000&quot;), debug=True) 建立並執行container寫入上述的Dockerfile內容後，執行 1docker build -t tom861012/imagedemo:0.0.1.RELEASE . 注意最後面的.為當前目錄，是假設Dockerfile在當前目錄下，因此會以.結尾 注意build指令，-t後面接的是repository地址，因為之後要push到自己Docker Hub的位置，而每個 Repository 的前綴字都會是登入帳號，所以上述範例tom861012為我自己的帳號 成功build一個Flask App後會看到類似上圖的內容，接著用剛build好的image以背景模式來run一個container起來。 1docker run -p 5000:5000 -d imagedemo:0.0.1.RELEASE 看到返回的containerID後就表示成功囉！進入到http://0.0.0.0:5000/ 查看log1docker logs -f containerID 查看images1docker images 執行上述指令就可以觀察到新建立得tom861012/imagedemo這個image囉 查看歷史紀錄1docker history containerID Build好的Image推到Docker Hub在push之前務必要記得先做docker login的動作 1docker push tom861012/imagedemo:0.0.1.RELEASE 再到自己的Docker Hub頁面去看 語法回顧 FROM [Docker Image Name:TAG]指定這個映像檔要以哪一個Image為基底來建構 WORKDIR 設定工作目錄 COPY 複製本地端的檔案/目錄到映像檔的指定位置中 RUN Build Image 時會執行的指令，下載相依套件 EXPOSE container 啟動時會監聽的port CMD 執行 Container 時的指令","link":"2020/04/26/DevOps/Docker/%5BDevOps%5D%20Docker%E5%8C%96%E4%BD%A0%E7%9A%84Python%20Flask%20APP%20%E4%B8%A6%E4%B8%8A%E5%82%B3%E8%87%B3Docker%20Hub/"},{"title":"[ELK] Elasticsearch Index 管理與效能優化技巧","text":"前言上週 參與保哥在臉書上發起的直播活動 - Elasticsearch Index 管理與效能優化技巧，邀請喬叔(Joe)來跟大家分享自己過去在管理 Elasticsearch 的經驗。 半年多前因工作需要，開始接觸 Elastic 這家公司的產品，最有名的莫過於搜尋引擎 - Elasticsearch，自己花不少時間摸索這項複雜的大型分散式系統上，這過程也因喬叔於三十天鐵人賽撰寫的喬叔帶你上手Elastic Stack 系列文章中獲益良多(聽說之後要出書，還不買爆！)，剛好這次喬叔本人受邀分享，千載難逢的機會怎麼能錯過！ 本文主要紀錄喬叔在本次座談分享中所提到的實戰技巧及個人經驗分享，還有加入我自己使用的心得，以下資料主要出自喬叔簡報。 Elasticsearch 常見的應用一般會採用 Elasticsearch 不外乎遇到以下場景: 全文檢索、資料比對 (Search Engine) 數據觀測 (Obseverability) -&gt; 偏向維運面，包含: Log, Metrics, Open Tracing, Monitoring 線上分析處理 (OLAP; Online Analytical Processing) 資安解決方案 (SIEM; Security Information and Event Management) 大數據 (Big Data) 非關聯式資料庫 (NoSQL Database) 常見問題喬叔在本次分享整理幾個大家最常面臨的問題: 上述問題可從兩個大面向來探討： 基於 Java 開發的 Service，運行於 JVM 上，對於記憶體有最基本的要求，即便是小專案要使用，要運行一個 Elasticsearch Cluster 仍有它的最低要求在。 若是遇到資料量大的情況下，優化 Elasticsearch Index 有助於提升資源利用，這與 Elasticsearch 底層運作和 Schema 如何 Mapping 有關，這也是本次分享的重點。 Index 管理分兩大塊 Index 建立之前 資料進入 Elasticsearh 之後 Index 建立之前 在資料進入 Elasticsearh 建立 Index 之前，資料該被如何處理？ 喬叔分享了幾個常見技巧: Dynamic Mapping Index Template Index Alias Dynamic MappingDynamic Mapping 意指一筆資料進入 Elasticsearch 做 indexing 時，若該筆資料欄位沒有在 Mapping 事先被定義好，Elasticsearch 會自動根據送進來的資料型別進行判斷，依照預設 or 指定的規則產生新欄位的 Mapping 設定。 Dynamic Mapping 的資料型別判斷規則下方表格為 Elasticsearch 對送進來的資料預設判定的規則 JSON 資料型態 判定成 Elasticsearch 的資料型態 null 不會產生對應的欄位 true or false boolean 浮點數 float 整數 long 物件 object 陣列 根據陣列內的資料型別決定 -&gt; 補充：精確來說是 陣列中的第一個非空值的資料型別 字串 1. 是否為日期格式 2. 是否為 double or long 格式 3. 若非上述兩種格式，會直接指派 text 型別，搭配 keyword 型別的作附加欄位(sub-field) 更多細節可參考文件 補充: text 與 keyword 的差異 在 Elasticsearch 中，text 用於純文字的處理，而 keyword 可針對字串進行排序或是聚合(Aggregation)等進階類型的操作。 上述比較圖表中可觀察到 Elasticsearch 對字串做 Dynamic Mapping 時，若非日期 or double or long 的格式，預設會給text 和 keyword 兩種型別的資料欄位，類似用空間來換取未來操作的便利性。 喬叔在這邊建議盡量使用自己預先定義好 mapping 的資料型別，以上述的字串型別為例： Elasticsearch 預設會給定兩個分別為 text 和 keyword 兩種型別的欄位，等於是在資料處理上會多做一件事情，若預先定義好特定欄位需要的字串型別(如直接指定text 或 keyword)，可以節省不必要的空間浪費。 Dynamic Mapping 的好處有些場景之下很難預判一定只有哪些欄位，例如：系統的 Log，這時 Dynamic Mapping 的優點就是對送進來的資料做 Mapping 設定，動態地建立欄位。 另外要注意的地方是，在原始資料欄位不存在的情況下，Dynamic Mapping 是由第一筆送進 Elasticsearch 的資料來做決定。 Dynamic Mapping 的實用技巧 以 log 為例，若明確知道字串要如何被處理，只有少數特定欄位會是 text 的話，可將預設的字串欄位指定為keyword，只對特定欄位宣告為 text -&gt; 結合 Dynamic Template 設。定e.g. strings_as_keywords，設定細節可參考喬叔的鐵人賽文章 若預設送進 Elasticsearch 的資料非常明確是 text，無需用到像是 Aggregation, Sorting or Script等操作，就不必保留 keyword 類型的 sub-field 若資料特性大多的數值欄位帶有小數點，且空間並非為最大考量下，可將數值預設為 double or float -&gt; 避免一開始進來的資料整數，後續送進 Index 資料卻帶有小數的話就無法寫入 Index 裡(因為在 Elasticsearch 的 Index 一旦做好 Mapping ，即無法修改)，有效減少這類非預期的狀況發生。 依統一欄位命名規則，套用資料型態 若值為日期時間 -&gt; 以 _datetime 做結尾。 e.g. create_datetime, modify_datetime 若值為整數 -&gt; 以 _count 做結尾。 e.g. play_count 將特定形態定義於欄位開頭 -&gt; long_, double_, int_ 等等，依照團隊達成的共識定義好命名規則 必要的嚴謹，避免意外 小心設定 Dynamic Template，特別是修改 Dynamic Template，可能會遇到 Runtime Error (Indexing 時才會報錯) 關閉 Dynamic Field Mapping: 未事先定義的欄位，進入 Elasticsearch 做 indexing 時 dynamic: false: 這邊需注意，即便設定為 false，仍會存在 index 的 _source 裡面，不僅不會被 index 且搜尋時沒有作用 dynamic: strict: 此為較佳的做法，在 indexing 時遇到未被宣告的欄位直接拋出 exeception 關閉 日期 和 數值 的自動判斷： 避免手誤產生非預期的 Mapping，造成無法修改的狀況 Index Template一般較好的做法是先依合適的 settings 及 mapping 來設置 Index，但隨著時間增加，資料量也會跟著增長，Index 也應該要隨著時間產生新的，需要透過 Index Template 來有效管理這些動態增長的 Index Index Template 的好處當新的 Index 要被建立時，若符合預先設定好的 Index Template 中的 index_pattern，Elasticsearch 會依據 Template 的設定來建立 Index Index Template 使用建議喬叔分享個建議： 針對 Index Template 的 index_pattern 和 priority 來建立結構化的管理方式，e.g. index_pattern 設為logs-xxxx-* ，這類規則擁有繼承效果，如: logs-20210101-v1 與 logs-20210101-v2 可套用於同個 Template(pattern 為 logs-xxxx-*) version 一定要給，同時建議將該 Template 的基本描述以及最後更新時間記錄於 _meta 之中，以便於維護與管理 抽出可共用的設置，變成 Component Template，增加重用性，管理起來更容易。 善用 Simulate API 來驗證 Index Template 產生的結果及影響範圍 可多參考官方及他人的 Index Template 設計方式 Index Alias透過別名來存取一個 or 多個 Index，喬叔提供幾個建議： 盡量全面使用 Index Alias 來存取 Index: 若非 time-series index，原始 Index 可加入 _v1 這類的版本號，Alias 可用原始名稱，如：song alias 指向 song_v1 的 Index =&gt; 未來要修改或是 reindex 時，較不影響使用端 善用 Index Alias 搭配 Filter Filter 在 Elasticsearch 是 Cacheable 的搜尋用法，相較一般的 query，filter 可被 cache，效能也較佳 Filter 類似於關連式資料庫的 View 適度將 filter 封裝於 alias 中，降低使用端的複雜化查詢 資料存取範圍的權限管理： 限制使用者只能存取特定子集合 or 特定時間範圍的資料，適度搭配 security 權限控管，可避免使用者存取到不應取得的資料，或是一口氣查詢太多的舊資料，對效能產生影響 配合 routing 來指定資料寫入特定的 shard: Elasticsearch 是一個 Cluster 的架構，一般來說都會設置許多 replicaions，這些 replicaions 可能會分散於多台機器上。 資料在 Indexing 時，會依據 routing value 決定資料要寫入哪個 shard 上面，若有指定 routing value，同樣 routing value 的資料會被計算放到相同的 shard 上，對於 performance 優化與管理資料都有幫助 =&gt; e.g. 相同使用者 or 相同地區的資料寫入相同的shard 上，可提升 routing 的 cache hit rate 配合 Index Management Lifecycle Management (ILM): 使用 ILM 功能來管理會隨時間增長的資料，搭配 Index Alias 來切換寫入 Index 時指定的實體 Index 資料進入 Elasticsearh 之後寫入 Elasticsearh 之後，要考量的面向變成如何管理保留在 Elasticsearh 的資料 Segment File 的數量Elasticsearh 的底層用 Apache Lucene 來建立 Index，建立好的 Index 實際上是寫入硬碟裡面，也就是 Segment File，Segment File 數量多寡 Elasticsearh 有影響，數量越多對 查詢速度 和 硬碟空間 越不好。 Shard 的數量Elasticsearh Shard 的數量多，表資料被切分成很多塊，可放置在不同台機器做處理，這有助於大量寫入(indexing) =&gt; 有多台機器分擔寫入的工作，故 Shard 越多，indexing 的速度愈快，但查詢成本愈高，單一 shard 愈大，則 Cluster 的 Rebalance 成本愈高 Index 的大小Index 愈大，查詢效率愈好(資料都放在同個 Index 裡面)，但是會影響資料移轉的等待時間，如 time-series 資料可能會依據時間移轉至不同的階段(hot -&gt; warm -&gt; cold 等不同階段) 資料的新舊程度新資料通常使用頻率較高，會給較好的硬體資源，較舊的資料因為使用頻率較低，可配置較差的硬體資源 時間粒度遇上資料量較大的情形，觀察過往的資料去切分較大的時間粒度，查看匯總結果，如：每天的 log 數量、每天的銷售金額等等 Index 數量資源有限，移除過舊的資料，只保留匯總結果 資料的安全性 妥善規劃存取限制 記得備份！ Index 生命週期管理： Index Lifecycle Management大部分存在 Elasticsearch 的資料都是隨著時間變化的。隨著時間增長，如何管理且有效利用保存在 Elasticsearch 的資料顯得格為重要，官方對於時間序的資料建議採用熱溫冷架構搭配Index Lifecycle Management 進行管理 熱溫冷架構： Hot-Warm-Cold Architecture又稱三溫暖架構(?)，官方的 Blog 有更詳細的解釋，這邊簡單摘要 Hot Phase: 此階段存放最新的資料，同時使用機率也最高，所以會負責處理 indexing 的資料，還有頻繁的搜尋請求 =&gt; 配置較多的 primary shard。 Rollover: 由於資料會隨時間增長，透過 Rollover 的機制，對 Index 進行 Rotate，進而產生新的 Index 來接新的資料，原先的 Index 則會進入下個階段 Warm Phase: 當一份 Index 的資料成長到一定的量 or 已經過了一段時間，則將該資料轉到 Warm 階段，這時的資料是 read-only 的，也就是不處理寫入 Index 的請求，只能被搜尋。 Cold Phase: 當一份 Index 資料經歷一段較長的時間，使用頻率較少時，將其轉移到 Cold 階段，並且針對這些資料進行冷凍(Freeze)處理，此時資料會以最節省系統資源的狀態下進行保存，查詢的速度又會比 Warm 階段來得更慢。 Delete: 對不再需要存放於 Elasticsearch 的 index 進行刪除(可設定備份成功後才移除 Index) 快照週期管理: Snapshot Lifecycle Management(SLM) 可設定任務做定期備份 可設定備份的保存時間與數量 -&gt; 確保備份佔用的空間不會無限制增長 Elasticsearch 相關術語 Node: Elasticsearch 實例(Instance)，可以看成叢集(Cluster)中的一個節點，一個 Node 為一個 process，一般情況下：一台機器執行一個 Elasticsearch 的 process。 補充：官方建議一台機器的 JVM heap size 不超過 32G Cluster: 表一個叢集，叢集中包含多個節點，節點之間會分工處理、或執行備援任務 Index: 可視為一個資料庫，擁有1~多個 shard (分片)，資料會被分配到這些 shard 中 Shard: 一個 Lucene index 的儲存單位，裡面存有多個 segments，同時也是 Cluster 資料搬移的最小單位 Segment: 實際寫入 Disk 的 Lucene index 的唯獨檔案 Document: 指 Elasticsearch 一筆筆的資料 Elasticsearch 如何保存資料？上圖源自喬叔簡報，解釋 Elasticsearch 存放資料的整個架構 - elasticsearch persistence model 從上面分層的架構圖來看，資料寫入 Elasticsearch 時，因 Elasticsearch 透過 Lucene 做 indexing 時，大部分的時間都是保存在記憶體，經過 Refresh 1 秒(預設是1秒)，才能在 Elasticsearch 中查詢到，滿 30mins or 512mb 時才會執行 Flush，將資料寫到 Disk 裡面。 為避免資料遺失(真正寫入 Disk 而非留在記憶體)，Elasticsearch 會先寫 Translog(每 5 秒寫一次) 到 Disk 上。 即便是 Elasticsearch 預設的配置還是有可能發生資料遺失的狀況，所以要設置 replica 才能在發生資料遺失時還原資料。 Elasticsearch 其他優化方法Index 效能優化 Indexing 大量資料時，善用 bulk request 減少來回 indexing 的次數 =&gt; 不過要注意 bulk 一次寫入的資料量過大可能會吃光所有的記憶體 善用 multi-thread / multi-worker 做 indexing 調低 or 暫時關閉 refrersh_interval 指定 routing 方式，減少 thread 數量 第一批資料做 indexing 時，先不設定 replica 關閉 java process swapping 調高 indexing buffer 大小 調整 Translog 的 Flush 設定，減少 Disk I/O 搜尋優化 善用並將 filter 條件切割，增加 cache 利用率 搜尋欄位愈少愈好 少用 join, nested, regex 少用 script 依據 Aggregation 的需求 Pre-index 資料 盡量使用 keyword 當 identifier 型態 將不會再使用的 index 做強制合併 在 query 或 aggregation 需求量較高的環境，安排特定的 cordinating Node 控制 replica 數量，不設過多得 replica 小結本次線上直播活動滿滿的乾貨，從 Elasticsearch 的概念、原理到應用方法，這麼多的資訊量實在很難在一時之間消化，這兩週週末花了點時間把分享內容整理到本篇文章，非常感謝喬叔在本次活動分享這麼多寶貴的實戰經驗，之後可以把這些知識慢慢的運用在實際工作上！ 資源 Will 保哥的技術交流中心 - Elasticsearch Index 管理與效能優化技巧 [簡報] 喬叔 Elasticsearch Index 管理技巧與效能優化 喬叔教 Elastic - 10 - 管理 Index 的 Best Practices (2/7) - 三溫暖架構 - Hot Warm Cold Architecture","link":"2021/06/06/DevOps/ELK/Elasticsearch%20Index%20%E7%AE%A1%E7%90%86%E8%88%87%E6%95%88%E8%83%BD%E5%84%AA%E5%8C%96%E6%8A%80%E5%B7%A7/"},{"title":"[ELK] Elasticsearch","text":"鼠年全馬鐵人挑戰 - WEEK 16 前言繼續上一篇的ELK筆記，本篇主要近一步筆記ELK中的Elasticsearch ElasticesearchElasticesearch是一個基於RESTful API的架構設計，使用者所有的操作都可以透過HTTP Method如：GET/POST/PUT/DELETE來完成。可以簡單的把它定義成分散式叢集架構的非關聯式資料庫，回顧一下上一篇所提到的幾個重要名詞，可以簡單對照資料庫 node : server index : database type : table fields : columns documents : rows API幾個重要行為 index： 針對整個document，既可以新增又可以更新； create：只是新增操作，可以用PUT指定ID，或POST不指定ID； update：指的是部分更新，官方只是說用POST，請求body裡用script或doc裡包含document要更新的部分； delete和read：就是發delete和get這兩種HTTP Method了 常用的指令進入Kibana的管理介面中，左側的導覽列找到一個名為Dev Tools的鈕，點擊之後就可以開始下指令囉！ 查看cluster狀態如果想查看cluster的當前狀態，可以在Kibana的管理介面執行下方指令 1GET _cluster/health 會回傳一個JSON格式的資料更多cluster health可參考官方文件或是執行下方指令可以查看整個cluster的狀態 1GET _cluster/state 查看node狀態如果想查看node的狀態 1GET _cat/nodes?v 在預設情況下只會有一個Node更多用法可以參考官方文件: Nodes info API、cat nodes API 查看Indice的相關訊息1GET _cat/indices?v 上圖中的欄位細節 health: 代表資料點的健康狀態，red表資料有缺損無法使用;yellow 表資料只有一份沒有shard，若單一結點壞損無法進行回復;green表資料有 shard 的備援若單點損壞依然可以正常運行檢索 status : 是否啟用 index : index 檢索名稱 uuid : 唯一識別 key pri : 主要 shards 數量 rep : 副本 shards 數量 docs.count : index 下總紀錄筆數 docs.deleted : 資料被異動的次數 store.size : 儲存主要資料所佔用的空間 pri.store.size : 儲存副本所佔空間 剛才上述的指令都是在Kibana介面上去操作，不過其實也可以透過cURL的方式來取得回傳資料到該行指令右邊有個板手的icon，點擊後會跳出下拉式選單，選擇Copy cURL，接著開啟終端機，貼上剛剛的cURL 其他補充shardsElasticsearch可以把一個完整的Index分成多個切片(slice)，每個切片(slice)稱作shard，好處是可以把一個大的Index拆分成多個，分布到不同的Node(節點)上，構成分布式搜尋，加快處理速度，透過水平擴展(horizontally scale)增加資料儲存的總量。 不過需要注意的是: 切分多個shard是在Index的層級上運作。也就是說，slice的數量只能在Index創建前指定，如果Index創建後不能更改。 每個shard可看作是一個獨立的Index shard分兩種類型 Primary shard: 每個Document都存在一個Primary shard。搜尋document時，會先在Primary shard上加上索引值，然後在此shard的所有副本(replicas)上加上索引值。索引(Index)可以包含一個或多個Primary shard（預設值為5）。建好Index後，便無法更改Index中的Primary shard數量。 Replica shard: 每個Primary shard可擁有零到多個Replica shard。有兩個目的： 增加系統Crash的容忍度;如果Primary shard故障，可以將Replica shard變更為Primary shard。預設情況下，每個Primary shard都有一個Replica shard，但可以在現有Index上動態修改Replica shard數量 replicas代表Index副本，白話一點就是備份，而Elasticsearch可以建立多個Index的副本，Elasticsearch預設就會啟用replicas值得注意的是：replica的數量是可以動態修改的。假設一種情況，若今天在其中一台Node server壞掉時，啟用備份的資料，用最快的速度還原原始資料，這是一種在災難復原上常用的手段。副本的作用一是提高系統的容錯性，當個某個Node或某個Shard損壞或遺失時可以從副本中恢復。二是提高Elasticsearch的查詢效率，Elasticsearch會自動對搜尋要求進行負載平衡。 replicas相關運作 在Index層級進行配置。在建立Index時，可選擇每個shard可作需要多少個replica replicas是根據Index中的shard複製的，複製出新的replica shard 被複製的shard被稱作primary shard primary shard和replica shard的集合稱作replication group 來看張範例架構圖上面的架構圖將一個Index分割出兩個primary shards，分別做兩個replica shard，而primary shards與其衍生出來的replica shards形成一個replication group，故此Index涵蓋兩組replication group接著來看replica shard是如何設計來做資料還原上圖可知，replica shard不會被放在原始的primary shard，而是放在不同個Node裡面，如primary shard A在Node A其產生的兩個replica shards放在Node B，故Node A有天突然無法運作時，Node B中至少還有一個replica shards可以做資料還原。 參閱 Elasticsearch中的一些重要概念","link":"2020/05/23/DevOps/ELK/%5BELK%5D%20Elasticsearch/"},{"title":"[ELK] Hello! ELK","text":"鼠年全馬鐵人挑戰 - WEEK 15 圖片源 前言最近因為實習環境需要接觸ELK，故藉此機會來筆記一下，加深學習印象。 什麼是ELK？其實大家所稱的ELK並非一套軟體，而是由三個不同的開源軟體的字首縮寫所構成的套件，三者為: Logstash: 蒐集日誌(log)，為日誌資料處理系統，可同時從多個來源獲取資料 Elasticsearch: 強大的搜尋功能 Kibana: 將資料視覺化的報表軟體 ELK時常被應用在解決搜尋、紀錄、保安分析、指標分析、營運分析等問題，越來越多企業採用ELK，可見此篇文章的整理。 ELK workflowELK的整體運作流程可參考下方圖片: 圖片源整體運作流程是將設備的日誌，透過檔案或系統的log傳送給Logstash進行解析，再存入ElasticSearch進行查詢/統計，最後由Kibana將統計結果以資料視覺化呈現。 安裝對ELK有初步認識後就來動手安裝吧！ Elasticsearch至官方載點找到適合自己作業系統的檔案進行下載，Mac的話，下載完tar.gz的檔案後，至終端機執行下方指令解壓縮 1tar -xzf elasticsearch-7.6.2-darwin-x86_64.tar.gz 接著切換到elasticsearch-7.6.2目錄下執行bin資料夾下的elasticsearch執行檔 1./bin/elasticsearch 測試是否安裝成功預設會開在port號9200，到另外一個終端機上執行 1curl 127.0.0.1:9200 如果成功的話會回傳一個JSON格式的資料 Kibana至官方載點找到適合自己作業系統的檔案進行下載，Mac的話，下載完tar.gz的檔案後，至終端機執行下方指令解壓縮 1tar -xzf kibana-7.6.2-linux-x86_64.tar.gz 接著切換到kibana-7.6.1-darwin-x86_64目錄下執行bin資料夾下的kibana執行檔 1./bin/kibana 注意: 要先把elasticsearch 給run起來後再起kibana 預設會開在port號5601，訪問http://localhost:5601可確任是否有成功啟動kibana LogStashLogstash 是一套 Log 分析框架，可以幫助我們處理各式各樣的 Log。官方載點 Elasticsearch basic architecture前面安裝完ELK後，接著要討論Elasticsearch的基礎架構 Node 節點上圖的每個節點(Node) 就是一個Elasticsearch的實例(Instance)，用於儲存資料，一台機器可以同時啟用多個Node。 Cluster 叢集而叢集(Cluster) 是由一個或者多個擁有相同cluster name配置的Node所組成，在預設的情況下，每個Cluster之間是互相獨立的。 當然，如果要跨叢集(Cross-Cluster)進行搜尋也是可以，不過實際上比較少會這樣使用，通常同時啟用多個Cluster是為了不同目的，如：一個Cluster用於搜尋電商的AP，另一個Cluster則負責AP的效能管理(Performance Management)。 Document 文檔稱作文檔，是搜尋資料的最小單元，以JSON作為儲存的資料格式，在一個Index或者Type中，可以存儲很多個document。 index 索引index在Elasticsearch中相當於一個資料庫，所以index底下會包含多個document 整理幾個重要的相關名詞 index: 在Elasticsearch中index相當於一個資料庫。 type: 相當於資料庫中的一個表。 id: 類似資料庫的主鍵(Primary Key)，作為唯一的值，document中的的ID可以由Elasticsearch自動分配，或手動添加到index時分配給它們。 node: 節點是Elasticsearch實例(Instance)，可以看成叢集(Cluster)中的一個節點。一台機器可以執行多個實例，但是同一台機器上的實例在配置上要確保http和tcp Port不同。 cluster: 表一個叢集，叢集中有多個節點，其中有一個會被選爲主節點，這個主節點是可以通過選舉産生的，主從節點是對於集群內部來說的。 document: 稱作文檔，是搜尋資料的最小單元，可能是 log 文件中的一筆紀錄 ，以JSON（由一堆 Key:Value 的資料組成）作為儲存的資料格式。在一個Index或者Type中，可以存儲很多個document。雖然document是儲存在Index中，但實際上，它必需被索引或分配到Index中的一個Type上。 參閱 What is an Elasticsearch Index? Introduction to the Elasticsearch Architecture","link":"2020/05/16/DevOps/ELK/%5BELK%5D%20Hello!%20ELK/"},{"title":"[ELK] 如何備份 Elastic Cloud 的 Snapshot 至 AWS S3","text":"前言Elastic Cloud 提供快照 (Snapshot) 機制來備份 Cluster 的資料，我們可以將其連接至 AWS S3 上進行保存。 本文將示範如何將 Elastic Cloud Snapshot 存放至 AWS S3 服務，並設置 Policy 進行定期備份工作。 流程大綱 AWS IAM 設置 AWS S3 Bucket 設置 Elastic Cloud Credential 設置 Elastic Cloud Repositories 和 Policy 設置 實作AWS IAM 設置建立 User 進入 AWS Console 的 IAM 服務頁面 點擊左方欄位的 User，找到上方的 Add User 按鈕建立專門操作 S3 的 User 建立成功後會產生憑證資訊，點擊 Download .csv 下載至自己電腦 建立 Policy 點擊左方欄位的 Policies，找到上方的 Add Policy 按鈕建立專門操作 S3 的 Policy 貼下下方 JSON 格式的資料，定義好 Policy123456789101112131415161718{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListAllMyBuckets&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::*&quot; }, { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:*&quot;, &quot;Resource&quot;: [ &quot;arn:aws:s3:::elastic-cloud-snapshot-demo&quot;, &quot;arn:aws:s3:::elastic-cloud-snapshot-demo/*&quot; ] } ]} 其中，本文以 elastic-cloud-snapshot-demo 為要存放 Snapshot 的 S3 Bucket Name，可自行替換成自訂的名稱。 自訂 Policy Name 後點擊 Create Policy 完成建立 將目標 Policy Attach 至新建立的 User 選擇 Attach 搜尋並選擇剛才新建的 User AWS S3 Bucket 設置 建立 S3 Bucket，自訂 Bucket 名稱，本文範例為 elastic-cloud-snapshot-demo，可自行替換成自訂的名稱。 Elastic Cloud Credential 設置 進入 Elastic Cloud 後台管理介面，選擇要備份至 S3 的 Cluster → 左方列表中的 Security → 點擊右下 Elasticsearch Keystore 的 Add settings 按鈕 添加剛才於 AWS IAM 服務中新建 User 時所載的憑證資訊，裡面會包含 Access Key 和 Secret Key， 需要將這些資訊填入 KeyStore 中。 兩者皆填入後查看一下是否有顯示於畫面中 Elastic Cloud Repositories 和 Policy 設置 於 Elastic Cloud 中設置 Registries 自訂 Repository 名稱 → 選擇 S3 → 點擊 Next 填入 Client 名稱 (本文為 default) → 輸入目標的 S3 Bucket 名稱 (本文為 elastic-cloud-snapshot-demo)，其餘參數可依自身需求做調整，設定完點擊 Register 按鈕完成建立。 建立成功後選擇剛剛建好的 Repository，可點擊下方的 Verify repository 檢驗是否成功連結 若成功連結會出現下圖的圖示 對該 Repository 新增對應的 Policy 輸入自訂的 Policy Name (本文為 elastic-cloud-cluster-backup) → 輸入自訂的 Snapshot Name (本文為 &lt;cluster-daily-snap-{now/d}&gt; ) → 選擇目標 Repository → 設置 Schedule 排定備份的頻率 選擇備份來源 Index (也可以點擊上方按鈕開啟 all data 做 全選) 最後確認一下設置的 Policy 資訊 設置成功後可以回 Snapshot 頁面查看是否有存在依剛剛規則所建好的 Snapshot 囉！ 回到 S3 Bucket 查看資料是否有成功備份 以上為備份 Elastic Cloud Snapshot 至 AWS S3 服務的整套流程。 相關參考文件 Configure a snapshot repository using AWS S3 Repository Settings","link":"2021/03/13/DevOps/ELK/%5BELK%5D%20%E5%A6%82%E4%BD%95%E5%82%99%E4%BB%BD%20Elastic%20Cloud%20%E7%9A%84%20Snapshot%20%E8%87%B3%20AWS%20S3/"},{"title":"[ELK] 如何透過 enrich processor 擴增資料屬性","text":"前言在資料處理的過程中，會針對資料源的不完整或是冗余的資料訂定 pipelines 來做預處理，Elastic 官方提供 elastic ingest pipeline 功能，將一連串的制定好的處理器(Processors) 匯集在一個 pipeline ，對來源資料做結構化處理。 我們可以設置多個獨立的 Processors 在同個 Pipeline 裡面，在來源資料送進 Elasticsearch 做 indexing 之前，會經過指定的 Pipeline， Pipeline 裡含有多個 Processors， Processor 可以做的事情很多，如: 重新命名、新增欄位、資料型別&amp;大小寫轉換，甚至支援正規表達式，可以做複雜的判斷式。 本文主要示範其中一種 Processor - Enrich Processor Enrich ProcessorEnrich Processor 的功能是針對傳入資料源(elasticsearch 中的 document)擴增資料屬性，下方圖片展示整個擴增資料的運作流程：由上圖可知資料源(incoming documnet)送進 Elasticsearch 前，經過預先設置好的 pipeline，pipeline 裡面包含多個定義好且相互獨立的 processor 。 Enrich Processor 可選定已經存在於 Elasticsearch 的某個 index，指定被選定的 index 某個欄位作為參考(注意: 這個參考欄位必須是來源 documents 也有的欄位)，將被選定的 index 中的其他欄位 mapping 至來源 document，形成新的資料欄位。 看完前面說明，對 processor 有初步概念後，接著來實作吧！ Let’s get technical at the Hands-on Labs藉由官方範例來實做一個 Enrich Processor。以下範例皆於 Kibana 的 Dev tool 進行： 新建 Index下述方法來建立名為 postal_codes 的 index 12345678910111213PUT /postal_codes{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;location&quot;: { &quot;type&quot;: &quot;geo_shape&quot; }, &quot;postal_code&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }} 新增 document向 postal_codes 裡新增一個 document 中，包含 post_code 及相關位置的資料 12345678PUT /postal_codes/_doc/1?refresh=wait_for{ &quot;location&quot;: { &quot;type&quot;: &quot;envelope&quot;, &quot;coordinates&quot;: [ [ 13.0, 53.0 ], [ 14.0, 52.0 ] ] }, &quot;postal_code&quot;: &quot;96598&quot;} 可透過 GET 方法來查詢 index 內容 1GET /postal_codes/_search 新建 enrich policy透過 enrich policy API 來制定 enrich policy 給新建立的 enrich processor，enrich policy 必須涵蓋： 一個或多個來源 index： 已存在的 elasticsearch 裡的 index match_field: 用於配對的參考欄位(field)，這個欄位必須是來源 document 和已存在的 document 共有的 enrich_fields：配對後要新增至來源 document 中的欄位。這些欄位必須存在來源 index 裡 接著來建立新的 policy - postal_policy 12345678PUT /_enrich/policy/postal_policy{ &quot;geo_match&quot;: { &quot;indices&quot;: &quot;postal_codes&quot;, &quot;match_field&quot;: &quot;location&quot;, &quot;enrich_fields&quot;: [ &quot;location&quot;, &quot;postal_code&quot; ] }} 上述範例表示透過 geo_match 的方法，來源 index（source index）- postal_codes 會透過 location 欄位來進行配對，如果配對到 指定的 field name ，則會將 location 及 postal_code 這兩個欄位一同添加到來源 index 的 document 裡面 其他 match 方法可參考文件 執行 enrich policy： execute enrich policy執行 execute enrich policy API 為該 enrich policy 建一個來源 index執行成功回傳下述結果： 12345{ &quot;status&quot; : { &quot;phase&quot; : &quot;COMPLETE&quot; }} 查詢enrich policy1GET /_enrich/policy 查詢結果如下 123456789101112131415{ &quot;config&quot; : { &quot;geo_match&quot; : { &quot;name&quot; : &quot;postal_policy&quot;, &quot;indices&quot; : [ &quot;postal_codes&quot; ], &quot;match_field&quot; : &quot;location&quot;, &quot;enrich_fields&quot; : [ &quot;location&quot;, &quot;postal_code&quot; ] } }} 建立 pipeline透過 PUT pipeline API 方法來新增 or 更新 enrich processor 至名為 postal_lookup 的 pipeline 中 12345678910111213PUT /_ingest/pipeline/postal_lookup{ &quot;processors&quot;: [ { &quot;enrich&quot;: { &quot;description&quot;: &quot;Add 'geo_data' based on 'geo_location'&quot;, &quot;policy_name&quot;: &quot;postal_policy&quot;, &quot;field&quot;: &quot;geo_location&quot;, &quot;target_field&quot;: &quot;geo_data&quot; } } ]} 回傳結果 123{ &quot;acknowledged&quot; : true} 說明 policy_name: 於 pipeline 指定 enrich policy field: 配對的欄位，前述範例以 geo_location 為配對的欄位 target_field: 配對成功後，來源 document 會新增的欄位名稱 新增來源資料新增 document 並指定 postal_lookup 這個 pipeline 擴增資料 123456PUT /users/_doc/0?pipeline=postal_lookup{ &quot;first_name&quot;: &quot;Mardy&quot;, &quot;last_name&quot;: &quot;Brown&quot;, &quot;geo_location&quot;: &quot;POINT (13.5 52.5)&quot;} 查詢 users 1GET /users/_doc/0 查詢結果 123456789101112131415161718192021222324252627282930{ &quot;_index&quot; : &quot;users&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;0&quot;, &quot;_version&quot; : 1, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : { &quot;geo_location&quot; : &quot;POINT (13.5 52.5)&quot;, &quot;last_name&quot; : &quot;Brown&quot;, &quot;geo_data&quot; : { &quot;location&quot; : { &quot;coordinates&quot; : [ [ 13.0, 53.0 ], [ 14.0, 52.0 ] ], &quot;type&quot; : &quot;envelope&quot; }, &quot;postal_code&quot; : &quot;96598&quot; }, &quot;first_name&quot; : &quot;Mardy&quot; }} 由上述查詢結果得知，透過 pipeline 裡的 enrich processor 擴增了 geo_data 裡的資料，包含coordinates 以及 postal_code Enrich processor 幾個要注意的點 建好 enrich policy 後，將無法更新或更改。反之，可以藉由建立並執行新的 enrich policy 替換舊的 policy 使用 delete enrich policy API 刪除舊的 enrich policy (重要)enrich policy 連接的來源 index (source index) 若有更新資料，則需要重新執行 execute enrich policy API 更新舊的 source index。 以下擷取自部分文件內容 Update an enrich indexOnce created, you cannot update or index documents to an enrich index. Instead, update your source indices and execute the enrich policy again. This creates a new enrich index from your updated source indices and deletes the previous enrich index. If wanted, you can reindex or update any already ingested documents using your ingest pipeline. 小結前面實作了如何建立 enrich processor 至 pipeline 中，並將來源資料(document) 指定由該 pipeline 處理，將配對到的 document 擴充欄位，這個概念類似於關連式資料庫的 Join Table，透過 enrich processor 我們能夠藉由已存在的資料對來源資料進行擴增。 Reference Set up an enrich processor","link":"2021/04/17/DevOps/ELK/%5BELK%5D%20%E5%A6%82%E4%BD%95%E9%80%8F%E9%81%8E%20enrich%20processor%20%E6%93%B4%E5%A2%9E%E8%B3%87%E6%96%99%E5%B1%AC%E6%80%A7/"},{"title":"[Terraform] Terraform入門(2) - 變數","text":"前言本篇為Terraform系列的第二篇，紀錄Terraform如何定義及應用變數 Hands on Lab變數宣告variable開頭做變數宣告，後面接自定義的變數名稱，如下方範例，變數名為iam_user_name，變數值為my_iam_user 123variable &quot;iam_user_name&quot; { default = &quot;my_iam_user&quot;} 若無給予default這個屬性的話，執行terraform apply後會要求輸入值。 匯出變數除了上面使用變數宣告的方法外，也可以在終端機中輸入指令來定義變數，如: Mac版採export TF_VAR_iam_user_name=VALUE的語法來匯出變數。 1export TF_VAR_iam_user_name=&quot;test_prefix&quot; 匯出變數後執行terraform plan -refresh=false查看變化上圖可觀察到iam_user_name替換成test_prefix Windows版相異於Mac指令，Windows版採用SET VARIABLE=VALUE指令來匯出變數。 取用變數值採var.*的方式來取得變數值，如延續上一篇文的範例: 1234resource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { count = 2 name = &quot;${var.iam_user_name}_${count.index}&quot;} 更改後執行terraform apply指令。另外也可以透過terraform console的方式驗證是否能取得變數值。 賦予變數型態既然能給變數值，那當然也可以定義變數型態啦，只要在宣告變數的地方給予type屬性，並指定哪個型態作為屬性值。如： 1234variable &quot;iam_user_name&quot; { default = &quot;my_iam_user&quot; type = string #any(預設) or number, boolen, list, map} 統一管理變數(variable)我們可以另外建一個terraform.tfvars或是*.auto.tfvars檔案來集中管理變數。 範例於根目錄下建立一terraform.tfvars檔案，此檔寫入 1iam_user_name = &quot;tf_file_test_iam_user_name&quot; 表示宣告變數iam_user_name，並賦予值tf_file_test_iam_user_name。執行terraform plan -refresh=false查看變化","link":"2020/04/03/DevOps/Terraform/%5BDevOps%5D%20Terraform%E5%85%A5%E9%96%80(2)%20-%20%E8%AE%8A%E6%95%B8/"},{"title":"[Terraform] Terraform入門(3) - list&amp;map","text":"前言本篇為Terraform系列的第三篇，主要紀錄在Terraform中的list和map兩種資料結構 Hands on LabListterraform list 如同一般程式語言的陣列結構，我們可以存放多個元素在陣列內，透過索引值(index)的方式進行查找。 123456789101112131415# declare variablevariable &quot;names&quot; { default = [&quot;tom&quot;, &quot;jack&quot;, &quot;tonny&quot;]}# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}resource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { count = length(var.names) name = var.names[count.index]} 分別執行下方指令 12terraform initterraform apply 在AWS IAM User分別新增tom、jack、tonny三位Users 接著進入terraform console 1terraform console 取得變數長度123length(var.names)# 3 反轉list中的元素順序123456reverse(var.names)# [# &quot;tonny&quot;,# &quot;jack&quot;,# &quot;tom&quot;,# ] 合併list1concat(var.names, [&quot;amy&quot;]) 注意，合併時，資料結構為list，否則會報Invalid value for &quot;seqs&quot; parameter: all arguments must be lists or tuples; got string.的錯誤訊息 concat()合併list時，不影響原始的list 排序list1sort(var.names) 檢查是否存在可以透過contains進行元素是否存在，存在的話回傳為true，反之為false。 12contains(var.names, &quot;tom&quot;)contains(var.names, &quot;hey&quot;) 限定範圍1range(start, end, space) start：表起始值 end：表結束值(實際印出的值為end-1) space：間隔(預設為1) 1range(1,10) 1range(1,20, 2) 更多Terraform 內建的functions可參考官方文件 添加terraform listterraform list預設index以數值0開始做排序，如果想改以element名稱來排序的話，改成下方作法:main,tf 1234567891011121314151617# declare variablevariable &quot;names&quot; { default = [&quot;jason&quot;,&quot;tom&quot;, &quot;jack&quot;, &quot;chris&quot;]}# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}resource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { # count = length(var.names) # name = var.names[count.index] for_each = toset(var.names) name = each.value} for_each可參考官方文件, each.value可參考官方文件執行terraform apply -refresh=false後查看terraform.tfstate這個檔案內容，觀察變化。 index_key由原本的數值轉為jack mapmap在Terraform中的資料結構用{key : value}來表示，如要取得key對應的value值，語法為key.value。範例 1234567891011121314# declare variablevariable &quot;names&quot; { default = { tom : &quot;Taiwan&quot;, jack : &quot;UK&quot;, chris : &quot;US&quot;, }}# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;} 進入terraform console 取得map內所有資料1var.names 取得某個key對應的value1var.names.jack map內取得所有的key名稱1234567keys(var.names)# [# &quot;chris&quot;,# &quot;jack&quot;,# &quot;tom&quot;,# ] map內取得所有的value1234567values(var.names)# [# &quot;US&quot;,# &quot;UK&quot;,# &quot;Taiwan&quot;,# ] 查看特定值採lookup(obj, &quot;key&quot;) obj: 目標物件 key: 物件中的某個key123lookup(var.names, &quot;jack&quot;)# UK 綜合練習假設今天想建立三個IAM Users，分別讓每個User加上tag，tag值為對應所在的國家 1234567891011121314151617181920# declare variablevariable &quot;users&quot; { default = { tom : &quot;Taiwan&quot;, jack : &quot;UK&quot;, chris : &quot;US&quot;, }}# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}resource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { for_each = var.users name = each.key # 對每個user加上key tags = { country :each.value # 加上key對應的value }} 上述程式碼寫完執行terraform apply查看aws IAM User管理介面，會新增程式碼寫的3個user可點開單一user查看詳情，確認剛才建立的tag是否有真的加上去，以chris為例: 或是採第二種做法： 原物件內再包一層物件 1234567891011121314151617181920212223variable &quot;users&quot; { default = { tom : {country :&quot;Taiwan&quot;, department: &quot;ABC&quot;} jack : {country :&quot;UK&quot;, department: &quot;EFG&quot;}, chris : {country :&quot;US&quot;, department: &quot;XYZ&quot;}, }}# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}resource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { for_each = var.users name = each.key tags = { # country :each.value country :each.value.country # 直接從第二層物件取value department :each.value.department }} 補充本篇包含前面幾篇有關Teraaform的文章範例裡面，有提到terraform apply指令，眼尖的人會發現我後面在下執行的指令時，會在後面加-refresh=false。主因是若日後專案變大，Terraform寫得腳本愈多，涉及到的服務愈來愈雜，每次執行時會花大量時間進行資源的請求，為了減少每次請求的數量及時間，採用cache的方式，每次執行時只更新有異動的部分，而非對所有服務重新請求所有的服務資源。 Ref For larger infrastructures, querying every resource is too slow. Many cloud providers do not provide APIs to query multiple resources at once, and the round trip time for each resource is hundreds of milliseconds. On top of this, cloud providers almost always have API rate limiting so Terraform can only request a certain number of resources in a period of time. Larger users of Terraform make heavy use of the -refresh=false flag as well as the -target flag in order to work around this. In these scenarios, the cached state is treated as the record of truth.","link":"2020/04/04/DevOps/Terraform/%5BDevOps%5D%20Terraform%E5%85%A5%E9%96%80(3)%20-%20list&map/"},{"title":"[ELK] 如何更新 Kibana Visualization &amp; Dashboard 對應的 Index Pattern","text":"前言要將 Elasticsearch 內的資料做視覺化，透過 Kibana Visualization 拉圖表呈現，並整合進一張 Dashboard 中。 由於 Visualization 是對應於 Kibana 中的 index pattern，若今天把原始的 index pattern 刪除，重建一個同名的 index pattern，原始的 Visualization 會出現 Could not locate that index-pattern 這類的錯誤訊息，無法正常顯示。 如下圖所示： 原因是每個建好的 index pattern 都會帶一個獨立 ID ，Kibana Visualization 會綁定該 ID，故原始 index pattern 被刪除時，即便新建一個同名 index pattern，ID 改變造成 Visualization 找不到原始綁定的 index pattern。 本篇文章會示範如何在不另外建 Visualization 和 Dashboard 的情況下，替換新的 Index Pattern 實作 Elastic Cloud 版本為 7.10 以下透過兩種方法來更新 Kibana Visualization，實際情況依照既有的 Visualization 數量。 若要更改的 Visualization 數量很少:請在保存的對象設置下更改索引模式ID 若要更改的 Visualization 數量很多(e.g. 同一張 Dashboard 下多個 Visualization):匯出 JSON 物件（Objects），打開該物件，替換檔案內的舊 index pattern ID ，並重新匯入 Kibana Objects 中 Visualization 數量少 點擊單一個 Visualization，會出現如下圖的提示訊息 回到 Stack Management -&gt; 點擊 Index Pattern -&gt; 找到新建的 Index Pattern 點擊新建的 Index Pattern -&gt; 於頁面最上方的網址列找到新的 Index Pattern ID，將其複製 到剛剛出現 Error 訊息的 Visualization 頁面 -&gt; 滑鼠滾動至最下方 於 references 欄位中的 id 替換成新的 Index Pattern ID 替換完畢後點擊 Save visualization object -&gt; 原本的 Visualization 恢復正常 Visualization 數量多下方以同一張 Dashboard 下有多個 Visualization 的情形下作為範例 進入Kibana 介面 -&gt; 點擊畫面左上角的 icon 展開選單 -&gt; Stack Management 點擊 Saved Objects 選擇目標 Object -&gt; Export 打開下載至本機的 Object -&gt; 將 Object 內的 id 全數替換新的 Index pattern ID 將修改完後的 Object 重新上傳至 Kibana Saved Objects 查看 Dashboard，所有圖表都正常顯示囉！ 以上為更新 Kibana Visualization &amp; Dashboard 對應 Index Pattern ID 的方法","link":"2021/03/15/DevOps/ELK/%5BELK%5D%20%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0%20Kibana%20Visualization%20&%20Dashboard%20%E5%B0%8D%E6%87%89%E7%9A%84%20Index%20Pattern/"},{"title":"[Terraform] Terraform入門(4) - 利用Terraform來操作AWS EC2","text":"鼠年全馬鐵人挑戰 - WEEK 09 前言本篇為Terraform系列的第四篇，主要實作用Terraform遠端建立並連接EC2，代替之前手動點擊aws console，IAM的部分會選擇Amazon Linux AMI，閱讀本篇建議要先了解AWS EC2的相關知識。 Hands on Lab建立Security Group屬性可詳見官方給的sample 1234567891011121314151617181920212223242526272829303132333435# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; #選擇你要的區域 version = &quot;~&gt; 2.55&quot;}// HTTP Server -&gt;Security Group// Security Group(即fire wall)=&gt; 80 port : TCP , 22 port : TCP, CIDR: [&quot;0.0.0.0/0&quot;]resource &quot;aws_security_group&quot; &quot;http_server_sg&quot; { name = &quot;http_server_sg&quot; vpc_id = &quot;VPC ID&quot; # 貼上AWS 預設的VPC ID ingress{ # ingress為入口的限制規則 from_port = 80 to_port = 80 protocol = &quot;tcp&quot; cidr_blocks = [&quot;0.0.0.0/0&quot;] } ingress{ # ingress為入口的限制規則 from_port = 22 to_port = 22 protocol = &quot;tcp&quot; cidr_blocks = [&quot;0.0.0.0/0&quot;] } egress{ # 出口規則 from_port = 0 to_port = 0 protocol = -1 cidr_blocks = [&quot;0.0.0.0/0&quot;] } tags = { name = &quot;http_server_sg&quot; }} 依照上述程式碼執行terraform apply，即可成功建立Security Group 有關Security Group設定的rule，範例的設定不是比較安全的做法，如ingress設定。NOTE: Setting protocol = “all” or protocol = -1 with from_port and to_port will result in the EC2 API creating a security group rule with all ports open. This API behavior cannot be controlled by Terraform and may generate warnings in the future.上述為其中一個有關安全設定的提醒，更多安全建議可參考官方文件 務必要看清楚當前VPC所在的Region，別像我一樣第一次實作把不同Region的VPC ID貼上去，結果一直跳出The vpc ID does not exist的錯誤！ 到AWS EC2的管理介面，左方列表找到Security Groups即可看見剛剛新建的Security Group 下載key pair至AWS EC2的管理介面，左方列表找到Key Pairs，進入頁面點擊Create key pair。取名為ec2-terraform，選擇pem檔完成建立的同時，會下載一組key pair到本地，將此檔移入專案資料夾中，接著更改檔案權限 1chmod 400 ec2-terraform.pem chmod 400表示只有擁有者才能夠修改的權限，非擁有者只能夠讀取 建立EC2接續上面的範例程式碼，接著新增aws_instance這個resource 1234567resource &quot;aws_instance&quot; &quot;http_server&quot; { ami = &quot;ami-0e01ce4ee18447327&quot; # 對應 Amazon Linux 2 AMI key_name = &quot;ec2-terraform&quot; # 下載至本地的pem檔檔名 instance_type = &quot;t2.micro&quot; vpc_security_group_ids = [aws_security_group.http_server_sg.id] subnet_id = &quot;subnet-16ee127d&quot;} 點擊Launch Instance，選擇AMI為Amazon Linux 2 AMI，Instance Type為t2.microAMI對應id的部分可以在Choose AMI的管理介面中看到每個IAM專屬的ID而Instance Type的部分可以參考AWS提供的type，不一定要按照上述範例 vpc_security_group_ids的話，其實可以從 .tfstate 檔案中找到security group 的id，不過建議靈活一點，不要直接寫死，還是透過aws_security_group.http_server_sg.id來取得id會比較好。 subnet_id的話，回到VPC管理介面，左方欄位有subnet，可找到想要的subnet id 確認沒問題之後可以先下terraform validate進行驗證，接著執行terraform apply就可以囉！ 連接EC2現在要進行遠端連接EC2，我的作法在專案目錄下新增一資料夾，名為aws_key_pair，並原先下載的key pair移入此資料夾下，再設一變數aws_key_pair，裡面存放key pair的位置路徑。接著新增resource設定connection屬性。 type = &quot;ssh&quot;: 表我們採用SSH的方式連接 host = self.public_ip: 表主機對應的ip private_key = file(var.aws_key_pair): 私鑰從本地專案夾內進行路徑搜尋，找到下載下來的.pem檔 接著設定provisioner屬性，&quot;remote-exec&quot;表進行遠端操作下達的指令，給定inline陣列，裡面存放要下達的指令，每行指令,區隔 1234567891011121314151617181920212223242526variable &quot;aws_key_pair&quot; { default = &quot;./aws_key_pair/ec2-terraform.pem&quot;}resource &quot;aws_instance&quot; &quot;http_server&quot; { ami = &quot;ami-0e01ce4ee18447327&quot; # 對應 Amazon Linux 2 AMI key_name = &quot;ec2-terraform&quot; # 下載至本地的pem檔檔名 instance_type = &quot;t2.micro&quot; vpc_security_group_ids = [aws_security_group.http_server_sg.id] subnet_id = &quot;subnet-16ee127d&quot; connection { # 遠端連接EC2 type = &quot;ssh&quot; host = self.public_ip # 公有ip user = &quot;ec2-user&quot; private_key = file(var.aws_key_pair) } provisioner &quot;remote-exec&quot; { # 遠端執行指令 inline = [ # 連接遠端時，會開始執行一系列的指令 &quot;sudo yum install httpd -y&quot;, # install httpd &quot;sudo service httpd start&quot;, # start # 印出字串訊息至index.html 檔 &quot;echo Welcome to virtual server which is at ${self.public_dns} | sudo tee /var/www/html/index.html&quot;, # copy file ] }} 新增連接EC2的程式碼後，須先將EC2 terminate才會執行remote-exec的指令，所以先執行terraform destroy，再執行terraform apply在終端機上大概會看到上述的執行畫面。接著從.tfstate檔中找到public_dns對應的網址，貼上網址之後就可以順利訪問剛剛的內容囉！ 進階：選用預設的VPC直接使用預設(default)的VPC，將它改為動態的，用來取代原本寫死的vpc_id，Terraform會自動根據當前Provider設定的Region，找該Region下預設的VPC ID，這樣就不會發生像我上述犯下的錯誤: 找錯Region的VPC ID執行下方指令 1terraform apply -target=aws_default_vpc.default 並修改vpc_id給定的值 12# vpc_id = &quot;vpc-4dbe6a26&quot; # 貼上AWS 預設的VPC ID vpc_id = aws_default_vpc.default.id # 使用預設的VPC ID 執行下方指令 1terraform apply -refresh=false 完整程式碼12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}resource &quot;aws_default_vpc&quot; &quot;default&quot; { }// HTTP Server -&gt;Security Group// Security Group(即fire wall)=&gt; 80 port : TCP , 22 port : TCP, CIDR: [&quot;0.0.0.0/0&quot;]resource &quot;aws_security_group&quot; &quot;http_server_sg&quot; { name = &quot;http_server_sg&quot; # vpc_id = &quot;vpc-4dbe6a26&quot; # 貼上AWS 預設的VPC ID vpc_id = aws_default_vpc.default.id # 使用預設的VPC ID ingress { // ingress為入口的限制規則 from_port = 80 to_port = 80 protocol = &quot;tcp&quot; cidr_blocks = [&quot;0.0.0.0/0&quot;] } ingress { // ingress為入口的限制規則 from_port = 22 to_port = 22 protocol = &quot;tcp&quot; cidr_blocks = [&quot;0.0.0.0/0&quot;] } egress { # 讓任何人都能連進來 from_port = 0 to_port = 0 protocol = -1 cidr_blocks = [&quot;0.0.0.0/0&quot;] } tags = { name = &quot;http_server_sg&quot; }}variable &quot;aws_key_pair&quot; { default = &quot;./aws_key_pair/ec2-terraform.pem&quot;}resource &quot;aws_instance&quot; &quot;http_server&quot; { ami = &quot;ami-0e01ce4ee18447327&quot; key_name = &quot;ec2-terraform&quot; instance_type = &quot;t2.micro&quot; vpc_security_group_ids = [aws_security_group.http_server_sg.id] subnet_id = &quot;subnet-16ee127d&quot; connection { # 遠端連接EC2 type = &quot;ssh&quot; host = self.public_ip # 公有ip user = &quot;ec2-user&quot; private_key = file(var.aws_key_pair) } provisioner &quot;remote-exec&quot; { # 遠端執行指令 inline = [ # 連接遠端時，會開始執行一系列的指令 &quot;sudo yum install httpd -y&quot;, # install httpd &quot;sudo service httpd start&quot;, # start # 印出字串訊息至index.html 檔 &quot;echo Welcome to virtual server which is at ${self.public_dns} | sudo tee /var/www/html/index.html&quot;, # copy file ] }} 另外值得一提的是，官方有提到aws_default_vpc不同於其他的resource，Terraform並不會額外建立這項資源，而是直接將它納入管理。 The aws_default_vpc behaves differently from normal resources, in that Terraform does not create this resource, but instead “adopts” it into management.官方文件","link":"2020/04/12/DevOps/Terraform/%5BDevOps%5D%20Terraform%E5%85%A5%E9%96%80(4)%20-%20%E5%88%A9%E7%94%A8Terraform%E4%BE%86%E6%93%8D%E4%BD%9CAWS%20EC2/"},{"title":"[Terraform] Terraform入門(5) - 利用Terraform來建置多個workspace","text":"鼠年全馬鐵人挑戰 - WEEK 10 前言不知不覺Terraform這系列的隨手筆記寫到第五篇，本文記錄如何透過撰寫Terraform腳本來開啟S3、DynamoDB，綁定IAM User，並建置在不同workspace下。 Hands on Lab初始化專案12345# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;} 執行下方指令做初始化 1terraform init 建立S3 bucket、DynamoDB再來就是建立S3 bucket、DynamoDB，會分別定義S3 bucket、DynamoDB兩個resource，S3會設定生命週期為永久保存，並透過versioning設定來紀錄多個版本號，若未來開發時，專案改壞了還可以退回前一個版本！ 123456789101112131415161718192021222324252627282930313233343536# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}# S3 Bucketresource &quot;aws_s3_bucket&quot; &quot;backend_state&quot; { bucket = &quot;dev-application-backend-state01&quot; # 自訂 bucket 名稱 # 設定S3的生命週期 lifecycle { # 永久保存 prevent_destroy = true } # 儲存多個版本號，若之後開發上遇到問題，可退回舊的版本 versioning{ enabled = true } server_side_encryption_configuration{ rule { apply_server_side_encryption_by_default { sse_algorithm = &quot;AES256&quot; } } }}# Locking - DynamoDB resource &quot;aws_dynamodb_table&quot; &quot;dynamodb_demo&quot; { name = &quot;dev_application_dynamodb01&quot; billing_mode = &quot;PAY_PER_REQUEST&quot; hash_key = &quot;LockID&quot; attribute { name = &quot;LockID&quot; type = &quot;S&quot; # 以字串的方式儲存 }} 完成上述程式碼後執行下指令完成建立 1terraform apply 查看兩者是否成功新增 S3 DynamoDB 配置IAM User接著我們要將前面建立的S3、DynamoDB賦予某個User，為了方便管理，另外新建一個名為users的資料夾，目錄結構如下:接著建立main.tf，並寫入下方程式碼，執行terraform init初始化 1234567891011121314151617181920terraform { backend &quot;s3&quot;{ bucket = &quot;dev-application-backend-state01&quot; key = &quot;backendState-proj-dev&quot; region = &quot;us-east-2&quot; dynamodb_table = &quot;dev_application_dynamodb01&quot; encrypt = true }}# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}# AWS IAM Userresource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { name = &quot;my_iam_user_demo&quot; # 被賦予的User名稱} 執行terraform apply後查看新建立的User查看S3設定，會發現剛才給予加密的種類-AES 修改S3存放檔案的路徑上面的範例程式碼成功執行後，檔案會放在S3的根目錄底下，實務上可能會有很多專案存放，這時要個別歸類在不同的專案目錄下，所以我們將原始key(作爲檔案存放路徑)改為dev/user/backendState-proj-dev。 123456789101112131415161718192021terraform { backend &quot;s3&quot;{ bucket = &quot;dev-application-backend-state01&quot; # key = &quot;backendState-proj-dev&quot; key = &quot;dev/user/backendState-proj-dev&quot; # 可自訂檔案路徑 region = &quot;us-east-2&quot; dynamodb_table = &quot;dev_application_dynamodb01&quot; encrypt = true }}# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;}# AWS IAM Userresource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { name = &quot;my_iam_user_demo&quot;} 修改前要記得先執行terraform init進行初始化 系統會提示是否將狀態複製到新的狀態。初始化完成後重新刷新頁面，會看到原本backendState-proj-dev的檔案路徑變成在dev/user/這個路徑下。 建置多個workspace查看當前的workspace1terraform workspace show 尚未建立其他workspace的情況下，workspace名稱為default。 建立新workspace語法如下，workspace為自定的名稱 1terraform workspace new workspace 範例以prod-dev作為新的workspace名稱 1terraform workspace new prod-dev 建立完新的workspace後要進行初始化 1terraform init 回到AWS S3 console介面會發現新增env:資料夾，裡面存放剛才建立的workspace 查看env:資料夾 不過這邊要注意一個地方，點開剛才建立workspace裡的檔案 會發現物件是空的！ 怎麼回事？？？ 因為我們把IAM User寫死了，造成與前一個workspace使用同一組IAM User name，因此將aws_iam_user這個resource修改為動態的IAM User，以當前的workspace name作為前綴 1234resource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { # name = &quot;my_iam_user_demo&quot; name = &quot;${terraform.workspace}_my_iam_user_demo&quot;} 接著執行terraform plan觀察變化prod-dev變為前綴名稱，接著執行terraform apply回到workspace裡的檔案：這一次物件裡面就不是空的～～～之後不管在其他workspace建立的IAM User也不會衝突！ 切換至特定的workspace如果要切回原本的workspace，語法如下方，workspace可替換成目前存在的workspace名稱 1terraform workspace select workspace 以切換回default為例： 1terraform workspace select default 查看所有的workspace1terraform workspace list *之處表當前所處的workspace 除了使用指令查看當前所處的workspace之外，也可以到專案資料夾下的.terraform目錄裡面有一個名為environment的檔案，裡面會顯示當前workspace名稱。 最終的檔案目錄結構如下:","link":"2020/04/13/DevOps/Terraform/%5BDevOps%5D%20Terraform%E5%85%A5%E9%96%80(5)%20-%20%E5%88%A9%E7%94%A8Terraform%E4%BE%86%E5%BB%BA%E7%BD%AE%E5%A4%9A%E5%80%8B%E7%92%B0%E5%A2%83(workspace)/"},{"title":"[Terraform] Terraform入門(1)","text":"鼠年全馬鐵人挑戰 - WEEK 08 前言因目前實習公司代理許多雲服務，有使用Terraform撰寫腳本來管理雲平台，藉此機會筆記一下學習Terraform這項工具。本篇會紀錄如何實際撰寫Terraform腳本來操作AWS S3、IAM這兩項服務。 什麼是Terraform？Terraform是由HashiCorp這家公司所開發，是一個基礎架構即程式碼(Infrastructure as Code;簡稱IaC)的開源工具，關於IaC架構的細節可參考這篇，而且它支持多種雲環境，還可以進行版本控制。可以想像一種情況，如果今天有多個雲要進行管理，可能架構會隨時需要調整，或是要配置資料庫、網路安全等設定時Terraform變成是很好的工具去管理這些雲端的基礎架構。以AWS為例，有了Terraform後，我們便不再需要透過手動操作滑鼠點擊console介面，只要撰寫好 Terraform 腳本，一鍵就能完成想要做的事情，透過程式碼去管理擁有的雲端資源。簡單歸納一下Terraform的優點及特色 針對擁有的雲端服務做版本控管 自動化測試雲端架構 容易閱讀，一起開發的人可閱讀腳本理解目前使用的雲服務相關設定 在不同的環境下(如: 開發、測試、實際上線)，雲服務的配置都會相同 Terraform的檔案副檔名是*.tf 用HCL語言撰寫 跨平台(支援哪些平台可看官方文件) Hands On Lab安裝官方載點如果是Mac的話可以使用Homebrew 1brew install terraform 當然也可以手動下載壓縮檔，解壓縮到/usr/bin、/usr/local/bin 目錄，解壓縮得到編譯好的執行檔。 查看版本檢查是否可執行terraform，開啟終端機，輸入terraform -version，會顯示當前terraform版本訊息 初始化Provider先來個範例吧！在專案資料夾建立一個名為main.tf的檔案 1234# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot;} 下指令進行初始化 1terraform init terraform 會根據在當前的目錄下產生一些本地端設定，並根據上面的設定下載相對應的二進位檔，放到.terraform目錄中。上述的程式碼中，provider用於決定對哪一個平台操作 region是AWS需要的屬性，表示地區。 配置Provider將終端機出現的version = &quot;~&gt; 2.55&quot; 這段資訊加入main.tf內。 12345# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-east-2&quot; version = &quot;~&gt; 2.55&quot;} 查看當前目錄結構 下載並匯出 Access Key開啟終端機，輸入下方指令，並替換成自從AWS download下來的Access Key 12export AWS_ACCESS_KEY_ID=Your Access Keyexport AWS_SECRET_ACCESS_KEY=Your SECRET ACCESS Key 建立S3配置resourceresource是表示決定用指定雲平台中的哪個服務(資源)，採類似JSON的結構，結構大概會是 123resource 雲端服務(服務)名稱 自定資源名稱 { 屬性 = 值} 以AWS S3作為範例: 1234# plan - excuteresource &quot;aws_s3_bucket&quot; &quot;my_s3_bucket&quot; { bucket = &quot;my-s3-bucket-terraform-01&quot;} 上述程式碼表示以aws_s3_bucket為雲端資源(AWS有S3這項儲存靜態資源的服務)，並自定義一個my_s3_bucket名稱 查看Terraform異動在實際執行之前觀察 Terraform 將做哪些哪些改變，這是為了防止我們修改到我們不應該修改的東西，或是有不是我們預期的結果 1terraform plan 執行/創建1terraform apply 這裡 Terraform 一樣會輸出相關的資訊內容，告訴你會有哪些改變，並讓你輸入去確認是否真的要執行，只要輸入 yes，就會實際開啟S3服務了。建立成功！ 成功後回到S3 管理介面就會看到剛剛建立好的bucket囉！ 查看狀態(state)terraform在執行完後，會在當前目錄下產生一個terraform.tfstate檔，此檔案包含了透過terraform 產生出來resource的詳細資訊，而terraform依據這個檔案來追蹤及維護resource。輸入下方指令可秀出當前resource狀態的相關資訊 1terraform show 異動假設今天我們把bucket = &quot;my-s3-bucket-terraform-01&quot;改成bucket = &quot;my-s3-bucket-terraform-02&quot;並執行terraform apply，會看到如下圖所示的異動資訊回到S3管理介面會看到名稱已經做更動 因為terraform.tfstate保留所有resource的狀態，執行terraform命令時，這個檔案必須要存在，確保 terraform可以正確的監聽resource的狀況。 另外，透過terraform plan指令，可以讓你在實際執行之前觀察Terraform將做哪些哪些改變 啟動VersioningS3有個Versioning的功能，現在我們要透過撰寫.tf黨的方式來開啟這個功能，於resource內添加versioning {enabled = true}這段程式碼 123456resource &quot;aws_s3_bucket&quot; &quot;my_s3_bucket&quot; { bucket = &quot;my-s3-bucket-terraform-02&quot; versioning { enabled = true }} 添加完畢之後執行terraform apply，terraform會自動幫我們變更S3的設定，執行後會看到下方這段訊息:表示versioning功能已被開啟，接著回到aws S3的console介面點選my-s3-bucket-terraform-02，找到Properties上圖可檢視此功能成功被開啟！ 刪除執行terraform destroy就可以清除所有的資源，會要你輸入yes做為確認。 terraform consoleterraform也提供console的方式來遠端操作 實作執行下方指令進入console 1terraform console 如果要查看剛剛建立的S3 bucket，依照resource中的type.name的方式輸入指令，如: 1aws_s3_bucket.my_s3_bucket 表示從aws_s3_bucket這個resource中選擇剛剛建立的my_s3_bucket執行指令後會秀出該Bucket內含的相關資訊。當然我們也可以往下找更詳細的資訊，如剛剛新增的versioning指令 1aws_s3_bucket.my_s3_bucket.versioning 回傳值為一個list資料結構的資訊，所以可以近一步取得list內的物件。 1aws_s3_bucket.my_s3_bucket.versioning[0].enabled 退出console1exit Output 查看輸出訊息除了利用console查看.tf配置的訊息外，也可以撰寫output語法來輸出我們想要的訊息，例如印出剛剛在console內看到的訊息，可以把aws_s3_bucket.my_s3_bucket.versioning[0].enabled放入output中，如： 123output &quot;my_s3_bucket_versioning&quot; { value = aws_s3_bucket.my_s3_bucket.versioning[0].enabled} my_s3_bucket_versioning為自己定義的名稱，接著執行terraform apply -refresh=false查看訊息或是可以印出完整的訊息 123output &quot;my_s3_bucket_detail&quot; { value = aws_s3_bucket.my_s3_bucket} 操作IAM接著用terraform腳本來建立AWS IAM User 1234# IAM Userresource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { name = &quot;my_iam_user001&quot;} 在終端機輸入指令 1terraform plan -out iam.tfplan 畫面會提示輸入terraform apply &quot;iam.tfplan&quot;的指令印出上圖訊息表示成功建立IAM User如上圖，進入IAM User Console介面就會看見剛剛建立好的User哦！當然我們也可以印出output來做檢查 123output &quot;my_iam_user_detail&quot; { value = aws_iam_user.my_iam_user} 更新IAM User name假設要更改User名my_iam_user001為my_iam_user001_update 1234# IAM Userresource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { name = &quot;my_iam_user001_update&quot;} 更改完畢後，輸入下方指令 1terraform apply -target=aws_iam_user.my_iam_user 建立多個IAM User本篇只有先記錄最基礎的用法，更多相關用法可參考官方文件。假設今天要一次建立兩個User，做法是給予IAM User這個Resource次數(count)，並透過物件的方式assign，如： 1234resource &quot;aws_iam_user&quot; &quot;my_iam_user&quot; { count = 2 name = &quot;my_iam_user_${count.index}&quot;} 其中index編號是從0開始，執行terraform apply後打開console介面會看到新建立的兩個User，分別為my_iam_user_0、my_iam_user_1 補充一些較常用的指令 terraform fmt： 將指令進行統一格式，改善因多人共同開發，各自風格差異過大的問題。 terraform graph： 圖形化所有資源的相異性。 terraform import : 導入目前已經在雲端上手動建立資源到Terraform中。 terraform validate： 用於驗證是否存在語法錯誤。 以上透過AWS兩個服務範例來實作Terraform腳本，倘若有疏漏或錯誤之處，可在下方留言讓我知道！ 參閱Terraform 入門學習筆記","link":"2020/04/02/DevOps/Terraform/%5BDevOps%5D%20Terraform%E5%85%A5%E9%96%80/"},{"title":"[Django] 在 Ubuntu 中運用 Nginx、Gunicorn 架設 Django API Server","text":"鼠年全馬鐵人挑戰 - WEEK 19 前言目前正在進行一個Side Project，用朋友開給我的虛擬機(VM)架設一台API Server，趁還有記憶時趕快來筆記一下。 前置作業: OS: Ubuntu 18.04 Web Framework: Django 3.0; djangorestframework 3.11 Server: Nginx 1.14 Database: MySQL 實作架構圖如下: 安裝環境安裝所需要的環境，會下載python3、mysql、nginx 12sudo apt-get updatesudo apt-get install python3-pip python3-dev mysql-server libmysqlclient-dev nginx 資料庫12sudo mysql_install_dbsudo mysql_secure_installation 執行上述指令進行初始化，系統會詢問一些相關設定，可以全部都採預設的方式。其中，要設定root權限的密碼，設定完之後執行下方指令登入root帳號 1mysql -u root -p 完成登入便會進入MySQL Shell，在Shell中寫下腳本建立資料庫 1CREATE DATABASE &lt;yourprojectname&gt; CHARACTER SET UTF8; 將上述的&lt;yourprojectname&gt;替換成自己要建立的資料庫名稱，其中utf8為Django預設得編碼。 接著是在MySQL中建立另一個User，建議之後都使用User的帳號來登入資料庫！ 1CREATE USER &lt;yourdbuser&gt;@localhost IDENTIFIED BY '&lt;password&gt;'; 上述指令中，&lt;yourdbuser&gt;為自訂的User名稱，&lt;password&gt;為自訂的密碼，注意密碼要以字串的形式撰寫(要有'')。 1GRANT ALL PRIVILEGES ON &lt;yourprojectname&gt;.* TO &lt;yourdbuser&gt;@localhost; 執行上述指令，賦予剛建立的User訪問資料庫的權限。 12FLUSH PRIVILEGES;exit 專案下載相依套件 12sudo -H pip3 install --upgrade pipsudo -H pip3 install virtualenv 如果先前在Github上的repo已經有專案，可以直接Clone到Ubuntu的環境中 1git clone repoAddress 或是直接在Ubuntu中建立新的專案 12mkdir ~/&lt;yourprojectdir&gt;cd ~/&lt;yourprojectdir&gt; 在專案資料夾中建立虛擬環境 1virtualenv &lt;yourenv&gt; 啟動虛擬環境 1source &lt;yourenv&gt;/bin/activate 以我為例，我的虛擬環境名稱為env 啟動虛擬環境後會看到終端機的最左方有的(env)表示啟動虛擬環境，若要退出虛擬環境則執行deactive。 下載專案所需的相依套件 1pip3 install django gunicorn pymysql djangorestframework 建立Django restframework的手把手教學可以參考官網範例。 本文是直接Clone之前已經在Github建立好的Repo，建立Django專案的部分便不多加詳述，主要是紀錄部署到實際環境需要修改的設定。 到Django主要專案的資料夾下，建立一個名為__init__.py的檔案 1vim __init__.py 寫下下方程式碼__init__.py 123import pymysqlpymysql.version_info = (1, 3, 13, &quot;final&quot;, 0)pymysql.install_as_MySQLdb() 寫完上述程式碼後儲存離開ESC+:wq!接著在settings.py中做下方幾個更改 1vim settings.py settings.py 12345678910111213141516ALLOWED_HOSTS = [ 'domain.com', '&lt;yourserverip&gt;', 'localhost']# 此數將預設的SQLite替換成MySQLDATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': '&lt;yourdatabasename&gt;', # 資料庫名稱 'USER': '&lt;yourdbuser&gt;', # 資料庫使用者帳號 'PASSWORD': '&lt;password&gt;', # 資料庫密碼 'HOST': 'localhost', # 主機位置 'PORT': '3306', }}STATIC_URL = '/static/'STATIC_ROOT = os.path.join(BASE_DIR, 'static/') 寫完上述程式碼後儲存離開ESC+:wq!ALLOWED_HOSTS為網域名稱、IP，還有設定連接Mysql資料庫，輸入剛才前面設定資料時，建立的資料庫名稱、使用者帳號、密碼。最後是STATIC_ROOT為設定靜態資源的根路徑。 執行 1python3 manage.py collectstatic 執行下方指令進行資料庫遷移 12python3 manage.py makemigrationspython3 manage.py migrate gunicorn使用gunicorn測試Server12cd ~/&lt;yourprojectdir&gt;gunicorn --bind 0.0.0.0:8000 &lt;yourproject&gt;.wsgi 成功後會看到下方畫面接著訪問你的伺服器IP加上Port號即可查看目前運作狀況，如xxx.xxx.xx.xx:8000。跳出當前虛擬環境 1deactivate 設定gunicorn建立gunicorn.socket 1sudo vim /etc/systemd/system/gunicorn.socket 檔案寫入 12345678[Unit]Description=gunicorn socket[Socket]ListenStream=/run/gunicorn.sock[Install]WantedBy=sockets.target 寫完上述程式碼後儲存離開ESC+:wq! 確認一下gunicorn的位置，因為後續建立gunicorn.service檔時會使用到 1which gunicorn 執行上述指令會回傳gunicorn的路徑 建立gunicorn.service 1sudo vim /etc/systemd/system/gunicorn.service gunicorn.service檔案寫入 1234567891011121314151617[Unit]Description=gunicorn daemonRequires=gunicorn.socketAfter=network.target[Service]User=&lt;youruser&gt; # 此處輸入這台機器的使用者名Group=www-dataWorkingDirectory=&lt;path/to/yourprojectdir&gt; # 輸入Django專案的路徑ExecStart=&lt;gunicorn_path&gt; \\ # 輸入gunicorn的路徑 --access-logfile - \\ --workers 3 \\ --bind unix:/run/gunicorn.sock \\ &lt;yourproject&gt;.wsgi:application[Install]WantedBy=multi-user.target 寫完上述程式碼後儲存離開ESC+:wq!啟用 Gunicorn socket 12sudo systemctl start gunicorn.socketsudo systemctl enable gunicorn.socket 檢查Gunicorn socket是否運作成功 1sudo systemctl status gunicorn.socket 成功會顯示綠色active字樣 檢查gunicorn.sock 檔案是否存在/run這個資料夾中 1file /run/gunicorn.sock 如果發現沒有在/run這個資料夾中，或是有其他問題，可以執行下方指令查看Log找問題 1sudo journalctl -u gunicorn.socket 測試Server運作情況 1sudo systemctl status gunicorn 或是發Curl測試 1curl --unix-socket /run/gunicorn.sock localhost 回傳結果為HTML格式的資料要對gunicorn排查問題也可以執行下方指令看Log 1sudo journalctl -u gunicorn 若遇到問題，且查看Log後將問題排除，需要再重新run一次gunicorn 12sudo systemctl daemon-reloadsudo systemctl restart gunicorn 配置Nginx代理傳給Gunicorn1sudo vim /etc/nginx/sites-available/project_name.conf project_name修改為專案名稱project_name.conf 1234567891011121314server { listen 80; server_name &lt;domain_name&gt; &lt;server_ip&gt;; # 此處輸入網域名及ip，兩者以空格隔開。 location = /favicon.ico { access_log off; log_not_found off; } location /static/ { root &lt;your_static_root_path&gt;; # static的根目錄位置 }location / { include proxy_params; proxy_pass http://unix:/run/gunicorn.sock; }} 將檔案連結到啟動網站的目錄來啟動該檔案 123sudo ln -s /etc/nginx/sites-available/project_name.conf /etc/nginx/sites-enabledsudo nginx -tsudo systemctl restart nginx 設防火牆需要開放80 port上的流量，並刪除8000 port，禁止訪問。 12sudo ufw delete allow 8000sudo ufw allow 'Nginx Full' 建立成功！","link":"2020/07/19/Python/Django/%5BDjango%5D%20%E5%9C%A8Ubuntu%E4%B8%AD%E9%81%8B%E7%94%A8Nginx%E3%80%81Gunicorn%20%E6%9E%B6%E8%A8%AD%20Django%20API%20Server/"},{"title":"[Python] Django連接現有MySQL資料庫","text":"鼠年全馬鐵人挑戰 - WEEK 01 前言Django預設的資料庫使用sqlite3，本篇紀錄如何從預設的sqlite3改完連接MySQL中現有的資料庫，本篇也作為今年參加鼠年全馬鐵人挑戰的開篇 XD 安裝我是在虛擬環境下安裝，使用pipenv做套件管理。 安裝pymysql1pipenv install pymysql 安裝django1pipenv install django 建立專案建立名為mysite的專案名稱1django-admin startproject mysite 建立名為exrate的APP1python manage.py startapp exrate 相關設定設定__init__.py檔至專案根目錄(mysite)下的__init__.py檔，添加下方兩行程式碼: 12import pymysqlpymysql.install_as_MySQLdb() 設定database至專案根目錄(mysite)下的settings.py檔，替換成下方程式碼: 123456789101112131415DATABASES = { 'default': { # ========= 將預設的sqlite3 ENGINE 還有 NAME 註解掉 ========= # 'ENGINE': 'django.db.backends.sqlite3', # 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), # ========= 配置自己的MySQL ========= 'ENGINE': 'django.db.backends.mysql', 'NAME': 'exrate', # 目標資料庫的名稱 'USER': 'your account', # 資料庫帳號 'PASSWORD': 'your password', # 資料庫密碼 'HOST': 'localhost', # 主機位置，可以先測本地localhost 'PORT': '8889', # 設定連接埠 }} 連接連接已有的資料庫與Django app1python manage.py inspectdb 可能會遇到的問題: 版本問題執行上個連接步驟的指令時，可能會遇到以下錯誤: 解決方法上方圖片中的錯誤訊息有提示問題發生在哪個檔案，打開提示路徑下的目標檔案base.py，檔案內尋找version = Database.version_info的程式碼，會看到下方程式碼: 123version = Database.version_infoif version &lt; (1, 3, 13): raise ImproperlyConfigured('mysqlclient 1.3.13 or newer is required; you have %s.' % Database.__version__) 上述程式碼改成 1234version = Database.version_infoif version &lt; (1, 3, 13): pass #raise ImproperlyConfigured('mysqlclient 1.3.13 or newer is required; you have %s.' % Database.__version__) 更改後存檔，在執行一次連接MySQL資料庫的指令 1python manage.py inspectdb 執行結果 引用inspectdb套件建立模型第一種方法複製執行後所看到的程式碼內容貼到建立的app專案資料夾中的models.py 第二種方法將下方指令中的myapp替換成自己建立的app專案名稱並執行 1python manage.py inspectdb &gt; myapp/models.py 建立migrations資料表myapp替換成自己建立的app專案名 1python manage.py makemigrations myapp migrate同步資料表myapp替換成自己建立的app專案名 1python manage.py migrate myapp 完成遷移！ 參考資料官方文件-舊有資料庫遷移","link":"2020/02/13/Python/Django/%5BPython%5D%20Django%E9%80%A3%E6%8E%A5%E7%8F%BE%E6%9C%89MySQL%E8%B3%87%E6%96%99%E5%BA%AB/"},{"title":"[Python] Django筆記 - Django Template Language(1)","text":"鼠年全馬鐵人挑戰 - WEEK 02 前言Django提供獨特的模板語法，將HTML頁面做動態載入。因為在HTML檔，無法使用python來撰寫程式，Django的模板引擎讓撰寫好的python程式碼可以建構在網頁上面。簡單來說，透過模板語法，我們可以在HTML檔寫入python的程式碼，讓網頁變成動態載入的狀態。 Template相關設定(Configuration)至專案根目錄下找到settings.py檔案，搜尋TEMPLATES，便能夠看到以下設定： Django 預設去找 TEMPLATES 的設定DIRS: 為Django額外搜尋TEMPLATES的目錄，如果要另外設定的話，在這個地方填寫自訂的路徑 一般情況下，會習慣在每個新增apps 專案目錄下創建該apps的專屬templates資料夾，因為Django預設會去找名為templates資料夾下的檔案。 實作註冊APP先建立Django application(app)，例如建立名為food的app，並在settings.py檔案下找到INSTALLED_APPS，在末端加入'food'。 指定專案路徑再到urls.py，設定path('food/', include(&quot;food.urls&quot;) ),，指定food專案的根路徑。 建立模板在food資料夾下另外設立一個template目錄，新增index.html(我有多一層food資料夾做區分)index.html 12345678910&lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Index&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt;Welcome to Django!!!&lt;/h2&gt; &lt;/body&gt; &lt;/html&gt; 載入模板並進行渲染(render)app專案下的views.py寫入下方程式碼 123456from django.shortcuts import renderfrom django.http import HttpResponsefrom django.template import loader def index(request): template = loader.get_template('food/index.html') # getting our template return HttpResponse(template.render()) # rendering the template in HttpResponse 查看頁面開啟伺服器，執行python3 manage.py runserver，原始網頁路徑加上/food即可看到渲染出來的index.html畫面 各式語法變數(Variables)兩個花括弧{ {} }裡面放入傳遞過去的變數。 範例傳遞Hello index!訊息，並assign給變數名txt，將此變數傳遞到index.html檔進行渲染。views.py 1234from django.shortcuts import renderdef index(request): txt = &quot;Hello index!&quot; return render(request, 'food/index.html', {&quot;txt&quot;: txt} ) 在index.html檔中加入&lt;h3&gt; { {txt} } &lt;/h3&gt;，變數的值就會被模板語法渲染上去了！ 1234567891011&lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Index&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt;Welcome to Django!!!&lt;/h2&gt; &lt;h3&gt; { {txt} } &lt;/h3&gt; &lt;/body&gt; &lt;/html&gt; 標籤(Tags)Django提供填入標籤的模板語法: { % tag % }，藉由{ % tag % }可以寫入更複雜的邏輯，如:if-else、for等等。 條件判斷1234567{ % if athlete_list % } Number of athletes: { { athlete_list|length } }{ % elif athlete_in_locker_room_list % } Athletes should be out of the locker room soon!{ % else % } No athletes.{ % endif % } 迴圈12345&lt;ul&gt;{ % for athlete in athlete_list % } &lt;li&gt;{ { athlete.name } }&lt;/li&gt;{ % endfor % }&lt;/ul&gt; 繼承Django提供繼承的模板語法，讓開發者可以做到重複利用、彈性更動。 區塊標籤(block tags)定義一個區間，讓繼承者做更動 =&gt; 彈性更動 1{ % block name % } .... { % endblock % } 展延標籤(extends tags)很多時候一個網站某部分的頁面會重複，為了避免一直寫重複的代碼，可以使用extends tags。 =&gt; 重複利用 1{ % extends &quot;xxx.html&quot; % } 實際應用時，通常會針對網頁重複的部分獨立出一個HTML檔。 實作建立一個base.html的HTML，網頁內容重複的部分都寫在這個檔，例如:網站的導覽條 base.html 12345678910111213141516171819202122232425262728293031&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;!-- Required meta tags --&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt; &lt;!-- Bootstrap CSS --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css&quot; integrity=&quot;sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh&quot; crossorigin=&quot;anonymous&quot;&gt; &lt;title&gt;Index&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;nav class=&quot;navbar navbar-dark bg-dark&quot;&gt; &lt;a href=&quot;#&quot; class=&quot;navbar-brand&quot;&gt; FoodApp&lt;/a&gt; &lt;div class=&quot;navbar&quot;&gt; &lt;a href=&quot;#&quot; class=&quot;nav-item nav-link&quot;&gt; Add Item&lt;/a&gt; &lt;a href=&quot;#&quot; class=&quot;nav-item nav-link&quot; &gt; Delete Item&lt;/a&gt; &lt;a href=&quot;#&quot; class=&quot;nav-item nav-link&quot;&gt; Menu Item&lt;/a&gt; &lt;/div&gt; &lt;/nav&gt; { % block body % } { % comment % } 此處為彈性更動之處 { % endcomment % } { % endblock % } &lt;!-- Optional JavaScript --&gt; &lt;!-- jQuery first, then Popper.js, then Bootstrap JS --&gt; &lt;script src=&quot;https://code.jquery.com/jquery-3.4.1.slim.min.js&quot; integrity=&quot;sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js&quot; integrity=&quot;sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js&quot; integrity=&quot;sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; { % block body % }{ % endblock % }內就是之後被引入其他檔案中，會變動的內容。再來看index.html檔 123456789101112131415161718192021222324252627282930313233343536373839{ % extends 'food/base.html' % }&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;!-- Required meta tags --&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt; &lt;!-- Bootstrap CSS --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css&quot; integrity=&quot;sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh&quot; crossorigin=&quot;anonymous&quot;&gt; &lt;title&gt;Index&lt;/title&gt; &lt;/head&gt; &lt;body&gt; { % block body % } { % for item in item_list % } &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-3 offset-md-2&quot;&gt; &lt;img class=&quot;card&quot; height=&quot;150px&quot; src=&quot;{ { item.item_iamge } }&quot;&gt; &lt;/div&gt; &lt;div class=&quot;col-md-4&quot;&gt; &lt;h3&gt;{ { item.item_name } }&lt;/h3&gt; &lt;h4&gt;{ { item.item_desc } }&lt;/h4&gt; &lt;h5&gt;${ { item.item_price } }&lt;/h5&gt; &lt;/div&gt; &lt;div class=&quot;col-md-2&quot;&gt; &lt;a href=&quot;{ % url 'food:detail' item.id% }&quot; class=&quot;btn btn-success&quot;&gt;Details&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; { % endfor % } { % endblock % } &lt;!-- Optional JavaScript --&gt; &lt;!-- jQuery first, then Popper.js, then Bootstrap JS --&gt; &lt;script src=&quot;https://code.jquery.com/jquery-3.4.1.slim.min.js&quot; integrity=&quot;sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js&quot; integrity=&quot;sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js&quot; integrity=&quot;sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 上面index.html檔案內的{ % extends 'food/base.html' % }作為繼承base.html的結構，並在{ % block body % }... { % endblock % }內寫上要變動的內容 結果 跨站請求偽造的防護1{ % csrf_token % } 參閱 Official Doc Django 命名空間(NameSpace) Django Tutorial- Template Day14 : Template 的運作","link":"2020/02/20/Python/Django/%5BPython%5D%20Django%E7%AD%86%E8%A8%98%20-%20Django%20Template%20Language(1)/"},{"title":"[Python] Django 筆記","text":"什麼是 Django?一個基於python建立的Ｗeb框架(Framework)，幫你把大部分的程式架構都建構好，開發者可基於這個骨幹結構做開發應用，加強程式開發速度、重用性和程式的可讀性。相較於傳統的MVC(Model-View-Contorller)架構，Django也有屬於它的MTV(Model-Template-Views)架構。 Django的運作的架構及流程架構Django架構主要分為下面四個部分 Django本體：主要提供路由的功能 Model: 與資料溝通 View: 處理請求，進行資料計算，並決定顯示template資料內容 Template: 資料呈現，主要檔案是放靜態頁面，通常是html文件 Cache: 保存擷取過的網頁資料，加速瀏覽速度 MTV與一般看到的MVC架構稍微不同的點在於Template主要放純靜態網頁的資料。 流程接著來看Django的運作流程假設有用戶要訪問Django架設的頁面，會在瀏覽器上輸入網址，瀏覽器在得到網址之後，會經過路由，如果路由發現這個網頁的內容使用者已經有，快取(Cache)模組就會返還之前擷取過的資料，加速瀏覽速度;若沒有，則會去找Template要網頁資料，Template回傳基本的html網頁之後，Template顯示的內容一部分的資料需透過View去決定，有些內容可能需要從資料撈取的話，會透過Model向資料庫溝通。 Hands on Lab使用Pipenv在虛擬環境中安裝django1pipenv install django 建立Django專案專案名稱為stocks 1django-admin.py startproject stocks 資料夾結構 Django的Management commandsmanage.py 為Django提供的命令列工具，提供許多不同功能的指令。 啟動Django伺服器切換stocks資料夾下 1python manage.py runserver 打開瀏覽器輸入 http://127.0.0.1:8000/ 或是 http://localhost:8000/，會看到django專案已成功在 web server 上執行。 若想了解有哪些指令可用，輸入 help或-h指令會列出所有指令列表: 1python manage.py -h 上圖可以看到紅色錯誤訊息，我們需要對資料庫做同步。 1python manage.py migrate 指令會根據你對 Model 的修改刪除建立一個新的 migration 檔案，讓 migrate 指令執行時，可以照著這份紀錄更新資料庫。Model說明文件 Admin大部份網站都設計有管理後台，讓管理者方便新增或異動網站內容。而這樣的管理後台，Django 也有內建一個 App – Django Admin 。只需要稍微設定，網站就能擁有管理後台功能。 建立一個管理員帳號(superuser) 1python manage.py createsuperuser 接著將帳號密碼等設定完成後重啟一次Django，輸入剛設定的管理員(superuser)即可登入 建立 Django application（app）每一個 Django project 裡面可以有多個 Django apps。實作時，通常會依功能分成不同 app，方便管理及重複使用。以quotes為app的名稱為例: 1python manage.py startapp quotes 此時的檔案目錄結構多一個quotes專案(app)資料夾 但若要讓 Django 知道要管理哪些 apps，還需再調整設定檔。作法： 打開 stocks/settings.py，找到 INSTALLED_APPS 注意 app 之間有時候需要特定先後順序，盡量將自訂的apps加在最後面 在quotes專案資料夾下創建一個名為url.py的檔案。 假如一個project中有多個app，用以上的方式來管理url可能會造成比較混亂的局面，為了解決這個問題，我們可以用include的方法來配置url 1234567from django.contrib import adminfrom django.urls import path , include # 配置urlurlpatterns = [ path('admin/', admin.site.urls), path('', include(&quot;quotes.urls&quot;) ),] Django 的 MTV 架構處理 request 的流程: 瀏覽器送出 HTTP request Django依URL配置分配至對應的View View進行資料庫的操作或其他運算，並回傳HttpResponse物件 瀏覽器依據 HTTP response 顯示網頁畫面 Django的MTV架構View用 render 這個 function 產生要回傳的 HttpResponse 物件建立一個function用於處理 HttpRequest 物件，並回傳 HttpResponse 物件，下圖範例是在quotes資料夾下的views.py檔從網頁接收到 request 後，會將 request 中的資訊封裝產生一個 HttpRequest 物件，並當成第一個參數，傳入對應的 view function。HttpResponse 物件官方說明 上面可以看到當about(requset)被呼叫時，回傳一個名為about.html的網頁名稱。 URL 設定在quotes資料夾下建立一個新資料夾做templates，templates資料夾下新增about.html檔，現在要對about這個網頁做路徑對應的配置，通常會定義在urls.py檔，所以在quotes資料夾下創建urls.py，建立URL 與 view 的對應關係，稱作URL conf (URL configuration)範例: 123456from django.urls import pathfrom . import viewsurlpatterns = [ # 設置路徑、接收view回傳的頁面 path('about.html', views.about, name= &quot;about&quot;),] 從views.py將定義好的function 做import。 再到stocks資料夾下的urls.py做配置，先import include，加入quotes.urls，連結quotes的url配置，方便進行管理。 TemplateTemplate可以幫助我們將前端頁面存放的一個獨立資料夾，一來不會全部丟在view內，二來如果未來也比較好與做前端頁面的人合作，對方只需要將寫好的頁面放置在template下即可。打開資料夾settings.py，搜尋TEMPLATES，便能夠看到以上設定。Django 預設會去找 TEMPLATES 的設定，DIRS是讓Django額外搜尋TEMPLATES的目錄settings.py內搜尋BASE_DIR，透過BASE_DIR設定，可以了解預設的專案的路徑。 ModelDjango預設使用後端的資料庫系統為SQLite，可以在settings.py檔案下搜尋DATABASES，Django已先做好設置。 說明: ENGINE – 要使用的資料庫引擎。例如：MySQL: django.db.backends.mysqlSQLite3: django.db.backends.sqlite3PostgreSQL: django.db.backends.postgresql_psycopg2 NAME – 資料庫名稱若使用MySQL或PostgreSQL等其他資料庫，還需另外設定它的位置、名稱、使用者。Model的幾個重點: 負責資料層、操作Database 基於ORM，且用Class 定義資料格式，建立資料欄位。 Model Fields 可為 Django Model 定義不同型態資料屬性，紀錄幾個比較常用的:CharField — 字串欄位，適合像 title、location 這種有長度限制的字串。TextField — 合放大量文字的欄位URLField — URL 設計的欄位DateTimeField — 日期與時間的欄位，使用時會轉成Python datetime 型別。 步驟 到model.py檔內建立名為Stock的物件，Django會依據這個建立資料表，以及資料表裡的欄位設定。12345class Stock(models.Model): # CharField: 定義資料格式為字串 ticker = models.CharField(max_length=10) def __str__(self): return self.ticker 接著執行python manage.py makemigrations，makemigrations會告訴 Django，Model有所變動，這會建立一個遷移（migration）檔案。 對Model進行註冊，需要在讓Django知道，有哪些Model需要管理後台。資料庫同步，完成遷移。1python manage.py migrate 執行上述指令即可完成遷移。 參考教學:來源1來源2來源3","link":"2020/01/11/Python/Django/%5Bpython%5DDjango%20%E7%AD%86%E8%A8%98/"},{"title":"[Python] 淺談 Python 中的Decorator (上)","text":"前言之前專題寫Linebot時用Flask串接Linebot的SDK，一開始只是照個官方給的 Sample Code 去架設Linebot，後來深入研究Sample Code後一直不太理解裡面@的意涵，利用空檔撰寫這篇文章，加深對 Decorator 的觀念。 Decorator 中文翻作 裝飾器，裝飾 Python 中的 class 和 function，它其實是 Python 的一種語法糖(簡化寫法)，不僅能使程式碼重複利用，將程式碼化繁為簡，更易於擴充，故被廣泛實作在套件上，而辨識 Decorator 的方法就是 Decorator 名稱前面會以@做開頭。如下圖的 @app: Decorator背後牽涉到兩個很重要的觀念 - 閉包(Closure) 以及頭等函式 (First-class Function)， 相關討論記錄在這篇筆記 本文主要著重探討 Decorator 的概念。 實作Smaple Code (Decorator)來看簡單範例: 12345678def print_my_name(name): print(&quot;My name is %s&quot; %(name()))@print_my_namedef my_name(): return &quot;Tom&quot; # My name is Tom 執行上面的範例結果，可以發現函式看起來好像沒有東西被呼叫，卻自動被執行?那如果改成呼叫my_name()函式的話會出現錯誤情形。 12345678def print_my_name(name): print(&quot;My name is %s&quot; %(name()))@print_my_namedef my_name(): return &quot;Tom&quot; my_name() 如果呼叫 my_name() 的話就報 TypeError: 'NoneType' object is not callable 的錯誤訊息 還原Sample Code (不加Decorator)上述有使用@做簡化的範例程式碼，如果要還原成不加Decorator的話: 12345678def print_my_name(name): print(&quot;My name is %s&quot; %(name())) return namedef my_name(): return &quot;Tom&quot;name = print_my_name(my_name) 由上述例子可知: function也可作為參數傳遞並執行。 前後比較有無Decorator的範例發現，有Decorator的程式碼省略掉name = print_my_name(my_name)，不必多寫。透過範例，可以把它簡單理解為: 對一個函式進行打包的動作，後續可重複呼叫打包過的函式。利用function可作參數傳入的特性，將my_name()作為參數傳入print_my_name(name)中(做為decorator)。 原因name = print_my_name(my_name) 表示把my_name這個 function傳入print_my_name做處理，再把 print_my_name(my_name) 的回傳值assign給變數name。 一開始的my_name是function，但是因為重新賦值的關係，my_name() 已經不是一個function，而是與 print_my_name(my_name)的回傳值連結在一起。 12print(my_name)# None 因為print_my_name沒有指定回傳的值，python會預設return None，最後執行print(my_name)時就會得到None的結果。 解決方法針對剛才加入Decorator範例中，呼叫my_name()報錯問題，只需在加上@的函式裡面做return，回傳由外部傳入的參數即可！ 1234567def print_my_name(name): print(&quot;My name is %s&quot; %(name())) return name @print_my_namedef my_name(): return &quot;Tom&quot; 或是單純不想印出錯誤訊息的話可以在呼叫函式時刪除() 12345678def print_my_name(name): print(&quot;My name is %s&quot; %(name()))@print_my_namedef my_name(): return &quot;Tom&quot; my_name 分析函數舉剛才未使用Decorator範例，若印出name的話: 123456789def print_my_name(name): print(&quot;My name is %s&quot; %(name())) return namedef my_name(): return &quot;Tom&quot;name = print_my_name(my_name)print(name) 回傳值會是一個function物件。若要執行function物件的內容，需改成print_my_name(my_name)()，因為print_my_name(my_name)只會return function自己，必須在後面加上()來呼叫。 12345678def print_my_name(name): print(&quot;My name is %s&quot; %(name())) return namedef my_name(): return &quot;Tom&quot;name = print_my_name(my_name)() 以上是目前整理Python裝飾器(Decorator)初步的用法，其實裝飾器的寫法總共有四種，更多Python Decorator的進階用法留待下一篇。 如果觀念上有不正確或是文章內容有錯誤之處還請看過文章的人指教！ 參閱 Advanced Uses of Python Decorators Python Decorator 入門教學 Python進階技巧 (3) — 神奇又美好的 Decorator 萬惡的 Python Decorator 究竟是什麼？","link":"2020/02/05/Python/Python/%5BPython%5D%20Decorator(%E4%B8%8A)/"},{"title":"[Python] Lambda函式","text":"前言一般來說，如果Python要定義一個函式，基本上是使用def來定義，而Lambda函式是一種無名函式(anonymous function)，不需給函數名稱，基於追求簡潔的設計原則，內容只能有一則運算式。 Lambda函式的程式碼只能有一行，可以放一個運算式，或是一個單行if-else，但不能使用指定運算子，也不可以跑迴圈。 特點 匿名的函式 結構簡單、使用頻率過少、節省記憶體 “用完即丟”，只會用一次 運算式的計算結果會自動回傳，不需做return 實作語法結構為: lambda arg1, arg2, …: operation ...arg帶入目標參數，冒號:後方的operation則寫入運算式或條件判斷式等，好比一般函式裡的程式碼。 範例1假設今天要寫一個函式判斷傳入的數是否為偶數 一般寫法：12345def isEven(n): return &quot;yes&quot; if n %2 == 0 else &quot;no&quot;print(isEven(10)) # yesprint(isEven(5)) # no Lambda函式:123f = lambda n : &quot;yes&quot; if n %2 == 0 else &quot;no&quot;print(f(10)) # yesprint(f(5)) # no 範例2123def isEven1(a, b): return True if (a+b) % 2 == 0 else Falseprint(isEven1(2, 3)) Lambda函式:12f = lambda a, b : True if (a+b) % 2 == 0 else Falseprint(f(2, 3)) 常搭配的函式filter()利用filter()函式進行資料篩選。假設今天要建立篩選不及格成績的lambda函式可採下面的方法。 12345scores = [90, 10, 80, 30, 100, 80]faile = lambda x: True if x &lt; 60 else Falsefaile_scores = filter(faile, scores)print([k for k in faile_scores]) # [10, 30] map()map()利用一個指定的函式來處理資料，回傳一組處理過的新資料。假設今天要調整學生成績，分數55分以上但未滿60分的分數一律以60分採計，作法如下 123scores = [50, 55, 53, 56, 57, 54]adjust_scores = list(map(lambda score: 60 if 60 &gt; score &gt;= 55 else score, scores ))print(adjust_scores) # [50, 60, 53, 60, 60, 54] 參考Lambda函式 Day16-Lambda函式","link":"2020/01/05/Python/Python/%5BPython%5D%20Lambda%E5%87%BD%E5%BC%8F/"},{"title":"[Python] Pandas資料處理- 基本概念及操作","text":"前言Pandas是python的一個數據分析的函式庫，提供簡易使用的資料格式，使用者透過這項工具快速操作及分析資料，提供十分容易操作的資料結構如：DataFrame。Pandas不但可以網頁中的表格資料，還能從外部匯入資料，將這些資料進行排序、修改或是做成統計相關的圖表。 安裝 Pandas1pip install pandas Pandas資料結構 Series是一維陣列的資料結構，能夠保存不同資料的型態，如：整數、字串、浮點數。 DataFrame是一個二維陣列的資料結構，可以操作某行/列，或是多行/列的資料，也可以做排序、插入、修改或刪除等操作。 DataFrame 是常用資料處理的格式，尤其是在做報表處理的時候非常方便。 Series基本操作建立SeriesSeries可以處理一維資料的型態包含陣列(array)、字典(dictionary)、單一資料。 資料為陣列(array)時123456import pandas as pd cars = [&quot;高雄&quot;, &quot;花蓮&quot;, &quot;台東&quot;, &quot;台北&quot;, &quot;台中&quot;]select = pd.Series(cars) print(select) 資料為字典(dictionary)時123456789101112import pandas as pdseri = { &quot;col0&quot;: &quot;0&quot;, &quot;col1&quot;: &quot;1&quot;, &quot;col2&quot;: &quot;2&quot;, &quot;col3&quot;: &quot;3&quot;, &quot;col4&quot;: &quot;4&quot;,}seris = pd.Series(seri)seris 取值透過索引值或key名，篩選出目標值12345678print(seris[1]) # 依照索引值取單一值print(&quot;--------&quot;)print(seris[&quot;col2&quot;]) # 依照key名稱取單一值print(&quot;--------&quot;)print(seris[[0, 2, 4]]) # 依照索引值取多個值print(&quot;--------&quot;)print(seris[[&quot;col1&quot;, &quot;col3&quot;, &quot;col4&quot;]]) # 依照key名稱取多個值print(&quot;--------&quot;) 透過索引值或key名，篩選出目標值透過切片(slice)的方式進行索引值或key名，分割出目標值的範圍。 123print(seris[:3]) # slice方法依照索引值選取目標範圍print(&quot;--------&quot;)print(seris[:&quot;col3&quot;]) # slice方法依照&quot;key&quot;名稱選取目標範圍 資料為資料為單一資料時12345678910111213import pandas as pdstudent = &quot;Tom&quot; ser = pd.Series(student, index = range(3)) print(ser) &quot;&quot;&quot;結果0 Tom1 Tom2 Tomdtype: object&quot;&quot;&quot; DataFrame基本操作建立DataFrame資料為陣列(array)時123456import pandas as pdstudents = [[&quot;A&quot;, &quot;male&quot;],[&quot;B&quot;, &quot;female&quot;], [&quot;C&quot;, &quot;male&quot;]]df = pd.DataFrame(students, columns = [&quot;name&quot;, &quot;gender&quot;]) # 指定欄位名稱 df 資料為字典(dictionary)時1234567891011import pandas as pdstudents = { &quot;name&quot;: [&quot;A&quot;,&quot;B&quot;, &quot;C&quot;], &quot;stid&quot;: [1,2, 3], &quot;gender&quot;: [&quot;male&quot;,&quot;female&quot;, &quot;male&quot;], &quot;age&quot;: [20, 30, 40], &quot;city&quot;: [&quot;高雄&quot;, &quot;台北&quot;, &quot;台中&quot;]}df = pd.DataFrame(students)df 讀取資料pandas支援的資料格式很多種，常見的格式包含: read_csv() 讀取*.csv格式的檔案 read_html() 讀取*.heml格式的檔案 read_sql() 讀取*.csv格式的檔案 read_excel() 讀取*.xlsx格式的檔案 read_json() 讀取*.json格式的檔案 寫入資料 to_csv() 讀取*.csv格式的檔案 to_html() 讀取*.heml格式的檔案 to_sql() 讀取*.csv格式的檔案 to_excel() 讀取*.xlsx格式的檔案 to_json() 讀取*.json格式的檔案 說明 encoding=&quot;utf-8-sig&quot;: 將BOM去除的utf-8編碼 index_col=0: 去除索引欄位 寫入資料範例(*.csv為例)1234567891011121314import pandas as pdscores = [ [60, 70, 80], [90, 66, 50], [47, 50, 88]]students = [ &quot;student1&quot;, &quot;student2&quot;, &quot;student3&quot;]subjects = [ &quot;國&quot;, &quot;英&quot;, &quot;數&quot;]df = pd.DataFrame(scores, columns=subjects, index=students )print(df)df.to_csv(&quot;scores.csv&quot;, encoding=&quot;utf-8-sig&quot;) 讀取資料範例12345import pandas as pd# 讀檔data = pd.read_csv(&quot;scores.csv&quot;, encoding=&quot;utf-8-sig&quot;, index_col=0)data.head() 讀取線.csv檔透過正確的URL就可以讀取網路上的任意.csv檔案轉成DataFrame。 12df = pd.read_csv('http://bit.ly/kaggletrain')df.head() 顯示前5筆資料df.head(): 使用.head()可以顯示資料，(預設5筆)，當然也能自訂，只需要內加上要顯示資料的筆數 顯示最後一筆df.head(1) 顯示後5筆資料df.tail():要顯示最後五筆資料則可以使用df.tail()，和df.head()一樣，可以在括號內加上要顯示資料的筆數 資料資訊使用df.info()可以看到該檔案資訊 知道檔案的大小回傳訊息為：顯示(rows,columns) 篩選資料選擇一項資料df[&quot;欄位名稱&quot;]假設我們想要選擇某個科目的欄位所有資料，以英文為例 1df[&quot;英&quot;] 選擇某幾筆資料假設我們要前兩筆英文科目的成績資料 1df[&quot;英&quot;][:2] 選擇多項資料要擴增選擇的欄位很簡單，用一個list的資料結構即可完成。df[['欄位名稱','欄位名稱']]以取得英文、數學這兩格欄位為例 1df[[&quot;英&quot;, &quot;數&quot;]].head() loc[&quot;x_label&quot;, &quot;y_label&quot;]loc[&quot;x_label&quot;, &quot;y_label&quot;]基於行(column)和列(row)進行資料篩選，x_label表示列(row)的篩選，而y_label則是基於行(column)。 範例原始資料:針對student1至student3及國文英文科進行篩選，採用切片(slice)的方式。 12# 用index的標籤來篩選出資料 concat_dfconcat_df.loc[&quot;student1&quot;:&quot;student3&quot;, :&quot;英&quot;] iloc[]基於行和列的索引值進行篩選，索引值都是從0開始。 範例篩選列(row)的前五筆及行(column)的前兩筆 12# 用index位置來篩選出資料concat_df.iloc[:5, :2] 運算子篩選資料除了上述方法外，pandas也可以利用運算子的方式來篩選條件，如條件運算的:== !=、&gt; &lt;、&gt;= &lt;=， 範例假設要篩選出英文分數&gt;70分的學生 12# 運算子篩選資料concat_df[&quot;英&quot;] &gt; 70 執行範例程式碼後可看到回傳條件顯示True或False，接著以True或False當作篩選條件 12condition = (concat_df[&quot;英&quot;] &gt; 70)concat_df[condition] 多個運算子篩選資料如果過濾條件不只一個，布林運算子就派上用場了！ 範例篩選出國等於80分、數學大於60分、英文大於70分的學生，三個條件都須符合的話用and運算，或是&amp;符號。 1234condition1 = (concat_df[&quot;國&quot;] == 80)condition2 = (concat_df[&quot;數&quot;] &gt; 60)condition3 = (concat_df[&quot;英&quot;] &gt; 70)concat_df[(condition1 &amp; condition2 &amp; condition3)] 資料新增新增column並加上資料，採用insert()方法df.insert(位置索引值,column=&quot;欄位名稱&quot;,value=&quot;該筆資料的值&quot;) 新增一個叫物理的欄位名稱在索引值為1(第二個欄位)的位置，裡面的值是[80, 90, 100] 12phy_arr=[80, 90, 100]df.insert(1, column=&quot;物理&quot;, value=phy_arr) 空的資料填充把NaN的資料代換成自訂的資料，語法: fillna(要替換的值)範例: 1df.fillna(0) 資料刪除DataFrame.drop(labels=None,axis=0, index=&quot;索引值&quot;, columns=&quot;欄位名&quot;, inplace=False) 參數說明： labels: 要刪除的行/列的名字 axis: 預設為0，指刪除列(row);若要刪除行(column)時要指定axis=1； index: 直接指定要刪除的列(row) columns: 直接指定要刪除的行(column) inplace =False，預設不改變原資料，而是回傳一個執行刪除操作後的新dataframe； inplace=True，會在原數據上進行刪除操作，無返回值。 因此，刪除行列有兩種方式：1）labels=None,axis=0的組合2）index或columns直接指定要刪除的行或列 注意 指定參數axis = 0表示要刪除的值(row)，axis = 1表示要刪除欄位(column)。 刪除資料的話，預設不改變原資料，而是回傳刪除後的新表格，所以要取新表格的資料要採用賦值的方式 刪除欄位列(column)假設今天要刪除物理 12345# 刪除欄位df.drop(&quot;物理&quot;, axis=1)# 或是df.drop(columns=&quot;物理&quot;) 刪除列(row)刪除索引值(index)為student1的列 1234df.drop(&quot;student1&quot;)#或是df.drop(index=[&quot;student1&quot;]) 若要刪除多個值，給定一個list即可。 刪除多個列也同理。 刪除空值有時候得到的資料不一定是完全都有數值，很可能含有NaN，這時候就需要把它給刪除。df.dropna() 資料排序sort_values()指定欄位的數值排序採用.sort_values(&quot;欄位名&quot;, ascending=True, axis=0)方法，ascending=True和axis=0為預設的排列方式 1234df.sort_values(&quot;物理&quot;, ascending=True)# 順序反轉df.sort_values(&quot;物理&quot;, ascending=False) 當axis=1時，改以行(columns)為排序方式1234df.sort_values(&quot;student1&quot;, axis=1)# 反轉df.sort_values(&quot;student1&quot;, ascending=False, axis=1) 合併資料合併多個CSV檔成單一DataFrame，若遇上相同類型的資料被分成多個不同的 CSV檔的情形，可以將之合併。 範例假設本地分別有scores1.csv、scores2.csv兩個檔案。 12345scores1_df = pd.read_csv(&quot;scores1.csv&quot;, encoding=&quot;utf-8-sig&quot;, index_col=0)print(scores1_df)# ========scores2_df = pd.read_csv(&quot;scores2.csv&quot;, encoding=&quot;utf-8-sig&quot;, index_col=0)print(scores2_df) 讀取DataFrames後發現格式一模一樣，可以將其進行合併。使用pd.concat 將資料格式相同但分散在不同CSV檔合併成單一 DataFrame，方便之後處理。 12concat_df = pd.concat([scores1_df, scores2_df],axis=0)concat_df 改變欄位名稱方法一: df.rename(rename_dic, axis=1)透過df.rename(rename_dic, axis=1)方法，回傳一個新的df，不改變原始df。 pandas預設處理的軸為列(row)：以axis=0表示；而axis=1表示想以行(column)為單位 1234## 方法一: df.rename(rename_dic, axis=1)，不改變原始dfrename_dic = {&quot;age&quot;: &quot;a&quot;, &quot;city&quot;: &quot;ct&quot;}new_df = df.rename(rename_dic, axis=1) new_df 方法二: df.columns()透過df.columns()方法，會改變原始df，對目標欄位重新命名。 123## 方法二: df.columns() df.columns = ['na', 'id'] + list(df.columns[2:])df 參考資料Python for Data Sciencetutorials[第 14 天] 常用屬性或方法（3）Data Frame 資料科學家的 pandas 實戰手冊：掌握 40 個實用數據技巧 [Day08]Pandas資料的取得與篩選！","link":"2019/09/04/Python/Python/%5BPython%5D%20Pandas%E8%B3%87%E6%96%99%E8%99%95%E7%90%86%E7%B3%BB%E5%88%971-%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E6%93%8D%E4%BD%9C/"},{"title":"[Database] MongoDB 資料操作","text":"前言本篇紀錄MongoDB整合Python的pymongo及mongo shell進行資料庫操作，安裝方式參考本篇。 傳統SQL與MongoDB兩者對應關係在操作MongoDB前需要了解兩者的對應關係，才能理解如何下操作指令 使用Pymongo安裝pymongo1pip install pymongo 連接pymongo連接MongoDB時，需使用PyMongo庫裡面的MongoClient。一般來說，傳入MongoDB的host及port即可，其中第一個參數為主機位置(host)，第二個參數為port(如果不傳參數，預設是27017) 123from pymongo import MongoClient # 引入pymongo# 連接pymongoclient = MongoClient(host='localhost', port=27017) 純字串的連接方式1client = MongoClient('mongodb://localhost:27017/') 連接雲端的MongoDB 點擊Connect Instructions -&gt; 選擇Connect Your Application -&gt; 選擇程式語言，並複製下方指令 貼上剛才複製的指令，並將password替換成自己的用戶密碼 1client = MongoClient(&quot;mongodb://tomchen:user_password@cluster0-shard-00-00-q0zkl.mongodb.net:27017,cluster0-shard-00-01-q0zkl.mongodb.net:27017,cluster0-shard-00-02-q0zkl.mongodb.net:27017/test?ssl=true&amp;replicaSet=Cluster0-shard-0&amp;authSource=admin&amp;retryWrites=true&amp;w=majority&quot;) 建立/指定資料庫MongoDB中可以建立多個資料庫，需要指定操作哪個資料庫。以test資料庫為例: 方法11db = client.test 方法21db = client['test'] 建立/指定CollectionMongoDB中的collection對應傳統資料庫的table建立students為collection名稱 方法11collection = db.students 方法21collection = db[students] 新增資料新增單筆資料採insert_one()方法 123456789student = { 'id': '20170101', 'name': 'Jordan', 'age': 20, 'gender': 'male'}result = collection.insert_one(student)print(result) 新增多筆資料採insert_many()方法，傳入一個陣列形式的資料結構 1234567891011121314151617students = [ { 'id': '20180101', 'name': 'Jean', 'age': 20, 'gender': 'female' }, { 'id': '20190101', 'name': 'Tom', 'age': 22, 'gender': 'male' },]result = collection.insert_many(students)print(result.inserted_ids) # 回傳 ObjectId 查詢可以利用find_one()或find()方法進行查詢，其中find_one()查詢得到的是符合條件的第一個結果。 如果查詢結果不存在，則會返回None 查詢單一筆資料如查詢name為Tom的資料 123result = collection.find_one({'name': 'Tom'})print(type(result)) # 回傳結果是dic類型print(result) 根據ObjectId來查詢需要使用package-bson裡面的objectid 123from bson.objectid import ObjectIdresult = collection.find_one({'_id': ObjectId('5e41253fe2d639ab3976e620')})print(result) 查詢多筆資料 查詢多筆資料時，務必要在查詢的結果轉為list 12result = list(collection.find({'name': 'Tom'}))print(result) 條件查詢大於的條件在dic內使用$gt作為篩選條件 12results = list(collection.find({'age': {'$gt': 20}}))print(results) 小於的條件在dic內使用$lt作為篩選條件 12result = list(collection.find({'age': {'$lt': 22}}))print(results) 配合正規表達式在dic內使用$regex作為篩選條件，如: 查詢名字以T開頭的學生資料 更新方法一update()使用update()方法，如更新name為Tom的age：先指定查詢條件，再查詢該筆資料，修改年齡後呼叫update()方法將原條件和修改後的資料傳入 123456condition = {'name': 'Tom'}student = collection.find_one(condition)print(student)student['age'] = 25result = collection.update_one(condition, student)print(result) 回傳結果: 也可以使用$set對資料進行更新 1result = collection.update(condition, {'$set': student}) 方法二: update_one()和update_many()是官方比較推薦的方法update_one()和update_many()是官方比較推薦的方法，用法更加嚴謹 1result = collection.update_one(condition, {'$set': student}) 嚴謹的方法會回傳UpdateResult object，而matched_count和modified_count屬性則是指獲得匹配的資料數量和更動的資料數量 另外的例子: update_one()指定查詢條件為age大於20，更新條件為{'$inc': {'age': 1}}，也就是age加1，執行之後會將第一條符合條件的資料age加1。 12345condition = {'age': {'$gt': 20}}result = collection.update_one(condition, {'$inc': {'age': 1}})print(result)print(result.matched_count, result.modified_count) update_many()1234condition = {'age': {'$gt': 20}}result = collection.update_many(condition, {'$inc': {'age': 1}})print(result)print(result.matched_count, result.modified_count) 回傳結果可看到所有資料都被更新 刪除使用delete_one()和delete_many()方法指定刪除的條件，此時符合條件的資料會被刪除。 12345result = collection.delete_many({'name': 'Jean'})print(result)print(result.deleted_count) result = collection.delete_many({'age': {'$gt': 25}})print(result.deleted_count) deleted_count為被刪除的數量 使用Mongo Shellmongo 是一個用來操作MongoDB的JavaScript介面，可以使用它來進行新增、刪除、修改、查詢資料庫中的資料，另外也可以進行資料庫管理。 連結本地1mongo 打開終端機執行mongo 以MongoDB Shell來連線到MongoDB。上圖表示連結成功！ 若無加上任何參數，mongo指令預設會連線到localhost: 27017，如果要改變主機與連接埠，參考 mongo Shell Reference Page。 查看基本的操作說明1help 一開始進入 MongoDB Shell 時，可以執行help來查看基本的操作說明 選擇 database在輸入資料之前，先下use指令來選擇目標database。 新增資料MongoDB內新增資料採insert()方法，所有儲存在collection中的 document都會有一個 _id的field名稱作為 primary key，如果輸入資料時沒有加上這個 field，MongoDB 會自動產生一個 ObjectId 作為 _id。範例：寫入一個名為students的collection 1234567891011121314151617181920212223242526db.students.insert({ &quot;name&quot; : &quot;Tom&quot;, &quot;sid&quot; : &quot;41704620&quot;, &quot;gender&quot; : &quot;male&quot; , &quot;family&quot; : { &quot;fatherName&quot; : &quot;father&quot;, &quot;matherName&quot; : &quot;mather&quot;, &quot;totalMember&quot;: 3 }, &quot;city&quot; : &quot;金門&quot;, &quot;grades&quot; : [ { &quot;subject&quot;: &quot;體育&quot;, &quot;date&quot;: ISODate(&quot;2019-10-01T00:00:00Z&quot;), &quot;grade&quot; : &quot;A+&quot;, &quot;score&quot; : 95 }, { &quot;subject&quot;: &quot;國文&quot;, &quot;date&quot; : ISODate(&quot;2014-01-16T00:00:00Z&quot;), &quot;grade&quot; : &quot;A-&quot;, &quot;score&quot; : 80 } ] }) 成功寫入！ 如果遇到 collection 不存在的狀況，MongoDB 會自動建立這個 collection。在執行之後，會傳回一個 WriteResult 物件，nInserted 的值就是輸入資料的筆數 查詢資料未指定條件執行find()不加任何查詢條件時，會列出該collection中所有的 documents。 1db.students.find() 查詢成功！ 指定查詢條件範例1查詢某個物件 1db.students.find({&quot;name&quot; : &quot;Tom&quot;}) 範例2查詢某個物件下的特定物件，使用dot.的方式取得。 1db.students.find({&quot;family.fatherName&quot; : &quot;father&quot;}) 範例3也可以用於查詢陣列中的field值。 1db.students.find({&quot;grades.grade&quot; : &quot;A+&quot;}) 配合運算子查詢條件範例1大於條件 1db.students.find({&quot;grades.score&quot; : {$gt: 90} }) 範例2小於條件 1db.students.find({&quot;grades.score&quot; : {$lt: 90} }) 多個查詢條件做AND運算 1db.students.find( {&quot;gender&quot; : &quot;male&quot;,&quot;city&quot; : &quot;金門&quot;} ) 做OR運算 123db.students.find( { $or: [ { &quot;gender&quot; : &quot;male&quot; }, { &quot;city&quot; : &quot;金門&quot; } ] }) 排序查詢結果讓查詢的結果依照 field 來排序，可以加sort()方法，並且指定排序的 field名稱與排列方式，1:表遞增;-1：表遞減。 1db.students.find().sort( { &quot;grades&quot;: 1 } ) 更多查詢條件 列出所有的collections下方三行指令擇一 123show collectionsshow tablesdb.getCollectionNames() 資料庫系統資訊1db.stats() 參考教學MongoDB 基礎入門教學：MongoDB Shell 篇 Python操作MongoDB看這一篇就夠了","link":"2019/09/12/Python/Python/%5BPython%5D%20MongoDB%20%E8%B3%87%E6%96%99%E6%93%8D%E4%BD%9C/"},{"title":"[Python] MySQL 資料操作","text":"前言本篇用於紀錄使用Python操作MySQL 安裝MySQL因為之前有下載MAMP，裡面已經安裝過MySQL。 安裝pysql123pip install pymysql或pip3 install pymysql 安裝完成後建立名為crud_test的資料庫。 實作引入pymysql並創建cursor1234import pymysqldb = pymysql.connect(&quot;127.0.0.1&quot;, port=8889 , user=&quot;root&quot;, password=&quot;root&quot;, db=&quot;crud_test&quot;, charset='utf8') # db為指定的資料庫名稱#建立操作游標cursor = db.cursor() cursor()為獲得python執行ＭySQL語法的方法 查詢資料庫版本sql查詢指令為SELECT VERSION() 1234567891011121314#========== 查詢資料庫版本 =======sql = 'SELECT VERSION()' #執行語法cursor.execute(sql)print(&quot;Success!!!!&quot;)#選取第一筆結果data = cursor.fetchone()print (&quot;Database version : %s &quot; % data)#關閉連線db.close()# 回傳結果：Database version : 5.6.35 新增資料先定義表格結構 insert語法:insert into 資料表名稱(欄位1, 欄位2, 欄位3....) values (欄位1的值,欄位2的值, 欄位3的值.... ); 範例123456789101112131415161718192021222324import pymysqlfrom datetime import datetimedb = pymysql.connect(&quot;127.0.0.1&quot;, port=8889 , user=&quot;root&quot;, password=&quot;root&quot;, db=&quot;crud_test&quot;, charset='utf8')#建立操作游標cursor = db.cursor()# sql 新增sql = &quot;insert into student_record(sid, name, gender, age, score) values (1, 'Jean', 'female', '20', 100);&quot;#執行語法try: cursor.execute(sql) #提交修改 db.commit() print('success')except: #發生錯誤時停止執行SQL db.rollback() print('error')# 提交commit，不然無法存新建或者修改的資料db.commit()# #選取第一筆結果data = cursor.fetchone() 務必記得提交commit，不然無法存新建或者修改的資料 查看結果：新增成功一筆資料 修改資料update語法:update record set 欄位名 where 更新條件 set後面接更新目標的欄位，where後面接更新的條件 範例123456789101112131415161718192021222324import pymysqlfrom datetime import datetimedb = pymysql.connect(&quot;127.0.0.1&quot;, port=8889 , user=&quot;root&quot;, password=&quot;root&quot;, db=&quot;crud_test&quot;, charset='utf8')#建立操作游標cursor = db.cursor()# sql 修改sql = &quot;update record set name= 'Tony' where age = '30' &quot; try: cursor.execute(sql) #提交修改 db.commit() print('success')except: #發生錯誤時停止執行SQL db.rollback() print('error')db.commit() # 提交commit，不然無法存新建或者修改的資料#選取第一筆結果data = cursor.fetchone()#關閉連線db.close() 查詢select 目標欄位 from 資料表，返回值的資料型態為tuple 範例(選取第一筆結果):1234567891011121314151617181920212223242526import pymysqlfrom datetime import datetimedb = pymysql.connect(&quot;127.0.0.1&quot;, port=8889 , user=&quot;root&quot;, password=&quot;root&quot;, db=&quot;crud_test&quot;, charset='utf8')#建立操作游標cursor = db.cursor()# sql 查詢sql = &quot;select * from student_record&quot;#執行語法try: cursor.execute(sql) #提交修改 db.commit() print('success')except: #發生錯誤時停止執行SQL db.rollback() print('error')# 提交commit，不然無法存新建或者修改的資料db.commit()#選取第一筆結果data = cursor.fetchone()print(data)# (1, 'Jean', 'female', 20, 100) 範例(選取全部結果):採用fetchall() 1234567891011121314151617181920212223242526import pymysqlfrom datetime import datetimedb = pymysql.connect(&quot;127.0.0.1&quot;, port=8889 , user=&quot;root&quot;, password=&quot;root&quot;, db=&quot;crud_test&quot;, charset='utf8')#建立操作游標cursor = db.cursor()# sql 查詢sql = &quot;select * from student_record&quot;#執行語法try: cursor.execute(sql) #提交修改 db.commit() print('success')except: #發生錯誤時停止執行SQL db.rollback() print('error')# 提交commit，不然無法存新建或者修改的資料db.commit()#選取第一筆結果data = cursor.fetchall()print(data)# ((1, 'Jean', 'female', 20, 100), (2, 'Tom', 'male', 21, 70), (3, 'Tony', 'male', 22, 60), (4, 'Jack', 'male', 30, 90)) 範例(指定取回查詢筆數):fetchmany(size= number)，size限制查詢筆數。 12345678910111213141516171819202122232425import pymysqlfrom datetime import datetimedb = pymysql.connect(&quot;127.0.0.1&quot;, port=8889 , user=&quot;root&quot;, password=&quot;root&quot;, db=&quot;crud_test&quot;, charset='utf8')#建立操作游標cursor = db.cursor()# sql 查詢sql = &quot;select * from student_record&quot;#執行語法try: cursor.execute(sql) #提交修改 db.commit() print('success')except: #發生錯誤時停止執行SQL db.rollback() print('error')# 提交commit，不然無法存新建或者修改的資料db.commit()#選取第一筆結果data = cursor.fetchmany(size=2)print(data)# ((1, 'Jean', 'female', 20, 100), (2, 'Tom', 'male', 21, 70)) 刪除delete from 資料表名稱 where 刪除條件 範例1234567891011121314151617181920212223import pymysqlfrom datetime import datetimedb = pymysql.connect(&quot;127.0.0.1&quot;, port=8889 , user=&quot;root&quot;, password=&quot;root&quot;, db=&quot;crud_test&quot;, charset='utf8')#建立操作游標cursor = db.cursor()# sql 查詢sql = &quot;delete from student_record where name= 'Jack' &quot; #執行語法try: cursor.execute(sql) #提交修改 db.commit() print('success')except: #發生錯誤時停止執行SQL db.rollback() print('error')# 提交commit，不然無法存新建或者修改的資料db.commit()#選取第一筆結果data = cursor.fetchmany(size=2)print(data) 結果 參考文章Day22- Python X MySql 2","link":"2019/09/13/Python/Python/%5BPython%5D%20MySQL%20%E8%B3%87%E6%96%99%E6%93%8D%E4%BD%9C/"},{"title":"[Python] Module&amp;Package","text":"前言任何一個python程式都可以作為python的模組(模組是一個.py的檔案)，裡面有許多定義的變數和函式供其他程式使用，模組設計目的是由其他程式引入並使用，將功能模組化帶來的好處是模組化的程式可以在不同程式引入，減少重複寫相同功能的情況。同時，如果有別人別人寫好實用的模組，可以透過引入的方式，直接拿來使用。 引入import方法Python引入模組的方法(import)有四種: 12345678# 單純引入import module# 將引入的模組進行重新命名，將name替換自訂的模組名稱 -&gt; 常用於模組名稱太長的情形import module as name# 引入模組內特定的函式或變數 from module import variable/function# 引入模組內所以有的函式或變數from module import * 單純引入模組的情況下，若要呼叫該模組內特定的函式或變數，需要module.function或 module.variable 來呼叫目標函式或是變數。 from module import variable/function使用時機在於，有些module相當龐大，若每次都要將整個module的內容引入，會有效能問題。 自訂一個模組假設自訂一個名為mod.py的模組，要讓main.py引入使用，將兩個檔案的程式碼放在同一個目錄下執行。 1234567891011&quot;&quot;&quot;&quot;mod.py被導出的模組&quot;&quot;&quot;var = &quot;This is variable&quot;def sayHello(): return &quot;This is mod.py&quot;def sayGoodBy(): return &quot;Bye!&quot; 12345#### main.pyimport mod # 需要與mod.py同一目錄下print(mod.sayHello()) # 呼叫 sayHello函式 -&gt; This is mod.pyprint(mod.var) # 呼叫var變數 -&gt; This is variable 模組的路徑實際情況是，不可能總是把所有的程式碼放在同一個路徑或是資料夾。為了要讓這一份程式碼能在同一個環境底下任何時候都能使用，需要將檔案設定在Python環境的路徑。那Python 如何知道在哪裡搜尋模組的路徑呢？這時可以使用sys模組幫助我們尋找模組路徑。 123456789import sysprint(sys.path)# 結果&quot;&quot;&quot;['/Users/tsungyuchen/Desktop/python_practice', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7', '/Users/tsungyuchen/Library/Python/3.7/lib/python/site-packages']&quot;&quot;&quot; 印出結果為Python尋找模組的路徑，我們可以看到Python/3.7/lib/python/site-packages的路徑，將mod.py將入此資料夾後，電腦上其他位置的專案就可以直接引入此模組。 路徑配置有時import模組會出現ImportError的錯誤訊息，大多數的情況都是路徑的問題，為了解決上述問題，需要新增模組搜尋路徑，可以使用以下幾種方式： 增加路徑通過sys模組的append()方法在Python環境中增加搜尋路徑，語法結構為: 1sys.path.append('新增的搜尋路徑') 修改環境變數修改PYTHONPATH變數。 打開vim 1vim ~/.bashrc 設置路徑並添加以下內容： 1export PYTHONPATH=$PYTHONPATH:你要的路徑 退出後保存(相關指令說明點我)，再重新啟動。 1source ~/.bashrc Package有時會需要將功能類似的module進行整合，會需要將這些模組放在同個package下。package可簡單看作一個資料夾，若要讓電腦辨認這是一個可被引入的package，該package下必須要放一個__init__.py 檔案。此檔案可以為空，或是寫入任何該package或該package內module被引入時要執行的程式碼。 引用方法12345import packageimport package.modulefrom package import module1, module2... 範例假設有一個名為pkg的資料夾(視為一個package)，底下有mod1.py、mod2.py、mod3.py三個模組，透過main.py檔進行呼叫。 在__init__.py為空的情況下寫以下範例: 1234567891011121314151617# mod1.pyvar1 = &quot;This is variable1&quot;def sayHello(): return &quot;This is mod1.py&quot;def sayGoodBy(): return &quot;Bye!&quot;# mod2.pyvar2 = &quot;This is variable2&quot;def sayHello(): return &quot;This is mod2.py&quot;def sayGoodBy(): return &quot;Bye!&quot; 分別引入mod1.py、mod2.py 12345678910# main.pyfrom pkg import mod1, mod2print(mod1.sayHello())print(mod2.sayHello())&quot;&quot;&quot;This is mod1.pyThis is mod2.py&quot;&quot;&quot; __init__.py 配置在__init__.py加入該package下不同的模組所呼叫的函式或變數。__init__.py配置個模組下呼叫的函數 123# __init__.pyfrom .mod1 import sayHellofrom .mod2 import sayHello 123456# main.pyimport pkg print(dir(pkg)) # 檢視一個模組中含有的內容（attribute）print(pkg.mod1.sayHello())print(pkg.mod2.sayHello()) 檢視模組、package中的內容(attribute)12345678print(dir(pkg))print(&quot;=============&quot;)print(dir(pkg.mod1))&quot;&quot;&quot;['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'mod1', 'mod2', 'sayHello']=============['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'sayGoodBy', 'sayHello', 'var1']&quot;&quot;&quot; 上述範例可以看到該package及模組中的內容。 __builtins__表內建模組，不需要手動匯入，所以在啟動Python時系統就會自動匯入了，任何程式都能直接使用它們。 __doc__: 查看對於該模組的文件說明。 __file__: 查看模組所在路徑 __package__：該package的名稱 __name__：該package的名稱 常用模組os模組包含了常用的作業系統功能，提供系統操作的方法。 12345678910111213141516171819202122232425262728293031323334import os#取得系統平台資訊os.name#獲取當前工作目錄os.getcwd()# 取得指定目錄中所有的檔案與子目錄名稱os.listdir(path)# 判斷該項目是否為普通檔案os.path.isfile# 判斷該項目是否為目錄os.path.isdir# 列出指定的路徑下所有子目錄與檔案資訊os.walk#改變目前路徑os.chdir(path)#建立新目錄os.makedir(path)#刪除空目錄os.removedirs(path)#刪除文件os.remove(&quot;文件名&quot;)#執行Shell指令os.system(&quot;命令&quot;)#得到當前文件的絕對路徑os.path.abspath()#輸入一個全路徑名。得到當前文件的路徑os.path.dirname(&quot;pathName&quot;)#輸入一個全路徑名。得到文件名os.path.basename(&quot;fullPathName&quot;)#判斷路徑是否存在os.path.exists(&quot;fullPathName&quot;)#路徑拼接os.path.join(&quot;pathName1&quot;,&quot;pathName2&quot;) 範例: 取得檔案列表利用os.listdir(path)取得檔案列表 12345678910111213141516171819202122from os import listdirfrom os.path import isfile, isdir, join, dirnamemypath = &quot;django&quot;# 取得所有檔案與子目錄名稱files = listdir(mypath)# 以迴圈處理for f in files: # 產生檔案的絕對路徑 fullpath = join(mypath, f) # 判斷 fullpath 是檔案還是目錄 if isfile(fullpath): print(&quot;檔案：&quot;, f) elif isdir(fullpath): print(&quot;目錄：&quot;, f) &quot;&quot;&quot;檔案： .DS_Store目錄： stocks檔案： Pipfile檔案： Pipfile.lock&quot;&quot;&quot; 範例: 拼接文件的絕對路徑列出指定的路徑下所有子目錄與檔案資訊。os.walk 將每一個目錄中的檔案都列出來，並且自動區分檔案與目錄。 123456from os import walkfrom os.path import joinfor root, dirs, files in walk(mypath): print(&quot;路徑：&quot;, root) print(&quot;目錄：&quot;, dirs) print(&quot;檔案：&quot;, files) 輸出結果 實際拼接 12345678from os import walkfrom os.path import joinmypath = &quot;django&quot;# 取得所有檔案與子目錄名稱for root, dirs, files in walk(mypath): for f in files: fullpath = join(root, f) print(fullpath) 印出所有檔案的絕對路徑 sys模組12345678import syssys.argv # 回傳執行文件時的參數列表sys.exit([arg]) # 退出當前程式sys.modules # sys.modules查詢當前系統模組包含的變數或類的路徑sys.path # sys.path查詢當前模組所處路徑sys.platform # sys.platform查詢當前直譯器執行的平臺sys.stdin, stdout, stderr # 常見輸入輸出 參考Day17-模組 Day18-標準函式庫 Python進階篇二：Python模組 Python 列出目錄中所有檔案教學：os.listdir 與 os.walk Python 初學第十三講—模組","link":"2019/08/05/Python/Python/%5BPython%5D%20module&package/"},{"title":"[Python] 串列(List)&amp;元組(Tuple)","text":"前言串列是夠提供儲存資料的記憶體空間，Python中的串列(List)類似其他程式語言中的陣列(Array)，是一個有順序性的元素集合，若要可根據list中的實際內容或是該元素在list中的位置用索引值(index)進行查找。 串列(List)建立空串列1arr = [] 給定初始值得串列1arr = [1, 2, 3, 4] 串列內元素的資料型態可以相同或不同，甚至可以是串列1234list1 = [1, 2, 3, 4, 5] #元素皆整數list2 = [&quot;hey&quot;, &quot;hello&quot;, &quot;hi&quot;] #元素皆字串list3 = [3, &quot;hey&quot;, True] #包含不同資料型態list4 = [&quot;Tom&quot;, 180, 65, &quot;student&quot;, ['Go', 'Python']] # list內也可以放入串列 注意索引值是從0開始計 索引值不可超出串列範圍，否則會產生錯誤123list3 = [3, &quot;hey&quot;, True] print(list3[5])# list index out of range 負索引值也同樣不可超出串列範圍 取得串列長度使用len()方法，回傳該串列的長度，得知串列內包含多少元素。 取得list內的元素範圍取值若想要取得一連串某個範圍的值，使用方法跟切片相似(Slice)，結構如下: 1my_list[start:end:sep] 其中: start: 開始索引的位置，預設的索引位置為第一個 end: 結束索引的位置，預設的索引位置為最後一個 sep: 索引的間隔，預設為1 範圍取值更多的應用若範圍取值的start被省略，Python會自動選取預設的索引位置 (第一個;index=0) ，而範圍取值的end被省略，則自動選取預設的索引位置 (最後一個;index=-1)。 取出來的值只會包含開頭，不會包含結束的index 取得最後一個元素若想要取得list中的最後一個元素，index值輸入-1。以此類推，若要選擇倒數第二個位置的元素，index值則填入-2。 12list3 = [3, &quot;hey&quot;, True] print(list3[-1]) # True 複製串列省略start及end兩個索引值，只留一個冒號在中括號中，如[:]就可以複製整個串列。 123arr=[1,3,5] # 建立一個arr串列arr1=arr[:] # 將arr串列複製到arr1串列print(arr1) # 印出arr1串列： [1,3,5] 重複n次list1 * n方法，符號使用*，次數為n。 1234arr = ['tom', 'jean', 'hank']arr1 = arr * 2print(arr1)# ['tom', 'jean', 'hank', 'tom', 'jean', 'hank'] 印出切片的串列12345numbs=[1,2,3,4,5]for num in numbs[1:3] : # 印出numbs串列中索引值為1和2的元素 print(num)# 2# 3 多維串列內元素的存取使用多個中括號[]組合來完成。如:my_list[index][index] 123list4 = [&quot;Tom&quot;, 180, 65, &quot;student&quot;, ['Go', 'Python']] print(list4[4]) # ['Go', 'Python']print(list4[4][0]) # Go 增加元素append()使用append() 方法將新元素增加到list最後面。 123arr = ['hi', 'hello', 'hey']arr.append('ya')print(arr) # ['hi', 'hello', 'hey', 'ya'] insert()指定所增加元素的位置，使用insert() 方法，結構會是:myList.insert(index, element)。 index: 表插入位置 element: 表放入的元素123arr = ['hi', 'hello', 'hey']arr.insert(1, &quot;ya&quot;)print(arr) # ['hi', 'ya', 'hello', 'hey'] extend()extend() 方法可以一次加入很多個值或將某個list中的元素加到另一個list。 1234arr = ['hi', 'hello', 'hey']arr1 = [1, 2, 2]arr.extend(arr1)print(arr) # ['hi', 'hello', 'hey', 1, 2, 2] 注意：如果是要一次添加多個元素，不能使用insert()或append()方法。 範例(採用append()增加)1234arr = ['hi', 'hello', 'hey']arr1 = [1, 2, 2]arr.append(arr1)print(arr) # ['hi', 'hello', 'hey', [1, 2, 2]] 範例(採用insert()增加)1234arr = ['hi', 'hello', 'hey']arr1 = [1, 2, 2]arr.insert(2,arr1)print(arr) # ['hi', 'hello', [1, 2, 2], 'hey'] 上述範例會發現若採用apppend()或是insert()方法一次新增list中的所有元素，會發生直接把list放入另一個list的情形。簡單來說，前兩者是以整個list 的資料型態被塞入，而不是以元素的形式被加入。 List合併Python在合併串列上提供一個簡單的方法: +，與字串拼接用法相同，將多個串列用+進行合併。 1234num = [23, 4, 53, 5 ,35, 6]strArr = [&quot;hi&quot;, &quot;hello&quot;, &quot;hey&quot;]# [23, 4, 53, 5, 35, 6, 'hi', 'hello', 'hey'] 移除元素remove()如果不確定或不在意元素在list中的位置，可以使用remove()根據指定的值來刪除元素。 123arr = ['hi', 'hello', 'hey']arr.remove(&quot;hello&quot;)print(arr) # ['hi', 'hey'] pop()藉由索引值位置來指定刪除的元素，且會回傳被刪除的值。結構為myList.pop(index) 若pop內省略index值的話，預設為刪除最後一個元素， 1234567891011# ==== 刪除索引值為0的元素 =======arr = ['hi', 'hello', 'hey']word = arr.pop(0)print(arr) # ['hello', 'hey']print(word) # hi# ==== 預設為刪除最後一個元素 =======arr = ['hi', 'hello', 'hey']word = arr.pop()print(arr) # ['hi', 'hello']print(word) # hey del刪除指定位置元素，使用del方法可以刪除一個元素，當元素刪除之後，位於它後面的元素會自動往前填補空出來的位置。 123arr = ['hi', 'hello', 'hey']del arr[1]print(arr) 排序使用sort()方法對list內的元素進行排序，預設情況下，字串會照字母順序排列、數字則會是遞增排列。 字母順序排列123arr = ['tom', 'jean', 'hank']word = arr.sort() print(arr) # ['hank', 'jean', 'tom'] 數字遞增排列123num = [23, 4, 53, 5 ,35, 6]num.sort()print(num) # [4, 5, 6, 23, 35, 53] sort()方法會改變原始list 不改變原始list的方法複製一個排序過的list若想要保存完整的原始資料，但同時又需要有被排序過的資料。可以使用sorted方法。 1234num = [23, 4, 53, 5 ,35, 6]newNum = sorted(num)print(num) # [23, 4, 53, 5, 35, 6]print(newNum) # [4, 5, 6, 23, 35, 53] 排序反轉數字遞減排列、或是依照字母順序的反向排列。 123num = [23, 4, 53, 5 ,35, 6]num.sort()print(num) # [4, 5, 6, 23, 35, 53] 括號中()可以設定排序的條件在原本的sort()內加上參數reverse=True即可。 123num = [23, 4, 53, 5 ,35, 6]num.sort(reverse=True)print(num) # [53, 35, 23, 6, 5, 4] 反轉把 list內的元素順序反轉可以使用reverse()，會照當前的順序進行反轉。 123num = [23, 4, 53, 5 ,35, 6]num.reverse()print(num) # [6, 35, 5, 53, 4, 23] 查找/檢測/計算找極大(max())、min(sum())與計算list內元素的總和(sum())1234num = [23, 4, 53, 5 ,35, 6]print(max(num)) # 53print(min(num)) # 4 print(sum(num)) # 126 查找某個元素在list內的索引值採用.index(element)的方法，element為要查找的元素，回傳值為該元素的在list中的位置(index值) 123arr = ['tom', 'jean', 'hank']word = arr.index(&quot;jean&quot;) print(word) # 1 如果輸入的元素並不包含在list裡面的話，會出現ValueError 12345arr = ['tom', 'jean', 'hank']word = arr.index(&quot;yo&quot;)print(word)# ValueError: 'yo' is not in list 檢測某值是否不在串列中：in、not inlist可搭配Python中的運算元in判斷目標元素是否在該list裡面，回傳值為True或False的bool值。若運算元為not in，判斷後的回傳結果與in相反。 123arr = ['tom', 'jean', 'hank']print(&quot;hello&quot; in arr) # Falseprint(&quot;hello&quot; not in arr) # True 同時取得目標元素值與index值使用enumerate()方法，配合for loop進行實作。 12345678for index, item in enumerate(arr): print(index, item)&quot;&quot;&quot;結果0 tom1 jean2 hank&quot;&quot;&quot; index值可以省略，回傳值為tuple的資料結構123456789for item in enumerate(arr): print(item)&quot;&quot;&quot;結果(0, 'tom')(1, 'jean')(2, 'hank')&quot;&quot;&quot; 更改index起始值enumerate() 內加上start參數並給index值即可。 12345678910111213141516for index, item in enumerate(arr, start=1): print(index, item)&quot;&quot;&quot;1 tom2 jean3 hank&quot;&quot;&quot;# ======= 無index ========for item in enumerate(arr, start=1): print( item)&quot;&quot;&quot;(1, 'tom')(2, 'jean')(3, 'hank')&quot;&quot;&quot; 上面的範例將index起始值從預設的0改為1 list轉換為字串使用.join()方法，格式為newList = &quot;seperator&quot;.join(listName)，其中seperator替換成要隔開的符號。 12345arr = ['There', 'are', 'tom', 'jean', 'hank']newstr = '_'.join(arr)newstr1 = ' '.join(arr)print(newstr) # There_are_tom_jean_hank print(newstr1) # There are tom jean hank 把字串分割成list在原有的字串上使用.split()做分割，預設以空白做分割的符號。 123newstr = &quot;There_are_tom_jean_hank&quot;newstr1 = newstr.split(&quot;_&quot;)print(newstr1) # ['There', 'are', 'tom', 'jean', 'hank'] 元組(Tuple)Tuple就是不可做修改的List，元組的結構與串列完全相同，差別在於元素個數及元素值皆不能改變，但串列可以。語法結構會是:元組名 = (元素1, 元素2,.... ) 範例12tuple1 = (1, 2, 3, 4, 5) #元素皆整數tuple2 = (0, &quot;Hey&quot;, False) #放入不同資料型態 若發生tuple內的元素被修改會出現TypeError的錯誤資訊。 12tuple1[0] = &quot;hello&quot; print(tuple1[0]) # TypeError: 'tuple' object does not support item assignment Tuple好處: 執行速度比List快: 因為內容不會改變，因此Tuple內部結構比List簡單，執行速度較快。 存於Tuple的資料較為安全: 因為內容不會改變，不會因程式設計疏忽而變更資料內容。 參考Python 初學第五講 — 串列的基本用法DAY 04 串列的操作與運用Day09-List的進階操作與用法","link":"2019/08/02/Python/Python/%5BPython%5D%20%E4%B8%B2%E5%88%97(List)&%E5%85%83%E7%B5%84(Tuple)/"},{"title":"[Python] 使用 isinstance() 來檢查資料型別吧！","text":"前言先前使用 Python 測試物件、變數是否為指定的『類別』或『資料型態』 時(e.g. int、float、bool、str、list ……)，都是使用 type() 方法，但其實 Python 有提供 isinstance() 函式，此法是較好的作法，不僅執行速度較快，也適用於自己建立的 Class 物件繼承(type() 不考慮物件繼承，若為繼承類別的物件不會判斷與父類是相同類別)數，來看看他有哪些特性與用法吧！ 如何在 Python 中使用 isinstance() 函數語法isinstance() 函數需傳入兩個必要參數，若檢查的結果相符，回傳結果為 True，反之為 False object: 此參數傳入指定的 類別(Class) or 變數 classinfo: 此參數傳入指定類別(Class)名稱或變數型別，另外支援以tuple形式傳遞多個類別 or 資料型別的值 語法規則：1isinstance(object, classinfo) 範例1 - 檢查變數的型別檢查 numb 這項變數的型別是否為 str(字串) 1234567word= &quot;hello&quot;result = isinstance(word, str)print(result)if result: print(&quot;Y&quot;)else: print(&quot;N&quot;) output: 12TrueY 由輸出結果可知，透過 isinstance() 函式對 word 變數做型別檢查是否為 string，回傳結果為 True 表類型相符。 isinstance() 函式亦能對其他 Pyhton 內建的型別(e.g. )進行檢查，以下列出幾個範例 12345678910111213141516171819202122232425262728293031323334# 檢查 numb 是否為 intnumb = 10print(isinstance(number, int))# output Trueprint(isinstance(number, float)) # output FalsePI = 3.14# 檢查 PI 是否為 floatprint(isinstance(PI, float))# Output True# Check if (1 + 2j) is an instance of complexcomplex_num = 1 + 2jprint(isinstance(complex_num, complex))# Output True# Check if names is an instance of class listnames_list = [&quot;Tom&quot;, &quot;Jack&quot;, &quot;Jason&quot;]print(isinstance(names_list, list))# Output Truepeople = {&quot;Tom&quot;: 80, &quot;Jack&quot;: 70, &quot;Jason&quot;: 90}print(isinstance(people, dict))# Output Truenames_tuple = (&quot;Emma&quot;, &quot;Jackson&quot;, 'Amy')print(isinstance(names_tuple, tuple))# Output Truenumbs = {1, 2, 3, 4}print(isinstance(numbs, set))# Output True 注意：若將 isinstance() 與任何帶有 None 的變數或物件一起使用時，回傳結果為 False 12345none_var = None# 空字串非 None 值empty_str = ''print(isinstance(none_var, float)) # Falseprint(isinstance(empty_str, str)) # True 範例2 - 檢查類別(Class)除了針對變數做型別檢查外，亦可對類別檢查 123456789101112131415161718class Animal: def __init__(self, name, age): self.name = name self.age = ageclass Student: def __init__(self, name, degree): self.name = name self.degree = degreeani = Animal(&quot;Amy&quot;, 3)stud = Student(&quot;Tom&quot;, &quot;master&quot;)# 檢查 stud 是否為 Student 類別print(isinstance(ani, Animal)) # True# 檢查 stud 是否為 Student 類別print(isinstance(stud, Student)) # False 範例3 - 檢查變數的多個型別前述第一個範例只有針對單一型別做檢查，isinstance() 提供一次檢查多個型別的功能，參數可以tuple 形式一次帶入多個資料型別。例如我們想確認該變數是否為數值時，可能同時包含 int, float 兩種型別，以下作為範例 1234567891011121314151617def is_number(numb): if isinstance(numb, (int, float)): print(f'變數 {numb} 為數值型別的實例') else: print(f'變數 {numb} 非數值型別的實例')n1 = 80is_number(n1)# 變數 80 為數值型別的實例n2 = 55.70is_number(n2)# 變數 55.7 為數值型別的實例n3 = '20'is_number(n3)# 變數 20 非數值型別的實例 範例4 - 檢查類別繼承(Class Inheritance)isinstance 函式也可針對物件導向的類別(Class)繼承(如子類別的物件也是父類別的一種類型)做檢查，若 instance() 的 classinfo 參數是目標類別的父類別，則回傳 True ，反之為 False，來看個例子: 1234567891011121314151617181920class Vehicle(object): def __init__(self, category): self.category = category def display(self): print(&quot;Vehicle: &quot;, self.category)class Car(Vehicle): def __init__(self, category, color): self.category = category self.color = color # 顏色屬性 def display(self): print(&quot;Category: &quot;, self.category, &quot;color: &quot;, self.color)obj = Car(&quot;car&quot;, &quot;red&quot;)print(isinstance(obj, Car)) # Output Trueprint(isinstance(obj, Vehicle)) # Output True 比較 type() 與 isinstance() 兩者的速度 type() 1python3 -m timeit -s &quot;variable = 'test'&quot; &quot;type(variable) is str&quot; output: 5000000 loops, best of 5: 43.7 nsec per loop isinstance() 1python3 -m timeit -s &quot;variable = 'test'&quot; &quot;isinstance(variable, str)&quot; output: 10000000 loops, best of 5: 35.5 nsec per loop 分別執行上述兩者針對同一變數是否為字串時的比對時，執行速度是 isinstance() 較佳。 總結isinstance 通常是比較類型的首選。藉由上面幾個範例可知，它不僅更快，同時考慮繼承，下次若要對資料做型別檢查時，就優先考慮 isinstance 這個函式吧～ Reference Python isinstance() function explained with examples type() vs. isinstance()","link":"2021/06/30/Python/Python/%5BPython%5D%20%E4%BD%BF%E7%94%A8%20isinstance()%20%E4%BE%86%E6%AA%A2%E6%9F%A5%E8%B3%87%E6%96%99%E5%9E%8B%E5%88%A5%E5%90%A7%EF%BC%81/"},{"title":"[Python] 字串處理","text":"前言本篇紀錄經常用到的字串處理方法, 而這些方法已經可以滿足大部分字串處理的需求。 字串(string)Python的字串有單引號''或雙引號&quot;&quot;的形式， 若字串中本身就包含單引號或是雙引號，可以使用另一種引號以利區別 如果在字串資料中遇到相同引號時，則需使用跳脫(escape)字元: \\做跳脫處理，避免被誤判為字串的結束點。 範例若要寫入I'm這類型的縮寫文字，為了避免被誤判為字串的結束點，可以採用兩種方法: 方法一: 跳脫字元12name = 'I\\'m Tom.'print(name) 方法二: 改用另一形式的引號12name = &quot;I'm Tom.&quot;print(name) 建立字串以下三個都是建立空字串的方法，當然也可以給定初始值 1234567# 建立空字串str1 = str()str2 = ''str3 = &quot;&quot;# 給定初始值init_str = &quot;hello&quot; 字串的處理字串拼接兩個字串作相加+運算，資料串接起來。 123str1 = &quot;Hello, &quot;str2 = &quot; my name is Tom&quot;print(str1 + str2) 重複印出字串透過乘法*可以重覆字串的內容。 12x = 'Hello'print(x*3) # HelloHelloHello 是在哈囉? 計算字串長度len()函式取得字串的長度並回傳。 12str = &quot;Python&quot;print(len(str)) 字串擷取利用中括號[起始索引值:結束索引值]可以取出字串需要的部份內容，字串的索引值(index)是從0開始，若要取最後一個字可以用 -1。 12345str = &quot;Python&quot;print(str[4]) # 表是從index=0~4# &quot;o&quot;print(str[-1]) # &quot;n&quot; 字串分割split(&quot;分割符號&quot;)的方法以()內的分割符號作為分割依據，回傳list的資料結構。 split()預設以空白作為分割依據，回傳所有單字 123456789101112131415161718str1 = 'My name is Tom.'str2 = '123.456.789'str3 = 'MMS-231-HIA-Hel988'list1 = str1.split(' ')print(list1)list2 = str2.split('.')print(list2)list3 = str3.split('-')print(list3)&quot;&quot;&quot;['My', 'name', 'is', 'Tom.']['123', '456', '789']['MMS', '231', 'HIA', 'Hel988']&quot;&quot;&quot; 翻轉字串Python在處理reverse string非常厲害，只需要一行程式碼即可搞定。也可以呼叫reverse()這個函式。 123456sss = 'abcdefg'sss = sss[::-1]print(sss) # 此法也可以sss.reverse() 上面為slice方法(又稱切片)，結構說明: [起始點:終點:間隔值] 格式化 大小寫轉換123456s = &quot;Hello&quot;s.upper() #全部字元轉成大寫s.lower() #全部字元轉成小寫s.title() #首字轉成大寫s.capitalize #每個字詞的首字轉成大寫s.swapacase #將大小寫顛倒 新增和刪除空格1234567891011121314space=&quot; abc &quot; space.strip() #刪除前後的空格space.rstrip() #刪除右邊的空格space.lstrip() #刪除左邊的空格 numb=&quot;1112233111&quot;numb.strip(&quot;1&quot;) #刪除特定字元 space = &quot;this is the space&quot;space.center(30) #產生一定數量的空格，並中心對齊一個給定的字串space.ljust(30) #產生一定長度的空格並左對齊space.rjust(30) #產生一定長度的空格並右對齊&quot;123&quot;.rjust(10,&quot;0&quot;) #能以任意字元填充空格&quot;123&quot;.zfill(10) #在左邊填充一定數量的0 format()格式化在既有的字串中加入{}，放入被format()格式化後的值。12345678pi=3.14&quot;The value of pi is {}&quot;.format(pi) #串格式化後的值&quot;&quot;&quot;First letter: {0}. Last letter: {1}.&quot;&quot;&quot; .format('A', 'Z')#{}中設定數字代表要插入的參數的索引&quot;&quot;&quot;First letter: {first}. Last letter: {last}.&quot;&quot;&quot; .format(last='Z', first='A')#若{}中包括了一個字串，則可以名稱指定要插入的值&quot;pi = {0:.3f}&quot;.format(pi)#數字的插入，0代表要插入的參數的索引，:代表後面要跟著格式化的程式碼，.3f代表需要的精度資訊，小數點後保留3位小數的浮點數 查找字串1234567stat = 'Today is not my day'stat.find('Today') #查詢字串在字串中出現的索引，若搜尋不到子字串，會回傳-1stat.index('Today') #查詢字串在字串中出現的索引，若搜尋不到子字串，會回傳ValueErrorstat.rfind('Today') #從尾部往前查詢子字串在字串中出現的索引 stat.endswith('day') #檢查字串最後一個字串stat.startswith('Today') #檢查字串首個字串 替換字串replace('舊字串','新字串')方法做新/舊字串的替換。 1stat.replace('brown','red') 型別轉換一個值從一種型態轉變為另外一種型態。 範例: 將一個字串 (str) 轉為整數123456789101112131415stringNum = &quot;155&quot;intNum = int(stringNum)print(stringNum)print(intNum)print(type(stringNum))print(type(intNum))# 結果'''5555&lt;&lt;class 'str'&gt;&lt;&lt;class 'int'&gt;''' 範例: 將一個數值轉為字串 (str)可用str(數值)的方法將數值轉為字串。 12345intNum = 155stringNum = str(stringNum)print(type(stringNum))print(type(intNum)) 測試字串 isupper(): 若字串為大寫字母組成, 就回傳True islower(): 若字串為小寫字母組成, 就回傳True isspace(): 若字串為空白字元組成, 就回傳True isalnum(): 若字串為字母和數字組成, 就回傳True isalpha(): 若字串為字母組成, 就回傳True isdigit(): 若字串為數字組成, 就回傳True isidentifier(): 若字串為識別字, 就回傳True 參考文章[Python]B13─字串處理(string processing)[Python] 字串處理","link":"2019/08/01/Python/Python/%5BPython%5D%20%E5%AD%97%E4%B8%B2%E8%99%95%E7%90%86/"},{"title":"[Python] 實戰系列 - 抓取台灣銀行牌告匯率寫入MySQL","text":"前言本篇主要紀錄學習過pandas、檔案寫入、MySQL後做整合。 實作步驟: pandas讀取html的table標籤，轉為dataframe 處理dataframe 篩選目標欄位，並更改欄位名稱 更改某欄位的值 轉為.csv並存入MySQL 觀察目標網頁並擷取資料 引入相關工具，使用pandas讀取html。 123456789import pandas as pdfrom datetime import datetimeimport pymysqlurl = 'https://rate.bot.com.tw/xrt?Lang=zh-TW'#讀取網頁dfs=pd.read_html(url) # 輸出資料為一個listdfs[0] 顯示出來的資料表有許多不需要的欄位資料 過濾資料先確認資料格式，確認為dataframe後，過濾出目標值。 123456currency=dfs[0]type(currency) # 確認資料格式# 過濾出要的值： 前五個columnscurrency_fix=currency.iloc[:,0:5] currency_fix 查看過濾後的dataframe 自訂欄位名稱12currency_fix.columns=[u'幣別',u'現金匯率-本行買入',u'現金匯率-本行賣出',u'即期匯率-本行買入',u'即期匯率-本行賣出']currency_fix 更新幣別欄位的資料1currency_fix[u'幣別'] # 查看&quot;幣別&quot;欄位 對幣別進行重新命名123# 採用正規表達式過濾字元，其中`w+`表示過濾出應英文字且一個以上currency_fix[u'幣別'] = currency_fix[u'幣別'].str.extract('\\((\\w+)\\)')currency_fix[u'幣別'] 查看資料結果 1currency_fix 寫入.csv並存入資料庫 程式碼1234567currency_fix.to_csv('currency.csv')df = pd.read_csv(&quot;./currency.csv&quot;, sep=',')engine = create_engine('mysql+pymysql://root:root@localhost:8889/exrate?charset=utf8')df.to_sql('test_currency', engine, index = False,index_label = False)print(&quot;Write to MySQL successfully!&quot;) 感謝大數學堂提供的教學影片，簡單又快速上手 參考抓取台灣銀行的牌告匯率","link":"2019/09/14/Python/Python/%5BPython%5D%20%E5%AF%A6%E6%88%B0%E7%B3%BB%E5%88%97-%E5%8F%B0%E7%81%A3%E9%8A%80%E8%A1%8C%E7%89%8C%E5%91%8A%E5%8C%AF%E7%8E%87%E5%AF%AB%E5%85%A5MySQL/"},{"title":"[Python] 字典-Dictionary","text":"前言每一個元素都由鍵(key)和值(value)組成的鍵值對物件，結構為{key: value}，鍵和值之間是用冒號 : 來分隔，鍵-值對之間是用逗號, 做分隔。 創建字典方式有兩種: 使用大刮號 {} 使用內建函數 dict() 1234567891011121314151617181920212223# ======= 大括號{}方法建立 ======student_1 = {'name': 'Tom', 'birth': 1997, 'ID': '1234567'}# ======= dic()方法建立 ======student_2 = dict(name='Jack', birth=1985, ID='46383')# ==========================student_3 = {'name': 'Amy', 'birth': 2002, 'ID': '1938098'}# ====== 取得對應的 value ========print(student_1['name']) print(student_2['birth']) print(student_3['ID']) &quot;&quot;&quot;結果:Tom19851938098&quot;&quot;&quot; 字典裡的value可以是任何的資料型態，例如: 字串、list、物件等等。但 key 必須是唯一且不可變的。 dictionary 沒有順序性 回傳錯誤的訊息預設如果輸入了一個不存在的 key，則會回傳KeyError的錯誤訊息。 1print(student_3[&quot;hi&quot;]) 替換錯誤訊息若要避免上述情形的話，可以使用get()來取值，此時會回傳None，而不會回傳錯誤訊息了。 1print(student_3.get(&quot;hi&quot;)) # hi 自訂錯誤訊息若不希望回傳None，想自訂None訊息的話，可在括號內設定自己想要的`None訊息。 1print(student_3.get(&quot;hi&quot;, &quot;不存在哦！&quot;)) # 不存在哦！ 新增&amp;更新存取值的方法來新增或是更動某一組鍵值對(key-value)。 123456789student_1 = {'name': 'Tom', 'birth': 1997, 'ID': '1234567'} student_1[&quot;age&quot;] = 20 # 新增age的鍵值對student_1[&quot;ID&quot;] = 787878 # 更新ID的鍵值對print(student_1)# {'name': 'Tom', 'birth': 1997, 'ID': 787878, 'age': 20} 更新多筆資料可以使用update(dic)方法，dic替換成要新增的字典。 12345678910student_1 = {'name': 'Tom', 'birth': 1997, 'ID': '1234567'}dic = { &quot;age&quot;: 30, &quot;gender&quot;: &quot;male&quot;, &quot;city&quot;: &quot;高雄&quot;}student_1.update(dic)print(student_1) 刪除刪除一筆元素，有兩種方法: del123456student_1 = {'name': 'Tom', 'birth': 1997, 'ID': '1234567'}del student_1[&quot;birth&quot;]print(student_1)# {'name': 'Tom', 'ID': '1234567'} pop回傳刪掉的值，且不改變原始字典的資料。 計算鍵值對的個數用len()方法 12345student_1 = {'name': 'Tom', 'birth': 1997, 'ID': '1234567'}print(len(student_1))# 3 印出字典裡所有的key123print(student_1.keys())# dict_keys(['name', 'birth', 'ID']) 印出字典裡所有的value123print(student_1.values())# dict_values(['Tom', 1997, '1234567']) 印出字典裡的所有key、value`12print(student_1.items())# dict_items([('name', 'Tom'), ('birth', 1997), ('ID', '1234567')]) 檢查指定的key是否存在於字典內使用in這個運算元判定key是否存在於字典中，若存在則回傳True，反之則回傳False 12345print(&quot;ddf&quot; in student_1)print(&quot;birth&quot; in student_1)# False# True 判斷兩個字典是否為同一個物件利用is運算子，可以判斷兩個字典是否為相同的物件。 123456789101112131415student_1 = {'name': 'Tom', 'birth': 1997, 'ID': '1234567'} student_2 = dict(name='Jack', birth=1985, ID='46383')print(student_1 is student_1)print(student_1 is student_2)&quot;&quot;&quot;TrueFalse&quot;&quot;&quot; for loop應用123dict_squares = {i: i**2 for i in range(6)}print(dict_squares)# {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25} 參考DAY 08 字典應用Python 初學第九講 — 字典","link":"2019/08/03/Python/Python/%5BPython%5D%20%E5%AD%97%E5%85%B8-Dictionary/"},{"title":"[Python] 字串格式化","text":"前言進行資料處理時，很多時候都需要對數值進行格式化轉為字串做拼接，或是某段字串與變數做串連。Python的字串格式化用於簡化靜態字串和變數的串接，並格式化變數，當然也可以對數值進行格式化成字串，字串格式化的方式有四種: 百分比(%) str.format =&gt; 作法:'{}'.format() f-string(又作formatted string literals) 樣板字串(Template String) f-string是Python3.6之後才有的，實際上對比的話f-string是三者中(百分比(%)與'{}'.format())效能最好的，同時也提高可讀性，建議實際開發時，直接用f-string方法取代前兩者哦！ 實作百分比(%)為Python最早格式化字串的方法，透過%運算符號，將在tuple中的一組變數依照指定的格式化方式輸出。如格式化: 字串(%s)、 十進位整數(%d)、浮點數(%f)等。 範例1234567891011print('%d' % 20) # 格式化整數print('%f' % 1.11) # 預設保留6位小數print('%.1f' % 1.11) # 取1位小數print('My name is %s'% 'tom') # 格式化字串&quot;&quot;&quot;201.1100001.1My name is tom&quot;&quot;&quot; 缺點 不適合多個變數 可讀性低 '{}'.format()相較於第一個格式化方法，format()方法更好用，使用大括號{}作為特殊字元，放在目標字串的指定位置，format()中則放入要拼接的變數、字串或數值。 範例: 不指定順序若{}內不指定索引值的話，預設依序從0開始，()會依照參數填入的順序 1234name = &quot;tom&quot;age = 20strr = &quot;my name is {} and my age is {}&quot;.format(name, age)strr 範例: 指定順序當然他也可以指定放入的位置，只要在{}內加入索引值(index)即可。 1234name = &quot;tom&quot;age = 20strr = &quot;my name is {1} and my age is {0}&quot;.format(name, age)strr 執行上面的程式碼即可將name、age兩個變數的位置對調 str-formatting 除了可以指定格式化變數名稱及它的位置外，亦可調整輸出樣式，只要加入^（置中）、&lt;（向左對齊）、&gt;（向右對齊）等字元。 範例: 對齊12345678910# ========== 向右對齊 =============print('{:&gt;10}'.format('test')) # ========== 向左對齊 =============print('{:10}'.format('test'))# 等同print('{:&lt;10}'.format('test'))# ============ 置中 ===========print('{:^10}'.format('test')) 或是以'{:,}'的方式以逗號分隔數字 1print('{:,}'.format(243554543)) 除了對齊之外，還可以應用在list串列、dic字典及class物件中 範例：格式化list串列1print('The student is {students[1]}'.format(students=['Tom', 'Jack','Amy'])) # The student is Jack 範例分開字串可使用*方法分開字串 1print('{} {} {} {} {} {}'.format(*'123456')) # 1 2 3 4 5 6 範例：格式化dic字典如果要格式化字典，需要在每個物件前面加上**，否則會如同下方範例，報KeyError錯誤 12print('My age is {age} and gender is {gender}'.format({'age':20}, {'gender': &quot;female&quot;} )) # KeyError: 'age' 在每個物件前面加上**後即可正常執行。 12print('My age is {age} and gender is {gender}'.format(**{'age':20}, **{'gender': &quot;female&quot;} )) # My age is 20 and gender is female 範例：格式化物件中的屬性1234567class Name: def __init__(self, name): self.name = name def __str__(self): return 'Name({self.name})'.format(self=self)print('My name is {0.name}'.format(Name('Tom'))) # My name is Tomprint(Name('Tom')) # Name(Tom) 缺點 當變數太多時，要撰寫的程式碼就會過長 f-stringPython3.6+方可使用，只需要在字串前面加個f即可進行格式化，並將{}填入目標變數。把剛剛的範例改寫成f-string的方式 12345# f-stringname = &quot;tom&quot;age = 20strr = f&quot;my name is {name} and my age is {age}&quot;strr 會獲得相同結果！ 可放表達式與呼叫函數{}可以填入表達式或呼叫函數，Python會回傳求出的結果並填入字串內 1234567891011121314151617181920print(f'A total number of {100 * 2 + 20}')print(f'Complex number {(2 + 2j) / (2 - 3j)}')print(f'convert STUDENT to lower words are {&quot;STUDENT&quot;.lower()}')import mathprint(f'The answer is {math.log(math.pi)}')score = 90print(f'My score is {score}, so I am {&quot;good&quot; if score &gt; 80 else &quot;bad&quot;}.') &quot;&quot;&quot;回傳結果:A total number of 220Complex number (-0.15384615384615388+0.7692307692307692j)convert STUDENT to lower words are studentThe answer is 1.1447298858494002My score is 90, so I am good.&quot;&quot;&quot; 格式化list串列1234students=['Tom', 'Jack','Amy']print(f'The student is {students[1]}') # The student is Jack 格式化dic字典1234567dic = { 'name': &quot;Tom&quot;, 'age':20, 'gender': &quot;female&quot; }print(f'My name is {dic[&quot;name&quot;]}, age is {dic[&quot;age&quot;]} and gender is {dic[&quot;gender&quot;]}') # My name is Tom, age is 20 and gender is female 巢狀結構注意: 巢狀結構只能一層 123456print(f&quot;Ans: {12.3456789:10.6}&quot;) # Ans: 12.3457value = 12.3456789print(f&quot;Ans: {value:10.6}&quot;) # Ans: 12.3457width = 10precision = 6print(f&quot;Ans: {value:{width}.{precision}}&quot;) # Ans: 12.3457 單雙引號、大括號({})與跳脫字元123456789101112131415161718pens = 3print(f'I have {pens} pens.') print(f'I\\thave \\t{pens}\\t pens.') # 引入tab 跳脫字元print(f'I have {pens} {{pens}}.') # 雙大括號 =&gt; 如果需要顯示大括號，則應輸入連續兩個大括號{{和}}txt = f&quot;&quot;&quot;My\\tage\\tis\\t{age}&quot;&quot;&quot;print(txt)&quot;&quot;&quot;結果I have 3 pens.I have 3 pens.I have 3 {pens}.My age is 20&quot;&quot;&quot; f-string大括號內所用的引號不能和大括號外的引號定義的符號相衝突，可依使用情況切換''和&quot;&quot;。若大括號內外兩個引號相衝突，會報SyntaxError錯誤。 123print(f'I am {'Tom'}') # SyntaxError: invalid syntaxprint(f'I am {&quot;Tom&quot;}') # I am Tom 若&quot;&quot;和''無法滿足需求，可以使用''' '''和&quot;&quot;&quot; &quot;&quot;&quot; 1234567print(f&quot;He said {&quot;I'm Tom&quot;}&quot;) # SyntaxError: invalid syntaxprint(f'He said {&quot;I'm Tom&quot;}') #SyntaxError: invalid syntaxprint(f&quot;&quot;&quot;He said {&quot;I'm Tom&quot;}&quot;&quot;&quot;) # I'm Tomprint(f'''He said {&quot;I'm Tom&quot;}''') # I'm Tom backslash斜槓(\\)的使用大括號外的引號可以使用\\，但大括號內不能使用\\ 12print(f'''He\\'ll say {&quot;I'm Tom&quot;}''') # He'll say I'm Tomprint(f'''He'll say {&quot;I\\'m Tom&quot;}''') # SyntaxError: f-string expression part cannot include a backslash 如果在大括號內使用\\，會報SyntaxError。 解決方式先將含\\的字串assign給一變數，再以變數的形式填入{}中。 12name = &quot;I\\'m Tom&quot;print(f'''He'll say {name}''') # He'll say I'm Tom 上述例子即是把&quot;I\\'m Tom&quot;這個含有特殊字元的\\assign給一變數，透過解析變數的方式來避免SyntaxError。 用於多行字串12345678age = 20gender = &quot;male&quot;txt = f&quot;&quot;&quot;My age is {age} and My gender is {gender}&quot;&quot;&quot;txt f-string採用{content:format}來設定字串格式，content是替換並填入字符串的內容，可以是變數、表達式(運算子亦可)或函數，format是格式設定。預設格式為{:format}。 讓跳脫字元失效若要讓跳脫字元失效，在f指令前再加上r，表示raw(原始字元) 12name = &quot;Tom&quot;print(rf'My\\tname\\tis\\tTom\\thave\\t{name}') 範例： 分割千分位12345678num = 1234567890.0987print(f'num is {num:f}' )print(f'num is {num:,f}' )&quot;&quot;&quot;num is 1234567890.098700num is 1,234,567,890.098700&quot;&quot;&quot; lambda大括號內也可放入lambda匿名函式，但lambda匿名函式的:會被f-string誤判，為避免誤判的情況，需將lambda函式包在括號()內。 未將lambda函式包在括號()內 12print( f&quot;&quot;&quot;even ? answer: { lambda n : &quot;Yes&quot; if n %2 == 0 else &quot;No&quot; (10)}&quot;&quot;&quot; )# SyntaxError 將lambda函式包在括號()內 1234print( f&quot;&quot;&quot;even ? answer: {(lambda n : &quot;Yes&quot; if n %2 == 0 else &quot;No&quot;) (10)}&quot;&quot;&quot; )&quot;&quot;&quot;even ? answer: Yes&quot;&quot;&quot; 樣板字串(Template String) 需要從 Python 內建模組 string 引入Template 使用Template()包住目標字串，並使用錢$符號來標示變數 樣板字串預設使用錢$符號來標示變數 替換資料的格式為dictionary 最後使用substitute()來替換變數 來看段範例，改寫自官方文件 123from string import Templates = Template('$who likes $what')s.substitute(who='Tom', what='Python') 或是 1234temp_str = '$who likes $what'new = Template(temp_str)dic = {'who': 'Tom', 'what': 'Python'}new.substitute(dic) 兩個範例可得相同結果 改變預設定義變數的$符號通過class繼承的方法重寫定義變數的符號 123456from string import Templateclass MyTemplate(Template): delimiter = '%' s = MyTemplate('%who knows?')s.substitute(who='Tom')# 'Tom knows?' 惡意腳本注入雖然前面提到的str.format方法方便，但是很有可能在面對處理使用者輸入的值時，遭到惡意字元的注入，來看個範例: 1234567891011121314151617181920&quot;&quot;&quot;source: https://realpython.com/python-string-formatting/#4-template-strings-standard-library&quot;&quot;&quot;# 金鑰、密碼、token等等SECRET = 'this-is-a-secret'class Error: def __init__(self): pass# A malicious user can craft a format string that# can read data from the global namespace:### 使用者輸入惡意字元user_input = '{error.__init__.__globals__[SECRET]}'# This allows them to exfiltrate sensitive information,# like the secret key:err = Error()user_input.format(error=err) 上方範例中，使用者輸入惡意字元:'{error.__init__.__globals__[SECRET]}'，經格式化處理後，會發生金鑰或token等機密性資料洩漏的問題。 解決方法那如果改成Template String的話呢？ 12345678910# solutionSECRET = 'this-is-a-secret'class Error: def __init__(self): passuser_input = '${error.__init__.__globals__[SECRET]}'Template(user_input).substitute(error=err) # ValueError: Invalid placeholder in string 執行上述範例會得到一個ValueError的錯誤結果，較能有效防止洩漏機密資訊。 使用時機綜合以上的方法，可依照不同時機點，建議使用不同格式化字串的方式，下面簡單做個整理： 面對User輸入的字元，使用Template String，避免惡意腳本注入 非User輸入的字元，如果使用Python3.6以下的版本，採用str.format 非User輸入的字元且使用Python3.6以上的版本，推薦使用f-string方法 Source 以上為格式化字串的總整理，如果有寫不清楚或是錯誤之處，請留言跟我說！ 參閱 PyFormat: Using % and .format() for great good! PEP 498 – Literal String Interpolation Python 字串格式化（套用變數） Python格式化字符串f-string概覽","link":"2020/01/13/Python/Python/%5BPython%5D%20%E5%AD%97%E4%B8%B2%E6%A0%BC%E5%BC%8F%E5%8C%96/"},{"title":"[Python] 淺談 Python 中的Decorator(下)","text":"前言上一篇有提到Decorator初階的概念，這篇再來更深入探討Decorator有哪些做法吧！ 範例先來兩個範例，註解的地方是執行順序 Function-based1234567891011121314151617181920212223# Decorator Function Sampledef logged(func): print('scope of logged') # 2 進入logged scope print(&quot;Entering function name is: {}&quot;.format(func.__name__)) # 3 def with_logging(*args, **kwargs): print('scope of with_logging') # 6 print(&quot;Entering function name is: {}&quot;.format(func.__name__)) # 7 print(&quot;arg:&quot;,*args) # 8 print(&quot;kwarg:&quot;,**kwargs) # 9 result = func(*args, **kwargs) print(&quot;Exited&quot;, func.__name__) # 11 return result print('exit') # 4 return with_logging print('start using decorator') # 1@logged # 呼叫loggeddef test(k): print(&quot;excute k: {}&quot;.format(k)) # 10 return k print('excute') # 5print(test(10)) # 12 輸出: Class-based1234567891011121314151617181920212223# Decorator Class Sampleclass decorator(object): def __init__(self, f): print('enter init') self.f = f print('exit init') def __call__(self, *args, **kwargs): print(&quot;Entering&quot;, self.f.__name__) r = self.f(*args, **kwargs) print(&quot;Exited&quot;, self.f.__name__) return r print('start decorator ') @decoratordef hello(k): print('inside hello') return(&quot;k is: &quot; + k) print('excute')print(hello('say hello!')) 印出結果: 執行完上述兩個範例程式碼，大概可以了解使用Class-based、Function-based兩者使用Decorator的差別以及執行順序。 接著來細分Decorator種類有哪幾種吧！ Decorator種類 不帶參數的function decorator 帶有參數的function decorator 不帶參數的class decorator 帶有參數的class decorator 不帶參數的function decorator1234567891011121314151617# 不帶參數的 Decorator Functiondef decorator(f): print(&quot;excute \\&quot;{}\\&quot; decorate&quot;.format(f.__name__)) def print_df(*args, **kargs): print(&quot;print_df before call&quot;) result = f(*args, **kargs) # 呼叫 hello()，並將回傳值傳遞給result print(&quot;print_df after call&quot;) print(&quot;印出回傳值: {}&quot;.format(result)) return result return print_df @decoratordef hello(): print(&quot;say hello.&quot;) return &quot;hello&quot;hello() 印出結果: 帶有參數的function decorator123456789101112131415161718192021# 帶有參數的 Decorator Functiondef parseDecorator(param1, param2): print(&quot;excute 'parseDecorator'&quot;) # 解析parseDecorator內的參數 def decorator(f): print(&quot;excute \\&quot;{}\\&quot; decorate&quot;.format(f.__name__)) def print_df(*args, **kargs): print(&quot;params are: '{}', '{}' &quot;.format(param1, param2)) print(&quot;print_df before call&quot;) result = f(*args, **kargs) # 呼叫 hello()，並將回傳值傳遞給result print(&quot;print_df after call&quot;) print(&quot;印出回傳值: {}&quot;.format(result)) return result return print_df return decorator @parseDecorator(&quot;param1&quot;, &quot;param2&quot;)def hello(): print(&quot;say hello.&quot;) return &quot;hello&quot;hello() 印出結果: 比較有無參數的function decorator藉由上述兩個例子觀察差異，帶有參數的decorator需在decorator外層再包一層function，而最外層稱作parseDecorator的function是用來解析decorator所傳遞的參數，parseDecorator的下一層decorator(f)是主要要修飾的函式，跟不帶參數的decorator作用發訪相同。 簡單來說就是將無參數的function decorator，外面再包一層function，用來傳遞參數。 不帶參數的class decorator1234567891011121314151617# 沒有參數的 Decorator Classclass decorator(): def __init__(self, f): # 對參數、函式進行初始化 self.f = f def __call__(self, *args, **kargs): print(&quot;person1 before call&quot;) result = self.f() # 呼叫 person1()獲得回傳值，並將回傳值assign給result print(&quot;result: {}&quot;.format(result)) # 印出回傳值 print(&quot;person1 after call&quot;) @decoratordef person1(): print(&quot;I'm person1&quot;) return &quot;person1&quot;person1() 輸出結果： 帶有參數的class decorator12345678910111213141516171819202122232425# 有參數的 Decorator Classclass decorateFruitClass(object): def __init__(self, fruit, amount): self.fruit = fruit self.amount = amount def __call__(self, f): def buy(*args, **kargs): print(&quot;%s %s before call&quot; % (self.amount, self.fruit)) result = f(*args, **kargs) print(&quot;%s %s after call&quot; % (self.amount, self.fruit)) return result return buy @decorateFruitClass('guava', 10)def person1(): print(&quot;I'm person1.&quot;)@decorateFruitClass('banana', 20)def person2(): print(&quot;I'm person2.&quot;)person1()print('-------')person2() 輸出結果： Decorator 的有序性如果decorators多層的話，執行的順序可能會和一般的想法不太一樣。 123456789101112131415161718192021222324def walk(func): print(&quot;walking outside&quot;) def warp_1(): print(&quot;walking inside&quot;) print(&quot;Now use function '{}'&quot;.format(func.__name__)) func() # call warp_2() return warp_1 # call warp_1()def jump(func): print(&quot;jumping outside&quot;) def warp_2(): print(&quot;jumping inside&quot;) print(&quot;Now use function '{}'&quot;.format(func.__name__)) print(func()) # call student() return warp_2 # 傳出warp_2給@walk@walk@jumpdef student(): print(&quot;I'm a student&quot;) return &quot;student&quot;student() 執行結果 上圖的執行順序是，先呼叫@jump後傳出新function(傳出warp_2)給往上一層的@walk，再walk(func)中依序執行warp_1()，最後呼叫warp_2()。 遇到多層decorators時，邏輯處理採用 “遞迴(recursive)” 的方式，也就是說，原則上會先合併「最靠近」的decorator，再傳出新的function給往上面一層的decorator 本篇紀錄Python中不同類型的Decorator，透過實際範例能夠更了解不同類型的Decorator是如何去運行！ 參閱 Python進階技巧 (3) — 神奇又美好的 Decorator Python Decorator 四種寫法範例 Code [Python] 對Python 裝飾器的理解心得","link":"2020/02/07/Python/Python/%5BPython%5D%20%E6%B7%BA%E8%AB%87%20Python%20%E4%B8%AD%E7%9A%84Decorator(%E4%B8%8B)/"},{"title":"[Python] 作用域與Closure(閉包)","text":"鼠年全馬鐵人挑戰 - WEEK 03 前言前幾篇提到Python中的Decorator，其實隱含許多作用域以及閉包的概念，故另外獨立寫成一篇來近一步討論這兩者。 First-class Function(頭等函式)在了解Closure之前，要先知道Python中的 First-class Function 是什麼，First-class Function 又可以被稱做頭等函數，或是頭等物件(First-class Object)，Python裡的每個function都是first-class function。根據MDN的定義 A programming language is said to have First-class functions when functions in that language are treated like any other variable. For example, in such a language, a function can be passed as an argument to other functions, can be returned by another function and can be assigned as a value to a variable. 上面這段描述白話來說就是： 函數可以被當做參數傳遞、能夠作為函數回傳值、能夠被修改、能夠被賦值給一個變數。這意味著函數可以傳遞可用作參數，如同其他物件（字串、整數、浮點數、list等）一樣 範例可被賦值給變數123456789101112131415def compare(m, n): return m if m &gt; n else nfunc = compare # assign function物件給funcprint(compare)print(func)print(compare(10, 20))print(func(10, 20))&quot;&quot;&quot;結果&lt;function compare at 0x112441e60&gt;&lt;function compare at 0x112441e60&gt;2020&quot;&quot;&quot; 由上面的範例來看，compare 函數物件被賦值給變數 func，print 出的結果顯示 compare 和 func 指向同一個函數物件。 可作為參數傳遞12345678910def square(x): return x * xdef arr(f, items): return [f(item) for item in items]numbers = [1, 2, 3, 4, 5]total = arr(square, numbers)print(total) # [1, 4, 9, 16, 25] 由上面的範例來看，函數 square 函數物件被當作 arr 函數的參數傳遞，隨後於 arr 中進行陣列處理。 再給個例子：以 say_hello, be_awesome 兩個函示做為參數，傳入 greet_tom 這項函式裡，接著呼叫該函式 123456789101112def say_hello(name): return f&quot;Hello {name}&quot;def be_awesome(name): return f&quot;Yo {name}, together we are the awesomest!&quot;def greet_tom(greeter_func): return greeter_func(&quot;Tom&quot;)print(greet_tom(say_hello)) # Hello Tomprint(greet_tom(be_awesome)) # Yo Tom, together we are the awesomest! 上述範例流程： 兩個函示分別為 greet_tom 函示的參數 執行 greet_tom 函式後呼叫 greeter_func 函式 這時 say_hello, be_awesome 兩個函示分別代表以 greeter_func 的參數形式進行函式呼叫 greeter_func 呼叫時傳入 Tom 這個字串型別的參數 最終根據傳入不同的參數(函示)來源，回傳相應的結果 可作為函數的回傳值12345678# 可作為函數的回傳值def logger(msg): def message(): print('Log:', msg) return messagelogWarning = logger('Warning')logWarning() # Log: Warning 由上面的範例來看，在函數 logger 內部建立函數 message，函數 message 內使用了 logger 傳入的參數 msg，最後 logger 將 message 函數作為回傳值，再assign給 logWarning 進行呼叫。 或是另外一個例子: 123456789101112def html_tag(tag): def wrap_text(text): print('&lt;{0}&gt;{1}&lt;/{0}&gt;'.format(tag, text, tag)) return wrap_texth1 = html_tag('h1')h1('This is a header') # &lt;h1&gt;This is a header&lt;/h1&gt;h1('This is a header, too') # &lt;h1&gt;This is a header, too&lt;/h1&gt;p = html_tag('p')p('This is the first paragraph') # &lt;p&gt;This is the first paragraph&lt;/p&gt;p('This is the second paragraph') # &lt;p&gt;This is the second paragraph&lt;/p&gt; Python Scope(作用域)有了頭等函式概念之後，再來談談 Python 的作用域。Python 的作用域(scope)規則規則叫做 LEGB，查找時 scope 會循這個規則，順序為 Local -&gt; Enclosed -&gt; Global -&gt; Built-in Local: 於 function 或是 class 內宣告的變數名 Enclosed: 位於巢狀層次的function結構，常用於Closure Global: 最上層位於模組(module)的全域變數名稱 Build-in: 內建模組(module)的名稱，例如print, abs()這樣的函式等等 圖片源 The Python Tutorial裡面有更詳細的解釋。 the innermost scope, which is searched first, contains the local names the scopes of any enclosing functions, which are searched starting with the nearest enclosing scope, contains non-local, but also non-global names the next-to-last scope contains the current module’s global names the outermost scope (searched last) is the namespace containing built-in names Python的作用域有許多細節可以討論，為了縮短篇幅和挑幾個重點出來，主要區分為global(全域)、local(區域)變數和Enclosed Scope。 global(全域)變數放在function外的變數 123456789a = &quot;hello a&quot;def scope1(): print(a) scope1()&quot;&quot;&quot;執行結果:hello a&quot;&quot;&quot; 執行scope1()，要印出a變數的值時，若在scope1內找不到變數a，便會往外找，找到全域中宣告的a變數 local(區域)變數在Python裡創建一個function，function內執行的區域稱作「local scope」，而建立區域變數最簡單的方式是於function中給定一個變數。一般來說，全域變數是無法被該function scope內重新定義的變數進行存取。 範例假設有一變數a初始值為 hello a，想要透過 scope1() 函數對 a 重新賦值 123456789a = &quot;hello a&quot;def scope1(): a = 1scope1()print(a)&quot;&quot;&quot;執行結果:hello a&quot;&quot;&quot; 上述結果告訴我們，a = 1無法對scope1()外的a重新賦值。 若要讓local scope內的變數讓外部進行存取，可以在目標變數的前面宣告一個global 12345678910a = &quot;hello a&quot;def scope1(): global a a = 1scope1()print(a)&quot;&quot;&quot;執行結果:1&quot;&quot;&quot; 特殊情況在Python中，區域變數或是全域變數，兩者只能「選邊站」，不可以同時指定為區域變數及全域變數。 123456a = 5def scope(): print(a) a = 10scope() 執行上述範例，會得到 UnboundLocalError 的錯誤資訊。 Enclosed Scope依據巢狀層次從內到外搜尋，當搜尋到 LEGB 的 E 時，Python會從最近的 enclosing scope 向外找起，那這些enclosing scopes 裡的所有變數，稱作 non-local variable。 12345678910111213# enclosuredef outer(a): b = a def inner(): c = 3 def inner_inner(b): k = b+c return b+c return inner_inner return inneroutcome = outer(5)ans = outcome()ans(3) # 6 以上述範例來說，b是outer()的區域變數，c是inner()的區域變數，由於離inner()最近的scope是outer所建立的，b又是於此scope被宣告，所以b是inner()的non-local variable。 再往下走，以inner_inner()來看，k為它的local variable ，值被assign為b+c，這時的b 並非被宣告在outer()scope裡，而是藉由參數傳遞的，也就是說，b屬於local variable。反之c則是被宣告在inner()的scope裡，對inner_inner()來說，是屬於non-local variable。 Closure前面提到很多關於頭等函式及作用域，可以開始進入正題: Closure 假設有個巢狀函式，最外層的函式把自己內層嵌套另外一個函式，將這個嵌套的函式作為回傳值傳遞出去，便會形成一個Closure。 先看一段範例: 12345678910111213141516171819def student(): height = 170 weight = 60 def info(): print(&quot;my height is {}.&quot;.format(height)) print(&quot;my weight is {}.&quot;.format(weight)) return infoprint(student)print(student())students = student()students()&quot;&quot;&quot;回傳結果:&lt;function student at 0x112479440&gt;&lt;function student.&lt;locals&gt;.info at 0x1124794d0&gt;my height is 170.my weight is 60.&quot;&quot;&quot; 上面的範例可以觀察出一個奇怪的點，一般情況下，function中內區域變數的生命週期(life cycle)會隨著function執行完畢而結束，但是print出來的結果卻還可以讀取到height、weight兩個屬於student()scope的變數。 原因在於return info這個地方，info這個function趁著return的時候捕捉外層函式裡的變數，並偷渡進來自己的scope裡面。 被捕捉的變數便稱做「captured variable」，帶有captured variable的函式稱為closure。 查看Closure若想知道閉包儲存多少物件，可以印出__closure__屬性查看資訊，__closure__會是一個唯讀屬性；印出的資料型態是tuple。 12345678910111213141516def student(): height = 170 weight = 60 def info(): print(&quot;my height is {}.&quot;.format(height)) print(&quot;my weight is {}.&quot;.format(weight)) return infostudents = student()print(student.__closure__) # Noneprint(students.__closure__) # (&lt;cell at 0x112cb1d50: int object at 0x10d522670&gt;, &lt;cell at 0x112cb1d90: int object at 0x10d5218b0&gt;)print(type(students.__closure__)) # &lt;class 'tuple'&gt;print(students.__closure__[0].cell_contents) # 170print(students.__closure__[1].cell_contents) # 60 從上面的範例來看會發現，雖然對info來說，有height、weight兩個non-local variable，但因為info並未使用它們，所以這時student.__closure__的回傳值是None。 再往下一步，對student進行呼叫，並assign給變數students，訪問__closure__屬性則會回傳(&lt;cell at 0x112cb1d50: int object at 0x10d522670&gt;, &lt;cell at 0x112cb1d90: int object at 0x10d5218b0&gt;)這樣的物件資訊。 若要印出裡面的某個物件的話，如取得物件的值，跟tuple取值的方法相同，[]填入要索引的位置，如students.__closure__[0].cell_contents，回傳index=0的值。 Captured variables 如何賦值如果要對Captured variables重新賦值的話， 123456789101112def student(): height = 170 weight = 60 def info(): height += 1 weight -= 1 print(&quot;my height is {}.&quot;.format(height)) print(&quot;my weight is {}.&quot;.format(weight)) return infostudents = student()print(students()) # UnboundLocalError 執行上述範例後會看到預期不到的錯誤: UnboundLocalError。 原因在function scope中，當變數被賦值時，Python會自動將變數設定為區域變數(local variable)。回頭看上面的範例中，height、weight被重新賦值，兩者在info這個function scope判定為區域變數，但兩者找不到相對應的變數名。 在一般情況下，若想在某個function中assign新的值給先前宣告在全域變數(global scope)中的變數時，一樣也會報UnboundLocalError錯誤訊息。 12345a = 5def scope(): a += 10scope() # UnboundLocalError 解決方法宣告nonlocal去操作captured variable。來看範例: 123456789101112131415161718192021def student(): height = 170 weight = 60 def info(): # nonlocal nonlocal height nonlocal weight height += 1 weight -= 1 print(&quot;my height is {}.&quot;.format(height)) print(&quot;my weight is {}.&quot;.format(weight)) return infostudents = student()students()&quot;&quot;&quot;結果my height is 171.my weight is 59.&quot;&quot;&quot; 加上nonlocal height、nonlocal weight後即可正常assign變數了哦！ captured variable在Python中並非區域或全域變數，所以只能用 nonlocal去宣告變數，才能進行其他操作。 Captured variables具獨立性123456789101112131415161718192021222324252627282930313233343536def student(): height = 170 weight = 60 def info(): # nonlocal nonlocal height nonlocal weight height += 1 weight -= 1 print(&quot;my height is {}.&quot;.format(height)) print(&quot;my weight is {}.&quot;.format(weight)) return infostudents1 = student()students1()students1()students1()print(&quot;\\n--- students1 比較 students2 ---\\n&quot;)students2 = student()students2()&quot;&quot;&quot;結果:my height is 171.my weight is 59.my height is 172.my weight is 58.my height is 173.my weight is 57.--- students1 比較 students2 ---my height is 171.my weight is 59.&quot;&quot;&quot; 由上述例子可知:即使students1持續將height與weight兩個Captured variables加總和遞減，另一個students2內的Captured variable完全不受影響，推論兩個closure function彼此獨立。 以上為關於作用域及Closure相關概念，如有錯誤之處，還請指教。 參閱什麼是first-class function 聊聊 Python Closure Python進階技巧 (4) — Lambda Function 與 Closure 之謎！","link":"2020/02/26/Python/Python/%5BPython%5D%20%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%88%87Closure(%E9%96%89%E5%8C%85)/"},{"title":"[Python] 探討例外錯誤的處理機制","text":"前言寫程式有時候會發生一些錯誤，程式就會立即停止-&gt;立即出現error mesaage。避免因為使用者輸入的問題或設定的問題造成程式被迫中斷，或產生不可預期的狀況，有些例外錯誤必須在某些特定的情況下才會發生，為了能夠更有效應付這種錯誤，可以使用例外處理來解決。 一般處理Try-except statement，一般情況下，Python在做錯誤處理機制使用try ... except來捕捉錯誤訊息，並在此錯誤發生時，執行後續的程式碼。如果要針對不同錯誤訊息做個別處理，可以繼續增加except指令 捕捉特定錯誤訊息可以針對Python某個類型的錯誤訊息進行捕捉，程式結構大概是： 1234567try: # 想要執行的程式except (例外錯誤類型1, 例外錯誤類型2, …) as 例外物件: # 發生例外錯誤時要執行的程式碼except (例外錯誤類型3, 例外錯誤類型4, …) as 例外物件: # code# 可依需求增加 捕捉任何錯誤訊息except支援多種錯誤，若不指定任何錯誤類型的話只需要寫except，即可捕捉所有錯誤類型，只要有錯誤訊息發生，就會執行except後續的程式碼。 值得一提的事:try只會捕捉第一個錯誤,假設try裡有2行程式碼, 2行都有錯誤, 第一行被捕捉到以後, 就會跳到except, 並不會兩個錯誤都被找出來. 1234try: # 想要執行的程式except: # 發生例外錯誤時要執行的程式碼 範例123a = 100b = 0print(a/b) 執行上述這段程式碼會跳出ZeroDivisionError的錯誤訊息，如果要捕捉此錯誤，並印出”分母不可為0”訊息，可以把程式碼改成: 123456789a = 100b = 0try: print(a/b)except ZeroDivisionError as error: print(&quot;分母不可為0, 系統錯誤訊息為:&quot;, error)# 結果# 分母不可為0, 系統錯誤訊息為: division by zero 進階處理除了一般處理外，也可依照自己需求增加else .... finally ...的方法做近一步處理。程式結構會是: 12345678910try: # codeexcept (例外錯誤) as 例外物件: # codeelse: # without errror finally: # program still run here if there are errors else指的是當try指令內的程式順利執行完畢，且沒有發生任何錯誤時才執行，而finally後的指令則是無論有無錯誤訊息，仍須進行該指令下的程式碼，最常見的地方用於開檔/讀檔時，使用open()方法，即使有錯誤產生，仍須正常關閉檔案。 範例以open()方法開啟檔案為例 12345678f = open(&quot;./123.txt&quot;, &quot;r&quot;)print(&quot;--------是否有執行到這裏&quot;)words = f.read()print(&quot;--------是否有執行到這裏&quot;)print(words)print(&quot;--------是否有執行到這裏&quot;)f.close()print(&quot;--------正常關閉&quot;) 若無此檔案存在，則會拋出一個FileNotFoundError的錯誤資訊，這時程式會因錯誤而中斷，無法往下執行(後續的訊息都未被印出來)。 參考文章[Python初學起步走-Day15] - 例外處理 例外處理的語法","link":"2019/08/12/Python/Python/%5BPython%5D%20%E6%8E%A2%E8%A8%8E%E4%BE%8B%E5%A4%96%E9%8C%AF%E8%AA%A4%E7%9A%84%E8%99%95%E7%90%86%E6%A9%9F%E5%88%B6/"},{"title":"[Python] 爬蟲筆記1-基本概念","text":"前言這學期因為專題需要用到網路爬蟲進行實作，所以將學習到的知識做一篇紀錄，之後忘記可以回來複習一下。 什麼是爬蟲?根據維基百科定義: 也叫網路蜘蛛（spider），是一種用來自動瀏覽全球資訊網的網路機器人。其目的一般為編纂網路索引。網路搜尋引擎等站點通過爬蟲軟體更新自身的網站內容或其對其他網站的索引。網路爬蟲可以將自己所存取的頁面儲存下來，以便搜尋引擎事後生成索引供用戶搜尋。 簡單來說就是對網站進行資料擷取，可以透過它自動蒐集我們所想要的資料，將資料進行分析或是再利用，這樣的技術在資料科學領域算是幾乎需具備的技能。 為何選擇Python? 工具多元 容易上手 學習資源多 有哪些可用的工具?Python工具非常多，內建的函式庫包含urllib或是第三方套件如:requests、seleium等強大易上手工具。本篇會先紀錄urllib、requests這兩個常用在爬取靜態網站的工具。 urllib是Python內建的函式庫，只要安裝python就可以直接使用了，不需額外安裝。 1234import urlliburl = urllib.request.urlopen('https://www.google.com')print(url.read()) 上面那段程式碼會進行網頁解析，但若是遇到網站有反爬蟲機制就會回報錯誤，例如下段程式碼: 12url = urllib.request.urlopen('https://group.i-fit.com.tw/?route=buy&amp;id=1&amp;in=')print(url.read()) 結果:有些網站為防止這種非正常的訪問，會設反爬蟲機制，驗證請求中的UserAgent。這時就必須設置一個header，加入UserAgent即可。 123456import urllibfrom urllib.request import Request, urlopenurl = Request('https://group.i-fit.com.tw/?route=buy&amp;id=1&amp;in=', headers={'User-Agent': 'Mozilla/5.0'})webpage = urlopen(url).read()print(webpage) 這時候就可以正常進行訪問，後續進行網頁解析時我們可以透過bs4這個套件協助我們parse網頁結構。 1234567from bs4 import BeautifulSoupfrom urllib.request import Request, urlopenurl = Request('https://group.i-fit.com.tw/?route=buy&amp;id=1&amp;in=', headers={'User-Agent': 'Mozilla/5.0'})webpage = urlopen(url).read()sp = BeautifulSoup(webpage, &quot;html.parser&quot;)print(sp) 繞過反爬蟲的方法有些網站不喜歡讓外部使用者擷取網站資料，會採用一些反爬蟲機制，要繞過這些機制可以採用幾個手段: UserAgent 因為爬蟲是機器人，為了要偽裝成如真人一般造訪網站，透過設置UserAgent來達成真人訪問網站的效果。 限制訪問頻率 有些網站無法進行短時間內頻繁的請求，在一定時間內對網站發出超過特定次數的請求會封鎖IP，可以設定訪問時間的間隔為一個隨機值，例如間隔0~5秒隨機發出請求。 requests是第三方套件，非python中內建，在使用它的時候就需要先安裝，執行pip install requests；requests功能非常強大，它比urllib更加方便快速。範例，使用get方法進行網站請求: 12345678import requestsheader={'User-Agent': 'Mozilla/5.0'}page = requests.get(&quot;https://group.i-fit.com.tw/?route=buy&amp;id=1&amp;in=&quot;, headers= header)print(page) # &lt;Response [200]&gt;print(page.text) # 解析網頁 -&gt; 以Unicode進行編碼 上面的範例程式碼裡面print(page)會回傳一個&lt;Response [200]&gt;的response物件，page.text會以Unicode的形式進行編碼。 幾個爬蟲要點 選定目標網址 分析目標網站的HTML網頁結構 Devtools觀察request訊息 擷取目標資料 選定目標網址選定目標網站。 分析目標網站的HTML網頁結構向目標網址發送HTTP請求封包，伺服器會回應HTML網頁原始碼，我們要定位網頁資料。 Devtools觀察request訊息打開Devtools的Network，觀察request header，裡面有許多重要的訊息，幫助我們在爬蟲時能夠快速了解網站訊息，決定採用何種擷取資料的方法。 擷取目標資料將擷取下來的資料儲存成特定格式，常見如: JSON CSV XLSX SQL 這篇主要紀錄爬蟲的目的、注意要點，下篇會紀錄我目前常用的方法。","link":"2019/09/01/Python/Python/%5BPython%5D%20%E7%88%AC%E8%9F%B2%E7%AD%86%E8%A8%981/"},{"title":"[Python] 檔案讀寫","text":"前言本篇紀錄Python在開檔/讀檔的操作方法，並以.txt檔為範例。 開啟檔案選定要處理得目標檔案，建立檔案物件(file object)，若檔案不存在，open()函式就會拋出一個FileNotFoundError的錯誤訊息。f = open(檔名, &quot;操作模式&quot;, encoding=&quot;編碼方式&quot;) Python 提供多個開啟檔案的模式，紀錄幾個常用的開檔模式： &quot;r&quot; =&gt; 唯讀模式(預設情況)：只能從指定的檔案讀取資料，不能對此檔案內容進行更改。若指定檔案不存在，會產生 FileNotFoundError的例外錯誤。&quot;w&quot; =&gt; (覆寫模式）：進行檔案的寫入，會在開啟的位置直接覆蓋掉原本的檔案。若指定的檔案路徑/名稱不存在，會自動新增一個新檔案。&quot;a&quot; =&gt; (續寫模式）：在此模式下開啟檔案要進行寫入時，會從原本的檔案最後面為起始點繼續寫入。&quot;r+&quot; =&gt; 檔案存在的情況下讀取舊資料並寫入(始於游標所在位置)&quot;w+&quot; =&gt; 清空檔案內容，可再讀出新寫入的東西(檔案可不存在，會自動新增) 範例1f = open('./test.txt', 'r') 關閉檔案在程式當中開啟了檔案以後，如果要停止對於這個檔案的更動或寫入，可以將檔案關閉，使用close()方法進行關閉。範例 1f.close() 讀取檔案成功開啟檔案以後，再來要讀取檔案當中的資料。Python在file object 當中提供了幾種從檔案讀取資料的方法: file.read()file.read(size)，若有設定size的值，會讀到指定的字節數量，若沒有設定則會讀取整個檔案。 範例：上方為 1234567891011121314151617f = open(&quot;./sample.txt&quot;, &quot;r&quot;)words = f.read(5)print(words)f.close()# 回傳結果# This is python example.# python is fun.# ======= 設定size ================f = open(&quot;./sample.txt&quot;, &quot;r&quot;)words = f.read(5)print(words)f.close()# 回傳結果# This file.readline()讀取檔案中的整行內容，但一次只讀取一行，包含\\n字元，若檔案內容包含了多行的資料，我們就必須呼叫f.readline() 多次。 12345678f = open(&quot;./sample.txt&quot;, &quot;r&quot;)first = f.readline()second = f.readline()print(second, first, sep = &quot;\\n&quot;)f.close()# 回傳結果# python is fun.# This is python example file.readlines()逐行讀取檔案所有內容，回傳一個list資料結構，並且在每一行文字最後面會加上一個\\n。 12345678f = open(&quot;./sample.txt&quot;, &quot;r&quot;)lines = f.readlines()print(lines)f.close()# 回傳結果# ['This is python example.\\n', 'python is fun.'] 寫入檔案將open()函數內的讀檔模式改為&quot;w&quot;，並使用file.write()，相對於剛才提到的f.read()，語法: 1f.write(&quot;string&quot;) 寫入檔案，並回傳寫入的string長度。 範例12345f = open(&quot;./sample.txt&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;)words = f.write(&quot;This is a new line be written&quot;)print(words)f.close()# 29 寫入多行若不想要每輸出一段東西就執行一次 f.write(sequence)，可以使用file.writelines()，一次寫入多行。 sequence參數為list或是tuple等這類的資料型態 範例12345f = open(&quot;./sample.txt&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;)seq = [&quot;測試第一行\\n&quot;,&quot;測試第二行&quot;]words = f.writelines(seq)print(words)f.close() 輸出結果 讀寫檔案的錯誤處理使用with open（）as讀寫檔案，最剛開始開啟檔案時，或檔案不存在，Python會拋出FileNotFoundError這類的錯誤訊息。 由於檔案讀寫時都有可能產生錯誤，若錯誤發生，後面的f.close()就不會被執行。為了保證無論是否出錯都能正確地關閉檔案，我們可以使用try ... finally來完成。 finally表示當錯誤發生時，finally後續的程式碼繼續執行 範例123456try: f = open('./sample.txt', 'r') print(f.read())finally: if f: f.close() 如果每次都這麼寫會顯得過於冗長，with ...方法可以自動呼叫close()方法 範例12with open('./sample.txt', 'r') as f: print(f.read()) 透過with方法定義f為變數名稱，同時又不需要寫try ... finally來確保檔案正常關閉。 參考python 使用 with open（） as 讀寫檔案","link":"2019/08/10/Python/Python/%5BPython%5D%20%E8%AE%80%E5%AF%AB%E6%AA%94%E6%A1%88/"},{"title":"[Python] 讓Pipenv 幫你做套件管理","text":"什麼是Pipenv?Pipenv 是一個簡單、更快速的 Python 套件管理工具，整合Pipfile, pip, virtualenv，我們需要一個乾淨環境來開發，會使用 virtualenv 建一個虛擬環境，再透過 pip 以及 requirements.txt 去管理套件的版本。解決痛點:剛學python時，對於套件管理不是那麼熟悉，路徑設置也是一知半解，用到的套件都亂安裝，安裝方式有時根本大雜燴，(mac為例)可能用brew install ，又用anaconda install，或是 pip install，又有 pip3 install，有時候發生，明明就有裝，但是 import 的時候卻找不到套件，後來才發現原來是該目錄沒有加入path，或是把專案發佈的時，不清楚這個專案到底安裝了哪些套件，一個一個回去查找專案內容等問題……這時如果有個工具可在虛擬環境下做套件管理，就可以解決上述問題 建立虛擬環境的幾個好處: 不同專案可使用不同版本相同套件，且不互相影響，可避免版本衝突。 在虛擬環境裡，pip 安裝的套件會被放在虛擬環境中，每個專案可擁有獨立環境。 套件版本升級時不會影響到其他的專案。 前面說了這麼多，接著開始實作看看吧！安裝1pip install pipenv mac也可以用homebrew進行安裝 1brew install pipenv `` 進入專案資料夾中建立新的專案資料夾，並切換至該資料夾下。 創建虛擬環境1pipenv install 你要的套件 若後面沒有帶任何參數則會安裝Pipfile內所有套件。pipenv install 安裝特定套件可參考下方範例: 123pipenv install --three #使用python 3建立環境pipenv install --two #使用python 2建立環境pipenv install --python 3.7.4 #更精確的指定版本 安裝成功 目錄下若無Pipfile，Pipenv會預設產生一個Pipfile，Pipfile會幫你記錄所載的相依套件若我下載requests這個套件 1pipenv install requests Pipfile內的packages會新增requests這項紀錄，Pipfile.lock也會有requests紀錄，同時記錄 requests 所需相依套件的版本，用來確保在任何地方透過這份檔案安裝套件都是相同的套件。 執行python相關指令如下: 不進入虛擬環境中 1pipenv run python test.py 進入虛擬環境中 1pipenv shell 印出專案相依套件的圖 1pipenv graph 如果仍然需要導出 requirements.txt，可能是要部署至特定平台服務，如AWS 1pipenv lock --requirements &gt; requirements.txt 其他指令:移除指定套件 1pipenv uninstall requests 更新pipenv＆pip到最新版本 1pipenv --upgrade 顯示虛擬環境根目錄資訊 1pipenv --upgrade pipenv --where 顯示虛擬環境執行檔所在目錄 1pipenv --venv 顯示目前使用的python執行檔資訊(同which python) 1pipenv --py 輸出相關環境變數 1pipenv --envs 顯示版本 1pipenv --version 參考文章參考文章圖片","link":"2020/01/10/Python/Python/%5BPython%5D%20%E8%AE%93Pipenv%20%E5%B9%AB%E4%BD%A0%E5%81%9A%E5%A5%97%E4%BB%B6%E7%AE%A1%E7%90%86/"},{"title":"[Python] 爬蟲筆記2-requests&amp;BeautifulSoup","text":"前言繼上篇筆記之後，本篇主要紀錄我常用的爬蟲工具：requests、BeautifulSoup這兩個模組。 所需先備知識-了解網站請求向網站發請求時，GET與POST是常見的HTTP Method，爬蟲大多採用這兩種方法。 安裝requests和bs412pip install bs4pip install requests 引入模組12import requestsfrom bs4 import BeautifulSoup requestsrequests模組可以讀取網站的原始碼，再利用正規表達式取得目標資料。 GET Method假設今天要抓取PTT的NBA版，讀取網頁的方法會是: 1requests.get(&quot;目標網址&quot;, headers=你設置的header) 範例: 12header={'User-Agent': 'Mozilla/5.0'}url = requests.get(&quot;https://www.ptt.cc/bbs/NBA/index.html&quot;, headers=header) requests相關知識: http狀態碼: resp.status_codehttp狀態碼(status code)，用於表示向網站請求的狀態。 通常2開頭為請求成功 開頭為4為請求失敗，表示Client端錯誤 開頭為5為請求失敗，表示Server端錯誤可以依照http狀態碼來排查問題，更詳細的狀態說明可以看這篇。 查看網頁編碼: url.encoding有時候解析下來的網頁會有文字編碼問題，python3內所有的文字都是 unicode類型的str，可以透過encoding的方式查看編碼，也可以改變網頁編碼，如:12345print(url.encoding) # utf-8# 改變編碼方式url.encoding = 'big5'print(url.encoding) # big5 解析網頁內容確定網頁請求成功後(狀態碼為200)，接著進行網頁內容解析，獲取的資料大部分會用上面兩種型式儲存: text: 返回的是 Unicode型態的資料，常用於字串。 content: 返回的是bytes型態的資料，常用於圖片、文件。 在網址列加上查詢參數(Query String)有時會在發GET請求時，在網址列加上查詢的參數，可採自訂payload(dic資料型態)的方法，GET以params為參數，將自訂的參數值assign給params:12payload = {'key1': 'value1', 'key2': 'value2'}requests.get(&quot;目標網址&quot;, params=payload) 以雅虎股市新聞為例，參數pg後面挾帶的數值表示頁數:1234payload = {'q': '', 'pg': '2'}page = requests.get(&quot;https://tw.stock.yahoo.com/news_list/url/d/e/N1.html&quot;, headers=header, params=payload)print(page.url)# 結果: https://tw.stock.yahoo.com/news_list/url/d/e/N1.html?q=&amp;pg=1 POST Method相較於GET，POST請求的資料通常都是網頁讓使用者填表單時會採用的方法。POST以data為參數，將自訂的參數值assign給data: 12payload = {'key1': 'value1', 'key2': 'value2'}requests.post(&quot;目標網址&quot;, data=payload) 範例: 123payload = {'key1': 'value1', 'key2': 'value2'}page = requests.post(&quot;http://httpbin.org/post&quot;, headers=header,data=page)print(page.text) Session Method有時使用者(Client)造訪網站時，網站(server)為了要辨識使用者身份，會發一個憑證給訪問者，憑證若儲存在Client端稱作cookie，存在Server端稱作Session，兩者常用於紀錄登入者資訊，這時可用Session方法紀錄cookie訊息。 實作:假設今天目標為PTT的八卦版，在第一次訪問時會導向另一個頁面先確定使用者是否超過18歲，以網路爬蟲來說，必須先經由認證的行為來取得合法身份，使用者資訊會夾雜在session裡面。在我同意的按鈕上點擊右鍵打開開發者工具觀察元素，可以發現預設值為yes，並以POST的形式傳送資料， 12345678910111213import requestspayload = { 'from': 'https://www.ptt.cc/bbs/Gossiping/index.html', 'yes': 'yes' }headers = { 'user-agent': 'Mozilla/5.0'}rs = requests.Session()rs.post('https://www.ptt.cc/ask/over18', data=payload, headers=headers)res = rs.get('https://www.ptt.cc/bbs/Gossiping/index.html', headers=headers)print(res.text) 上述範例程式碼中，from表來源網頁，yes為按鈕的預設值。 BeautifulSoup通常解析出來的網頁結構都比較複雜，要擷取特定資料需要其他工具來協助我們，這時BeautifulSoup就派上用場了，當然除了BeautifulSoup之外，常用的工具還包含xpath、正規表示式(re)等方法，本篇先記錄BeautifulSoup。延續上一段未完成的PTT八卦版程式碼，如果要取得多個標題文章，可以用下面這段完整的程式碼: 1234567891011121314151617# PTT八卦版爬蟲import requestsfrom bs4 import BeautifulSouppayload = { 'from': 'https://www.ptt.cc/bbs/Gossiping/index.html', 'yes': 'yes' }headers = { 'user-agent': 'Mozilla/5.0'}rs = requests.Session()rs.post('https://www.ptt.cc/ask/over18', data=payload, headers=headers)res = rs.get('https://www.ptt.cc/bbs/Gossiping/index.html', headers=headers)soup = BeautifulSoup(res.text, 'html.parser')items = soup.select('.r-ent')for item in items: print(item.select('.date')[0].text, item.select('.author')[0].text, item.select('.title')[0].text) BeautifulSoup(res.text, 'html.parser')採用解析器:html.parser是Python內建的，除了html.parser外，還支援lxml，更多解析器及比較可參考這篇文章 1soup.prettify() 上述方法可印出完整的HTML結構(排版後)。接著觀察網頁結構的HTML標籤 常用的方法find()、find_all() find(“標籤名稱”): 回傳第一個符合指定的標籤內容，找不到則回傳None。 find_all(“標籤名稱”): 回傳多個符合指定的標籤內容，是一個list結構，找不到則回傳空的list。 獲取標籤內容1234567## 範例soup.find('p').text # 印出第一個p標籤soup.find_all('p')[0].get_text() # 印出第一個p標籤的文字內容soup.find_all(class_=&quot;outer-text&quot;) # 取得有class得tagsoup.find(id='link2') # 取得有id得tag 上述的soup.find('h1')也可以寫作soup.h1。 注意 find用.text顯示文字find用.get_text()顯示文字(資料型態須為字串) 尋找指定的標籤中符合屬性條件的內容1find(&quot;標籤名&quot;, { &quot;屬性名&quot; : &quot;屬性值&quot;}) 或 find_all(&quot;標籤名&quot;, { &quot;屬性名&quot; : &quot;屬性值&quot;}) 範例 1soup.find('h1',{'class':'hello'}) # 印出第一個h4標籤且class名稱為hello中的內容 取得標籤的屬性內容如果想取得回傳值的屬性內容也可以用get(&quot;屬性名稱&quot;)或是[&quot;屬性名稱&quot;] 1234567&lt;a id=&quot;link&quot; href=&quot;http://example.com&quot;&gt;&lt;/a&gt;dataList = soup.select(&quot;#link&quot;)# 取得href的屬性內容print(dataList[0].get(&quot;href&quot;)) # http://example.comprint(dataList[0][&quot;href&quot;]) # http://example.com 搜尋多個標籤1tags = soup.find_all([&quot;title&quot;, &quot;p&quot;]) 搜尋多個標籤並限制數量1tags = soup.find_all([&quot;title&quot;, &quot;p&quot;], limit=2) select()以CSS選擇器的方式定位元素，讀取指定的資料，回傳值是list的資料結構。常見的CSS選擇器: 標籤 id(唯一): 要獲取具有id的標籤需在前面加上#，如select(&quot;#title&quot;)，id表唯一的選擇器。 class(類別): 要獲取具有class的標籤需在前面加上.，如select(&quot;.title&quot;)，class選擇器可以同時擁有多個。範例:123bs.select('h1') # 尋找h1標籤bs.select('#id_tag') # 尋找id名為id_tagbs.select('.class_tag') # 尋找class名為Pclass_tag 多層如果遇上層層嵌套的結構時可以採用範例的方法:獲取html底下的head底下的title標籤內容 1title = soup.select(&quot;html head title&quot;) 直接選擇標籤Tag12345678# 輸出title標籤print(soup.title)# 輸出title標籤的屬性print(soup.title.name)# 輸出title標籤的內容print(soup.title.string)# 輸出網頁中的所有文字soup.get_text() 以上為requests&amp;BeautifulSoup常用的方法","link":"2019/09/02/Python/Python/%5BPython%5D%20%E7%88%AC%E8%9F%B2%E7%AD%86%E8%A8%982-requests&BeautifulSoup/"},{"title":"[Python] 爬蟲筆記3- Selenium","text":"前言Selenium 是一個瀏覽器自動化測試工具，最初是為了自動化測試開發，在爬蟲流行開始後，也成為其中一種爬蟲工具。它的功能可以控制瀏覽器，模擬人對瀏覽器操作，整個過程是自動化的。selenium支援Java、JavaScript、Python等多種主流程式語言，本篇主要用Python實作。 安裝Selenium1pip install selenium 成功後，顯示Successfully installed selenium. 下載webdriver要讓Selenuim能夠控制瀏覽器、跟瀏覽器進行溝通，就需要使用Webdriver主流瀏覽器webdriver載點: Chrome Edge Firefox自己主要以Chrome為主要瀏覽器，所以下載ChromeDriver 實作.get('目標網址') 123from selenium import webdriver #從library中引入webdriverbrowser = webdriver.Chrome('./chromedriver') # 建立chrome browser 物件browser.get('https://www.google.com/') :::warning 可能會遇到的問題:版本問題webdriver的版本要和目前瀏覽器的版本相符合，不然會有版本號不同的錯誤訊息，瀏覽器會有閃退的情況，如下方: 解決方法 確認Chrome 瀏覽器版本 開啟瀏覽器右上方的選單 選擇說明&gt;關於 Google Chrome 查看當前版本 下載可支援此Chrome版本的ChromeDriver 路徑問題執行browser = webdriver.Chrome()之後，會顯示Message: ‘chromedriver’ executable needs to be in PATH. 解決方法把chromeDriver與的.py檔放置在同一目錄下，避免程式找不到ChromeDriver。::: 執行結果運行後，即可看到Chrome目前受到自動測試軟體控制，完成第一個Chrome自動化專案，我們剛才的動作就是在模擬瀏覽器登入Google網站！ 關閉瀏覽器前面的實作會發現打開瀏覽器後無法自動關閉瀏覽器，這時候可以執行close()進行關閉。 1browser.close() 讓瀏覽器在背景執行 webdriver.ChromeOptions() 來宣告options options.add_argument('--headless') 背景執行 將options加入Chrome方法裡面 *註: executable_path 為webdriver執行的路徑 123456options = webdriver.ChromeOptions()options.add_argument('--headless')browser=webdriver.Chrome(chrome_options=options, executable_path='./chromedriver')#在瀏覽器打上網址連入browser.get(&quot;https://www.google.com/&quot;) 上述程式碼可以在不開啟瀏覽器的情況下執行自動化腳本 開啟無痕模式將程式碼加入options.add_argument(&quot;--incognito&quot;)即可以無痕模式開啟瀏覽器 1234options = webdriver.ChromeOptions()options.add_argument(&quot;--incognito&quot;) browser=webdriver.Chrome(chrome_options=options, executable_path='./chromedriver')browser.get(&quot;https://www.google.com/&quot;) 瀏覽器視窗設定 視窗大小設定: browser.set_window_size(480, 800) 視窗最大化: browser.maximize_window() 視窗最小化: browser.minimize_window() 常用定位網頁元素的方法 搜尋帶有特定id名稱的元素: find_element_by_id() 搜尋帶有特定name屬性名稱的元素: find_element_by_name() 搜尋帶有特定class名稱的元素:find_element_by_class_name() 搜尋帶有特定名稱的網頁標籤:find_element_by_tag_name() 用Xpath來定位網頁元素: find_element_by_xpath() 用CSS選擇器定位網頁元素find_element_by_css_selector() 上述的方法都只有搜尋第一個符合條件的元素，如果要搜尋多個元素，只要在find_element上改為find_elements即可，返回結果為list的資料結構。 XpathXpath 全名為XML Path Language，即XML路徑語言，它可以在XML檔案中查找。最初設計是用來尋找XML檔案，但是它同樣也適用在搜尋HTML檔。另外，XPath的定位元素功能十分強大，提供非常簡潔的定位方法，幾乎所有我們想要定位的元素節點都可以靠XPath幫我們完成。 Xpath的語法非常多，先記錄比較常用的規則，掌握大方向後其他的再找文件很快就能上手。 XPath常用規則/ : 從當前節點選取直接子節點// : 從當前節點選取子孫節點. : 選取當前節點.. : 選取當前節點的父節點@ : 選取屬性 不錯的範例文章 selenium 的等待selenium等待方式常見的有下列3種，各有其優缺點。 强制等待從time模組裡面叫出sleep方法，強迫程式需過指定的時間後才可往下執行。 1234567from time import sleepoptions = webdriver.ChromeOptions()options.add_argument(&quot;--incognito&quot;) browser=webdriver.Chrome(options=options, executable_path='./chromedriver')browser.get(&quot;https://www.google.com/&quot;) sleep(3) # 強制等待3秒再執行下一步browser.close() 隱性等待隱形等待是設一個最長的等待時間，若在規定時間內網頁載入完成，則執行下一步，否則一直等到時間截止，然後執行下一步。這裡有一個問題: 程式會一直等待整個頁面載入完成。 123456options = webdriver.ChromeOptions()options.add_argument(&quot;--incognito&quot;) browser=webdriver.Chrome(chrome_options=options, executable_path='./chromedriver')browser.implicitly_wait(10) # 隱性等待最長時間為10秒再執行下一步browser.get(&quot;https://www.google.com/&quot;) browser.close() 顯性等待WebDriverWait，配合until()和until_not()方法，能根據判斷條件而進行彈性設定等待時間。 詳細的應用參考這篇。 獲得元素的相關訊息整理 size 獲得元素的尺寸 text 獲得元素的文字內容 get_attribute(name) 獲得該屬性名對應的屬性值 page_source 回傳網頁原始碼 driver.title 回傳網頁標題 current_url 獲得當前網頁的網址 is_displayed() 判斷此元素是否可見 is_enabled() 判斷此元素是否被使用 is_selected() 判斷此元素是否被選到 tag_name 回傳元素的tagName範例顯示元素尺寸find_element_by_id(&quot;size&quot;).size顯示元素文字find_element_by_id(&quot;txt&quot;).text 從隱藏元素中獲取文字在某些情況下，元素的文字會被隱藏，我們需要獲得隱藏元素的文字。這些內容在使用element.attribute('attributeName')很常遇到,透過textContent,innerText,innerHTML等屬性獲取。 innerHTML: 回傳元素的內部HTML，包含所有的HTML標籤。 textContent 和innerText只會得到文字內容，而不會包含HTML 標籤。 textContent 是 W3C 相容的文字內容屬性，但是 IE 不支援innerText 不是 W3C DOM 的指定內容，FireFox不支援 操作元素的方法下面整理幾個比較常用模擬訪問瀏覽器常用的操作方法。 整理 clear(): 清除元素内容 send_keys(): 鍵盤輸入的值 click(): 點擊元素 submit(): 送出表單 更多參考這篇 操作瀏覽器按鈕 back(): 按瀏覽器 “上一頁” 鈕 forward(): 按瀏覽器 “下一頁” 鈕 refresh(): 按瀏覽器 “更新” 鈕 quit(): 按瀏覽器 “關閉” 鈕, 同時關閉驅動程式 close(): 按瀏覽器 “關閉” 鈕 獲得Cookie.get_cookies() 儲存網頁截圖(screenshot)save_screenshot(filename): 將目前網頁儲存為 .png 檔案下載。*註: 傳入參數若單純只有檔名, 則png檔會儲存在 Python 安裝目錄下;若要存在指定目錄下，則需傳入包含路徑之檔名。 範例程式:1234from selenium import webdriver browser=webdriver.Chrome() browser.get(&quot;http://google.com&quot;) browser.save_screenshot(&quot;google.png&quot;) #儲存PNG圖檔 總結啟用selenium之後，被指定的瀏覽器就會開啟，並依照自己撰寫的腳本執行，所有網頁的操作，包含: 輸入帳號、密碼、點選按鈕、滾動頁面、變化視窗等，都可以進行模擬操作。因為是真正的瀏覽器在運作，可以輕鬆的繞過大部分網站反爬蟲機制，但也導致運行速度極慢。實際上還是會先嘗試使用requests獲取網頁原始碼，但如果實在無法突破對方網站伺服器的阻隔時，再嘗試改用selenium。我自己的話通常只有遇到動態載入的網頁才會使用selenium。","link":"2019/09/03/Python/Python/%5BPython%5D%20%E7%88%AC%E8%9F%B2%E7%AD%86%E8%A8%983-%20Selenium/"},{"title":"[Python] 讓Python程式碼更Pythonic","text":"前言之前跟朋友一起討論程式時，有時覺得寫的程式碼太多行，想辦法盡量寫得精簡一些，於是開始找網路上各個大神的寫法，沒查還好，一查天為驚人，藉此機會筆記一下，之後可以回過頭來檢視一下自己寫的程式碼品質。 兩個變數的值進行交換1234567# worst casetemp = aa = bb = temp# best casea,b = b,a 鏈式比較1234567a = 3b = 1 # worst caseb &gt;= 1 and b &lt;= a and a &lt; 10 #True # best case1 &lt;= b &lt;= a &lt; 10 #True 真值測試1234567891011name = 'Tim'langs = ['AS3', 'Lua', 'C']info = {'name': 'Tim', 'sex': 'Male', 'age':23 } # worst caseif name != '' and len(langs) &gt; 0 and info != {}: print('All True!') #All True!# best caseif name and langs and info: print('All True!') #All True! 對於任意目標變數，直接判斷其真假，無需寫判斷條件，這樣既能保證正確性，又能減少程式碼的量。 要訣: 記住False條件 True False 任意非空字串 空的字串 ‘’ 任意非數字0 數字0 任意非空容器 空的容器 [] () {} set() 其他任意非False None 字串反轉123456789101112name = 'Tim'langs = ['AS3', 'Lua', 'C']info = {'name': 'Tim', 'sex': 'Male', 'age':23 } # worst casefor x in range(len(string)-1,-1,-1): newstring += string[x]print(newstring) # nohtyp# best casestring = &quot;python&quot;print(string[::-1]) # nohtyp 字串、列表(list)合併12345678910111213strList = [&quot;Python&quot;, &quot;is&quot;, &quot;good&quot;] # worst caseres = ''for s in strList: res += s + ' 'print(res) #Python is good # best caseres = ' '.join(strList) print(res) #Python is good List Comprehension網路上有很多優雅的寫法，可點擊此網站參考。 表達式在list內做for loop時前面先宣告一個表達式(expression) 123456789101112# Add three to all list members.a = [3, 4, 5]b = a # worst casefor i in range(len(a)): a[i] += 3 # b[i] also changes# best casea = [i + 3 for i in a]b = a[:] # copy a listprint(a, b) # [6, 7, 8] [6, 7, 8] 比較兩個List12345678910# worst casecashier_5 = []for item in cart_1: if item in cart_2: cashier_5.append(item)print(cashier_5) # [8, 58, 88]# best casecashier_5 = [item for item in cart_1 if item in cart_2]print(cashier_5) # [8, 58, 88] 表達式&amp;單一條件判斷在list內做for loop時，除了可以前面先宣告一個表達式(expression)之外，還可以在後方添加條件判斷 123456789101112strList = [&quot;Python&quot;, &quot;is&quot;, &quot;good&quot;]# worst casel = []for x in range(10): if x % 3 == 0: l.append(x*x) print(l) # [0, 9, 36, 81]# best casel = [x*x for x in range(10) if x % 3 == 0]print(l) # [0, 9, 36, 81] 表達式&amp;單一條件判斷&amp;嵌入多個條件判斷12num_list = [y for y in range(100) if y % 2 == 0 if y % 5 == 0]print(num_list) 迴圈嵌套1234567891011121314151617181920# worst transposed = []matrix = [[1, 2, 3, 4], [4, 5, 6, 8]]for i in range(len(matrix[0])): transposed_row = [] for row in matrix: transposed_row.append(row[i]) transposed.append(transposed_row)print(transposed)# [[1, 4], [2, 5], [3, 6]]# bestmatrix = [[1, 2], [3,4], [5,6], [7,8]]transpose = [[row[i] for row in matrix] for i in range(2)]print (transpose) # [[1, 3, 5, 7], [2, 4, 6, 8]] if-else 簡寫123456789# worst caseif 'a'=='a': x=Trueelse : x=Falseprint(x) # True# best casex=True if 'a'=='a' else False print(x) # True Dictionary12345678910# worst casedict_squares = {}for i in range(6): dict_squares[i] = i**2print(dict_squares) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25}# best casedict_squares = {i: i**2 for i in range(6)}print(dict_squares) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25} 讀取檔案以讀檔案的模式開啟一個檔案物件，可用Python內建的open(&quot;檔名&quot;, '操作模式的符號')函式。 1234567891011# Bad practicetry: f = open(&quot;test.txt&quot;,encoding = 'utf-8') a = f.read() print(a)finally: f.close()# Best practicewith open(&quot;test.txt&quot;,encoding = 'utf-8') as f: print(f.read()) 參考文章The Hitchhiker’s Guide to Python","link":"2020/01/01/Python/Python/%5BPython%5D%20%E8%AE%93Python%E7%A8%8B%E5%BC%8F%E7%A2%BC%E6%9B%B4pythonic/"},{"title":"[Python] 物件導向入門","text":"什麼是物件導向？將現實生活中的人、事、時、地、物進行資料抽象化。類別，是具有相同屬性(Attribute)和功能(Method)的物件抽象集合，類別中包含資料的屬性、方法(也可以稱作行為)，將這些類別對應到真實生活中的人、事、時、地、物時稱作”實例化”，可以說這些對應的實際實體為實際案例(簡稱”實例”)，也作”物件”。 白話一點就是: “類別” 只是將真實世界的人、事、時、地、物做分類的”概念”，需對應真實世界中的實例才具意義或是資料處理的價值，類別底下會有多個物件(多個實例)。 不同物件會有不同屬性值，如: 以學生為類別(Class)名，學生A這個物件有兩個屬性，屬性名為姓名、學號，而屬性值為A、01;另一個學生B的物件則屬性值分別為B、02。由於雖然源自同一類別(學生)，但物件各自獨立，屬性值也跟著獨立，彼此互不影響。 好處是什麼? 容易擴展:如上面的例子，建立一個名為學生的類別，底下可以一直增加不同的學生，他們都有自己的屬性參數。 可重複使用:同一個物件、類別可以重複進行呼叫，減少撰寫重複的程式碼 模組化可將系統細分然後分配給不同團隊來進行工作 強調重點 一個物件（Object）可以包含屬性（Attribute）與方法（Method），而class的概念是屬性集合，並非所有物。 物件導向具有三大特性: 多型: 表示不同物件可以執行相同動作，但要透過它們自己的實作來執行。 如果子類別要完全實作父類別的成員，父類別則將該成員宣告為虛擬(virtual)。子類別可以使用override的方式，將自己的實作取代掉父類別的實作。 封裝: 每個物件都包含本身操作所需要的資訊，這個特性稱之為封裝，因此物件不需依賴其他物件來完成自己的操作。 那封裝的好處有哪些？ 良好的封裝能減少模組間的耦合。 類別內部的實作可以自由修改。 類別有明確的對外接口，讓外部進行呼叫。 繼承(像是親屬的垂直關係): 賦予物件重複使用和擴充的能力，父類別的資源可以透過子類別做擴充和重複使用。 繼承能定義出父類別與子類別，其中子類別繼承父類別所有的特性，且子類別還能定義新的特性。繼承有幾個重點： 子類別可拓展父類別沒有的屬性和方法 子類別能重寫父類別的方法 概略了解物件導向後就可進行實作。 實作 宣告類別: Python使用class語法來定義類別，通常會用首字大寫（Capitalized）的單字為類別命名 def __init__(self): 代表宣告時會自動執行的函式，常用來定義該類別的物件屬性，self為必要之參數。 類別中定義方法採用def進行方法宣告 訪問類別內的物件屬性使用類別名.屬性名的方式 1234567891011121314class Student: # 定義類別屬性名，進行類別宣告 major = &quot;CSE&quot; # 定義 static variabl def __init__(self, rollNumber, name): self.rolNo = rollNumber self.name = namestudent1 = Student(1, &quot;Tom&quot;)student2 = Student(2, &quot;Ken&quot;)# 取得屬性名對應的屬性值 print(student1.name, student2.name) # Tom Ken# 訪問Class內的static variablprint(Student.major, student1.major, student2.major) # CSE CSE CSE 上述範例宣告一個名為Student的類別(class)，並建立其屬性，先傳入不同的參數，在賦值給student1、student2，最後再透過.訪問屬性值。 我們還可以在Class 內定義另一個Class1234567891011121314class Car: def __init__(self, make, year): self.make = make self.year = year class Egine: def __init__(self, number): self.number = number def start(self): return &quot;Egine Start!&quot;car1 = Car(&quot;BMW&quot;, 2017)egine = car1.Egine(&quot;MHP-9778&quot;)print(egine.start(), egine.number, car1.make, car1.year)# Egine Start! MHP-9778 BMW 2017 上面範例建立一個Car類別，底下除了定義物件屬性外，另建立一個新類別Egine，並在Egine下定義其屬性名及方法。car1 = Car(&quot;BMW&quot;, 2017)建立BMW物件，在BMW下car1.Egine(&quot;MHP-9778&quot;)建立編號為MHP-9778的Egine物件，egine.start()用來呼叫Egine定義好的方法。 我們也可以更改物件屬性例子: 1234567891011class NewStudent: def __init__(self, sid = 123, name=&quot;Tom&quot;): self.id = sid self.name = name def display(self): return self.id, self.namenews1 = NewStudent()print(news1.id, news1.name) # 123 Tomnews1.id = 345print(news1.id, news1.name) # 345 Tom 資訊隱藏(information hiding)物件屬性有時如果變數不希望或不該隨意給外部程式更改，只需在屬性前加上連續兩個底線。 資訊隱藏後: 在屬性名前面加上 __1234567891011121314class NewStudent: def __init__(self, sid = 123, name=&quot;Tom&quot;): self.__id = sid self.__name = name def display(self): return self.__id, self.__name# 無法直接訪問屬性值print(news1.id, news1.name)# 'NewStudent' object has no attribute 'id'print(news1.__id, news1.__name) # AttributeError: 'NewStudent' object has no attribute '__id' 但也並非完全無法更改，只是需要其他方式，例如method方法訪問屬性值，或是透過 “_” 的方式進行直接訪問 12345# method 訪問屬性值print(news1.display()) # (123, 'Tom') # 透過 &quot;_&quot; 的方式進行直接訪問print(news1._NewStudent__id, news1._NewStudent__name) # 123 Tom 回顧重點: Python使用class語法來定義類別，通常會用首字大寫（Capitalized）的單字為類別命名 def __init__(self): 代表宣告時會自動執行的函式，常用來定義該類別的物件屬性，self為必要之參數。 類別中定義方法採用def進行方法宣告 訪問類別內的物件屬性使用類別名.屬性名的方式 物件屬性有時如果變數不希望或不該隨意給外部程式更改，只需在屬性前加上連續兩個底線__。 參考文章 物件導向與封裝 Name mangling Class 官方文件說明 淺談 Python 的特殊方法 (Special Method Names) (1) 物件導向程式設計 (OOP) 基礎觀念 Python的類別(Class)…基本篇 繼承","link":"2020/01/03/Python/Python/%5BPython%5D%20%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E5%85%A5%E9%96%80/"}],"tags":[{"name":"Database","slug":"Database","link":"tags/Database/"},{"name":"Postgres","slug":"Postgres","link":"tags/Postgres/"},{"name":"JSDC","slug":"JSDC","link":"tags/JSDC/"},{"name":"Conference","slug":"Conference","link":"tags/Conference/"},{"name":"Canvas","slug":"Canvas","link":"tags/Canvas/"},{"name":"Css","slug":"Css","link":"tags/Css/"},{"name":"JavaScript","slug":"JavaScript","link":"tags/JavaScript/"},{"name":"Github","slug":"Github","link":"tags/Github/"},{"name":"Webhook","slug":"Webhook","link":"tags/Webhook/"},{"name":"WebSocket","slug":"WebSocket","link":"tags/WebSocket/"},{"name":"Network","slug":"Network","link":"tags/Network/"},{"name":"SSL","slug":"SSL","link":"tags/SSL/"},{"name":"Certbot","slug":"Certbot","link":"tags/Certbot/"},{"name":"Ubuntu","slug":"Ubuntu","link":"tags/Ubuntu/"},{"name":"GoogleMap","slug":"GoogleMap","link":"tags/GoogleMap/"},{"name":"Session","slug":"Session","link":"tags/Session/"},{"name":"Cookie","slug":"Cookie","link":"tags/Cookie/"},{"name":"Proxy","slug":"Proxy","link":"tags/Proxy/"},{"name":"OOP","slug":"OOP","link":"tags/OOP/"},{"name":"Go","slug":"Go","link":"tags/Go/"},{"name":"Mac","slug":"Mac","link":"tags/Mac/"},{"name":"Linux","slug":"Linux","link":"tags/Linux/"},{"name":"w3HexSchool","slug":"w3HexSchool","link":"tags/w3HexSchool/"},{"name":"OS","slug":"OS","link":"tags/OS/"},{"name":"VSCode","slug":"VSCode","link":"tags/VSCode/"},{"name":"AWS","slug":"AWS","link":"tags/AWS/"},{"name":"Python","slug":"Python","link":"tags/Python/"},{"name":"MySQL","slug":"MySQL","link":"tags/MySQL/"},{"name":"Vue","slug":"Vue","link":"tags/Vue/"},{"name":"MongoDB","slug":"MongoDB","link":"tags/MongoDB/"},{"name":"NoSQL","slug":"NoSQL","link":"tags/NoSQL/"},{"name":"計概","slug":"計概","link":"tags/%E8%A8%88%E6%A6%82/"},{"name":"Redis","slug":"Redis","link":"tags/Redis/"},{"name":"DevOps","slug":"DevOps","link":"tags/DevOps/"},{"name":"GithubAction","slug":"GithubAction","link":"tags/GithubAction/"},{"name":"CICD","slug":"CICD","link":"tags/CICD/"},{"name":"SQL Server","slug":"SQL-Server","link":"tags/SQL-Server/"},{"name":"Kubernetes","slug":"Kubernetes","link":"tags/Kubernetes/"},{"name":"K8s","slug":"K8s","link":"tags/K8s/"},{"name":"Docker","slug":"Docker","link":"tags/Docker/"},{"name":"Ansible","slug":"Ansible","link":"tags/Ansible/"},{"name":"ELK","slug":"ELK","link":"tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"tags/Elasticsearch/"},{"name":"Kibana","slug":"Kibana","link":"tags/Kibana/"},{"name":"Terraform","slug":"Terraform","link":"tags/Terraform/"},{"name":"Django","slug":"Django","link":"tags/Django/"},{"name":"Pandas","slug":"Pandas","link":"tags/Pandas/"},{"name":"Project","slug":"Project","link":"tags/Project/"},{"name":"WebScraping","slug":"WebScraping","link":"tags/WebScraping/"}],"categories":[{"name":"Backend","slug":"Backend","link":"categories/Backend/"},{"name":"Conference","slug":"Conference","link":"categories/Conference/"},{"name":"Frontend","slug":"Frontend","link":"categories/Frontend/"},{"name":"Tool","slug":"Tool","link":"categories/Tool/"},{"name":"Network","slug":"Network","link":"categories/Network/"},{"name":"OS","slug":"OS","link":"categories/OS/"},{"name":"Cloud","slug":"Cloud","link":"categories/Cloud/"},{"name":"DevOps","slug":"DevOps","link":"categories/DevOps/"}]}